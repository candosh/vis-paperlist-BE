[
    {
        "title": "Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Kanit Wongsuphasawat",
            "Dominik Moritz",
            "Anushka Anand",
            "Jock Mackinlay",
            "Bill Howe",
            "Jeffrey Heer"
        ],
        "DOI": "10.1109/TVCG.2015.2467191",
        "citation": 258,
        "abstract": "General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering."
    },
    {
        "title": "Beyond Memorability: Visualization Recognition and Recall",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Michelle A. Borkin",
            "Zoya Bylinskii",
            "Nam Wook Kim",
            "Constance May Bainbridge",
            "Chelsea S. Yeh",
            "Daniel Borkin",
            "Hanspeter Pfister",
            "Aude Oliva"
        ],
        "DOI": "10.1109/TVCG.2015.2467732",
        "citation": 170,
        "abstract": "In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable “at-a-glance” are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one."
    },
    {
        "title": "Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Arvind Satyanarayan",
            "Ryan Russell",
            "Jane Hoffswell",
            "Jeffrey Heer"
        ],
        "DOI": "10.1109/TVCG.2015.2467091",
        "citation": 164,
        "abstract": "We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system."
    },
    {
        "title": "The Role of Uncertainty, Awareness, and Trust in Visual Analytics",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Dominik Sacha",
            "Hansi Senaratne",
            "Bum Chul Kwon",
            "Geoffrey Ellis",
            "Daniel A. Keim"
        ],
        "DOI": "10.1109/TVCG.2015.2467591",
        "citation": 164,
        "abstract": "Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making."
    },
    {
        "title": "MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Tatiana von Landesberger",
            "Felix Brodkorb",
            "Philipp Roskosch",
            "Natalia Andrienko",
            "Gennady Andrienko",
            "Andreas Kerren"
        ],
        "DOI": "10.1109/TVCG.2015.2468111",
        "citation": 150,
        "abstract": "Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population."
    },
    {
        "title": "Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Eric D. Ragan",
            "Alex Endert",
            "Jibonananda Sanyal",
            "Jian Chen"
        ],
        "DOI": "10.1109/TVCG.2015.2467551",
        "citation": 141,
        "abstract": "While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research."
    },
    {
        "title": "TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Xiaoke Huang",
            "Ye Zhao",
            "Chao Ma",
            "Jing Yang",
            "Xinyue Ye",
            "Chong Zhang"
        ],
        "DOI": "10.1109/TVCG.2015.2467771",
        "citation": 127,
        "abstract": "We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis."
    },
    {
        "title": "Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Benjamin Bach",
            "Conglei Shi",
            "Nicolas Heulot",
            "Tara Madhyastha",
            "Tom Grabowski",
            "Pierre Dragicevic"
        ],
        "DOI": "10.1109/TVCG.2015.2467851",
        "citation": 122,
        "abstract": "We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets."
    },
    {
        "title": "Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Stef van den Elzen",
            "Danny Holten",
            "Jorik Blaas",
            "Jarke J. van Wijk"
        ],
        "DOI": "10.1109/TVCG.2015.2468078",
        "citation": 110,
        "abstract": "We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks."
    },
    {
        "title": "TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Nan Cao",
            "Conglei Shi",
            "Sabrina Lin",
            "Jie Lu",
            "Yu-Ru Lin",
            "Ching-Yung Lin"
        ],
        "DOI": "10.1109/TVCG.2015.2467196",
        "citation": 103,
        "abstract": "Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors."
    },
    {
        "title": "Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Jimmy Johansson",
            "Camilla Forsell"
        ],
        "DOI": "10.1109/TVCG.2015.2466992",
        "citation": 98,
        "abstract": "The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed."
    },
    {
        "title": "Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Siming Chen",
            "Xiaoru Yuan",
            "Zhenhuang Wang",
            "Cong Guo",
            "Jie Liang",
            "Zuchao Wang",
            "Xiaolong Zhang",
            "Jiawan Zhang"
        ],
        "DOI": "10.1109/TVCG.2015.2467619",
        "citation": 94,
        "abstract": "Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns."
    },
    {
        "title": "Visual Analysis and Dissemination of Scientific Literature Collections with SurVis",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Fabian Beck",
            "Sebastian Koch",
            "Daniel Weiskopf"
        ],
        "DOI": "10.1109/TVCG.2015.2467757",
        "citation": 80,
        "abstract": "Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements."
    },
    {
        "title": "Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Florian Ferstl",
            "Kai Bürger",
            "Rüdiger Westermann"
        ],
        "DOI": "10.1109/TVCG.2015.2467204",
        "citation": 78,
        "abstract": "We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots."
    },
    {
        "title": "How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice's Information Visualization Sensemaking",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Sukwon Lee",
            "Sung-Hee Kim",
            "Ya-Hsin Hung",
            "Heidi Lam",
            "Youn-Ah Kang",
            "Ji Soo Yi"
        ],
        "DOI": "10.1109/TVCG.2015.2467195",
        "citation": 76,
        "abstract": "In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations."
    },
    {
        "title": "Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Julian Stahnke",
            "Marian Dörk",
            "Boris Müller",
            "Andreas Thom"
        ],
        "DOI": "10.1109/TVCG.2015.2467717",
        "citation": 72,
        "abstract": "We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets."
    },
    {
        "title": "egoSlider: Visual Analysis of Egocentric Network Evolution",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Yanhong Wu",
            "Naveen Pitipornvivat",
            "Jian Zhao",
            "Sixiao Yang",
            "Guowei Huang",
            "Huamin Qu"
        ],
        "DOI": "10.1109/TVCG.2015.2468151",
        "citation": 69,
        "abstract": "Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks."
    },
    {
        "title": "Supporting Iterative Cohort Construction with Visual Temporal Queries",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Josua Krause",
            "Adam Perer",
            "Harry Stavropoulos"
        ],
        "DOI": "10.1109/TVCG.2015.2467622",
        "citation": 66,
        "abstract": "Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers."
    },
    {
        "title": "InterAxis: Steering Scatterplot Axes via Observation-Level Interaction",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Hannah Kim",
            "Jaegul Choo",
            "Haesun Park",
            "Alex Endert"
        ],
        "DOI": "10.1109/TVCG.2015.2467615",
        "citation": 66,
        "abstract": "Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios."
    },
    {
        "title": "Beyond Weber's Law: A Second Look at Ranking Visualizations of Correlation",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Matthew Kay",
            "Jeffrey Heer"
        ],
        "DOI": "10.1109/TVCG.2015.2467671",
        "citation": 65,
        "abstract": "Models of human perception - including perceptual “laws” - can be valuable tools for deriving visualization design recommendations. However, it is important to assess the explanatory power of such models when using them to inform design. We present a secondary analysis of data previously used to rank the effectiveness of bivariate visualizations for assessing correlation (measured with Pearson's r) according to the well-known Weber-Fechner Law. Beginning with the model of Harrison et al. [1], we present a sequence of refinements including incorporation of individual differences, log transformation, censored regression, and adoption of Bayesian statistics. Our model incorporates all observations dropped from the original analysis, including data near ceilings caused by the data collection process and entire visualizations dropped due to large numbers of observations worse than chance. This model deviates from Weber's Law, but provides improved predictive accuracy and generalization. Using Bayesian credibility intervals, we derive a partial ranking that groups visualizations with similar performance, and we give precise estimates of the difference in performance between these groups. We find that compared to other visualizations, scatterplots are unique in combining low variance between individuals and high precision on both positively- and negatively correlated data. We conclude with a discussion of the value of data sharing and replication, and share implications for modeling similar experimental data."
    },
    {
        "title": "CiteRivers: Visual Analytics of Citation Patterns",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Florian Heimerl",
            "Qi Han",
            "Steffen Koch",
            "Thomas Ertl"
        ],
        "DOI": "10.1109/TVCG.2015.2467621",
        "citation": 65,
        "abstract": "The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback."
    },
    {
        "title": "Improving Bayesian Reasoning: The Effects of Phrasing, Visualization, and Spatial Ability",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Alvitta Ottley",
            "Evan M. Peck",
            "Lane T. Harrison",
            "Daniel Afergan",
            "Caroline Ziemkiewicz",
            "Holly A. Taylor",
            "Paul K. J. Han",
            "Remco Chang"
        ],
        "DOI": "10.1109/TVCG.2015.2467758",
        "citation": 64,
        "abstract": "Decades of research have repeatedly shown that people perform poorly at estimating and understanding conditional probabilities that are inherent in Bayesian reasoning problems. Yet in the medical domain, both physicians and patients make daily, life-critical judgments based on conditional probability. Although there have been a number of attempts to develop more effective ways to facilitate Bayesian reasoning, reports of these findings tend to be inconsistent and sometimes even contradictory. For instance, the reported accuracies for individuals being able to correctly estimate conditional probability range from 6% to 62%. In this work, we show that problem representation can significantly affect accuracies. By controlling the amount of information presented to the user, we demonstrate how text and visualization designs can increase overall accuracies to as high as 77%. Additionally, we found that for users with high spatial ability, our designs can further improve their accuracies to as high as 100%. By and large, our findings provide explanations for the inconsistent reports on accuracy in Bayesian reasoning tasks and show a significant improvement over existing methods. We believe that these findings can have immediate impact on risk communication in health-related fields."
    },
    {
        "title": "VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Tanja Blascheck",
            "Markus John",
            "Kuno Kurzhals",
            "Steffen Koch",
            "Thomas Ertl"
        ],
        "DOI": "10.1109/TVCG.2015.2467871",
        "citation": 63,
        "abstract": "Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications."
    },
    {
        "title": "TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Wenchao Wu",
            "Jiayi Xu",
            "Haipeng Zeng",
            "Yixian Zheng",
            "Huamin Qu",
            "Bing Ni",
            "Mingxuan Yuan",
            "Lionel M. Ni"
        ],
        "DOI": "10.1109/TVCG.2015.2467194",
        "citation": 61,
        "abstract": "Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks."
    },
    {
        "title": "Visualization, Selection, and Analysis of Traffic Flows",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Roeland Scheepens",
            "Christophe Hurter",
            "Huub Van De Wetering",
            "Jarke J. Van Wijk"
        ],
        "DOI": "10.1109/TVCG.2015.2467112",
        "citation": 59,
        "abstract": "Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts."
    },
    {
        "title": "A Linguistic Approach to Categorical Color Assignment for Data Visualization",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Vidya Setlur",
            "Maureen C. Stone"
        ],
        "DOI": "10.1109/TVCG.2015.2467471",
        "citation": 58,
        "abstract": "When data categories have strong color associations, it is useful to use these semantically meaningful concept-color associations in data visualizations. In this paper, we explore how linguistic information about the terms defining the data can be used to generate semantically meaningful colors. To do this effectively, we need first to establish that a term has a strong semantic color association, then discover which color or colors express it. Using co-occurrence measures of color name frequencies from Google n-grams, we define a measure for colorability that describes how strongly associated a given term is to any of a set of basic color terms. We then show how this colorability score can be used with additional semantic analysis to rank and retrieve a representative color from Google Images. Alternatively, we use symbolic relationships defined by WordNet to select identity colors for categories such as countries or brands. To create visually distinct color palettes, we use k-means clustering to create visually distinct sets, iteratively reassigning terms with multiple basic color associations as needed. This can be additionally constrained to use colors only in a predefined palette."
    },
    {
        "title": "Sketching Designs Using the Five Design-Sheet Methodology",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Jonathan C. Roberts",
            "Chris Headleand",
            "Panagiotis D. Ritsos"
        ],
        "DOI": "10.1109/TVCG.2015.2467271",
        "citation": 56,
        "abstract": "Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lo-fidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching."
    },
    {
        "title": "A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Hua Guo",
            "Steven R. Gomez",
            "Caroline Ziemkiewicz",
            "David H. Laidlaw"
        ],
        "DOI": "10.1109/TVCG.2015.2467613",
        "citation": 53,
        "abstract": "We present results from an experiment aimed at using logs of interactions with a visual analytics application to better understand how interactions lead to insight generation. We performed an insight-based user study of a visual analytics application and ran post hoc quantitative analyses of participants' measured insight metrics and interaction logs. The quantitative analyses identified features of interaction that were correlated with insight characteristics, and we confirmed these findings using a qualitative analysis of video captured during the user study. Results of the experiment include design guidelines for the visual analytics application aimed at supporting insight generation. Furthermore, we demonstrated an analysis method using interaction logs that identified which interaction patterns led to insights, going beyond insight-based evaluations that only quantify insight characteristics. We also discuss choices and pitfalls encountered when applying this analysis method, such as the benefits and costs of applying an abstraction framework to application-specific actions before further analysis. Our method can be applied to evaluations of other visualization tools to inform the design of insight-promoting interactions and to better understand analyst behaviors."
    },
    {
        "title": "A comparative study between RadViz and Star Coordinates",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Manuel Rubio-Sánchez",
            "Laura Raya",
            "Francisco Díaz",
            "Alberto Sanchez"
        ],
        "DOI": "10.1109/TVCG.2015.2467324",
        "citation": 51,
        "abstract": "RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks."
    },
    {
        "title": "HOLA: Human-like Orthogonal Network Layout",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Steve Kieffer",
            "Tim Dwyer",
            "Kim Marriott",
            "Michael Wybrow"
        ],
        "DOI": "10.1109/TVCG.2015.2467451",
        "citation": 51,
        "abstract": "Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new “human-centred” methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand."
    },
    {
        "title": "Temporal MDS Plots for Analysis of Multivariate Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Dominik Jäckle",
            "Fabian Fischer",
            "Tobias Schreck",
            "Daniel A. Keim"
        ],
        "DOI": "10.1109/TVCG.2015.2467553",
        "citation": 51,
        "abstract": "Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns."
    },
    {
        "title": "Visual Encodings of Temporal Uncertainty: A Comparative User Study",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Theresia Gschwandtnei",
            "Markus Bögl",
            "Paolo Federico",
            "Silvia Miksch"
        ],
        "DOI": "10.1109/TVCG.2015.2467752",
        "citation": 50,
        "abstract": "A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation – using a lighter color value to represent uncertain regions – or error bars for judging durations and temporal bounds, and gradient plots – using fading color or transparency – for judging probability values."
    },
    {
        "title": "TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Mona Hosseinkhani Loorak",
            "Charles Perin",
            "Noreen Kamal",
            "Michael Hill",
            "Sheelagh Carpendale"
        ],
        "DOI": "10.1109/TVCG.2015.2467325",
        "citation": 50,
        "abstract": "We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan."
    },
    {
        "title": "An Uncertainty-Aware Approach for Exploratory Microblog Retrieval",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Mengchen Liu",
            "Shixia Liu",
            "Xizhou Zhu",
            "Qinying Liao",
            "Furu Wei",
            "Shimei Pan"
        ],
        "DOI": "10.1109/TVCG.2015.2467554",
        "citation": 49,
        "abstract": "Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data."
    },
    {
        "title": "Gaze Stripes: Image-Based Visualization of Eye Tracking Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Kuno Kurzhals",
            "Marcel Hlawatsch",
            "Florian Heimerl",
            "Michael Burch",
            "Thomas Ertl",
            "Daniel Weiskopf"
        ],
        "DOI": "10.1109/TVCG.2015.2468091",
        "citation": 48,
        "abstract": "We present a new visualization approach for displaying eye tracking data from multiple participants. We aim to show the spatio-temporal data of the gaze points in the context of the underlying image or video stimulus without occlusion. Our technique, denoted as gaze stripes, does not require the explicit definition of areas of interest but directly uses the image data around the gaze points, similar to thumbnails for images. A gaze stripe consists of a sequence of such gaze point images, oriented along a horizontal timeline. By displaying multiple aligned gaze stripes, it is possible to analyze and compare the viewing behavior of the participants over time. Since the analysis is carried out directly on the image data, expensive post-processing or manual annotation are not required. Therefore, not only patterns and outliers in the participants' scanpaths can be detected, but the context of the stimulus is available as well. Furthermore, our approach is especially well suited for dynamic stimuli due to the non-aggregated temporal mapping. Complementary views, i.e., markers, notes, screenshots, histograms, and results from automatic clustering, can be added to the visualization to display analysis results. We illustrate the usefulness of our technique on static and dynamic stimuli. Furthermore, we discuss the limitations and scalability of our approach in comparison to established visualization techniques."
    },
    {
        "title": "Task-Driven Comparison of Topic Models",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Eric Alexander",
            "Michael Gleicher"
        ],
        "DOI": "10.1109/TVCG.2015.2467618",
        "citation": 47,
        "abstract": "Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity."
    },
    {
        "title": "The Visual Causality Analyst: An Interactive Interface for Causal Reasoning",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Jun Wang",
            "Klaus Mueller"
        ],
        "DOI": "10.1109/TVCG.2015.2467931",
        "citation": 46,
        "abstract": "Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets."
    },
    {
        "title": "In Situ Eddy Analysis in a High-Resolution Ocean Climate Model",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Jonathan Woodring",
            "Mark Petersen",
            "Andre Schmeißer",
            "John Patchett",
            "James Ahrens",
            "Hans Hagen"
        ],
        "DOI": "10.1109/TVCG.2015.2467411",
        "citation": 46,
        "abstract": "An eddy is a feature associated with a rotating body of fluid, surrounded by a ring of shearing fluid. In the ocean, eddies are 10 to 150 km in diameter, are spawned by boundary currents and baroclinic instabilities, may live for hundreds of days, and travel for hundreds of kilometers. Eddies are important in climate studies because they transport heat, salt, and nutrients through the world's oceans and are vessels of biological productivity. The study of eddies in global ocean-climate models requires large-scale, high-resolution simulations. This poses a problem for feasible (timely) eddy analysis, as ocean simulations generate massive amounts of data, causing a bottleneck for traditional analysis workflows. To enable eddy studies, we have developed an in situ workflow for the quantitative and qualitative analysis of MPAS-Ocean, a high-resolution ocean climate model, in collaboration with the ocean model research and development process. Planned eddy analysis at high spatial and temporal resolutions will not be possible with a postprocessing workflow due to various constraints, such as storage size and I/O time, but the in situ workflow enables it and scales well to ten-thousand processing elements."
    },
    {
        "title": "TimeLineCurator: Interactive Authoring of Visual Timelines from Unstructured Text",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Johanna Fulda",
            "Matthew Brehmer",
            "Tamara Munzner"
        ],
        "DOI": "10.1109/TVCG.2015.2467531",
        "citation": 45,
        "abstract": "We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment."
    },
    {
        "title": "TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "James Walker",
            "Rita Borgo",
            "Mark W. Jones"
        ],
        "DOI": "10.1109/TVCG.2015.2467751",
        "citation": 44,
        "abstract": "Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques."
    },
    {
        "title": "Visual Mementos: Reflecting Memories with Personal Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Alice Thudt",
            "Dominikus Baur",
            "Samuel Huron",
            "Sheelagh Carpendale"
        ],
        "DOI": "10.1109/TVCG.2015.2467831",
        "citation": 44,
        "abstract": "In this paper we discuss the creation of visual mementos as a new application area for visualization. We define visual mementos as visualizations of personally relevant data for the purpose of reminiscing, and sharing of life experiences. Today more people collect digital information about their life than ever before. The shift from physical to digital archives poses new challenges and opportunities for self-reflection and self-representation. Drawing on research on autobiographical memory and on the role of artifacts in reminiscing, we identified design challenges for visual mementos: mapping data to evoke familiarity, expressing subjectivity, and obscuring sensitive details for sharing. Visual mementos can make use of the known strengths of visualization in revealing patterns to show the familiar instead of the unexpected, and extend representational mappings beyond the objective to include the more subjective. To understand whether people's subjective views on their past can be reflected in a visual representation, we developed, deployed and studied a technology probe that exemplifies our concept of visual mementos. Our results show how reminiscing has been supported and reveal promising new directions for self-reflection and sharing through visual mementos of personal experiences."
    },
    {
        "title": "AmbiguityVis: Visualization of Ambiguity in Graph Layouts",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Yong Wang",
            "Qiaomu Shen",
            "Daniel Archambault",
            "Zhiguang Zhou",
            "Min Zhu",
            "Sixiao Yang",
            "Huamin Qu"
        ],
        "DOI": "10.1109/TVCG.2015.2467691",
        "citation": 42,
        "abstract": "Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews."
    },
    {
        "title": "Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Yael Albo",
            "Joel Lanir",
            "Peter Bak",
            "Sheizaf Rafaeli"
        ],
        "DOI": "10.1109/TVCG.2015.2467322",
        "citation": 42,
        "abstract": "A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization."
    },
    {
        "title": "The Data Context Map: Fusing Data and Attributes into a Unified Display",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Shenghui Cheng",
            "Klaus Mueller"
        ],
        "DOI": "10.1109/TVCG.2015.2467552",
        "citation": 41,
        "abstract": "Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs."
    },
    {
        "title": "Isosurface Visualization of Data with Nonparametric Models for Uncertainty",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Tushar Athawale",
            "Elham Sakhaee",
            "Alireza Entezari"
        ],
        "DOI": "10.1109/TVCG.2015.2467958",
        "citation": 39,
        "abstract": "The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields."
    },
    {
        "title": "CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Lingyun Yu",
            "Konstantinos Efstathiou",
            "Petra Isenberg",
            "Tobias Isenberg"
        ],
        "DOI": "10.1109/TVCG.2015.2467202",
        "citation": 39,
        "abstract": "We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency."
    },
    {
        "title": "Visually Comparing Weather Features in Forecasts",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "P. Samuel Quinan",
            "Miriah Meyer"
        ],
        "DOI": "10.1109/TVCG.2015.2467754",
        "citation": 38,
        "abstract": "Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data."
    },
    {
        "title": "Suggested Interactivity: Seeking Perceived Affordances for Information Visualization",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Jeremy Boy",
            "Louis Eveillard",
            "Françoise Detienne",
            "Jean-Daniel Fekete"
        ],
        "DOI": "10.1109/TVCG.2015.2467201",
        "citation": 38,
        "abstract": "In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward."
    },
    {
        "title": "Optimal Sets of Projections of High-Dimensional Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Dirk J. Lehmann",
            "Holger Theisel"
        ],
        "DOI": "10.1109/TVCG.2015.2467132",
        "citation": 38,
        "abstract": "Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets."
    },
    {
        "title": "BiSet: Semantic Edge Bundling with Biclusters for Sensemaking",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Maoyuan Sun",
            "Peng Mi",
            "Chris North",
            "Naren Ramakrishnan"
        ],
        "DOI": "10.1109/TVCG.2015.2467813",
        "citation": 38,
        "abstract": "Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, “in-between”, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics."
    },
    {
        "title": "Visualizing Multiple Variables Across Scale and Geography",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Sarah Goodwin",
            "Jason Dykes",
            "Aidan Slingsby",
            "Cagatay Turkay"
        ],
        "DOI": "10.1109/TVCG.2015.2467199",
        "citation": 37,
        "abstract": "Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable."
    },
    {
        "title": "VAiRoma: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Isaac Cho",
            "Wewnen Dou",
            "Derek Xiaoyu Wang",
            "Eric Sauda",
            "William Ribarsky"
        ],
        "DOI": "10.1109/TVCG.2015.2467971",
        "citation": 37,
        "abstract": "Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents."
    },
    {
        "title": "Poemage: Visualizing the Sonic Topology of a Poem",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Nina McCurdy",
            "Julie Lein",
            "Katharine Coles",
            "Miriah Meyer"
        ],
        "DOI": "10.1109/TVCG.2015.2467811",
        "citation": 35,
        "abstract": "The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies."
    },
    {
        "title": "Guidelines for Effective Usage of Text Highlighting Techniques",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Hendrik Strobelt",
            "Daniela Oelke",
            "Bum Chul Kwon",
            "Tobias Schreck",
            "Hanspeter Pfister"
        ],
        "DOI": "10.1109/TVCG.2015.2467759",
        "citation": 35,
        "abstract": "Semi-automatic text analysis involves manual inspection of text. Often, different text annotations (like part-of-speech or named entities) are indicated by using distinctive text highlighting techniques. In typesetting there exist well-known formatting conventions, such as bold typeface, italics, or background coloring, that are useful for highlighting certain parts of a given text. Also, many advanced techniques for visualization and highlighting of text exist; yet, standard typesetting is common, and the effects of standard typesetting on the perception of text are not fully understood. As such, we surveyed and tested the effectiveness of common text highlighting techniques, both individually and in combination, to discover how to maximize pop-out effects while minimizing visual interference between techniques. To validate our findings, we conducted a series of crowd-sourced experiments to determine: i) a ranking of nine commonly-used text highlighting techniques; ii) the degree of visual interference between pairs of text highlighting techniques; iii) the effectiveness of techniques for visual conjunctive search. Our results show that increasing font size works best as a single highlighting technique, and that there are significant visual interferences between some pairs of highlighting techniques. We discuss the pros and cons of different combinations as a design guideline to choose text highlighting techniques for text viewers."
    },
    {
        "title": "Glyph-Based Comparative Visualization for Diffusion Tensor Fields",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Changgong Zhang",
            "Thomas Schultz",
            "Kai Lawonn",
            "Elmar Eisemann",
            "Anna Vilanova"
        ],
        "DOI": "10.1109/TVCG.2015.2467435",
        "citation": 34,
        "abstract": "Diffusion Tensor Imaging (DTI) is a magnetic resonance imaging modality that enables the in-vivo reconstruction and visualization of fibrous structures. To inspect the local and individual diffusion tensors, glyph-based visualizations are commonly used since they are able to effectively convey full aspects of the diffusion tensor. For several applications it is necessary to compare tensor fields, e.g., to study the effects of acquisition parameters, or to investigate the influence of pathologies on white matter structures. This comparison is commonly done by extracting scalar information out of the tensor fields and then comparing these scalar fields, which leads to a loss of information. If the glyph representation is kept, simple juxtaposition or superposition can be used. However, neither facilitates the identification and interpretation of the differences between the tensor fields. Inspired by the checkerboard style visualization and the superquadric tensor glyph, we design a new glyph to locally visualize differences between two diffusion tensors by combining juxtaposition and explicit encoding. Because tensor scale, anisotropy type, and orientation are related to anatomical information relevant for DTI applications, we focus on visualizing tensor differences in these three aspects. As demonstrated in a user study, our new glyph design allows users to efficiently and effectively identify the tensor differences. We also apply our new glyphs to investigate the differences between DTI datasets of the human brain in two different contexts using different b-values, and to compare datasets from a healthy and HIV-infected subject."
    },
    {
        "title": "Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Soumya Dutta",
            "Han-Wei Shen"
        ],
        "DOI": "10.1109/TVCG.2015.2467436",
        "citation": 33,
        "abstract": "Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features."
    },
    {
        "title": "3D Regression Heat Map Analysis of Population Study Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Paul Klemm",
            "Kai Lawonn",
            "Sylvia Glaßer",
            "Uli Niemann",
            "Katrin Hegenscheid",
            "Henry Völzke",
            "Bernhard Preim"
        ],
        "DOI": "10.1109/TVCG.2015.2468291",
        "citation": 33,
        "abstract": "Epidemiological studies comprise heterogeneous data about a subject group to define disease-specific risk factors. These data contain information (features) about a subject's lifestyle, medical status as well as medical image data. Statistical regression analysis is used to evaluate these features and to identify feature combinations indicating a disease (the target feature). We propose an analysis approach of epidemiological data sets by incorporating all features in an exhaustive regression-based analysis. This approach combines all independent features w.r.t. a target feature. It provides a visualization that reveals insights into the data by highlighting relationships. The 3D Regression Heat Map, a novel 3D visual encoding, acts as an overview of the whole data set. It shows all combinations of two to three independent features with a specific target disease. Slicing through the 3D Regression Heat Map allows for the detailed analysis of the underlying relationships. Expert knowledge about disease-specific hypotheses can be included into the analysis by adjusting the regression model formulas. Furthermore, the influences of features can be assessed using a difference view comparing different calculation results. We applied our 3D Regression Heat Map method to a hepatic steatosis data set to reproduce results from a data mining-driven analysis. A qualitative analysis was conducted on a breast density data set. We were able to derive new hypotheses about relations between breast density and breast lesions with breast cancer. With the 3D Regression Heat Map, we present a visual overview of epidemiological data that allows for the first time an interactive regression-based analysis of large feature sets with respect to a disease."
    },
    {
        "title": "Association Analysis for Visual Exploration of Multivariate Scientific Data Sets",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Xiaotong Liu",
            "Han-Wei Shen"
        ],
        "DOI": "10.1109/TVCG.2015.2467431",
        "citation": 32,
        "abstract": "The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data's multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets."
    },
    {
        "title": "NeuroBlocks – Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Ali K. Ai-Awami",
            "Johanna Beyer",
            "Daniel Haehn",
            "Narayanan Kasthuri",
            "Jeff W. Lichtman",
            "Hanspeter Pfister",
            "Markus Hadwiger"
        ],
        "DOI": "10.1109/TVCG.2015.2467441",
        "citation": 32,
        "abstract": "In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project."
    },
    {
        "title": "Cluster Analysis of Vortical Flow in Simulations of Cerebral Aneurysm Hemodynamics",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Steffen Oeltze-Jafra",
            "Juan R. Cebral",
            "Gábor Janiga",
            "Bernhard Preim"
        ],
        "DOI": "10.1109/TVCG.2015.2467203",
        "citation": 32,
        "abstract": "Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices."
    },
    {
        "title": "Rotation Invariant Vortices for Flow Visualization",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Tobias Günther",
            "Maik Schulze",
            "Holger Theisel"
        ],
        "DOI": "10.1109/TVCG.2015.2467200",
        "citation": 31,
        "abstract": "We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts."
    },
    {
        "title": "Visually Exploring Transportation Schedules",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Cesar Palomo",
            "Zhan Guo",
            "Cláudio T. Silva",
            "Juliana Freire"
        ],
        "DOI": "10.1109/TVCG.2015.2467592",
        "citation": 31,
        "abstract": "Public transportation schedules are designed by agencies to optimize service quality under multiple constraints. However, real service usually deviates from the plan. Therefore, transportation analysts need to identify, compare and explain both eventual and systemic performance issues that must be addressed so that better timetables can be created. The purely statistical tools commonly used by analysts pose many difficulties due to the large number of attributes at tripand station-level for planned and real service. Also challenging is the need for models at multiple scales to search for patterns at different times and stations, since analysts do not know exactly where or when relevant patterns might emerge and need to compute statistical summaries for multiple attributes at different granularities. To aid in this analysis, we worked in close collaboration with a transportation expert to design TR-EX, a visual exploration tool developed to identify, inspect and compare spatio-temporal patterns for planned and real transportation service. TR-EX combines two new visual encodings inspired by Marey's Train Schedule: Trips Explorer for trip-level analysis of frequency, deviation and speed; and Stops Explorer for station-level study of delay, wait time, reliability and performance deficiencies such as bunching. To tackle overplotting and to provide a robust representation for a large numbers of trips and stops at multiple scales, the system supports variable kernel bandwidths to achieve the level of detail required by users for different tasks. We justify our design decisions based on specific analysis needs of transportation analysts. We provide anecdotal evidence of the efficacy of TR-EX through a series of case studies that explore NYC subway service, which illustrate how TR-EX can be used to confirm hypotheses and derive new insights through visual exploration."
    },
    {
        "title": "Effective Visualization of Temporal Ensembles",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Lihua Hao",
            "Christopher G. Healey",
            "Steffen A. Bass"
        ],
        "DOI": "10.1109/TVCG.2015.2468093",
        "citation": 30,
        "abstract": "An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions."
    },
    {
        "title": "Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Attila Gyulassy",
            "Aaron Knoll",
            "Kah Chun Lau",
            "Bei Wang",
            "Peer-Timo Bremer",
            "Michael E. Papka",
            "Larry A. Curtiss",
            "Valerio Pascucci"
        ],
        "DOI": "10.1109/TVCG.2015.2467432",
        "citation": 30,
        "abstract": "Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials."
    },
    {
        "title": "SensePath: Understanding the Sensemaking Process Through Analytic Provenance",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Phong H. Nguyen",
            "Kai Xu",
            "Ashley Wheat",
            "B.L. William Wong",
            "Simon Attfield",
            "Bob Fields"
        ],
        "DOI": "10.1109/TVCG.2015.2467611",
        "citation": 28,
        "abstract": "Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process."
    },
    {
        "title": "Speculative Practices: Utilizing InfoVis to Explore Untapped Literary Collections",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Uta Hinrichs",
            "Stefania Forlini",
            "Bridget Moynihan"
        ],
        "DOI": "10.1109/TVCG.2015.2467452",
        "citation": 28,
        "abstract": "In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While InfoVis has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an InfoVis perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to InfoVis, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes."
    },
    {
        "title": "Exploring Evolving Media Discourse Through Event Cueing",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Yafeng Lu",
            "Michael Steptoe",
            "Sarah Burke",
            "Hong Wang",
            "Jiun-Yi Tsai",
            "Hasan Davulcu",
            "Douglas Montgomery",
            "Steven R. Corman",
            "Ross Maciejewski"
        ],
        "DOI": "10.1109/TVCG.2015.2467991",
        "citation": 28,
        "abstract": "Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa."
    },
    {
        "title": "Occlusion-free Blood Flow Animation with Wall Thickness Visualization",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Kai Lawonn",
            "Sylvia Glaßer",
            "Anna Vilanova",
            "Bernhard Preim",
            "Tobias Isenberg"
        ],
        "DOI": "10.1109/TVCG.2015.2467961",
        "citation": 27,
        "abstract": "We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool."
    },
    {
        "title": "Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Gordon Kindlmann",
            "Charisee Chiw",
            "Nicholas Seltzer",
            "Lamont Samuels",
            "John Reppy"
        ],
        "DOI": "10.1109/TVCG.2015.2467449",
        "citation": 27,
        "abstract": "Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets."
    },
    {
        "title": "High-Quality Ultra-Compact Grid Layout of Grouped Networks",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Vahan Yoghourdjian",
            "Tim Dwyer",
            "Graeme Gange",
            "Steve Kieffer",
            "Karsten Klein",
            "Kim Marriott"
        ],
        "DOI": "10.1109/TVCG.2015.2467251",
        "citation": 26,
        "abstract": "Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks."
    },
    {
        "title": "A Psychophysical Investigation of Size as a Physical Variable",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Yvonne Jansen",
            "Kasper Hornbæk"
        ],
        "DOI": "10.1109/TVCG.2015.2467951",
        "citation": 26,
        "abstract": "Physical visualizations, or data physicalizations, encode data in attributes of physical shapes. Despite a considerable body of work on visual variables, “physical variables” remain poorly understood. One of them is physical size. A difficulty for solid elements is that “size” is ambiguous - it can refer to either length/diameter, surface, or volume. Thus, it is unclear for designers of physicalizations how to effectively encode quantities in physical size. To investigate, we ran an experiment where participants estimated ratios between quantities represented by solid bars and spheres. Our results suggest that solid bars are compared based on their length, consistent with previous findings for 2D and 3D bars on flat media. But for spheres, participants' estimates are rather proportional to their surface. Depending on the estimation method used, judgments are rather consistent across participants, thus the use of perceptually-optimized size scales seems possible. We conclude by discussing implications for the design of data physicalizations and the need for more empirical studies on physical variables."
    },
    {
        "title": "Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Matthew Brehmer",
            "Jocelyn Ng",
            "Kevin Tate",
            "Tamara Munzner"
        ],
        "DOI": "10.1109/TVCG.2015.2466971",
        "citation": 26,
        "abstract": "The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base."
    },
    {
        "title": "VisOHC: Designing Visual Analytics for Online Health Communities",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Bum Chul Kwon",
            "Sung-Hee Kim",
            "Sukwon Lee",
            "Jaegul Choo",
            "Jina Huh",
            "Ji Soo Yi"
        ],
        "DOI": "10.1109/TVCG.2015.2467555",
        "citation": 26,
        "abstract": "Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables."
    },
    {
        "title": "Interactive Visual Profiling of Musicians",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Stefan Jänicke",
            "Josef Focht",
            "Gerik Scheuermann"
        ],
        "DOI": "10.1109/TVCG.2015.2467620",
        "citation": 24,
        "abstract": "Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians' attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology."
    },
    {
        "title": "MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Sujin Jang",
            "Niklas Elmqvist",
            "Karthik Ramani"
        ],
        "DOI": "10.1109/TVCG.2015.2468292",
        "citation": 24,
        "abstract": "Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge."
    },
    {
        "title": "Orientation-Enhanced Parallel Coordinate Plots",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Renata Georgia Raidou",
            "Martin Eisemann",
            "Marcel Breeuwer",
            "Elmar Eisemann",
            "Anna Vilanova"
        ],
        "DOI": "10.1109/TVCG.2015.2467872",
        "citation": 24,
        "abstract": "Parallel Coordinate Plots (PCPs) is one of the most powerful techniques for the visualization of multivariate data. However, for large datasets, the representation suffers from clutter due to overplotting. In this case, discerning the underlying data information and selecting specific interesting patterns can become difficult. We propose a new and simple technique to improve the display of PCPs by emphasizing the underlying data structure. Our Orientation-enhanced Parallel Coordinate Plots (OPCPs) improve pattern and outlier discernibility by visually enhancing parts of each PCP polyline with respect to its slope. This enhancement also allows us to introduce a novel and efficient selection method, the Orientation-enhanced Brushing (O-Brushing). Our solution is particularly useful when multiple patterns are present or when the view on certain patterns is obstructed by noise. We present the results of our approach with several synthetic and real-world datasets. Finally, we conducted a user evaluation, which verifies the advantages of the OPCPs in terms of discernibility of information in complex data. It also confirms that O-Brushing eases the selection of data patterns in PCPs and reduces the amount of necessary user interactions compared to state-of-the-art brushing techniques."
    },
    {
        "title": "Visualization-by-Sketching: An Artist's Interface for Creating Multivariate Time-Varying Data Visualizations",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "David Schroeder",
            "Daniel F. Keefe"
        ],
        "DOI": "10.1109/TVCG.2015.2467153",
        "citation": 21,
        "abstract": "We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data “under” the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay “in the creative zone” as they work."
    },
    {
        "title": "AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Jan Byška",
            "Mathieu Le Muzic",
            "M. Eduard Gröller",
            "Ivan Viola",
            "Barbora Kozlíková"
        ],
        "DOI": "10.1109/TVCG.2015.2467434",
        "citation": 20,
        "abstract": "In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included."
    },
    {
        "title": "PhenoBlocks: Phenotype Comparison Visualizations",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Michael Glueck",
            "Peter Hamilton",
            "Fanny Chevalier",
            "Simon Breslav",
            "Azam Khan",
            "Daniel Wigdor",
            "Michael Brudno"
        ],
        "DOI": "10.1109/TVCG.2015.2467733",
        "citation": 19,
        "abstract": "The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting."
    },
    {
        "title": "Accurate Interactive Visualization of Large Deformations and Variability in Biomedical Image Ensembles",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Max Hermann",
            "Anja C. Schunke",
            "Thomas Schultz",
            "Reinhard Klein"
        ],
        "DOI": "10.1109/TVCG.2015.2467198",
        "citation": 18,
        "abstract": "Large image deformations pose a challenging problem for the visualization and statistical analysis of 3D image ensembles which have a multitude of applications in biology and medicine. Simple linear interpolation in the tangent space of the ensemble introduces artifactual anatomical structures that hamper the application of targeted visual shape analysis techniques. In this work we make use of the theory of stationary velocity fields to facilitate interactive non-linear image interpolation and plausible extrapolation for high quality rendering of large deformations and devise an efficient image warping method on the GPU. This does not only improve quality of existing visualization techniques, but opens up a field of novel interactive methods for shape ensemble analysis. Taking advantage of the efficient non-linear 3D image warping, we showcase four visualizations: 1) browsing on-the-fly computed group mean shapes to learn about shape differences between specific classes, 2) interactive reformation to investigate complex morphologies in a single view, 3) likelihood volumes to gain a concise overview of variability and 4) streamline visualization to show variation in detail, specifically uncovering its component tangential to a reference surface. Evaluation on a real world dataset shows that the presented method outperforms the state-of-the-art in terms of visual quality while retaining interactive frame rates. A case study with a domain expert was performed in which the novel analysis and visualization methods are applied on standard model structures, namely skull and mandible of different rodents, to investigate and compare influence of phylogeny, diet and geography on shape. The visualizations enable for instance to distinguish (population-)normal and pathological morphology, assist in uncovering correlation to extrinsic factors and potentially support assessment of model quality."
    },
    {
        "title": "LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Johannes Sorger",
            "Thomas Ortner",
            "Christian Luksch",
            "Michael Schwärzler",
            "Eduard Gröller",
            "Harald Piringer"
        ],
        "DOI": "10.1109/TVCG.2015.2468011",
        "citation": 18,
        "abstract": "State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty."
    },
    {
        "title": "Acquired Codes of Meaning in Data Visualization and Infographics: Beyond Perceptual Primitives",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Lydia Byrne",
            "Daniel Angus",
            "Janet Wiles"
        ],
        "DOI": "10.1109/TVCG.2015.2467321",
        "citation": 17,
        "abstract": "While information visualization frameworks and heuristics have traditionally been reluctant to include acquired codes of meaning, designers are making use of them in a wide variety of ways. Acquired codes leverage a user's experience to understand the meaning of a visualization. They range from figurative visualizations which rely on the reader's recognition of shapes, to conventional arrangements of graphic elements which represent particular subjects. In this study, we used content analysis to codify acquired meaning in visualization. We applied the content analysis to a set of infographics and data visualizations which are exemplars of innovative and effective design. 88% of the infographics and 71% of data visualizations in the sample contain at least one use of figurative visualization. Conventions on the arrangement of graphics are also widespread in the sample. In particular, a comparison of representations of time and other quantitative data showed that conventions can be specific to a subject. These results suggest that there is a need for information visualization research to expand its scope beyond perceptual channels, to include social and culturally constructed meaning. Our paper demonstrates a viable method for identifying figurative techniques and graphic conventions and integrating them into heuristics for visualization design."
    },
    {
        "title": "Spatial Reasoning and Data Displays",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Susan VanderPlas",
            "Heike Hofmann"
        ],
        "DOI": "10.1109/TVCG.2015.2469125",
        "citation": 15,
        "abstract": "Graphics convey numerical information very efficiently, but rely on a different set of mental processes than tabular displays. Here, we present a study relating demographic characteristics and visual skills to perception of graphical lineups. We conclude that lineups are essentially a classification test in a visual domain, and that performance on the lineup protocol is associated with general aptitude, rather than specific tasks such as card rotation and spatial manipulation. We also examine the possibility that specific graphical tasks may be associated with certain visual skills and conclude that more research is necessary to understand which visual skills are required in order to understand certain plot types."
    },
    {
        "title": "Intuitive Exploration of Volumetric Data Using Dynamic Galleries",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Daniel Jönsson",
            "Martin Falk",
            "Anders Ynnerman"
        ],
        "DOI": "10.1109/TVCG.2015.2467294",
        "citation": 15,
        "abstract": "In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach."
    },
    {
        "title": "Visualizing Tensor Normal Distributions at Multiple Levels of Detail",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Amin Abbasloo",
            "Vitalis Wiens",
            "Max Hermann",
            "Thomas Schultz"
        ],
        "DOI": "10.1109/TVCG.2015.2467031",
        "citation": 15,
        "abstract": "Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics."
    },
    {
        "title": "Planar Visualization of Treelike Structures",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Joseph Marino",
            "Arie Kaufman"
        ],
        "DOI": "10.1109/TVCG.2015.2467413",
        "citation": 15,
        "abstract": "We present a novel method to create planar visualizations of treelike structures (e.g., blood vessels and airway trees) where the shape of the object is well preserved, allowing for easy recognition by users familiar with the structures. Based on the extracted skeleton within the treelike object, a radial planar embedding is first obtained such that there are no self-intersections of the skeleton which would have resulted in occlusions in the final view. An optimization procedure which adjusts the angular positions of the skeleton nodes is then used to reconstruct the shape as closely as possible to the original, according to a specified view plane, which thus preserves the global geometric context of the object. Using this shape recovered embedded skeleton, the object surface is then flattened to the plane without occlusions using harmonic mapping. The boundary of the mesh is adjusted during the flattening step to account for regions where the mesh is stretched over concavities. This parameterized surface can then be used either as a map for guidance during endoluminal navigation or directly for interrogation and decision making. Depth cues are provided with a grayscale border to aid in shape understanding. Examples are presented using bronchial trees, cranial and lower limb blood vessels, and upper aorta datasets, and the results are evaluated quantitatively and with a user study."
    },
    {
        "title": "Vials: Visualizing Alternative Splicing of Genes",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Hendrik Strobelt",
            "Bilal Alsallakh",
            "Joseph Botros",
            "Brant Peterson",
            "Mark Borowsky",
            "Hanspeter Pfister",
            "Alexander Lex"
        ],
        "DOI": "10.1109/TVCG.2015.2467911",
        "citation": 15,
        "abstract": "Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets."
    },
    {
        "title": "AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "M. Adil Yalçin",
            "Niklas Elmqvist",
            "Benjamin B. Bederson"
        ],
        "DOI": "10.1109/TVCG.2015.2467051",
        "citation": 14,
        "abstract": "Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university."
    },
    {
        "title": "A Simple Approach for Boundary Improvement of Euler Diagrams",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Paolo Simonetto",
            "Daniel Archambault",
            "Carlos Scheidegger"
        ],
        "DOI": "10.1109/TVCG.2015.2467992",
        "citation": 13,
        "abstract": "General methods for drawing Euler diagrams tend to generate irregular polygons. Yet, empirical evidence indicates that smoother contours make these diagrams easier to read. In this paper, we present a simple method to smooth the boundaries of any Euler diagram drawing. When refining the diagram, the method must ensure that set elements remain inside their appropriate boundaries and that no region is removed or created in the diagram. Our approach uses a force system that improves the diagram while at the same time ensuring its topological structure does not change. We demonstrate the effectiveness of the approach through case studies and quantitative evaluations."
    },
    {
        "title": "JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Matthias Labschütz",
            "Stefan Bruckner",
            "M. Eduard Gröller",
            "Markus Hadwiger",
            "Peter Rautek"
        ],
        "DOI": "10.1109/TVCG.2015.2467331",
        "citation": 13,
        "abstract": "Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures."
    },
    {
        "title": "Automatic Selection of Partitioning Variables for Small Multiple Displays",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Anushka Anand",
            "Justin Talbot"
        ],
        "DOI": "10.1109/TVCG.2015.2467323",
        "citation": 12,
        "abstract": "Effective small multiple displays are created by partitioning a visualization on variables that reveal interesting conditional structure in the data. We propose a method that automatically ranks partitioning variables, allowing analysts to focus on the most promising small multiple displays. Our approach is based on a randomized, non-parametric permutation test, which allows us to handle a wide range of quality measures for visual patterns defined on many different visualization types, while discounting spurious patterns. We demonstrate the effectiveness of our approach on scatterplots of real-world, multidimensional datasets."
    },
    {
        "title": "Real-Time Molecular Visualization Supporting Diffuse Interreflections and Ambient Occlusion",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Robin Skånberg",
            "Pere-Pau Vázquez",
            "Victor Guallar",
            "Timo Ropinski"
        ],
        "DOI": "10.1109/TVCG.2015.2467293",
        "citation": 12,
        "abstract": "Today molecular simulations produce complex data sets capturing the interactions of molecules in detail. Due to the complexity of this time-varying data, advanced visualization techniques are required to support its visual analysis. Current molecular visualization techniques utilize ambient occlusion as a global illumination approximation to improve spatial comprehension. Besides these shadow-like effects, interreflections are also known to improve the spatial comprehension of complex geometric structures. Unfortunately, the inherent computational complexity of interreflections would forbid interactive exploration, which is mandatory in many scenarios dealing with static and time-varying data. In this paper, we introduce a novel analytic approach for capturing interreflections of molecular structures in real-time. By exploiting the knowledge of the underlying space filling representations, we are able to reduce the required parameters and can thus apply symbolic regression to obtain an analytic expression for interreflections. We show how to obtain the data required for the symbolic regression analysis, and how to exploit our analytic solution to enhance interactive molecular visualizations."
    },
    {
        "title": "Mining Graphs for Understanding Time-Varying Volumetric Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Yi Gu",
            "Chaoli Wang",
            "Tom Peterka",
            "Robert Jacob",
            "Seung Hyun Kim"
        ],
        "DOI": "10.1109/TVCG.2015.2468031",
        "citation": 12,
        "abstract": "A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach."
    },
    {
        "title": "Anisotropic Ambient Volume Shading",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Marco Ament",
            "Carsten Dachsbacher"
        ],
        "DOI": "10.1109/TVCG.2015.2467963",
        "citation": 10,
        "abstract": "We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading."
    },
    {
        "title": "Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Hanqi Guo",
            "Carolyn L. Phillips",
            "Tom Peterka",
            "Dmitry Karpeyev",
            "Andreas Glatz"
        ],
        "DOI": "10.1109/TVCG.2015.2466838",
        "citation": 10,
        "abstract": "We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible."
    },
    {
        "title": "SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Aurélie Cohé",
            "Bastien Liutkus",
            "Gilles Bailly",
            "James Eagan",
            "Eric Lecolinet"
        ],
        "DOI": "10.1109/TVCG.2015.2467035",
        "citation": 9,
        "abstract": "System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology."
    },
    {
        "title": "Multi-field Pattern Matching based on Sparse Feature Sampling",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Zhongjie Wang",
            "Hans-Peter Seidel",
            "Tino Weinkauf"
        ],
        "DOI": "10.1109/TVCG.2015.2467292",
        "citation": 9,
        "abstract": "We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts."
    },
    {
        "title": "VEEVVIE: Visual Explorer for Empirical Visualization, VR and Interaction Experiments",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "C. Papadopoulos",
            "I. Gutenko",
            "A. E. Kaufman"
        ],
        "DOI": "10.1109/TVCG.2015.2467954",
        "citation": 8,
        "abstract": "Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls."
    },
    {
        "title": "Visualization and Analysis of Rotating Stall for Transonic Jet Engine Simulation",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Chun-Ming Chen",
            "Soumya Dutta",
            "Xiaotong Liu",
            "Gregory Heinlein",
            "Han-Wei Shen",
            "Jen-Ping Chen"
        ],
        "DOI": "10.1109/TVCG.2015.2467952",
        "citation": 7,
        "abstract": "Identification of early signs of rotating stall is essential for the study of turbine engine stability. With recent advancements of high performance computing, high-resolution unsteady flow fields allow in depth exploration of rotating stall and its possible causes. Performing stall analysis, however, involves significant effort to process large amounts of simulation data, especially when investigating abnormalities across many time steps. In order to assist scientists during the exploration process, we present a visual analytics framework to identify suspected spatiotemporal regions through a comparative visualization so that scientists are able to focus on relevant data in more detail. To achieve this, we propose efficient stall analysis algorithms derived from domain knowledge and convey the analysis results through juxtaposed interactive plots. Using our integrated visualization system, scientists can visually investigate the detected regions for potential stall initiation and further explore these regions to enhance the understanding of this phenomenon. Positive feedback from scientists demonstrate the efficacy of our system in analyzing rotating stall."
    },
    {
        "title": "Visual Analytics for Development and Evaluation of Order Selection Criteria for Autoregressive Processes",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Thomas Löwe",
            "Emmy-Charlotte Förster",
            "Georgia Albuquerque",
            "Jens-Peter Kreiss",
            "Marcus Magnor"
        ],
        "DOI": "10.1109/TVCG.2015.2467612",
        "citation": 7,
        "abstract": "Order selection of autoregressive processes is an active research topic in time series analysis, and the development and evaluation of automatic order selection criteria remains a challenging task for domain experts. We propose a visual analytics approach, to guide the analysis and development of such criteria. A flexible synthetic model generator-combined with specialized responsive visualizations-allows comprehensive interactive evaluation. Our fast framework allows feedback-driven development and fine-tuning of new order selection criteria in real-time. We demonstrate the applicability of our approach in three use-cases for two general as well as a real-world example."
    },
    {
        "title": "Interactive Visualization for Singular Fibers of Functions f : R3 → R2",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Daisuke Sakurai",
            "Osamu Saeki",
            "Hamish Carr",
            "Hsiang-Yun Wu",
            "Takahiro Yamamoto",
            "David Duke",
            "Shigeo Takahashi"
        ],
        "DOI": "10.1109/TVCG.2015.2467433",
        "citation": 6,
        "abstract": "Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R3→R2. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians."
    },
    {
        "title": "Reconstruction and Visualization of Coordinated 3D Cell Migration Based on Optical Flow",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Christopher P. Kappe",
            "Lucas Schütz",
            "Stefan Gunther",
            "Lars Hufnagel",
            "Steffen Lemke",
            "Heike Leitte"
        ],
        "DOI": "10.1109/TVCG.2015.2467291",
        "citation": 6,
        "abstract": "Animal development is marked by the repeated reorganization of cells and cell populations, which ultimately determine form and shape of the growing organism. One of the central questions in developmental biology is to understand precisely how cells reorganize, as well as how and to what extent this reorganization is coordinated. While modern microscopes can record video data for every cell during animal development in 3D+t, analyzing these videos remains a major challenge: reconstruction of comprehensive cell tracks turned out to be very demanding especially with decreasing data quality and increasing cell densities. In this paper, we present an analysis pipeline for coordinated cellular motions in developing embryos based on the optical flow of a series of 3D images. We use numerical integration to reconstruct cellular long-term motions in the optical flow of the video, we take care of data validation, and we derive a LIC-based, dense flow visualization for the resulting pathlines. This approach allows us to handle low video quality such as noisy data or poorly separated cells, and it allows the biologists to get a comprehensive understanding of their data by capturing dynamic growth processes in stills. We validate our methods using three videos of growing fruit fly embryos."
    },
    {
        "title": "Adaptive Multilinear Tensor Product Wavelets",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Kenneth Weiss",
            "Peter Lindstrom"
        ],
        "DOI": "10.1109/TVCG.2015.2467412",
        "citation": 6,
        "abstract": "Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells."
    },
    {
        "title": "Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "31 Jan. 2016",
        "authors": [
            "Thomas Butkiewicz",
            "Andrew H. Stevens"
        ],
        "DOI": "10.1109/TVCG.2015.2467962",
        "citation": 1,
        "abstract": "Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudo-contour lines induced by banded color scales convey the same benefits."
    },
    {
        "title": "VIS Conference Committee",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2469071",
        "citation": 0,
        "abstract": "Presents a listing of this VIS 2015 conference committee."
    },
    {
        "title": "Message from the VIS Paper Chairs and Guest Editors",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2468793",
        "citation": 0,
        "abstract": "The papers in this special issue were presented at IEEE VIS 2015, held during October 25-30, 2015 in Chicago, IL. VIS consists of three conferences, held concurrently: the IEEE Visual Analytics Science and Technology Conference (VAST 2015), the IEEE Information Visualization Conference (InfoVis 2015), and the IEEE Scientific Visualization Conference (SciVis 2015). Visualization continues to develop rapidly as a research discipline and the three conferences are maintaining their positions as the leading annual events for researchers and practitioners to share the most innovative and impactful results of an increasingly diverse and influential community."
    },
    {
        "title": "Message from the Editor-in-Chief",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2469111",
        "citation": 0,
        "abstract": "Presents a message from the Editor-in-Chief for this issue of the publication."
    },
    {
        "title": "VAST Paper Reviewers",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2469115",
        "citation": 0,
        "abstract": "Presents a listing of the conference reviewers."
    },
    {
        "title": "The 2015 Visualization Technical Achievement Award",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2487020",
        "citation": 0,
        "abstract": "Presents the recipients of 2015 Visualization Technical Achievement Award."
    },
    {
        "title": "[Front cover]",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2473376",
        "citation": 0,
        "abstract": "Presents the title page of the proceedings record."
    },
    {
        "title": "Author Index IEEE Transactions on Visualization and Computer Graphics Vol. 20",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2471375",
        "citation": 0,
        "abstract": "Presents the author index from this conference."
    },
    {
        "title": "VIS Steering and Executive Committees",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2471376",
        "citation": 0,
        "abstract": "Presents a listing of the conference steering and executive committee."
    },
    {
        "title": "VIS International Program Committees",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2471377",
        "citation": 0,
        "abstract": "Presents a listing of the conference program committee."
    },
    {
        "title": "The 2015 Visualization Career Award",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2469052",
        "citation": 0,
        "abstract": "Presents the recipients of the  2015 Visualization Career Award."
    },
    {
        "title": "IEEE Visualization and Graphics Technical Committee (VGTC)",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2471378",
        "citation": 0,
        "abstract": "Presents a listing of this VGTC technical committee members."
    },
    {
        "title": "Table of Contents",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2016",
        "authors": [],
        "DOI": "10.1109/TVCG.2015.2471355",
        "citation": 0,
        "abstract": "Presents the table of contents from this conference."
    }
]