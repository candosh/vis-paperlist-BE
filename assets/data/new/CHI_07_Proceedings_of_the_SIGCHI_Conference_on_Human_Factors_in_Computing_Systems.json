[
    {
        "title": "A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Faces & bodies in interaction",
        "data": "April 2007",
        "authors": [
            "Nick Yee",
            "Jeremy N Bailenson",
            "Kathryn Rickertsen"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240626",
        "citation": "133",
        "abstract": "The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questionnaire ratings, interviews) than when analyzing behavioral responses such as task performance and memory. Furthermore, the effects of adding an agent to an interface are larger than the effects of animating an agent to behave more realistically. However, the overall effect sizes were quite small (e.g., across studies, adding a face to an interface only explains approximately 2.5% of the variance in results). We discuss the implications for both designers building interfaces as well as social scientists designing experiments to evaluate those interfaces."
    },
    {
        "title": "Session details: Faces & bodies in interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Faces & bodies in interaction",
        "data": "April 2007",
        "authors": [
            "Anne Anderson"
        ],
        "DOI": "https://doi.org/10.1145/3258852",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Improving recognition and characterization in groupware with rich embodiments",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Faces & bodies in interaction",
        "data": "April 2007",
        "authors": [
            "Tadeusz Stach",
            "Carl Gutwin",
            "David Pinelle",
            "Pourang Irani"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240627",
        "citation": "16",
        "abstract": "Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the feasibility of rich embodiment and their effects on group interaction, we carried out three studies. The first shows that users are able to recall and interpret a large set of variables that are graphically encoded on an embodiment. The second and third studies demonstrated rich embodiments in two groupware systems -- a multiplayer game and a drawing application -- and showed that the enhanced representations do improve recognition and characterization, and that they can enrich interaction in a variety of ways."
    },
    {
        "title": "Coordinating joint activity in avatar-mediated interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Faces & bodies in interaction",
        "data": "April 2007",
        "authors": [
            "Robert J. Moore",
            "E. Cabell Hankinson Gathman",
            "Nicolas Ducheneaut",
            "Eric Nickell"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240628",
        "citation": "24",
        "abstract": "Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game's standard awareness cues and the other with enhanced cues. We use conversation analysis to demonstrate interactional slippages caused by the absence of awareness cues, user practices that circumvent such limitations and ways in which enhanced cues can enable tighter coordination."
    },
    {
        "title": "Industrial Design: Challenges and Successes Towards an integrated Product Development Process",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "David Gilmore",
            "Jeremy Ashley",
            "Tucker Viemeister",
            "Tim Wood"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180996",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Web 2.0 and the Enterprise: The Business Impact of Modern Technological Approaches to Web Application Design",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "John Kolko",
            "Jeff Veen",
            "Jonathan Grubb"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180991",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Faceted Metadata for Information Architecture and Search",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Marti Hearst"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180994",
        "citation": "6",
        "abstract": "No abstract available."
    },
    {
        "title": "Introduction to CSCW - 2",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Jim Herbsleb",
            "Gary Olson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180958",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Welcome to CHI",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Mary Beth Rosson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180959",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "ACM welcome",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Stu Feldman"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180960",
        "citation": "1",
        "abstract": "No abstract available."
    },
    {
        "title": "Opening Plenary Talk",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Bill Moggridge"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180961",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Introduction to CSCW - 1",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Jim Herbsleb",
            "Gary Olson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180955",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "From Mice to Men - 24 Years of Evaluation in CHI",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Louise Barkhuus",
            "Jennifer A. Rode"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180963",
        "citation": "84",
        "abstract": "No abstract available."
    },
    {
        "title": "Thanks to our sponsors",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Mary Beth Rosson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2181020",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Public Usability Laboratory",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Ana Klasnja"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180965",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "CHI 2008 Preview",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Mary Czerwinski",
            "Desney Tan",
            "Arnie Lund",
            "Ben Shneiderman"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2181002",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Tuesday CHI Madness",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Gonzalo Ramos"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180967",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Introduction to HCI - 1",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Keith Butler",
            "Rob Jacobs",
            "David Kieras"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180956",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Monday CHI Madness",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Partick Baudish"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180969",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Avoiding We Can't Change THAT!: An Introduction to Usability & Software Architecture",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Bonnie E. John",
            "Len Bass",
            "Elspeth Golden"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180997",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Past, Present, and Future of HCC Education: What We Teach, How We Teach",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Jim Foley"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180988",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Wednesday CHI Madness",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180990",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Introduction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Steven Wall",
            "Ilona Posner"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2181021",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "CHI Madness: Summary of other entries",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Patrick Baudisch",
            "Gonzalo Ramos"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180995",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Program addenda",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [],
        "DOI": "https://doi.org/10.1145/1240624.2180968",
        "citation": "NONE",
        "abstract": "No abstract available."
    },
    {
        "title": "The Evolution of Evaluation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Joseph 'Jofish' Kaye",
            "Phoebe Sengers"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180962",
        "citation": "10",
        "abstract": "No abstract available."
    },
    {
        "title": "CHI 2007 Welcome",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Dennis Wixon",
            "Mary Beth Rosson",
            "David Gilmore"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2181033",
        "citation": "1",
        "abstract": "No abstract available."
    },
    {
        "title": "Avoiding We Can't Change That Either!: Usability Supporting Architectural Patterns",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Bonnie E. John",
            "Elspeth Golden"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2206886",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Using Computing Technologies to Face the Challenges of Autism",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Gregory D. Abowd"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2181000",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "The mobile as a post Industrial platform for socio-economic development",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Niti Bhan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2181001",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Make Evaluation Poverty History",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Gilbert Cockton"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180964",
        "citation": "8",
        "abstract": "No abstract available."
    },
    {
        "title": "Introduction to HCI - 2",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Keith Butler",
            "Rob Jacobs",
            "David Kieras"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180957",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Thursday CHI Madness",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Gonzalo Ramos"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180999",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Doing HCI Differently -- Stories from the Developing World",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Gary Marsden"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180966",
        "citation": "4",
        "abstract": "No abstract available."
    },
    {
        "title": "Along the Path of Pervasive Computing: Selected Works in GUI and TUI Design",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SECTION: Presentations",
        "data": "April 2007",
        "authors": [
            "Bill Lucas",
            "Hiroshi Ishii",
            "Jake Kolojejchick",
            "Peter Lucas",
            "David Rose"
        ],
        "DOI": "https://doi.org/10.1145/1240624.2180987",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Session details: Attention & interruption",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Attention & interruption",
        "data": "April 2007",
        "authors": [
            "Brian Bailey"
        ],
        "DOI": "https://doi.org/10.1145/3258853",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "How it works: a field study of non-technical users interacting with an intelligent system",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Attention & interruption",
        "data": "April 2007",
        "authors": [
            "Joe Tullio",
            "Anind K. Dey",
            "Jason Chalecki",
            "James Fogarty"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240630",
        "citation": "92",
        "abstract": "In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount some of their initial misconceptions about what information the system used for reasoning about interruptibility. However, the overarching structures of their mental models stayed relatively stable over the course of the study. Lastly, we found that participants were able to give lay descriptions attributing simple machine learning concepts to the system despite their lack of technical knowledge. Our findings suggest an appropriate level of feedback for user interfaces of intelligent systems, provide a baseline level of complexity for user understanding, and highlight the challenges of making users aware of sensed inputs for such systems."
    },
    {
        "title": "Matching attentional draw with utility in interruption",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Attention & interruption",
        "data": "April 2007",
        "authors": [
            "Jennifer Gluck",
            "Andrea Bunt",
            "Joanna McGrenere"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240631",
        "citation": "36",
        "abstract": "This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption's notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different levels of utility. Results indicate that the matching strategy decreases annoyance and increases perception of benefit compared to a strategy that uses the same signal regardless of interruption utility, with no significant impact on workload or performance. Design implications arising from the second experiment as well as recommendations for future work are discussed."
    },
    {
        "title": "Biases in human estimation of interruptibility: effects and implications for practice",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Attention & interruption",
        "data": "April 2007",
        "authors": [
            "Daniel Avrahami",
            "James Fogarty",
            "Scott E. Hudson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240632",
        "citation": "20",
        "abstract": "People have developed a variety of conventions for negotiating face to face interruptions. The physical distribution of teams, however, together with the use of computer mediated communication and awareness systems, fundamentally alters what information is available to a person considering an interruption of a remote collaborator. This paper presents a detailed comparison between self-reports of interruptibility, collected from participants over extended periods in their actual work environment, and estimates of this interruptibility, provided by a second set of participants based on audio and video recordings. Our results identify activities and environmental cues that affect participants' ability to correctly estimate interruptibility. We show, for example, that a closed office door had a significant effect on observers' estimation of interruptibility, but did not have an effect on participants' reports of their own interruptibility. We discuss our findings and their importance for successful design of computer-mediated communication and awareness systems."
    },
    {
        "title": "Session details: Capturing life experiences",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Capturing life experiences",
        "data": "April 2007",
        "authors": [
            "Sara Kiesler"
        ],
        "DOI": "https://doi.org/10.1145/3258854",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Understanding videowork",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Capturing life experiences",
        "data": "April 2007",
        "authors": [
            "David Kirk",
            "Abigail Sellen",
            "Richard Harper",
            "Ken Wood"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240634",
        "citation": "85",
        "abstract": "In this paper we elucidate the patterns of behavior of home movie makers through a study of 12 families and a separate focus group of 7 teenagers. Analogous to a similar study of photowork [13], the goal is to provide a deeper understanding of what people currently do with video technologies, balancing the preponderence of techno-centric work in the area with appropriate user-centric insight. From our analysis, we derive a videowork lifecycle to frame the practices users engage in when working with video technologies in the home, and uncover two broad types of video usage therein. This has implications for how we conceive of and devise tools to support these practices, as we discuss."
    },
    {
        "title": "Software or wetware?: discovering when and why people use digital prosthetic memory",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Capturing life experiences",
        "data": "April 2007",
        "authors": [
            "Vaiva Kalnikaité",
            "Steve Whittaker"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240635",
        "citation": "43",
        "abstract": "Our lives are full of memorable and important moments, as well as important items of information. The last few years have seen the proliferation of digital devices intended to support prosthetic memory (PM), to help users recall experiences, conversations and retrieve personal information. We nevertheless have little systematic understanding of when and why people might use such devices, in preference to their own organic memory (OM). Although OM is fallible, it may be more efficient than accessing information from a complex PM device. We report a controlled lab study which investigates when and why people use PM and OM. We found that PM use depended on users' evaluation of the quality of their OM, as well as PM device properties. In particular, we found that users trade-off Accuracy and Efficiency, preferring rapid access to potentially inaccurate information over laborious access to accurate information. We discuss the implications of these results for future PM design and theory. Rather than replacing OM, future PM designs need to focus on allowing OM and PM to work in synergy."
    },
    {
        "title": "Do life-logging technologies support memory for the past?: an experimental study using sensecam",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Capturing life experiences",
        "data": "April 2007",
        "authors": [
            "Abigail J. Sellen",
            "Andrew Fogg",
            "Mike Aitken",
            "Steve Hodges",
            "Carsten Rother",
            "Ken Wood"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240636",
        "citation": "188",
        "abstract": "We report on the results of a study using SenseCam, a \"life-logging\" technology in the form of a wearable camera, which aims to capture data about everyday life in order to support people's memory for past, personal events. We find evidence that SenseCam images do facilitate people's ability to connect to their past, but that images do this in different ways. We make a distinction between \"remembering\" the past, and \"knowing\" about it, and provide evidence that SenseCam images work differently over time in these capacities. We also compare the efficacy of user-captured images with automatically captured images and discuss the implications of these findings and others for how we conceive of and make claims about life-logging technologies."
    },
    {
        "title": "Session details: Large displays",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Large displays",
        "data": "April 2007",
        "authors": [
            "Mary Czerwinski"
        ],
        "DOI": "https://doi.org/10.1145/3258855",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "An exploratory study of input configuration and group process in a negotiation task using a large display",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Large displays",
        "data": "April 2007",
        "authors": [
            "Jeremy P. Birnholtz",
            "Tovi Grossman",
            "Clarissa Mak",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240638",
        "citation": "40",
        "abstract": "This paper reports on an exploratory study of the effects of input configuration on group behavior and performance in a collaborative task performed by a collocated group using a large display. Twelve groups completed a mixed-motive negotiation task under two conditions: a single, shared mouse and one mouse per person. Results suggest that the multiple mouse condition allowed for more parallel work, but the quality of discussion was higher in the single mouse condition. Moreover, participants were more likely to act in their own best interest in the multiple mouse condition."
    },
    {
        "title": "Beyond visual acuity: the perceptual scalability of information visualizations for large displays",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Large displays",
        "data": "April 2007",
        "authors": [
            "Beth Yost",
            "Yonca Haciahmetoglu",
            "Chris North"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240639",
        "citation": "71",
        "abstract": "The scalability of information visualizations has typically been limited by the number of available display pixels. As displays become larger, the scalability limit may shift away from the number of pixels and toward human perceptual abilities. This work explores the effect of using large, high resolution displays to scale up information visualizations beyond potential visual acuity limitations. Displays that are beyond visual acuity require physical navigation to see all of the pixels. Participants performed various information visualization tasks using display sizes with a sufficient number of pixels to be within, equal to, or beyond visual acuity. Results showed that performance on most tasks was more efficient and sometimes more accurate because of the additional data that could be displayed, despite the physical navigation that was required. Visualization design issues on large displays are also discussed."
    },
    {
        "title": "White rooms and morphing don't mix: setting and the evaluation of visualization techniques",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Large displays",
        "data": "April 2007",
        "authors": [
            "Derek F. Reilly",
            "Kori M. Inkpen"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240640",
        "citation": "13",
        "abstract": "The results presented in this paper illustrate how a specific map visualization technique is sensitive to setting: a comparative evaluation of the technique gives conflicting results depending on where it takes place. While prior research has explored the impact of factors other than basic visual perception on visualization techniques, relatively little attention has been directed toward the physical setting in which the technique is used. We present results from a study involving 120 participants, comparing the effectiveness of two different geovisualization techniques in promoting recall of map layout. Recall was shown to be sensitive to setting, such that one technique in particular was more effective in a noisy public space than in a controlled, 'white-room' environment. The results have implications for the validation and measurement of information visualization techniques as a whole, and in particular for those employing motion as a communicative attribute."
    },
    {
        "title": "Session details: Shake, rattle and roll: new forms of input and output",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Shake, rattle and roll: new forms of input and output",
        "data": "April 2007",
        "authors": [
            "Lars Erik Holmquist"
        ],
        "DOI": "https://doi.org/10.1145/3258856",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Shoogle: excitatory multimodal interaction on mobile devices",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Shake, rattle and roll: new forms of input and output",
        "data": "April 2007",
        "authors": [
            "John Williamson",
            "Roderick Murray-Smith",
            "Stephen Hughes"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240642",
        "citation": "115",
        "abstract": "Shoogle is a novel, intuitive interface for sensing data withina mobile device, such as presence and properties of textmessages or remaining resources. It is based around activeexploration: devices are shaken, revealing the contents rattlingaround \"inside\". Vibrotactile display and realistic impactsonification create a compelling system. Inertial sensingis used for completely eyes-free, single-handed interactionthat is entirely natural. Prototypes are described runningboth on a PDA and on a mobile phone with a wireless sensorpack. Scenarios of use are explored where active sensing ismore appropriate than the dominant alert paradigm."
    },
    {
        "title": "Session details: Ubicomp tools",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Ubicomp tools",
        "data": "April 2007",
        "authors": [
            "Beverly Harrison"
        ],
        "DOI": "https://doi.org/10.1145/3258857",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Momento: support for situated ubicomp experimentation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Ubicomp tools",
        "data": "April 2007",
        "authors": [
            "Scott Carter",
            "Jennifer Mankoff",
            "Jeffrey Heer"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240644",
        "citation": "66",
        "abstract": "We present the iterative design of Momento, a tool that providesintegrated support for situated evaluation of ubiquitouscomputing applications. We derived requirements for Momento from a user-centered design process that includedinterviews, observations and field studies of early versionsof the tool. Motivated by our findings, Momento supportsremote testing of ubicomp applications, helps with participantadoption and retention by minimizing the need for newhardware, and supports mid-to-long term studies to addressinfrequently occurring data. Also, Momento can gather logdata, experience sampling, diary, and other qualitative data."
    },
    {
        "title": "Toolkit support for developing and deploying sensor-based statistical models of human situations",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Ubicomp tools",
        "data": "April 2007",
        "authors": [
            "James Fogarty",
            "Scott E. Hudson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240645",
        "citation": "26",
        "abstract": "Sensor based statistical models promise to support a variety of advances in human computer interaction, but building applications that use them is currently difficult and potential advances go unexplored. We present Subtle, a toolkit that removes some of the obstacles to developing and deploying applications using sensor based statistical models of human situations. Subtle provides an appropriate and extensible sensing library, continuous learning of personalized models, fully automated high level feature generation, and support for using learned models in deployed applications. By removing obstacles to developing and deploying sensor based statistical models, Subtle makes it easier to explore the design space surrounding sensor based statistical models of human situations. Subtle thus helps to move the focus of human computer interaction research onto applications and datasets, instead of the difficulties of developing and deploying sensor based statistical models."
    },
    {
        "title": "Authoring sensor-based interactions by demonstration with direct manipulation and pattern recognition",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Ubicomp tools",
        "data": "April 2007",
        "authors": [
            "Björn Hartmann",
            "Leith Abdulla",
            "Manas Mittal",
            "Scott R. Klemmer"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240646",
        "citation": "104",
        "abstract": "Sensors are becoming increasingly important in interaction design. Authoring a sensor-based interaction comprises three steps: choosing and connecting the appropriate hardware, creating application logic, and specifying the relationship between sensor values and application logic. Recent research has successfully addressed the first two issues. However, linking sensor input data to application logic remains an exercise in patience and trial-and-error testing for most designers. This paper introduces techniques for authoring sensor-based interactions by demonstration. A combination of direct manipulation and pattern recognition techniques enables designers to control how demonstrated examples are generalized to interaction rules. This approach emphasizes design exploration by enabling very rapid iterative demonstrate-edit-review cycles. This paper describes the manifestation of these techniques in a design tool, Exemplar, and presents evaluations through a first-use lab study and a theoretical analysis using the Cognitive Dimensions of Notation framework."
    },
    {
        "title": "Session details: Mobile interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction",
        "data": "April 2007",
        "authors": [
            "Kori Inkpen"
        ],
        "DOI": "https://doi.org/10.1145/3258858",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Questions not answers: a novel mobile search technique",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction",
        "data": "April 2007",
        "authors": [
            "Matt Jones",
            "George Buchanan",
            "Richard Harper",
            "Pierre-Louis Xech"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240648",
        "citation": "26",
        "abstract": "Mobile search is becoming an increasingly important user activity. In this paper, instead of investigating the most efficient and effective ways of providing search results, the answers, we consider the value of giving access to previous queries, the questions, relating to a user's location. By exposing what other people have searched for, the aim is to provide useful insights into a location's character. To consider the value of the approach we deployed two mobile probes in a large-scale field study involving 391 participants. Our experiences suggest that presenting users with other people's in situ queries influences their information seeking interactions positively."
    },
    {
        "title": "Tactile feedback for mobile interactions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction",
        "data": "April 2007",
        "authors": [
            "Stephen Brewster",
            "Faraz Chohan",
            "Lorna Brown"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240649",
        "citation": "185",
        "abstract": "We present a study investigating the use of vibrotactile feedback for touch-screen keyboards on PDAs. Such key-boards are hard to use when mobile as keys are very small. We conducted a laboratory study comparing standard but-tons to ones with tactile feedback added. Results showed that with tactile feedback users entered significantly more text, made fewer errors and corrected more of the errors they did make. We ran the study again with users seated on an underground train to see if the positive effects trans-ferred to realistic use. There were fewer beneficial effects, with only the number of errors corrected significantly im-proved by the tactile feedback. However, we found strong subjective feedback in favour of the tactile display. The results suggest that tactile feedback has a key role to play in improving interactions with touch screens."
    },
    {
        "title": "Revisiting and validating a model of two-thumb text entry",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction",
        "data": "April 2007",
        "authors": [
            "Edward Clarkson",
            "Kent Lyons",
            "James Clawson",
            "Thad Starner"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240650",
        "citation": "12",
        "abstract": "MacKenzie and Soukoreff have previously introduced a Fitts' Law-based performance model of expert two-thumb text entry on mini-QWERTY keyboards [4]. In this work we validate the original model using results from a longitudinal study of mini-QWERTY keyboards, and update the model to account for observed inter-key time data."
    },
    {
        "title": "\"Jump and refine\" for rapid pointing on mobile phones",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction",
        "data": "April 2007",
        "authors": [
            "Martin Hachet",
            "Joachim Pouderoux",
            "Florence Tyndiuk",
            "Pascal Guitton"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240651",
        "citation": "5",
        "abstract": "Standard input devices for mobile phones are directional keys and discrete thumb-joysticks. These devices are dedicated to the discrete GUIs of the phones (eg. scroll lists and small icons arrays). Today, new mobile applications are arising and require adapted interfaces. In particular, the widespread of 3D applications will be favored if users can efficiently point on any part of thescreen. In this paper, we propose a new interaction technique called Jump and Refine for selection tasks on mobile phones. This technique is based on two levels of cursor displacement in order to reduce the number of keystrokes. The first level allows fast movements into an underlying grid. The second one can be used for accurate positioning into the selected area. We present a user study which shows that using a first coarse jump level decreases the selection completion times. The study also shows that the technique is widely accepted by the users. Finally, we discuss the optimal grid sizes."
    },
    {
        "title": "Session details: Politics & activism",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Politics & activism",
        "data": "April 2007",
        "authors": [
            "Jodi Forlizzi"
        ],
        "DOI": "https://doi.org/10.1145/3258859",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Usability of voting systems: baseline data for paper, punch cards, and lever machines",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Politics & activism",
        "data": "April 2007",
        "authors": [
            "Michael D. Byrne",
            "Kristen K. Greene",
            "Sarah P. Everett"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240653",
        "citation": "33",
        "abstract": "In the United States, computer-based voting machines are rapidly replacing other older technologies. While there is potential for this to be a usability improvement, particularly in terms of accessibility, the only way it is possible to know if usability has improved is to have baseline data on the usability of traditional technologies. We report an experiment assessing the usability of punch cards, lever machines, and two forms of paper ballot. There were no differences in ballot completion time between the four methods, but there were substantial effects on error rate, with the paper ballots superior to the other methods as well as an interaction with age of voters. Subjective usability was assessed with the System Usability Scale and showed a slight advantage for bubble-style paper ballots. Overall, paper ballots were found to be particularly usable, which raises important technological and policy issues."
    },
    {
        "title": "A game design methodology to incorporate social activist themes",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Politics & activism",
        "data": "April 2007",
        "authors": [
            "Mary Flanagan",
            "Helen Nissenbaum"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240654",
        "citation": "49",
        "abstract": "Can a set of articulated and tested methodologies be created whose endpoint is the reliable capacity for taking activist social themes into account? In this paper we explore a variety of educational and activist game approaches, and look specifically at the themes emerging from recent projects involving game design for young women. We articulate here design practices in a methodology, Values at Play (VAP), that could be used in the creation of games as well as the teaching of game design."
    },
    {
        "title": "Session details: Navigation & interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation & interaction",
        "data": "April 2007",
        "authors": [
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/3258860",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Move to improve: promoting physical navigation to increase user performance with large displays",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation & interaction",
        "data": "April 2007",
        "authors": [
            "Robert Ball",
            "Chris North",
            "Doug A. Bowman"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240656",
        "citation": "183",
        "abstract": "In navigating large information spaces, previous work indicates potential advantages of physical navigation (moving eyes, head, body) over virtual navigation (zooming, panning, flying). However, there is also indication of users preferring or settling into the less efficient virtual navigation. We present a study that examines these issues in the context of large, high resolution displays. The study identifies specific relationships between display size, amount of physical and virtual navigation, and user task performance. Increased physical navigation on larger displays correlates with reduced virtual navigation and improved user performance. Analyzing the differences between this study and previous results helps to identify design factors that afford and promote the use of physical navigation in the user interface."
    },
    {
        "title": "Copy-and-paste between overlapping windows",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation & interaction",
        "data": "April 2007",
        "authors": [
            "Olivier Chapuis",
            "Nicolas Roussel"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240657",
        "citation": "21",
        "abstract": "Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions."
    },
    {
        "title": "Consistency, multiple monitors, and multiple windows",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation & interaction",
        "data": "April 2007",
        "authors": [
            "Dugald Ralph Hutchings",
            "John Stasko"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240658",
        "citation": "3",
        "abstract": "We present an evaluation of mudibo, a prototype system for determining the position of dialog boxes in a multiple-monitor system. The analysis shows that, when compared to a standard approach, mudibo offered a 24% decrease in time needed to begin interaction in a dialog box. Analysis of participant behavior in the evaluation provides insight into the way users perceive and act in multiple-monitor environments. Specifically, the notion of consistency changes for multiple-monitor systems and the prospect of adaptive algorithms becomes further complicated and intricate, especially for window management."
    },
    {
        "title": "How pairs interact over a multimodal digital table",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation & interaction",
        "data": "April 2007",
        "authors": [
            "Edward Tse",
            "Chia Shen",
            "Saul Greenberg",
            "Clifton Forlines"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240659",
        "citation": "22",
        "abstract": "Co-located collaborators often work over physical tabletops using combinations of expressive hand gestures and verbal utterances. This paper provides the first observations of how pairs of people communicated and interacted in a multimodal digital table environment built atop existing single user applications. We contribute to the understanding of these environments in two ways. First, we saw that speech and gesture commands served double duty as both commands to the computer, and as implicit communication to others. Second, in spite of limitations imposed by the underlying single-user application, people were able to work together simultaneously, and they performed interleaving acts: the graceful mixing of inter-person speech and gesture actions as commands to the system. This work contributes to the intricate understanding of multi-user multimodal digital table interaction."
    },
    {
        "title": "Session details: Medical",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Medical",
        "data": "April 2007",
        "authors": [
            "David McDonald"
        ],
        "DOI": "https://doi.org/10.1145/3258861",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "An observational study on information flow during nurses' shift change",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Medical",
        "data": "April 2007",
        "authors": [
            "Charlotte Tang",
            "Sheelagh Carpendale"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240661",
        "citation": "52",
        "abstract": "We present an observational study that was conducted to guide the design and development of technologies to support information flow during nurses' shift change in a hospital ward. Our goal is to find out how the complex information sharing processes during nurses' brief shift change unfold in a hospital setting. Our study shows the multitude of information media that nurses access during the parallel processes of information assembly and disassembly: digital, paper-based, displayed and verbal media. An initial analysis reveals how the common information spaces, where information media are positioned and accessible by all participants, are actively used and how they interact with the personal information spaces ephemerally constructed by the participants. Several types of information are consistently transposed from the common information spaces to the personal information space including: demographics, historical data, reminders and to-dos, alerts, prompts, scheduling and reporting information. Information types are often enhanced with a variety of visual cues to help nurses carry out their tasks."
    },
    {
        "title": "Medical sensemaking with entity workspace",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Medical",
        "data": "April 2007",
        "authors": [
            "Dorrit Billman",
            "Eric A. Bier"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240662",
        "citation": "21",
        "abstract": "Knowledge workers making sense of a topic divide their time among activities including searching for information, reading, and taking notes. We have built a software system that supports and integrates these activities. To test its effectiveness, we conducted a study where subjects used it to perform medical question-answering tasks. Initial results indicate that subjects could use the system, but that the nature of this use depended on the subject's overall question-answering strategy. Two dominant strategies emerged that we call the Reader and Searcher strategies."
    },
    {
        "title": "Session details: Task & attention",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task & attention",
        "data": "April 2007",
        "authors": [
            "Anthony Hornof"
        ],
        "DOI": "https://doi.org/10.1145/3258862",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "A cognitive constraint model of dual-task trade-offs in a highly dynamic driving task",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task & attention",
        "data": "April 2007",
        "authors": [
            "Duncan P. Brumby",
            "Andrew Howes",
            "Dario D. Salvucci"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240664",
        "citation": "20",
        "abstract": "The paper describes an approach to modeling the strategic variations in performing secondary tasks while driving. In contrast to previous efforts that are based on simulation of a cognitive architecture interacting with a task environment, we take an approach that develops a cognitive constraint model of the interaction between the driver and the task environment in order to make inferences about dual-task performance. Analyses of driving performance data reveal that a set of simple equations can be used to accurately model changes in the lateral position of the vehicle within the lane. The model quantifies how the vehicle's deviation from lane center increases during periods of inattention, and how the vehicle returns to lane center during periods of active steering. We demonstrate the benefits of the approach by modeling the dialing of a cellular phone while driving, where drivers balance the speed in performing the dial task with accuracy (or safety) in keeping the vehicle centered in the roadway. In particular, we show how understanding, rather than simulating, the constraints imposed by the task environment can help to explain the costs and benefits of a range of strategies for interleaving dialing and steering. We show how particular strategies are sensitive to a combination of internal constraints (including switch costs) and the trade-off between the amount of time allocated to secondary task and the risk of extreme lane deviation."
    },
    {
        "title": "iPod distraction: effects of portable music-player use on driver performance",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task & attention",
        "data": "April 2007",
        "authors": [
            "Dario D. Salvucci",
            "Daniel Markley",
            "Mark Zuber",
            "Duncan P. Brumby"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240665",
        "citation": "36",
        "abstract": "Portable music players such as Apple's iPod have become ubiquitous in many environments, but one environment in particular has elicited new safety concerns and challenges -- in-vehicle use while driving. We present the first study of portable music-player interaction while driving, examining the effects of iPod interaction by drivers navigating a typical roadway in a driving simulator. Results showed that selecting media on the iPod had a significant effect on driver performance as measured by lateral deviation from lane center; the effect was comparable to previously reported effects of dialing a cellular phone. In addition, selecting media and watching videos had a significant effect on car-following speed, resulting in speed reductions that presumably compensated for impaired lateral performance. Given that iPod interaction has become increasingly common while driving, these results serve as a first step toward understanding the potential effects of portable music-player interaction on driver behavior and performance."
    },
    {
        "title": "InkSeine: In Situ search for active note taking",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task & attention",
        "data": "April 2007",
        "authors": [
            "Ken Hinckley",
            "Shengdong Zhao",
            "Raman Sarin",
            "Patrick Baudisch",
            "Edward Cutrell",
            "Michael Shilman",
            "Desney Tan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240666",
        "citation": "57",
        "abstract": "Using a notebook to sketch designs, reflect on a topic, or capture and extend creative ideas are examples of active note taking tasks. Optimal experience for such tasks demands concentration without interruption. Yet active note taking may also require reference documents or emails from team members. InkSeine is a Tablet PC application that supports active note taking by coupling a pen-and-ink interface with an in situ search facility that flows directly from a user's ink notes (Fig. 1). InkSeine integrates four key concepts: it leverages preexisting ink to initiate a search; it provides tight coupling of search queries with application content; it persists search queries as first class objects that can be commingled with ink notes; and it enables a quick and flexible workflow where the user may freely interleave inking, searching, and gathering content. InkSeine offers these capabilities in an interface that is tailored to the unique demands of pen input, and that maintains the primacy of inking above all other tasks."
    },
    {
        "title": "Session details: Expert/novice",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Expert/novice",
        "data": "April 2007",
        "authors": [
            "Paul Aoki"
        ],
        "DOI": "https://doi.org/10.1145/3258863",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Sharing a single expert among multiple partners",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Expert/novice",
        "data": "April 2007",
        "authors": [
            "Jeffrey Wong",
            "Lui Min Oh",
            "Jiazhi Ou",
            "Carolyn P. Rosé",
            "Jie Yang",
            "Susan R. Fussell"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240668",
        "citation": "3",
        "abstract": "Expertise to assist people on complex tasks is often in short supply. One solution to this problem is to design systems that allow remote experts to help multiple people in simultaneously. As a first step towards building such a system, we studied experts' attention and communication as they assisted two novices at the same time in a co-located setting. We compared simultaneous instruction when the novices are being instructed to do the same task or different tasks. Using machine learning, we attempted to identify speech markers of upcoming attention shifts that could serve as input to a remote assistance system."
    },
    {
        "title": "Dynamic detection of novice vs. skilled use without a task model",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Expert/novice",
        "data": "April 2007",
        "authors": [
            "Amy Hurst",
            "Scott E. Hudson",
            "Jennifer Mankoff"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240669",
        "citation": "46",
        "abstract": "If applications were able to detect a user's expertise, then software could automatically adapt to better match exper-tise. Detecting expertise is difficult because a user's skill changes as the user interacts with an application and differs across applications. This means that expertise must be sensed dynamically, continuously, and unobtrusively so as not to burden the user. We present an approach to this prob-lem that can operate without a task model based on low-level mouse and menu data which can typically be sensed across applications at the operating systems level. We have implemented and trained a classifier that can detect \"nov-ice\" or \"skilled\" use of an image editing program, the GNU Image Manipulation Program (GIMP), at 91% accuracy, and tested it against real use. In particular, we developed and tested a prototype application that gives the user dy-namic application information that differs depending on her performance."
    },
    {
        "title": "Approaches to web search and navigation for older computer novices",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Expert/novice",
        "data": "April 2007",
        "authors": [
            "Anna Dickinson",
            "Michael J. Smith",
            "John L. Arnott",
            "Alan F. Newell",
            "Robin L. Hill"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240670",
        "citation": "23",
        "abstract": "A proof of concept web search and navigation system was developed for older people for whom the Internet is seen as an alien territory. A joint industry/academia team deployed User Sensitive Inclusive Design principles, focusing on the usability of the interface for this user group. The search and navigation system that was developed was significantly preferred by the user group to that provided by a standard commercial (Internet Service Provider) system; it scored highly for ease of use and the participants reported increased confidence in their ability to master the Internet. Recorded quantitative measures showed fewer task errors. The outcome of the development was a successful \"proof of concept\" search and navigation system for older novice computer users together with approaches to design and development for those who wish to design for this user group."
    },
    {
        "title": "Session details: Mobile applications",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile applications",
        "data": "April 2007",
        "authors": [
            "Scott McCrickard"
        ],
        "DOI": "https://doi.org/10.1145/3258864",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Designing a mobile user interface for automated species identification",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile applications",
        "data": "April 2007",
        "authors": [
            "Sean Michael White",
            "Dominic Marino",
            "Steven Feiner"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240672",
        "citation": "19",
        "abstract": "Biological research in the field is constrained by the speed and difficulty of species determination, as well as by access to relevant information about the species encountered. However, recent work on vision-based algorithms raises the promise of rapid botanical species identification. The potential for mobile vision-based identification provides opportunities for new user interface techniques. To explore these issues, we present LeafView, a Tablet-PC-based user interface for an electronic field guide that supports automated identification of botanical species in the field. We describe a user interface design based on an ethnographic study of botanists, field tests of working prototypes by botanists at the Smithsonian Institution on Plummers Island, Maryland, and observations at an internal exhibition at the Smithsonian at which other staff members tried the prototypes. We present functionality specific to mobile identification and collection in the electronic field guide and use this to motivate discussion of mobile identification in general."
    },
    {
        "title": "BrickRoad: a light-weight tool for spontaneous design of location-enhanced applications",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile applications",
        "data": "April 2007",
        "authors": [
            "Alan L. Liu",
            "Yang Li"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240673",
        "citation": "5",
        "abstract": "It is difficult to design and test location-enhancedapplications. A large part of this difficulty is due to the added complexity of supporting location. Wizard of Oz (WOz) has become an effective technique for the early stage design of location-enhanced applications because it allows designers to test an application prototype bysimulating nonexistent components such as location sensing. However, existing WOz tools 1) require nontrivial effort from designers to specify how a prototype should behave before it can be tested with end users, and 2)support only limited control over application behavior during a test. BrickRoad is a WOz tool for spontaneousdesign of location-enhanced applications. It lowers the threshold to acquiring user feedback and exploring a design space. With BrickRoad, a designer does not need to specify any interaction logic and can experiment on-the-fly with different designs during testing. BrickRoad is a valuable complement to existing tool support for the early stage design of location-enhanced applications."
    },
    {
        "title": "Psychophysical elements of wearability",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile applications",
        "data": "April 2007",
        "authors": [
            "Lucy E. Dunne",
            "Barry Smyth"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240674",
        "citation": "34",
        "abstract": "Wearable technology presents a wealth of new HCI issues. In particular, this paper addresses the impact of the physical interaction between the user's body and the device's physical form on the user's mental representation of self and cognitive abilities, a blend of HCI and ergonomics that is unique to wearable computing. We explore the human sensory mechanisms that facilitate perception of worn objects and the elements of sensation that influence the comfort of worn objects, and discuss the psychological elements that may cause worn objects to be forgotten or detected, wearable or not. We discuss the implications of un-wearability on attention and cognitive capability."
    },
    {
        "title": "The tilt cursor: enhancing stimulus-response compatibility by providing 3d orientation cue of pen",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile applications",
        "data": "April 2007",
        "authors": [
            "Feng Tian",
            "Xiang Ao",
            "Hongan Wang",
            "Vidya Setlur",
            "Guozhong Dai"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240675",
        "citation": "27",
        "abstract": "In order to improve stimulus-response compatibility of touchpad in pen-based user interface, we present the tilt cursor, i.e. a cursor dynamically reshapes itself to providing the 3D orientation cue of pen. We also present two experiments that evaluate the tilt cursor's performance in circular menu selection and specific marking menu selection tasks. Results show that in a specific marking menu selection task, the tilt cursor significantly outperforms the shape-fixed arrow cursor and the live cursor [4]. In addition, results show that by using the tilt cursor, the response latencies for adjusting drawing directions are smaller than that by using the other two kinds of cursors."
    },
    {
        "title": "How younger and older adults master the usage of hyperlinks in small screen devices",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile applications",
        "data": "April 2007",
        "authors": [
            "Martina Ziefle",
            "Ulrik Schroeder",
            "Judith Strenk",
            "Thomas Michel"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240676",
        "citation": "33",
        "abstract": "In this paper we describe an experiment, in which we examined older and younger adults when interacting with a simulated PDA (personal digital assistant). Independent variables were users' age (young vs. older) and device interface (hyperlink vs. no hyperlink). Dependent variables were the effectiveness and efficiency of menu navigation. To understand how user characteristics influence performance, spatial ability, verbal memory, computer expertise and technical self-confidence were determined. Technology experienced young and older adults (benchmark testing) took part. They had to solve four tasks either with hyperlink interface or without hyperlinks in the interface. The method to collect, to automatically analyze and to structure the data according to interaction sequences and presumed user intentions is a novel approach supported by the open source software tool Clever [12]. The tool is briefly described; more details can be found in [23]. Results revealed that hyperlink interfaces showed overall higher effectiveness. However, the impact of hyperlinks for efficiency was age-related. Younger adults strongly benefit from having hyperlinks. The contrary was the case for older adults, who showed higher menu disorientation when using hyperlinks."
    },
    {
        "title": "Session details: Navigation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation",
        "data": "April 2007",
        "authors": [
            "Robert Jacob"
        ],
        "DOI": "https://doi.org/10.1145/3258865",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Modeling steering within above-the-surface interaction layers",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation",
        "data": "April 2007",
        "authors": [
            "Raghavendra S. Kattinakere",
            "Tovi Grossman",
            "Sriram Subramanian"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240678",
        "citation": "26",
        "abstract": "Interaction techniques that utilize the space above the display surface to extend the functionalities of digitized surfaces continue to emerge. In such techniques, movements are constrained by the bounds of a layer. In addition, constraints imposed on the direction of movement within the layer may be present. Despite the presence of such techniques, there is limited understanding of human capabilities for performing the required steering task. In this paper we study and model user performance when steering through constrained and unconstrained paths in above-the-surface layers. Through a series of experiments we validate the derivation and applicability of our proposed models."
    },
    {
        "title": "Quantifying degree of goal directedness in document navigation: application to the evaluation of the perspective-drag technique",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation",
        "data": "April 2007",
        "authors": [
            "Yves Guiard",
            "Yangzhou Du",
            "Olivier Chapuis"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240679",
        "citation": "11",
        "abstract": "This article pursues a two-fold goal. First we introduce degree of goal directedness (DGD), a novel quantitative dimension for the taxonomy of navigation tasks in general. As an attempt to operationalize the DGD concept in the context of electronic documents navigation, we introduce the serial target-acquisition (STA) experimental paradigm. We suggest that DGD and the STA paradigm may usefully enrich the conceptual toolkit of HCI research for the evaluation of navigation techniques. Our second goal is to illustrate the utility of the DGD concept by showing with a concrete example, Perspective Drag, the refinement it allows in evaluating navigation techniques. We report data obtained from two experiments with the STA paradigm that cast light on what Perspective Drag is specifically good for: it is particularly suitable in realistic task contexts where navigation is less than 100% directed by its terminal goal, that is, where the user wants not only to reach a particular item but also to pick up information from the document during document traversal."
    },
    {
        "title": "PageLinker: integrating contextual bookmarks within a browser",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation",
        "data": "April 2007",
        "authors": [
            "Aurélien Tabard",
            "Wendy Mackay",
            "Nicolas Roussel",
            "Catherine Letondal"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240680",
        "citation": "11",
        "abstract": "PageLinker is a browser extension that allows to contextualise navigation by linking web pages together and to navigate through a network of related web pages without prior planning. The design is based on extensive interviews with biologists, which highlighted their difficulties finding previously visited web pages. They found current browser tools inadequate, resulting in poorly organised bookmarks and rarely used history lists. In a four-week controlled field experiment, PageLinker significantly reduced time, page loads and mouse clicks. By presenting links in context, PageLinker facilitates web page revisitation, is less prone to bookmark overload and is highly robust to change."
    },
    {
        "title": "Session details: Photo sharing",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Photo sharing",
        "data": "April 2007",
        "authors": [
            "Jakob Bardram"
        ],
        "DOI": "https://doi.org/10.1145/3258866",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Give and take: a study of consumer photo-sharing culture and practice",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Photo sharing",
        "data": "April 2007",
        "authors": [
            "Andrew D. Miller",
            "W. Keith Edwards"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240682",
        "citation": "166",
        "abstract": "In this paper, we present initial findings from the study of a digital photo-sharing website: Flickr.com. In particular, we argue that Flickr.com appears to support-for some people-a different set of photography practices, socialization styles, and perspectives on privacy that are unlike those described in previous research on consumer and amateur photographers. Further, through our examination of digital photographers' photowork activities-organizing, finding, sharing and receiving-we suggest that privacy concerns and lack of integration with existing communication channels have the potential to prevent the 'Kodak Culture' from fully adopting current photo-sharing solutions."
    },
    {
        "title": "Over-exposed?: privacy patterns and considerations in online and mobile photo sharing",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Photo sharing",
        "data": "April 2007",
        "authors": [
            "Shane Ahern",
            "Dean Eckles",
            "Nathaniel S. Good",
            "Simon King",
            "Mor Naaman",
            "Rahul Nair"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240683",
        "citation": "172",
        "abstract": "As sharing personal media online becomes easier and widely spread, new privacy concerns emerge - especially when the persistent nature of the media and associated context reveals details about the physical and social context in which the media items were created. In a first-of-its-kind study, we use context-aware camerephone devices to examine privacy decisions in mobile and online photo sharing. Through data analysis on a corpus of privacy decisions and associated context data from a real-world system, we identify relationships between location of photo capture and photo privacy settings. Our data analysis leads to further questions which we investigate through a set of interviews with 15 users. The interviews reveal common themes in privacy considerations: security, social disclosure, identity and convenience. Finally, we highlight several implications and opportunities for design of media sharing applications, including using past privacy patterns to prevent oversights and errors."
    },
    {
        "title": "EasyAlbum: an interactive photo annotation system based on face clustering and re-ranking",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Photo sharing",
        "data": "April 2007",
        "authors": [
            "Jingyu Cui",
            "Fang Wen",
            "Rong Xiao",
            "Yuandong Tian",
            "Xiaoou Tang"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240684",
        "citation": "75",
        "abstract": "Digital photo management is becoming indispensable for the explosively growing family photo albums due to the rapid popularization of digital cameras and mobile phone cameras. In an effective photo management system photo annotation is the most challenging task. In this paper, we develop several innovative interaction techniques for semi-automatic photo annotation. Compared with traditional annotation systems, our approach provides the following new features: \"cluster annotation\" puts similar faces or photos with similar scene together, and enables user label them in one operation; \"contextual re-ranking\" boosts the labeling productivity by guessing the user intention; \"ad hoc annotation\" allows user label photos while they are browsing or searching, and improves system performance progressively through learning propagation. Our results show that these technologies provide a more user friendly interface for the annotation of person name, location, and event, and thus substantially improve the annotation performance especially for a large photo album."
    },
    {
        "title": "Session details: Empirical studies of web interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical studies of web interaction",
        "data": "April 2007",
        "authors": [
            "Joanna McGrenere"
        ],
        "DOI": "https://doi.org/10.1145/3258867",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "An exploration of web-based monitoring: implications for design",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical studies of web interaction",
        "data": "April 2007",
        "authors": [
            "Melanie Kellar",
            "Carolyn Watters",
            "Kori M. Inkpen"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240686",
        "citation": "22",
        "abstract": "Monitoring occurs when users return to previously viewed web pages to view new or updated information. While tools exist to support web-based monitoring, we know little about the monitoring activities users engage in and the nature of the support needed. We have conducted 40 semi-structured interviews in order to better understand the types of information users monitor and the characteristics of different monitoring activities. Using the data collected during the interviews, we characterized monitoring as an activity within six web information tasks: Browsing, Communications, Fact Finding, Information Gathering, Maintenance, and Transactions. The results of our study have been used to provide general, as well as task specific, recommendations for the design of monitoring tools."
    },
    {
        "title": "Investigating attractiveness in web user interfaces",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical studies of web interaction",
        "data": "April 2007",
        "authors": [
            "Jan Hartmann",
            "Alistair Sutcliffe",
            "Antonella De Angeli"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240687",
        "citation": "79",
        "abstract": "A theoretical framework for assessing the attractiveness of websites based on Adaptive Decision Making theory is introduced. The framework was developed into a questionnaire and used to evaluate three websites which shared the same brand and topic but differed in aesthetic design. The DSchool site was favoured overall and was best for aesthetics and usability. The subjective ratings of the sites were in conflict with the subject-reported comments on usability problems. Subjects were given two scenarios for their preference. They changed their preference from the DSchool to the HCI Group's site for the more serious (PhD study) scenario; however, design background students remained loyal to the DSchool. The implications of framing and halo effects on users' judgement of aesthetics are discussed."
    },
    {
        "title": "The relationship between accessibility and usability of websites",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical studies of web interaction",
        "data": "April 2007",
        "authors": [
            "Helen Petrie",
            "Omar Kheir"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240688",
        "citation": "158",
        "abstract": "Accessibility and usability are well established concepts for user interfaces and websites. Usability is precisely defined, but there are different approaches to accessibility. In addition, different possible relationships could exist between problems encountered by disabled and non-disabled users, yet little empirical data have been gathered on this question. Guidelines for accessibility and usability of websites provide ratings of the importance of problems for users, yet little empirical data have been gathered to validate these ratings. A study investigated the accessibility of two websites with 6 disabled (blind) and 6 non-disabled (sighted) people. Problems encountered by the two groups comprised two intersecting sets, with approximately 15% overlap. For one of the two websites, blind people rated problems significantly more severely than sighted people. There was high agreement between participants as to the severity of problems, and agreement between participants and researchers. However, there was no significant agreement between either participants or researchers and the importance/priority ratings provided by accessibility and usability guidelines. Practical and theoretical implications of these results are discussed."
    },
    {
        "title": "Session details: Gaze & eye tracking",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gaze & eye tracking",
        "data": "April 2007",
        "authors": [
            "Chris North"
        ],
        "DOI": "https://doi.org/10.1145/3258868",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "What are you looking for?: an eye-tracking study of information usage in web search",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gaze & eye tracking",
        "data": "April 2007",
        "authors": [
            "Edward Cutrell",
            "Zhiwei Guan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240690",
        "citation": "275",
        "abstract": "Web search services are among the most heavily used applications on the World Wide Web. Perhaps because search is used in such a huge variety of tasks and contexts, the user interface must strike a careful balance to meet all user needs. We describe a study that used eye tracking methodologies to explore the effects of changes in the presentation of search results. We found that adding information to the contextual snippet significantly improved performance for informational tasks but degraded performance for navigational tasks. We discuss possible reasons for this difference and the design implications for better presentation of search results."
    },
    {
        "title": "An eye tracking study of the effect of target rank on web search",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gaze & eye tracking",
        "data": "April 2007",
        "authors": [
            "Zhiwei Guan",
            "Edward Cutrell"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240691",
        "citation": "148",
        "abstract": "Web search engines present search results in a rank ordered list. This works when what a user wants is near the top, but sometimes the information that the user really wants is located at the bottom of the page. This study examined how users' search behaviors vary when target results were displayed at various positions for informational and navigational tasks. We found that when targets were placed relatively low in the first page of search results, people spent more time searching and were less successful in finding the target, especially for informational tasks. Further analysis of eye movements showed that the decrease in search performance was partially due to the fact that users rarely looked at lower ranking results. The large decrease in performance for informational search is probably because users have high confidence in the search engine's ranking; in contrast to navigational tasks, where the target is more obvious from information presented in the results, in informational tasks, users try out the top ranked results even if these results are perceived as less relevant for the task."
    },
    {
        "title": "EyePoint: practical pointing and selection using gaze and keyboard",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gaze & eye tracking",
        "data": "April 2007",
        "authors": [
            "Manu Kumar",
            "Andreas Paepcke",
            "Terry Winograd"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240692",
        "citation": "160",
        "abstract": "We present a practical technique for pointing and selection using a combination of eye gaze and keyboard triggers. EyePoint uses a two-step progressive refinement process fluidly stitched together in a look-press-look-release action, which makes it possible to compensate for the accuracy limitations of the current state-of-the-art eye gaze trackers. While research in gaze-based pointing has traditionally focused on disabled users, EyePoint makes gaze-based pointing effective and simple enough for even able-bodied users to use for their everyday computing tasks. As the cost of eye gaze tracking devices decreases, it will become possible for such gaze-based techniques to be used as a viable alternative for users who choose not to use a mouse depending on their abilities, tasks and preferences."
    },
    {
        "title": "A minimal model for predicting visual search in human-computer interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gaze & eye tracking",
        "data": "April 2007",
        "authors": [
            "Tim Halverson",
            "Anthony J. Hornof"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240693",
        "citation": "22",
        "abstract": "Visual search is an important part of human-computer interaction. It is critical that we build theory about how people visually search displays in order to better support the users' visual capabilities and limitations in everyday tasks. One way of building such theory is through computational cognitive modeling. The ultimate promise for cognitive modeling in HCI it to provide the science base needed for predictive interface analysis tools. This paper discusses computational cognitive modeling of the perceptual, strategic, and oculomotor processes people used in a visual search task. This work refines and rounds out previously reported cognitive modeling and eye tracking analysis. A revised \"minimal model\" of visual search is presented that explains a variety of eye movement data better than the original model. The revised model uses a parsimonious strategy that is not tied to a particular visual structure or feature beyond the location of objects. Three characteristics of the minimal strategy are discussed in detail."
    },
    {
        "title": "Session details: Online representation of self",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online representation of self",
        "data": "April 2007",
        "authors": [
            "A. J. Brush"
        ],
        "DOI": "https://doi.org/10.1145/3258869",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "A familiar face(book): profile elements as signals in an online social network",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online representation of self",
        "data": "April 2007",
        "authors": [
            "Cliff A.C. Lampe",
            "Nicole Ellison",
            "Charles Steinfield"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240695",
        "citation": "310",
        "abstract": "Using data from a popular online social network site, this paper explores the relationship between profile structure (namely, which fields are completed) and number of friends, giving designers insight into the importance of the profile and how it works to encourage connections and articulated relationships between users. We describe a theoretical framework that draws on aspects of signaling theory, common ground theory, and transaction costs theory to generate an understanding of why certain profile fields may be more predictive of friendship articulation on the site. Using a dataset consisting of 30,773 Facebook profiles, we determine which profile elements are most likely to predict friendship links and discuss the theoretical and design implications of our findings."
    },
    {
        "title": "Constructing my online self: avatars that increase self-focused attention",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online representation of self",
        "data": "April 2007",
        "authors": [
            "Asimina Vasalou",
            "Adam N. Joinson",
            "Jeremy Pitt"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240696",
        "citation": "37",
        "abstract": "Three studies investigated whether users' strategies for customising online avatars increase their self-focused attention, also known as private self-awareness. Study 1 showed that a high number of users adapt their avatars toreflect their own appearance. Study 2 demonstrated that users who perceive their avatars to be similar to their own appearance experience as a result heightened private self-awareness. In Study 3, private self-awareness pervadedsocial interaction taking place over time when users with representative avatars, compared to a control group, reported increased private self-awareness. Drawing from research in interpersonal communication, we suggest that avatars which increase their owners' self-focus may have an influence on online behavior in the context of social computing."
    },
    {
        "title": "The truth about lying in online dating profiles",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online representation of self",
        "data": "April 2007",
        "authors": [
            "Jeffrey T. Hancock",
            "Catalina Toma",
            "Nicole Ellison"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240697",
        "citation": "137",
        "abstract": "Online dating is a popular new tool for initiating romantic relationships, although recent research and media reports suggest that it may also be fertile ground for deception. Unlike previous studies that rely solely on self-report data, the present study establishes ground truth for 80 online daters' height, weight and age, and compares ground truth data to the information provided in online dating profiles. The results suggest that deception is indeed frequently observed, but that the magnitude of the deceptions is usually small. As expected, deceptions differ by gender. Results are discussed in light of the Hyperpersonal model and the self-presentational tensions experienced by online dating participants."
    },
    {
        "title": "He says, she says: conflict and coordination in Wikipedia",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online representation of self",
        "data": "April 2007",
        "authors": [
            "Aniket Kittur",
            "Bongwon Suh",
            "Bryan A. Pendleton",
            "Ed H. Chi"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240698",
        "citation": "348",
        "abstract": "Wikipedia, a wiki-based encyclopedia, has become one of the most successful experiments in collaborative knowledge building on the Internet. As Wikipedia continues to grow, the potential for conflict and the need for coordination increase as well. This article examines the growth of such non-direct work and describes the development of tools to characterize conflict and coordination costs in Wikipedia. The results may inform the design of new collaborative knowledge systems."
    },
    {
        "title": "Session details: Innovative interactions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovative interactions",
        "data": "April 2007",
        "authors": [
            "Ian Smith"
        ],
        "DOI": "https://doi.org/10.1145/3258870",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Modeling pointing at targets of arbitrary shapes",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovative interactions",
        "data": "April 2007",
        "authors": [
            "Tovi Grossman",
            "Nicholas Kong",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240700",
        "citation": "21",
        "abstract": "We investigate pointing at graphical targets of arbitrary shapes. We first describe a previously proposed probabilistic Fitts' law model [7] which, unlike previous models that only account for rectangular targets, has the potential to handle arbitrary shapes. Three methods of defining the centers of arbitrarily shaped targets for use within the model are developed. We compare these methods of defining target centers, and validate the model using a pointing experiment in which the targets take on various shapes. Results show that the model can accurately account for the varying target shapes. We discuss the implications of our results to interface design."
    },
    {
        "title": "Perception of elementary graphical elements in tabletop and multi-surface environments",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovative interactions",
        "data": "April 2007",
        "authors": [
            "Daniel Wigdor",
            "Chia Shen",
            "Clifton Forlines",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240701",
        "citation": "40",
        "abstract": "Information shown on a tabletop display can appear distorted when viewed by a seated user. Even worse, the impact of this distortion is different depending on the location of the information on the display. In this paper, we examine how this distortion affects the perception of the basic graphical elements of information visualization shown on displays at various angles. We first examine perception of these elements on a single display, and then compare this to perception across displays, in order to evaluate the effectiveness of various elements for use in a tabletop and multi-display environment. We found that the perception of some graphical elements is more robust to distortion than others. We then develop recommendations for building data visualizations for these environments."
    },
    {
        "title": "Exploring and reducing the effects of orientation on text readability in volumetric displays",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovative interactions",
        "data": "April 2007",
        "authors": [
            "Tovi Grossman",
            "Daniel Wigdor",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240702",
        "citation": "12",
        "abstract": "Volumetric displays, which provide a 360° view of imagery illuminated in true 3D space, are a promising platform for interactive 3D applications. However, presenting text in volumetric displays can be a challenge, as the text may not be oriented towards the user. This is especially problematic with multiple viewers, as the text could, for example, appear forwards to one user, and backwards to another. In a first experiment we determined the effects of 3D rotations on text readability. Based on the results, we developed and evaluated a new technique which optimizes text orientation for multiple viewers. This technique provided 33% faster group reading times in a collaborative experimental task."
    },
    {
        "title": "Session details: Design theory",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design theory",
        "data": "April 2007",
        "authors": [
            "Jon Kolko"
        ],
        "DOI": "https://doi.org/10.1145/3258871",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Research through design as a method for interaction design research in HCI",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design theory",
        "data": "April 2007",
        "authors": [
            "John Zimmerman",
            "Jodi Forlizzi",
            "Shelley Evenson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240704",
        "citation": "1,105",
        "abstract": "For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research."
    },
    {
        "title": "Sustainable interaction design: invention & disposal, renewal & reuse",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design theory",
        "data": "April 2007",
        "authors": [
            "Eli Blevis"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240705",
        "citation": "427",
        "abstract": "This paper presents the perspective that sustainability can and should be a central focus of interaction design-a perspective that is termed Sustainable Interaction Design (SID). As a starting point for a perspective of sustainability, design is defined as an act of choosing among or informing choices of future ways of being. This perspective of sustainability is presented in terms of design values, methods, and reasoning. The paper proposes (i) a rubric for understanding the material effects of particular interaction design cases in terms of forms of use, reuse, and disposal, and (ii) several principles to guide SID. The paper illustrates--with particular examples of design critique for interactive products and appeals to secondary research--how two of these principles may be applied to move the effects of designs from less preferred forms of use to more preferred ones. Finally, a vision for incorporating sustainability into the research and practice of interaction design is described."
    },
    {
        "title": "Computational composites",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design theory",
        "data": "April 2007",
        "authors": [
            "Anna Vallgårda",
            "Johan Redström"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240706",
        "citation": "157",
        "abstract": "Computational composite is introduced as a new type of composite material. Arguing that this is not just a metaphorical maneuver, we provide an analysis of computational technology as material in design, which shows how computers share important characteristics with other materials used in design and architecture. We argue that the notion of computational composites provides a precise understanding of the computer as material, and of how computations need to be combined with other materials to come to expression as material. Besides working as an analysis of computers from a designer's point of view, the notion of computational composites may also provide a link for computer science and human-computer interaction to an increasingly rapid development and use of new materials in design and architecture."
    },
    {
        "title": "Session details: Play & exercise",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Play & exercise",
        "data": "April 2007",
        "authors": [
            "Elizabeth Goodman"
        ],
        "DOI": "https://doi.org/10.1145/3258872",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Jogging the distance",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Play & exercise",
        "data": "April 2007",
        "authors": [
            "Shannon O'Brien",
            "Florian \"Floyd\" Mueller"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240708",
        "citation": "53",
        "abstract": "People enjoy jogging with others for social and motivational reasons. However, as reported by forum participants, finding a compatible, local jogging partner who shares the ability to jog at the same pace for the same duration is not always easy. One possible way to overcome this challenge is to expand the range of potential jogging partners by allowing for interaction with remote joggers. We investigated whether a jogging experience supporting conversation between remote partners could be desirable and motivating. We conducted an experiment with 18 volunteers using conventional mobile phones with headsets to support conversations as participants jogged in disjoint, outdoor areas. Results show that a simple audio connection supports participants' need to socialize and allows partners to encourage each other."
    },
    {
        "title": "Session details: Home spirituality",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home spirituality",
        "data": "April 2007",
        "authors": [
            "Michael Muller"
        ],
        "DOI": "https://doi.org/10.1145/3258873",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Sabbath day home automation: \"it's like mixing technology and religion\"",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home spirituality",
        "data": "April 2007",
        "authors": [
            "Allison Woodruff",
            "Sally Augustin",
            "Brooke Foucault"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240710",
        "citation": "138",
        "abstract": "We present a qualitative study of 20 American Orthodox Jewish families' use of home automation for religious purposes. These lead users offer insight into real-life, long-term experience with home automation technologies. We discuss how automation was seen by participants to contribute to spiritual experience and how participants oriented to the use of automation as a religious custom. We also discuss the relationship of home automation to family life. We draw design implications for the broader population, including surrender of control as a design resource, home technologies that support long-term goals and lifestyle choices, and respite from technology."
    },
    {
        "title": "Enhancing ubiquitous computing with user interpretation: field testing the home health horoscope",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home spirituality",
        "data": "April 2007",
        "authors": [
            "William Gaver",
            "Phoebe Sengers",
            "Tobie Kerridge",
            "Joseph Kaye",
            "John Bowers"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240711",
        "citation": "62",
        "abstract": "Domestic ubiquitous computing systems often rely on inferences about activities in the home, but the open-ended, dynamic and heterogeneous nature of the home poses serious problems for such systems. In this paper, we propose that by shifting the responsibility for interpretation from the system to the user, we can build systems that interact with people at humanly meaningful levels, preserve privacy, and encourage engagement with suggested topics. We describe a system that embodies this hypothesis, using sensors and inferencing software to assess 'domestic wellbeing' and presenting the results to inhabitants through an output chosen for its ambiguity. In a three-month field study of the system, customised for a particular volunteer household, users engaged extensively with the system, discussing and challenging its outputs and responding to the particular topics it raised."
    },
    {
        "title": "Home networking and HCI: what hath god wrought?",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home spirituality",
        "data": "April 2007",
        "authors": [
            "Erika Shehan",
            "W. Keith Edwards"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240712",
        "citation": "38",
        "abstract": "For much of the industrialized world, network connectivity in the home is commonplace. Despite the large number of networked homes, even the most technically savvy people can have difficulties with home network installation and maintenance. We contend that these problems will not disappear over time as the networking industry matures, but rather are due to structural usability flaws inherent in the design of existing network infrastructure, devices, and protocols. The HCI community can offer a unique perspective to overcoming the challenges associated with home networking. This paper discusses why home networking is difficult, based on analysis of historical, social, and technical factors. It explores how the designs of existing home networking technologies have implications for usability, and examines a range of models for addressing these usability challenges. The paper concludes with a discussion of how these models may impact future research efforts in both HCI and networking."
    },
    {
        "title": "Session details: Programming by professionals",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by professionals",
        "data": "April 2007",
        "authors": [
            "Margaret Burnett"
        ],
        "DOI": "https://doi.org/10.1145/3258874",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Let's go to the whiteboard: how and why software developers use drawings",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by professionals",
        "data": "April 2007",
        "authors": [
            "Mauro Cherubini",
            "Gina Venolia",
            "Rob DeLine",
            "Amy J. Ko"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240714",
        "citation": "154",
        "abstract": "Software developers are rooted in the written form of their code, yet they often draw diagrams representing their code. Unfortunately, we still know little about how and why they create these diagrams, and so there is little research to inform the design of visual tools to support developers' work. This paper presents findings from semi-structured interviews that have been validated with a structured survey. Results show that most of the diagrams had a transient nature because of the high cost of changing whiteboard sketches to electronic renderings. Diagrams that documented design decisions were often externalized in these temporary drawings and then subsequently lost. Current visualization tools and the software development practices that we observed do not solve these issues, but these results suggest several directions for future research."
    },
    {
        "title": "Aligning development tools with the way programmers think about code changes",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by professionals",
        "data": "April 2007",
        "authors": [
            "Marat Boshernitsan",
            "Susan L. Graham",
            "Marti A. Hearst"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240715",
        "citation": "29",
        "abstract": "Software developers must modify their programs to keepup with changing requirements and designs. Often, aconceptually simple change can require numerous editsthat are similar but not identical, leading to errors andomissions. Researchers have designed programming environmentsto address this problem, but most of thesesystems are counter-intuitive and difficult to use.By applying a task-centered design process, we developeda visual tool that allows programmers to makecomplex code transformations in an intuitive manner.This approach uses a representation that aligns wellwith programmers' mental models of programming structures.The visual language combines textual and graphicalelements and is expressive enough to support a broadrange of code-changing tasks. To simplify learning thesystem, its user interface scaffolds construction and executionof transformations. An evaluation with Java programmerssuggests that the interface is intuitive, easyto learn, and effective on a representative editing task."
    },
    {
        "title": "Task and social visualization in software development: evaluation of a prototype",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by professionals",
        "data": "April 2007",
        "authors": [
            "Jason B. Ellis",
            "Shahtab Wahid",
            "Catalina Danis",
            "Wendy A. Kellogg"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240716",
        "citation": "12",
        "abstract": "As open source development has evolved, differentiation of roles and increased sophistication of collaborative processes has occurred. Recently, we described coordination issues in software development and an interactive visualization tool called the Social Health Overview (SHO) developed to address them [12]. This paper presents an empirical evaluation of SHO intended to identify its strengths and weaknesses. Eleven informants in various open source roles were interviewed about their work practices. Eight of these participated in an evaluation comparing three change management tasks in SHO and Bugzilla. Results are discussed with respect to task strategy with each tool and participants' roles."
    },
    {
        "title": "Session details: Web usability",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Web usability",
        "data": "April 2007",
        "authors": [
            "Ed Chi"
        ],
        "DOI": "https://doi.org/10.1145/3258875",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "IGroup: presenting web image search results in semantic clusters",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Web usability",
        "data": "April 2007",
        "authors": [
            "Shuo Wang",
            "Feng Jing",
            "Jibo He",
            "Qixing Du",
            "Lei Zhang"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240718",
        "citation": "44",
        "abstract": "Current web image search engines still rely on user typing textual description: query word(s) for visual targets. As the queries are often short, general or even ambiguous, the images in resulting pages vary in content and style. Thus, browsing with these results is likely to be tedious, frustrating and unpredictable."
    },
    {
        "title": "Web page revisitation revisited: implications of a long-term click-stream study of browser usage",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Web usability",
        "data": "April 2007",
        "authors": [
            "Hartmut Obendorf",
            "Harald Weinreich",
            "Eelco Herder",
            "Matthias Mayer"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240719",
        "citation": "123",
        "abstract": "This paper presents results of an extensive long-term click-stream study of Web browser usage. Focusing on character and challenges of page revisitation, previous findings from seven to thirteen years ago are updated. The term page re-visit had to be differentiated, since the recurrence rate--the key measure for the share of page revisits--turns out to strongly depend on interpretation. We identify different types of revisitation that allow assessing the quality of current user support and developing concepts for new tools."
    },
    {
        "title": "Noticing notice: a large-scale experiment on the timing of software license agreements",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Web usability",
        "data": "April 2007",
        "authors": [
            "Nathaniel S. Good",
            "Jens Grossklags",
            "Deirdre K. Mulligan",
            "Joseph A. Konstan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240720",
        "citation": "56",
        "abstract": "Spyware is an increasing problem. Interestingly, many programs carrying spyware honestly disclose the activities of the software, but users install the software anyway. We report on a study of software installation to assess the effectiveness of different notices for helping people make better decisions on which software to install. Our study of 222 users showed that providing a short summary notice, in addition to the End User License Agreement (EULA), before the installation reduced the number of software installations significantly. We also found that providing the short summary notice after installation led to a significant number of uninstalls. However, even with the short notices, many users installed the program and later expressed regret for doing so. These results, along with a detailed analysis of installation, regret, and survey data about user behaviors informs our recommendations to policymakers and designers for assessing the \"adequacy\" of consent in the context of software that exhibits behaviors associated with spyware."
    },
    {
        "title": "Session details: Empirical models",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical models",
        "data": "April 2007",
        "authors": [
            "Ann Blandford"
        ],
        "DOI": "https://doi.org/10.1145/3258876",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Meta-analysis of correlations among usability measures",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical models",
        "data": "April 2007",
        "authors": [
            "Kasper Hornbæk",
            "Effie Lai-Chong Law"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240722",
        "citation": "118",
        "abstract": "Understanding the relation between usability measures seems crucial to deepen our conception of usability and to select the right measures for usability studies. We present a meta-analysis of correlations among usability measures calculated from the raw data of 73 studies. Correlations are generally low: effectiveness measures (e.g., errors) and efficiency measures (e.g., time) have a correlation of .247 ± .059 (Pearson's product-moment correlation with 95% confidence interval), efficiency and satisfaction (e.g., preference) one of .196 ± .064, and effectiveness and satisfaction one of .164 ± .062. Changes in task complexity do not influence these correlations, but use of more complex measures attenuates them. Standard questionnaires for measuring satisfaction appear more reliable than homegrown ones. Measures of users' perceptions of phenomena are generally not correlated with objective measures of the phenomena. Implications for how to measure usability are drawn and common models of usability are criticized."
    },
    {
        "title": "A predictive model of menu performance",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical models",
        "data": "April 2007",
        "authors": [
            "Andy Cockburn",
            "Carl Gutwin",
            "Saul Greenberg"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240723",
        "citation": "166",
        "abstract": "Menus are a primary control in current interfaces, but there has been relatively little theoretical work to model their performance. We propose a model of menu performance that goes beyond previous work by incorporating components for Fitts' Law pointing time, visual search time when novice, Hick-Hyman Law decision time when expert, and for the transition from novice to expert behaviour. The model is able to predict performance for many different menu designs, including adaptive split menus, items with different frequencies and sizes, and multi-level menus. We tested the model by comparing predictions for four menu designs (traditional menus, recency and frequency based split menus, and an adaptive 'morphing' design) with empirical measures. The empirical data matched the predictions extremely well, suggesting that the model can be used to explore a wide range of menu possibilities before implementation."
    },
    {
        "title": "Endpoint prediction using motion kinematics",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empirical models",
        "data": "April 2007",
        "authors": [
            "Edward Lank",
            "Yi-Chun Nikko Cheng",
            "Jaime Ruiz"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240724",
        "citation": "71",
        "abstract": "Recently proposed novel interaction techniques such as cursor jumping [1] and target expansion for tiled arrangements [13] are predicated on an ability to effectively estimate the endpoint of an input gesture prior to its completion. However, current endpoint estimation techniques lack the precision to make these interaction techniques possible. To address a recognized lack of effective endpoint prediction mechanisms, we propose a new technique for endpoint prediction that applies established laws of motion kinematics in a novel way to the identification of motion endpoint. The technique derives a model of speed over distance that permits extrapolation. We verify our model experimentally using stylus targeting tasks, and demonstrate that our endpoint prediction is almost twice as accurate as the previously tested technique [13] at points more than twice as distant from motion endpoint."
    },
    {
        "title": "Session details: Mobile interaction techniques I",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction techniques I",
        "data": "April 2007",
        "authors": [
            "Stephen Brewster"
        ],
        "DOI": "https://doi.org/10.1145/3258877",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Direct-touch vs. mouse input for tabletop displays",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction techniques I",
        "data": "April 2007",
        "authors": [
            "Clifton Forlines",
            "Daniel Wigdor",
            "Chia Shen",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240726",
        "citation": "231",
        "abstract": "We investigate the differences -- in terms of bothquantitative performance and subjective preference -- between direct-touch and mouse input for unimanual andbimanual tasks on tabletop displays. The results of twoexperiments show that for bimanual tasks performed ontabletops, users benefit from direct-touch input. However,our results also indicate that mouse input may be moreappropriate for a single user working on tabletop tasksrequiring only single-point interaction."
    },
    {
        "title": "Shift: a technique for operating pen-based interfaces using touch",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction techniques I",
        "data": "April 2007",
        "authors": [
            "Daniel Vogel",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240727",
        "citation": "320",
        "abstract": "Retrieving the stylus of a pen-based device takes time and requires a second hand. Especially for short intermittent interactions many users therefore choose to use their bare fingers. Although convenient, this increases targeting times and error rates. We argue that the main reasons are the occlusion of the target by the user's finger and ambiguity about which part of the finger defines the selection point. We propose a pointing technique we call Shift that is designed to address these issues. When the user touches the screen, Shift creates a callout showing a copy of the occluded screen area and places it in a non-occluded location. The callout also shows a pointer representing the selection point of the finger. Using this visual feedback, users guide the pointer into the target by moving their finger on the screen surface and commit the target acquisition by lifting the finger. Unlike existing techniques, Shift is only invoked when necessary--over large targets no callout is created and users enjoy the full performance of an unaltered touch screen. We report the results of a user study showing that with Shift participants can select small targets with much lower error rates than an unaided touch screen and that Shift is faster than Offset Cursor for larger targets."
    },
    {
        "title": "An alternative to push, press, and tap-tap-tap: gesturing on an isometric joystick for mobile phone text entry",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction techniques I",
        "data": "April 2007",
        "authors": [
            "Jacob O. Wobbrock",
            "Duen Horng Chau",
            "Brad A. Myers"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240728",
        "citation": "25",
        "abstract": "A gestural text entry method for mobile is presented. Unlike most mobile phone text entry methods, which rely on repeatedly pressing buttons, our gestural method uses an isometric joystick and the EdgeWrite alphabet to allow users to write by making letter-like \"pressure strokes.\" In a 15-session study comparing character-level EdgeWrite to Multitap, subjects' speeds were statistically indistinguishable, reaching about 10 WPM. In a second 15-session study comparing word-level EdgeWrite to T9, the same subjects were again statistically indistinguishable, reaching about 16 WPM. Uncorrected errors were low, around 1% or less for each method. In addition, subjective results favored EdgeWrite. Overall, results indicate that our isometric joystick-based method is highly competitive with two commercial keypad-based methods, opening the way for keypad-less designs and text entry on tiny devices. Additional results showed that a joystick on the back could be used at about 70% of the speed of the front, and the front joystick could be used eyes-free at about 80% of the speed of normal use."
    },
    {
        "title": "Session details: Tasks",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tasks",
        "data": "April 2007",
        "authors": [
            "Scott Klemmer"
        ],
        "DOI": "https://doi.org/10.1145/3258878",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Disruption and recovery of computing tasks: field study, analysis, and directions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tasks",
        "data": "April 2007",
        "authors": [
            "Shamsi T. Iqbal",
            "Eric Horvitz"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240730",
        "citation": "176",
        "abstract": "We report on a field study of the multitasking behavior of computer users focused on the suspension and resumption of tasks. Data was collected with a tool that logged users' interactions with software applications and their associated windows, as well as incoming instant messaging and email alerts. We describe methods, summarize results, and discuss design guidelines suggested by the findings."
    },
    {
        "title": "CAAD: an automatic task support system",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tasks",
        "data": "April 2007",
        "authors": [
            "Tye Rattenbury",
            "John Canny"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240731",
        "citation": "43",
        "abstract": "Recent HCI research shows strong interest in task management systems (e.g. [19, 27]) that support the multi-tasked nature of information work [13]. These systems either require users to manually create and maintain task representations or they depend on explicit user cues to guide the creation and maintenance process. To access and use the task representations in these systems, users must also specify their current task. This interaction overhead inhibits the adoption of these systems. In this paper, we present a novel approach to task management that automates the creation and maintenance of task representations. Our system supports the user by making commonly used information more \"ready-at-hand\" through an intuitive visualization of their task representations. Users can correct and organize their task representations by directly manipulating the visualization; however, this interaction is not required. We describe a feasibility study that demonstrates the actual utility (in terms of overhead reduction) and perceived utility of our system."
    },
    {
        "title": "Understanding and developing models for detecting and differentiating breakpoints during interactive tasks",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tasks",
        "data": "April 2007",
        "authors": [
            "Shamsi T. Iqbal",
            "Brian P. Bailey"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240732",
        "citation": "54",
        "abstract": "The ability to detect and differentiate breakpoints during task execution is critical for enabling defer-to-breakpoint policies within interruption management. In this work, we examine the feasibility of building statistical models that can detect and differentiate three granularities (types) of perceptually meaningful breakpoints during task execution, without having to recognize the underlying tasks. We collected ecological samples of task execution data, and asked observers to review the interaction in the collected videos and identify any perceived breakpoints and their type. Statistical methods were applied to learn models that map features of the interaction to each type of breakpoint. Results showed that the models were able to detect and differentiate breakpoints with reasonably high accuracy across tasks. Among many uses, our resulting models can enable interruption management systems to better realize defer-to-breakpoint policies for interactive, free-form tasks."
    },
    {
        "title": "Session details: Emergency action",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emergency action",
        "data": "April 2007",
        "authors": [
            "John Carroll"
        ],
        "DOI": "https://doi.org/10.1145/3258879",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Implicit coordination in firefighting practice: design implications for teaching fire emergency responders",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emergency action",
        "data": "April 2007",
        "authors": [
            "Phoebe O. Toups Dugas",
            "Andruid Kerne"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240734",
        "citation": "54",
        "abstract": "Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues."
    },
    {
        "title": "Back stage on the front lines: perspectives and performance in the combat information center",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emergency action",
        "data": "April 2007",
        "authors": [
            "Paul M. Aoki"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240735",
        "citation": "8",
        "abstract": "While tactical command. control and communication environments might appear to be entirely instrumental in nature, they nevertheless provide a setting for social interaction. This paper describes how such interaction occurs in a particular naval tactical command and control system, focusing on the shared perspectives created by the organizational, administrative and professional aspects of the environment and on issues of self-presentation. It is argued that the complexity and multiplicity of interactional regions in this environment lead to problematic situations for key actors, and that these problems may have relevance to future computing environments."
    },
    {
        "title": "Citizen communications in crisis: anticipating a future of ICT-supported public participation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emergency action",
        "data": "April 2007",
        "authors": [
            "Leysia Palen",
            "Sophia B. Liu"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240736",
        "citation": "240",
        "abstract": "Recent world-wide crisis events have drawn new attention to the role information communication technology (ICT) can play in warning and response activities. Drawing on disaster social science, we consider a critical aspect of post-impact disaster response that does not yet receive much information science research attention. Public participation is an emerging, large-scale arena for computer-mediated interaction that has implications for both informal and formal response. With a focus on persistent citizen communications as one form of interaction in this arena, we describe their spatial and temporal arrangements, and how the emerging information pathways that result serve different post-impact functions. However, command-and-control models do not easily adapt to the expanding data-generating and -seeking activities by the public. ICT in disaster contexts will give further rise to improvised activities and temporary organizations with which formal response organizations need to align."
    },
    {
        "title": "Session details: Design methods",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design methods",
        "data": "April 2007",
        "authors": [
            "Steve Harrison"
        ],
        "DOI": "https://doi.org/10.1145/3258880",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Transfer scenarios: grounding innovation with marginal practices",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design methods",
        "data": "April 2007",
        "authors": [
            "Sara Ljungblad",
            "Lars Erik Holmquist"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240738",
        "citation": "54",
        "abstract": "Transfer scenarios is a method developed to support the design of innovative interactive technology. Such a method should help the designer to come up with inventive ideas, and at the same time provide grounding in real human needs. In transfer scenarios, we use marginal practices to encourage a changed mindset throughout the design process. A marginal practice consists of individuals who share an activity that they find meaningful. We regard these individuals not as end-users, but as valuable input in the design process. We applied this method when designing novel applications for autonomous embodied agents, e.g. robots. Owners of unusual pets, such as snakes and spiders, were interviewed - not with the intention to design robot pets, but to determine underlying needs and interests of their practice. The results were then used to design a set of applications for more general users, including a dynamic living-room wall and a set of communicating hobby robots."
    },
    {
        "title": "Work-centered design: a case study of a mixed-initiative scheduler",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design methods",
        "data": "April 2007",
        "authors": [
            "Keith A. Butler",
            "Jiajie Zhang",
            "Chris Esposito",
            "Ali Bahrami",
            "Ron Hebron",
            "David Kieras"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240739",
        "citation": "24",
        "abstract": "We present the case study of a complex, mixed-initiative scheduling system to illustrate Work-Centered Design (WCD), a new approach for the design of information systems. WCD is based on theory of distributed cognition and extends established user-centered methods with abstract task modeling, using innovative techniques for work ontology and top-level algorithms to capture the logic of a human-computer interaction paradigm. WCD addresses a long-standing need for more effective methods of function allocation. The illustrating case study succeeded on a large, difficult problem for aircraft scheduling where prior expensive attempts failed. The new system, called Solver, reduces scheduling labor from 9 person-days a week to about 1 person-hour. These results were obtained from the first user test, demonstrating notable effectiveness of WCD. Further, the value of Solver's higher quality schedules is far-reaching. WCD extends HCI methods to fill an important need for technical problem-solving systems."
    },
    {
        "title": "Session details: Mobile interaction techniques II",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction techniques II",
        "data": "April 2007",
        "authors": [
            "Shumin Zhai"
        ],
        "DOI": "https://doi.org/10.1145/3258881",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Pointing lenses: facilitating stylus input through visual-and motor-space magnification",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction techniques II",
        "data": "April 2007",
        "authors": [
            "Gonzalo Ramos",
            "Andy Cockburn",
            "Ravin Balakrishnan",
            "Michel Beaudouin-Lafon"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240741",
        "citation": "43",
        "abstract": "Using a stylus on a tablet computer to acquire small targets can be challenging. In this paper we present pointing lenses -- interaction techniques that help users acquire and select targets by presenting them with an enlarged visual and interaction area. We present and study three pointing lenses for pen-based systems and find that our proposed Pressure-Activated Lens is the top overall performer in terms of speed, accuracy and user preference. In addition, our experimental results not only show that participants find all pointing lenses beneficial for targets smaller than 5 pixels, but they also suggest that this benefit may extend to larger targets as well."
    },
    {
        "title": "Comparing physical, automatic and manual map rotation for pedestrian navigation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile interaction techniques II",
        "data": "April 2007",
        "authors": [
            "Will Seager",
            "Danae Stanton Fraser"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240742",
        "citation": "36",
        "abstract": "It is well-established finding that people find maps easier to use when they are aligned so that \"up\" on the map corresponds to the user's forward direction. With map-based applications on handheld mobile devices, this forward/up correspondence can be maintained in several ways: the device can be physically rotated within the user's hands or the user can manually operate buttons to digitally rotate the map; alternatively, the map can be rotated automatically using data from an electronic compass. This paper examines all three options. In a field experiment, each method is compared against a baseline north-up condition. The study provides strong evidence that physical rotation is the most effective with applications that present the user with a wider map. The paper concludes with some suggestions for design improvements."
    },
    {
        "title": "Session details: Tangibility",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangibility",
        "data": "April 2007",
        "authors": [
            "Chia Shen"
        ],
        "DOI": "https://doi.org/10.1145/3258882",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Senspectra: a computationally augmented physical modeling toolkit for sensing and visualization of structural strain",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangibility",
        "data": "April 2007",
        "authors": [
            "Vincent LeClerc",
            "Amanda Parkes",
            "Hiroshi Ishii"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240744",
        "citation": "13",
        "abstract": "We present Senspectra, a computationally augmented physical modeling toolkit designed for sensing and visualization of structural strain. Senspectra seeks to explore a new direction in computational materiality, incorporating the material quality of malleable elements of an interface into its digital control structure. The system functions as a decentralized sensor network consisting of nodes, embedded with computational capabilities and a full spectrum LED, and flexible joints. Each joint functions as an omnidirectional bend sensing mechanism to sense and communicate mechanical strain between neighboring nodes."
    },
    {
        "title": "Tangible user interface for chemistry education: comparative evaluation and re-design",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangibility",
        "data": "April 2007",
        "authors": [
            "Morten Fjeld",
            "Jonas Fredriksson",
            "Martin Ejdestig",
            "Florin Duca",
            "Kristina Bötschi",
            "Benedikt Voegtli",
            "Patrick Juchli"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240745",
        "citation": "58",
        "abstract": "Augmented Chemistry (AC) is an application that utilizes a tangible user interface (TUI) for organic chemistry education. The empirical evaluation described in this paper compares learning effectiveness and user acceptance of AC versus the more traditional ball-and-stick model (BSM). Learning effectiveness results were almost the same for both learning environments. User preference and rankings, using NASA-TLX and SUMI, showed more differences and it was therefore decided to focus mainly on improving these aspects in a re-design of the AC system. For enhanced interaction, keyboard-free system configuration, and internal/external database (DB) access, a graphical user interface (GUI) has been incorporated into the TUI. Three-dimensional (3D) rendering has also been improved using shadows and related effects, thereby enhancing depth perception. The re-designed AC system was then compared to the old system by means of a small qualitative user study. This user study showed an improvement in subjective opinions a out the system's ease of use and ease of learning."
    },
    {
        "title": "Mechanical constraints as computational constraints in tabletop tangible interfaces",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangibility",
        "data": "April 2007",
        "authors": [
            "James Patten",
            "Hiroshi Ishii"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240746",
        "citation": "83",
        "abstract": "This paper presents a new type of human-computer interface called Pico (Physical Intervention in Computational Optimization) based on mechanical constraints that combines some of the tactile feedback and affordances of mechanical systems with the abstract computational power of modern computers. The interface is based on a tabletop interaction surface that can sense and move small objects on top of it. The positions of these physical objects represent and control parameters inside a software application, such as a system for optimizing the configuration of radio towers in a cellular telephone network. The computer autonomously attempts to optimize the network, moving the objects on the table as it changes their corresponding parameters in software. As these objects move, the user can constrain their motion with his or her hands, or many other kinds of physical objects. The interface provides ample opportunities for improvisation by allowing the user to employ a rich variety of everyday physical objects as mechanical constraints. This approach leverages the user's mechanical intuition for how objects respond to physical forces. As well, it allows the user to balance the numerical optimization performed by the computer with other goals that are difficult to quantify. Subjects in an evaluation were more effective at solving a complex spatial layout problem using this system than with either of two alternative interfaces that did not feature actuation."
    },
    {
        "title": "Intimate interfaces in action: assessing the usability and subtlety of emg-based motionless gestures",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangibility",
        "data": "April 2007",
        "authors": [
            "Enrico Costanza",
            "Samuel A. Inverso",
            "Rebecca Allen",
            "Pattie Maes"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240747",
        "citation": "50",
        "abstract": "Mobile communication devices, such as mobile phones and networked personal digital assistants (PDAs), allow users to be constantly connected and communicate anywhere and at any time, often resulting in personal and private communication taking place in public spaces. This private -- public contrast can be problematic. As a remedy, we promote intimate interfaces: interfaces that allow subtle and minimal mobile interaction, without disruption of the surrounding environment. In particular, motionless gestures sensed through the electromyographic (EMG) signal have been proposed as a solution to allow subtle input in a mobile context. In this paper we present an expansion of the work on EMG-based motionless gestures including (1) a novel study of their usability in a mobile context for controlling a realistic, multimodal interface and (2) a formal assessment of how noticeable they are to informed observers. Experimental results confirm that subtle gestures can be profitably used within a multimodal interface and that it is difficult for observers to guess when someone is performing a gesture, confirming the hypothesis of subtlety."
    },
    {
        "title": "Session details: Games",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2007",
        "authors": [
            "Carl Gutwin"
        ],
        "DOI": "https://doi.org/10.1145/3258883",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Project massive: self-regulation and problematic use of online gaming",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2007",
        "authors": [
            "A. Fleming Seay",
            "Robert E. Kraut"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240749",
        "citation": "57",
        "abstract": "A longitudinal design was employed to collect three waves of survey data over a 14 month period from 2790 online gamers. Respondents were asked questions about their gaming activity, motivations, personality, social and emotional environment, and the effect gaming has had on their lives. Prospective analysis was used to establish causal and temporal linkages among the repeatedly measured factors. While the data provide some indication that a player's reasons for playing do influence the development of problematic usage, these effects are overshadowed by the central importance of self-regulation in managing both the timing and amount of play. An individual's level of self-regulatory activity is shown to be very important in allowing them to avoid negative outcomes like problematic use. The role of depression is also discussed. With responsible use, online gaming appears to be a healthy recreational activity that provides millions of people with hours of social entertainment and adaptive diversion. However, failure to manage play behavior can lead to feelings of dependency."
    },
    {
        "title": "The life and death of online gaming communities: a look at guilds in world of warcraft",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2007",
        "authors": [
            "Nicolas Ducheneaut",
            "Nicholas Yee",
            "Eric Nickell",
            "Robert J. Moore"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240750",
        "citation": "159",
        "abstract": "Massively multiplayer online games (MMOGs) can be fascinating laboratories to observe group dynamics online. In particular, players must form persistent associations or \"guilds\" to coordinate their actions and accomplish the games' toughest objectives. Managing a guild, however, is notoriously difficult and many do not survive very long. In this paper, we examine some of the factors that could explain the success or failure of a game guild based on more than a year of data collected from five World of Warcraft servers. Our focus is on structural properties of these groups, as represented by their social networks and other variables. We use this data to discuss what games can teach us about group dynamics online and, in particular, what tools and techniques could be used to better support gaming communities."
    },
    {
        "title": "Testing the technology: playing games with video conferencing",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2007",
        "authors": [
            "Archer L. Batcheller",
            "Brian Hilligoss",
            "Kevin Nam",
            "Emilee Rader",
            "Marta Rey-Babarro",
            "Xiaomu Zhou"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240751",
        "citation": "15",
        "abstract": "Video connections can establish a media space in which games may be played, just as people play games while collocated. Experiments with participants playing the game 'Mafia' indicate that people in a video condition have similar levels of satisfaction, fun, and frustration, to those that play while collocated. This finding holds for both those with prior experience using video systems and those without, suggesting it is not merely a \"novelty effect.\" Results differ about whether there exist differences in focus of attention, suspicion/trust, and pointing for people playing the game while using a video system. Implications for both fun and work uses of video are suggested."
    },
    {
        "title": "Using heart rate to control an interactive game",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2007",
        "authors": [
            "Ville Nenonen",
            "Aleksi Lindblad",
            "Ville Häkkinen",
            "Toni Laitinen",
            "Mikko Jouhtio",
            "Perttu Hämäläinen"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240752",
        "citation": "78",
        "abstract": "This paper presents a novel way of using real-time heart rate information to control a physically interactive biathlon (skiing and shooting) computer game. Instead of interfacing the game to an exercise bike or other equipment with speed output, the skiing speed is directly proportional to heart rate. You can freely choose the form of physical exercise, which makes it easier for people with different skill levels and backgrounds to play together. The system can be used with any exercise machine or form. To make playing meaningful instead of simply exercising as hard as you can, a high heart rate impedes the shooting part of the game by making the sight less steady. This balancing mechanism lets the player try out different tactics, varying from very slow skiing and sharp shooting to fast skiing and random shooting. The game has been evaluated in a user study with eight participants. The results show that heart rate interaction is fun and usable interaction method."
    },
    {
        "title": "Session details: Video",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Video",
        "data": "April 2007",
        "authors": [
            "Wendy Mackay"
        ],
        "DOI": "https://doi.org/10.1145/3258884",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Consuming video on mobile devices",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Video",
        "data": "April 2007",
        "authors": [
            "Kenton O'Hara",
            "April Slayden Mitchell",
            "Alex Vorbau"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240754",
        "citation": "125",
        "abstract": "Mobile video is now an everyday possibility with a wide array of commercially available devices, services and content. These technologies promise to transform the way that people can consume video media in their lives beyond the familiar behaviours associated with fixed TV and video technologies. Building upon earlier studies of mobile video, this paper reports on a study using diary techniques and ethnographic interviews to better understand how people are using commercially available mobile video technologies in their everyday lives. Drawing on reported episodes of mobile video behaviour, the study identifies the social motivations and values underpinning these behaviours that help characterise mobile video consumption beyond the simplistic notion of viewing TV to kill time wherever you may be. Implications for adoption and design of mobile video technologies and services are discussed."
    },
    {
        "title": "Effects of audio and visual surrogates for making sense of digital video",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Video",
        "data": "April 2007",
        "authors": [
            "Yaxiao Song",
            "Gary Marchionini"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240755",
        "citation": "19",
        "abstract": "Video surrogates are meant to help people quickly make sense of the content of a video before downloading or seeking more detailed information. In this paper we present the results of a study comparing the effectiveness of three different surrogates for objects in digital video libraries. Thirty-six people participated in a within subjects user study in which they did five tasks for each of three surrogate alternatives: visual alone (a storyboard), audio alone (spoken description), and combined visual and audio (a storyboard augmented with spoken description). The results show that combined surrogates are more effective, strongly preferred, and do not penalize efficiency. The results also demonstrate that spoken descriptions alone lead to better understanding of the video segments than do visual storyboards alone, although people like to have visual surrogates and use them to confirm interpretations and add context. Participants were able to easily use the combined surrogates even though they were not synchronized, suggesting that synchronization of different media channels may not be necessary in surrogates as it is in full video. The results suggest that multimodal surrogates should be incorporated into video retrieval user interfaces and audio surrogates should be used in small display interfaces. The study also raises questions about the need to synchronize different information channels in multimedia surrogates."
    },
    {
        "title": "Watching together: integrating text chat with video",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Video",
        "data": "April 2007",
        "authors": [
            "Justin D. Weisz",
            "Sara Kiesler",
            "Hui Zhang",
            "Yuqing Ren",
            "Robert E. Kraut",
            "Joseph A. Konstan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240756",
        "citation": "87",
        "abstract": "Watching video online is becoming increasingly popular, and new video streaming technologies have the potential to transform video watching from a passive, isolating experience into an active, socially engaging experience. However, the viability of an active social experience is unclear: both chatting and watching video require attention, and may interfere with one another and detract from the experience. In this paper, we empirically examine the activity of chatting while watching video online. We examine how groups of friends and strangers interact, and find that chat has a positive influence on social relationships, and people chat despite being distracted. We discuss the benefits and opportunities provided by mixing chat and video, uncover some of the attentional and social challenges inherent in this combination of media, and provide guidance for structuring the viewing experience."
    },
    {
        "title": "Session details: Security",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security",
        "data": "April 2007",
        "authors": [
            "Carlos Jensen"
        ],
        "DOI": "https://doi.org/10.1145/3258885",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Pictures at the ATM: exploring the usability of multiple graphical passwords",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security",
        "data": "April 2007",
        "authors": [
            "Wendy Moncur",
            "Grégory Leplâtre"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240758",
        "citation": "51",
        "abstract": "Users gain access to cash, confidential information and services at Automated Teller Machines (ATMs) via an authentication process involving a Personal Identification Number (PIN). These users frequently have many different PINs, and fail to remember them without recourse to insecure behaviours. This is not a failing of users. It is a usability failing in the ATM authentication mechanism. This paper describes research executed to evaluate whether users find multiple graphical passwords more memorable than multiple PINs. The research also investigates the success of two memory augmentation strategies in increasing memorability of graphical passwords. The results demonstrate that multiple graphical passwords are substantially more effective than multiple PIN numbers. Memorability is further improved by the use of mnemonics to aid their recall.This study will be of interest to HCI practitioners and information security researchers exploring approaches to usable security."
    },
    {
        "title": "Password sharing: implications for security design based on social practice",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security",
        "data": "April 2007",
        "authors": [
            "Supriya Singh",
            "Anuja Cabraal",
            "Catherine Demosthenous",
            "Gunela Astbrink",
            "Michele Furlong"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240759",
        "citation": "82",
        "abstract": "Current systems for banking authentication require that customers not reveal their access codes, even to members of the family. A study of banking and security in Australia shows that the practice of sharing passwords does not conform to this requirement. For married and de facto couples, password sharing is seen as a practical way of managing money and a demonstration of trust. Sharing Personal Identification Numbers (PINs) is a common practice among remote indigenous communities in Australia. In areas with poor banking access, this is the only way to access cash. People with certain disabilities have to share passwords with carers, and PIN numbers with retail clerks. In this paper we present the findings of a qualitative user study of banking and money management. We suggest design criteria for banking security systems, based on observed social and cultural practices of password and PIN number sharing."
    },
    {
        "title": "Protecting people from phishing: the design and evaluation of an embedded training email system",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security",
        "data": "April 2007",
        "authors": [
            "Ponnurangam Kumaraguru",
            "Yong Rhee",
            "Alessandro Acquisti",
            "Lorrie Faith Cranor",
            "Jason Hong",
            "Elizabeth Nunge"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240760",
        "citation": "158",
        "abstract": "Phishing attacks, in which criminals lure Internet users to websites that impersonate legitimate sites, are occurring with increasing frequency and are causing considerable harm to victims. In this paper we describe the design and evaluation of an embedded training email system that teaches people about phishing during their normal use of email. We conducted lab experiments contrasting the effectiveness of standard security notices about phishing with two embedded training designs we developed. We found that embedded training works better than the current practice of sending security notices. We also derived sound design principles for embedded training systems."
    },
    {
        "title": "Session details: Emotion & empathy",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emotion & empathy",
        "data": "April 2007",
        "authors": [
            "Diane Schiano"
        ],
        "DOI": "https://doi.org/10.1145/3258886",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Studying antecedents of emotional experiences in interactive contexts",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emotion & empathy",
        "data": "April 2007",
        "authors": [
            "Sascha Mahlke",
            "Manfred Thüring"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240762",
        "citation": "86",
        "abstract": "This paper describes a research approach to the experimental study of emotional experiences and their connections to other components of user experience in human-technology interaction. We present a model of user experience that integrates interaction characteristics, instrumental and non-instrumental quality perceptions, emotional user reactions and overall judgments of system quality. An experiment is reported to illustrate the application of our approach. System properties of an interactive prototype were varied to produce versions of different usability and aesthetics which in turn led to different perceptions of instrumental and non-instrumental qualities. The results indicate that both quality aspects significantly influence emotional reactions with respect to subjective feelings, facial expressions and physiological responses. These findings are consistent with the users' overall judgments of the systems and show that the perception of both, instrumental and non-instrumental qualities influences the appraisal of interactive systems."
    },
    {
        "title": "Patterns of empathy in online communication",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emotion & empathy",
        "data": "April 2007",
        "authors": [
            "Ulrike Pfeil",
            "Panayiotis Zaphiris"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240763",
        "citation": "61",
        "abstract": "This article presents an investigation of empathy within an online community for older people (SeniorNet). Qualitative content analysis of 400 messages from a discussion board about depression was used to determine how empathy is expressed and facilitated in online communication. Special emphasis was placed on determining the components of online empathy. A code scheme that we developed to analyse online empathy is also presented. The findings were compared to offline studies about empathy in order to investigate the influence that the mediating technology has on the phenomenon."
    },
    {
        "title": "Expressing emotion in text-based communication",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emotion & empathy",
        "data": "April 2007",
        "authors": [
            "Jeffrey T. Hancock",
            "Christopher Landrigan",
            "Courtney Silver"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240764",
        "citation": "172",
        "abstract": "Our ability to express and accurately assess emotional states is central to human life. The present study examines how people express and detect emotions during text-based communication, an environment that eliminates the nonverbal cues typically associated with emotion. The results from 40 dyadic interactions suggest that users relied on four strategies to express happiness versus sadness, including disagreement, negative affect terms, punctuation, and verbosity. Contrary to conventional wisdom, communication partners readily distinguished between positive and negative valence emotional communicators in this text-based context. The results are discussed with respect to the Social Information Processing model of strategic relational adaptation in mediated communication."
    },
    {
        "title": "Exploring affective design for physical controls",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Emotion & empathy",
        "data": "April 2007",
        "authors": [
            "Colin Swindells",
            "Karon E. MacLean",
            "Kellogg S. Booth",
            "Michael J. Meitner"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240765",
        "citation": "30",
        "abstract": "Physical controls such as knobs, sliders, and buttons are experiencing a revival as many computing systems progress from personal computing architectures towards ubiquitous computing architectures. We demonstrate a process for measuring and comparing visceral emotional responses of a physical control to performance results of a target acquisition task. In our user study, participants experienced mechanical and rendered friction, inertia, and detent dynamics as they turned a haptic knob towards graphical targets of two different widths and amplitudes. Together, this process and user study provide novel affect- and performance-based design guidance to developers of physical controls for emerging ubiquitous computing environments. Our work bridges extensive human factors work in mechanical systems that peaked in the 1960's, to contemporary trends, with a goal of integrating mechatronic controls into emerging ubiquitous computing systems."
    },
    {
        "title": "Session details: Collaboration at work",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaboration at work",
        "data": "April 2007",
        "authors": [
            "Wendy Kellogg"
        ],
        "DOI": "https://doi.org/10.1145/3258887",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Koala: capture, share, automate, personalize business processes on the web",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaboration at work",
        "data": "April 2007",
        "authors": [
            "Greg Little",
            "Tessa A. Lau",
            "Allen Cypher",
            "James Lin",
            "Eben M. Haber",
            "Eser Kandogan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240767",
        "citation": "112",
        "abstract": "We present Koala, a system that enables users to capture, share, automate, and personalize business processes on the web. Koala is a collaborative programming-by-demonstration system that records, edits, and plays back user interactions as pseudo-natural language scripts that are both human- and machine-interpretable. Unlike previous programming by demonstration systems, Koala leverages sloppy programming that interprets pseudo-natural language instructions (as opposed to formal syntactic statements) in the context of a given web page's elements and actions. Koala scripts are automatically stored in the Koalescence wiki, where a community of users can share, run, and collaboratively develop their \"how-to\" knowledge. Koala also takes advantage of corporate and personal data stores to automatically generalize and instantiate user-specific data, so that scripts created by one user are automatically personalized for others. Our initial experiences suggest that Koala is surprisingly effective at interpreting instructions originally written for people."
    },
    {
        "title": "Understanding memory triggers for task tracking",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaboration at work",
        "data": "April 2007",
        "authors": [
            "A.J. Bernheim Brush",
            "Brian R. Meyers",
            "Desney S. Tan",
            "Mary Czerwinski"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240768",
        "citation": "9",
        "abstract": "Software can now track which computer applications and documents you use. This provides us with the potential to help end-users recall past activities for tasks such as status reporting. We describe findings from field observations of eight participants writing their status reports. We observed interesting trends, including the reliance on memory triggers, which were either retrieved from explicit self-reminders, from implicit breadcrumbs left while performing their tasks or directly from memory. Participants perceived spending relatively short amounts of time composing their status reports, suggesting that any technology solution must offer dramatic improvements over current practice."
    },
    {
        "title": "Exploring patterns of social commonality among file directories at work",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaboration at work",
        "data": "April 2007",
        "authors": [
            "John C. Tang",
            "Clemens Drews",
            "Mark Smith",
            "Fei Wu",
            "Alison Sue",
            "Tessa Lau"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240769",
        "citation": "17",
        "abstract": "We studied files stored by members of a work organization for patterns of social commonality. Discovering identical or similar documents, applications, developer libraries, or other files may suggest shared interests or experience among users. Examining actual file data revealed a number of individual and aggregate practices around file storage. For example, pairs of users typically have many (over 13,000) files in common. A prototype called LiveWire exploits this commonality to make file backup and restore more efficient for a work organization. We removed commonly shared files and focused on specific filetypes that represent user activity to find more meaningful files in common. The Consolidarity project explores how patterns of file commonality could encourage social networking in an organizational context. Mechanisms for addressing the privacy concerns raised by this approach are discussed."
    },
    {
        "title": "A study of out-of-turn interaction in menu-based, IVR, voicemail systems",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaboration at work",
        "data": "April 2007",
        "authors": [
            "Saverio Perugini",
            "Taylor J. Anderson",
            "William F. Moroney"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240770",
        "citation": "17",
        "abstract": "We present the first user study of out-of-turn interaction inmenu-based, interactive voice-response systems. Out-of-turn interaction is atechnique which empowers the user (unable to respond to the current prompt) totake the conversational initiative by supplying information that is currentlyunsolicited, but expected later in the dialog. The technique permits the userto circumvent any flows of navigation hardwired into the design and navigatethe menus in a manner which reflects their model of the task. We conducted alaboratory experiment to measure the effect of the use of out-of-turninteraction on user performance and preference in a menu-based, voice interfaceto voicemail. Specifically, we compared two interfaces with the exact samehierarchical menu design: one with the capability of accepting out-of-turnutterances and one without this feature. The results indicate that out-of-turninteraction significantly reduces task completion time, improves usability, andis preferred to the baseline. This research studies an unexplored dimension ofthe design space for automated telephone services, namely the nature ofuser-addressable input (utterance) supplied (in-turn vs. out-of-turn), incontrast to more traditional dimensions such as input modality (touch-tone vs.text vs. voice) and style of interaction (menu-based vs. natural language)."
    },
    {
        "title": "Session details: Tags, tagging & notetaking",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tags, tagging & notetaking",
        "data": "April 2007",
        "authors": [
            "Gina Venolia"
        ],
        "DOI": "https://doi.org/10.1145/3258888",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Why we tag: motivations for annotation in mobile and online media",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tags, tagging & notetaking",
        "data": "April 2007",
        "authors": [
            "Morgan Ames",
            "Mor Naaman"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240772",
        "citation": "503",
        "abstract": "Why do people tag? Users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. We investigate the incentives for annotation in Flickr, a popular web-based photo-sharing system, and ZoneTag, a cameraphone photo capture and annotation tool that uploads images to Flickr. In Flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. ZoneTag, in turn, makes it easier to tag cameraphone photos that are uploaded to Flickr by allowing annotation and suggesting relevant tags immediately after capture."
    },
    {
        "title": "Selection-based note-taking applications",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tags, tagging & notetaking",
        "data": "April 2007",
        "authors": [
            "Aaron Bauer",
            "Kenneth R. Koedinger"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240773",
        "citation": "16",
        "abstract": "The increasing integration of education and technology has led to the development of a range of note-taking applications. Our project's goal is to provide empirical data to guide the design of such note-taking applications by evaluating the behavioral and learning outcomes of different note-taking functionality. The study reported here compares note-taking using a text editor and four interaction techniques. The two standard techniques are typing and copy-paste. The two novel techniques are restricted copy-paste and menu-selection, intended to increase attention and processing respectively. Hypothesized learning gains from the novel techniques were not observed. As implemented these techniques were less efficient and appeared to be more frustrating to use. However, data regarding differences in both note-taking efficiency and learning suggest several important implications for selection-based note-taking applications, such as pasting and highlighting. Our results also indicate that students have strong opinions regarding their note-taking practices, which may complicate potentially beneficial interventions."
    },
    {
        "title": "Mobile interaction with visual and RFID tags: a field study on user perceptions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tags, tagging & notetaking",
        "data": "April 2007",
        "authors": [
            "Kaj Mäkelä",
            "Sara Belt",
            "Dan Greenblatt",
            "Jonna Häkkilä"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240774",
        "citation": "40",
        "abstract": "In this paper, we present a study of user perceptions on mobile interaction with visual and RFID tags. Although mobile interaction with tags has been proposed in several earlier studies, user perceptions and usability comparisons of different tag technologies have not been intensively investigated. In contrast to earlier studies, which report on user studies with evaluating new concepts or interaction techniques, we take another approach and examine the current understanding of the techniques and user perceptions on them. Our field study of 50 users charts currently existing user perceptions and reveals potential usability risks that are due to the limited or erroneous understanding of the interaction technique."
    },
    {
        "title": "Getting our head in the clouds: toward evaluation studies of tagclouds",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tags, tagging & notetaking",
        "data": "April 2007",
        "authors": [
            "A. W. Rivadeneira",
            "Daniel M. Gruen",
            "Michael J. Muller",
            "David R. Millen"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240775",
        "citation": "194",
        "abstract": "Tagclouds are visual presentations of a set of words, typically a set of \"tags\" selected by some rationale, in which attributes of the text such as size, weight, or color are used to represent features, such as frequency, of the associated terms. This note describes two studies to evaluate the effectiveness of differently constructed tagclouds for the various tasks they can be used to support, including searching, browsing, impression formation and recognition. Based on these studies, we propose a paradigm for evaluating tagclouds and ultimately guidelines for tagcloud construction."
    },
    {
        "title": "Session details: Multimodal interactions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multimodal interactions",
        "data": "April 2007",
        "authors": [
            "Ed Cuttrell"
        ],
        "DOI": "https://doi.org/10.1145/3258889",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Supporting multi-point interaction in visual workspaces",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multimodal interactions",
        "data": "April 2007",
        "authors": [
            "Garth Shoemaker",
            "Carl Gutwin"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240777",
        "citation": "22",
        "abstract": "Multi-point interaction tasks involve the manipulation of several mutually-dependent control points in a visual workspace -- for example, adjusting a selection rectangle in a drawing application. Multi-point interactions place conflicting requirements on the interface: the system must display objects at sufficient scale for detailed manipulation, but it must also provide an efficient means of navigating from one control point to another. Current interfaces lack any explicit support for tasks that combine these two requirements, forcing users to carry out sequences of zoom and pan actions. In this paper, we describe three novel mechanisms for view control that explicitly support multi-point interactions with a single mouse, and preserve both visibility and scale for multiple regions of interest. We carried out a study to compare two of the designs against standard zoom and pan techniques, and found that task completion time was significantly reduced with the new approaches. The study shows the potential of interfaces that combine support for both scale and navigation."
    },
    {
        "title": "Multimodal redundancy across handwriting and speech during computer mediated human-human interactions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multimodal interactions",
        "data": "April 2007",
        "authors": [
            "Edward C. Kaiser",
            "Paulo Barthelmess",
            "Candice Erdmann",
            "Phil Cohen"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240778",
        "citation": "10",
        "abstract": "Lecturers, presenters and meeting participants often say what they publicly handwrite. In this paper, we report on three empirical explorations of such multimodal redundancy -- during whiteboard presentations, during a spontaneous brainstorming meeting, and during the informal annotation and discussion of photographs. We show that redundantly presented words, compared to other words used during a presentation or meeting, tend to be topic specific and thus are likely to be out-of-vocabulary. We also show that they have significantly higher tf-idf (term frequency-inverse document frequency) weights than other words, which we argue supports the hypothesis that they are dialogue-critical words. We frame the import of these empirical findings by describing SHACER, our recently introduced Speech and HAndwriting reCognizER, which can combine information from instances of redundant handwriting and speech to dynamically learn new vocabulary."
    },
    {
        "title": "Session details: Distributed interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed interaction",
        "data": "April 2007",
        "authors": [
            "Susan Fussell"
        ],
        "DOI": "https://doi.org/10.1145/3258890",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "An empirical study of the use of visually enhanced voip audio conferencing: the case of IEAC",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed interaction",
        "data": "April 2007",
        "authors": [
            "Xianghua Ding",
            "Thomas Erickson",
            "Wendy A. Kellogg",
            "Stephen Levy",
            "James E. Christensen",
            "Jeremy Sussman",
            "Tracee Vetting Wolf",
            "William E. Bennett"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240780",
        "citation": "7",
        "abstract": "IBM Enhanced Audio Conferencing (IEAC) is a VoIP-based audio conferencing system that, like several other systems, provides a visualization showing who is present and their states (e.g., speaking, muted). This paper presents the first study of the use of such a system. Drawing on log files collected over six weeks of use by over 1300 corporate employees, and interviews with 10 of them, we look at how and why various features of the system are used and what sorts of practices are supported. Our findings shed light on the factors that drive the use of visual enhancements to audio conferencing, and suggest further research topics."
    },
    {
        "title": "Voyagers and voyeurs: supporting asynchronous collaborative information visualization",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed interaction",
        "data": "April 2007",
        "authors": [
            "Jeffrey Heer",
            "Fernanda B. Viégas",
            "Martin Wattenberg"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240781",
        "citation": "162",
        "abstract": "This paper describes mechanisms for asynchronous collaboration in the context of information visualization, recasting visualizations as not just analytic tools, but social spaces. We contribute the design and implementation of sense.us, a web site supporting asynchronous collaboration across a variety of visualization types. The site supports view sharing, discussion, graphical annotation, and social navigation and includes novel interaction elements. We report the results of user studies of the system, observing emergent patterns of social data analysis, including cycles of observation and hypothesis, and the complementary roles of social navigation and data-driven exploration."
    },
    {
        "title": "Turn it this way: grounding collaborative action with remote gestures",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed interaction",
        "data": "April 2007",
        "authors": [
            "David Kirk",
            "Tom Rodden",
            "Danaë Stanton Fraser"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240782",
        "citation": "89",
        "abstract": "Remote gesture systems have been shown to provide a significant enhancement to performance in collaborative physical tasks, an effect ascribed to the ability of remote gestures to help ground deictic references. The argument that this effect works by replacing complex referential descriptions with simple pointing behaviours has been drawn into question by recent research. In this paper we significantly unpack the effects of remote gesturing on collaborative language, arguing for a more complex role for remote gestures in interaction. We demonstrate how remote gestures influence the structure of collaborative discourse, and how their use can also influence the temporal nature of the grounding process. Through generating a deeper understanding of these effects of remote gesturing on collaborative language we derive implications for the development and deployment of these technologies."
    },
    {
        "title": "Session details: Learning & education",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning & education",
        "data": "April 2007",
        "authors": [
            "Deborah Tatar"
        ],
        "DOI": "https://doi.org/10.1145/3258891",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "The validity of a virtual human experience for interpersonal skills education",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning & education",
        "data": "April 2007",
        "authors": [
            "Kyle Johnsen",
            "Andrew Raij",
            "Amy Stevens",
            "D. Scott Lind",
            "Benjamin Lok"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240784",
        "citation": "50",
        "abstract": "Any new tool introduced for education needs to be validated. We developed a virtual human experience called the Virtual Objective Structured Clinical Examination (VOSCE). In the VOSCE, a medical student examines a life-size virtual human who is presenting symptoms of an illness. The student is then graded on interview skills. As part of a medical school class requirement, thirty three second year medical students participated in a user study designed to determine the validity of the VOSCE for testing interview skills. In the study, participant performance in the VOSCE is compared to participant performance in the OSCE, an interview with a trained actor. There was a significant correlation (r(33)=.49, p<.005) between overall score in the VOSCE and overall score in the OSCE. This means that the interaction skills used with a virtual human translate to the interaction skills used with a real human. Comparing the experience of virtual human interaction to real human interaction is the critical validation step towards using virtual humans for interpersonal skills education."
    },
    {
        "title": "Modeling and understanding students' off-task behavior in intelligent tutoring systems",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning & education",
        "data": "April 2007",
        "authors": [
            "Ryan S.J.d. Baker"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240785",
        "citation": "95",
        "abstract": "We present a machine-learned model that can automatically detect when a student using an intelligent tutoring system is off-task, i.e., engaged in behavior which does not involve the system or a learning task. This model was developed using only log files of system usage (i.e. no screen capture or audio/video data). We show that this model can both accurately identify each student's prevalence of off-task behavior and can distinguish off-task behavior from when the student is talking to the teacher or another student about the subject matter. We use this model in combination with motivational and attitudinal instruments, developing a profile of the attitudes and motivations associated with off-task behavior, and compare this profile to the attitudes and motivations associated with other behaviors in intelligent tutoring systems. We discuss how the model of off-task behavior can be used within interactive learning environments which respond to when students are off-task."
    },
    {
        "title": "Improvisation principles and techniques for design",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning & education",
        "data": "April 2007",
        "authors": [
            "Elizabeth Gerber"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240786",
        "citation": "33",
        "abstract": "Existing research addresses how designers create tools to support improvisation, yet little research explores how improvisation offers tools to support design work. This paper explores the potential relationship between improvisation and design, examining how design can benefit from improvisation. The paper argues that improvisation can build perspectives and skills that are critical for designers, such as creative collaboration, fostering innovation, supporting spontaneity, learning through error, and presenting ideas. The paper reviews the use of improvisation activities by designers in a multi-case study. The applications are analyzed to demonstrate individual and group level outcomes in design work."
    },
    {
        "title": "Supporting multidisciplinary collaboration: requirements from novel HCI education",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning & education",
        "data": "April 2007",
        "authors": [
            "Piotr D. Adamczyk",
            "Michael B. Twidale"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240787",
        "citation": "25",
        "abstract": "Many collaborative design tools may suffer from being too generic to address the specific complexities inherent in multidisciplinary collaboration. We provide accounts of several multidisciplinary HCI courses at our institution, elaborating on the challenges student teams face when integrating design practice from a wide variety of disciplines. Of particular interest are the distinct approaches that these multidisciplinary teams adopt that differ from more common forms of collaborative design. We suggest reasons for the poor rate of adoption of existing collaborative support tools and outline specific suggestions for directions in both ethnographic studies of multidisciplinary collaboration and collaborative systems design."
    },
    {
        "title": "Session details: Designing for specific cultures",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Designing for specific cultures",
        "data": "April 2007",
        "authors": [
            "John Thomas"
        ],
        "DOI": "https://doi.org/10.1145/3258892",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "How HCI interprets the probes",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Designing for specific cultures",
        "data": "April 2007",
        "authors": [
            "Kirsten Boehner",
            "Janet Vertesi",
            "Phoebe Sengers",
            "Paul Dourish"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240789",
        "citation": "284",
        "abstract": "We trace how cultural probes have been adopted and adapted by the HCI community. The flexibility of probes has been central to their uptake, resulting in a proliferation of divergent uses and derivatives. The varying patterns of adaptation of the probes reveal important underlying issues in HCI, suggesting underacknowledged disagreements about valid interpretation and the relationship between methods and their underlying methodology. With this analysis, we aim to clarify discussions around probes, and, more importantly, around how we define and evaluate methods in HCI, especially those grounded in unfamiliar conceptions of how research should be done."
    },
    {
        "title": "Social dynamics of early stage co-design in developing regions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Designing for specific cultures",
        "data": "April 2007",
        "authors": [
            "Divya Ramachandran",
            "Matthew Kam",
            "Jane Chiu",
            "John Canny",
            "James F. Frankel"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240790",
        "citation": "47",
        "abstract": "Technology arguably has the potential to play a key role in improving the lives of people in developing regions. However, these communities are not well understood and designers must thoroughly investigate possibilities for technological innovations in these contexts. We describe findings from two field studies in India and one in Uganda where we explore technological solutions in the domains of communication, microfinance and education. Two common underlying themes emerge from these studies: (1) local stakeholders can contribute cultural information relevant to design such as needs and practices through interaction with technology artifacts and (2) unique social network structures embedded within communities are crucial to the acceptance and potential adoption of technology. We end with a synthesis of the three experiences that draws some practical lessons for ICT designers to elicit meaningful feedback and participation from local stakeholders in developing regions communities."
    },
    {
        "title": "Localized iterative design for language learning in underdeveloped regions: the PACE framework",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Designing for specific cultures",
        "data": "April 2007",
        "authors": [
            "Matthew Kam",
            "Divya Ramachandran",
            "Varun Devanathan",
            "Anuj Tewari",
            "John Canny"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240791",
        "citation": "33",
        "abstract": "Poor literacy remains a decisive barrier to the economic empowerment of many people in the developing world. Of particular importance is literacy in a widely spoken \"world language\" such as English, which is typically a second language for these speakers. For complex reasons, schools are often not effective as vehicles for second language learning. In this paper we explore game-like language learning on cell phones. We argue that phones are an excellent technology platform in the typical ecologies of developing countries. We present the PACE framework that is intended to support the rapid, scalable development of language learning software localized for a particular community of learners. These learners are usually skeptical of formal education and of cultural biases they encounter in learning \"remote\" languages in particular. Localization of content is crucial to make the language relevant to them and to encourage them to adopt it."
    },
    {
        "title": "Session details: Mobile kits & stuff",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile kits & stuff",
        "data": "April 2007",
        "authors": [
            "Yvonne Rogers"
        ],
        "DOI": "https://doi.org/10.1145/3258893",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "iStuff mobile: rapidly prototyping new mobile phone interfaces for ubiquitous computing",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile kits & stuff",
        "data": "April 2007",
        "authors": [
            "Rafael Ballagas",
            "Faraz Memon",
            "Rene Reiners",
            "Jan Borchers"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240793",
        "citation": "41",
        "abstract": "iStuff Mobile is the first rapid prototyping framework that helps explore new sensor-based interfaces with existing mobile phones. It focuses on sensor-enhanced physical interfaces for ubiquitous computing scenarios. The framework includes sensor network platforms, mobile phone software, and a proven rapid prototyping framework. Interaction designers can use iStuff Mobile to quickly create and test functional prototypes of novel interfaces without making internal hardware or software modifications to the handset. A visual programming paradigm provides a low threshold for prototyping activities: the system is not difficult to learn. At the same time, the range of examples built using the toolkit demonstrates a high ceiling for prototyping activities: the toolkit places few limits on prototype complexity. A user study shows that the visual programming metaphor enables prototypes to be built faster and encourages more iterations than a previous approach."
    },
    {
        "title": "Appropriation of a MMS-based comic creator: from system functionalities to resources for action",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile kits & stuff",
        "data": "April 2007",
        "authors": [
            "Antti Salovaara"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240794",
        "citation": "32",
        "abstract": "Technologies can be used - or appropriated - in different ways by different users, but how do the use patterns evolve, and how can design facilitate such evolution? This paper approaches these questions in light of a case study in which a group of 8 high school students used Comeks, a mobile comic strip creator that enables users to exchange rich, expressive multimedia messages. A qualitative analysis of the use processes shows how users turned the functionalities embodied in Comeks into particular resources for communication during the 9-week trial period. The paper discusses the relationship of functionalities of the artifact and the development of resources by presenting how functionalities can be designed to support three ways to appropriate communication technologies: increasing technical mastery, re-channeling existing communication into the new medium and inventing new communicative acts between users."
    },
    {
        "title": "Mobile kits and laptop trays: managing multiple devices in mobile information work",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile kits & stuff",
        "data": "April 2007",
        "authors": [
            "Antti Oulasvirta",
            "Lauri Sumari"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240795",
        "citation": "77",
        "abstract": "A study at a large IT company shows that mobile information workers frequently migrate work across devices (here: smartphones, desktop PCs, laptops). While having multiple devices provides new opportunities to work in the face of changing resource deprivations, the management of devices is often problematic. The most salient problems are posed by 1) the physical effort demanded by various management tasks, 2) anticipating what data or functionality will be needed, and 3) aligning these efforts with work, mobility, and social situations. Workers' strategies of coping with these problems center on two interwoven activities: the physical handling of devices and cross-device synchronization. These aim at balancing risk and effort in immediate and subsequent use. Workers also exhibit subtle ways to handle devices in situ, appropriating their physical and operational properties. The design implications are discussed."
    },
    {
        "title": "Session details: Novel navigation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel navigation",
        "data": "April 2007",
        "authors": [
            "Anind Dey"
        ],
        "DOI": "https://doi.org/10.1145/3258894",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Command strokes with and without preview: using pen gestures on keyboard for command selection",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel navigation",
        "data": "April 2007",
        "authors": [
            "Per Ola Kristensson",
            "Shumin Zhai"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240797",
        "citation": "50",
        "abstract": "This paper presents a new command selection method that provides an alternative to pull-down menus in pen-based mobile interfaces. Its primary advantage is the ability forusers to directly select commands from a very large set without the need to traverse menu hierarchies. The proposed method maps the character strings representing the commands onto continuous pen-traces on a stylus keyboard. The user enters a command by stroking part of its character string. We call this method \"command strokes.\" We present the results of three experiments assessing the usefulness of the technique. The first experiment shows that command strokes are 1.6 times faster than the de-facto standard pull-down menus and that users find command strokes more fun to use. The second and third experiments investigate the effect of displaying a visual preview of the currently recognized command while the user is still articulating the command stroke. These experiments show that visual preview does not slow users down and leads to significantly lower error rates and shorter gestures when users enter new unpracticed commands."
    },
    {
        "title": "Shallow-depth 3d interaction: design and evaluation of one-, two- and three-touch techniques",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel navigation",
        "data": "April 2007",
        "authors": [
            "Mark Hancock",
            "Sheelagh Carpendale",
            "Andy Cockburn"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240798",
        "citation": "124",
        "abstract": "On traditional tables, people frequently use the third dimension to pile, sort and store objects. However, while effective and informative for organization, this use of the third dimension does not usually extend far above the table. To enrich interaction with digital tables, we present the concept of shallow-depth 3D -- 3D interaction with limited depth. Within this shallow-depth 3D environment several common interaction methods need to be reconsidered. Starting from any of one, two and three touch points, we present interaction techniques that provide control of all types of 3D rotation coupled with translation (6DOF) on a direct-touch tabletop display. The different techniques exemplify a wide range of interaction possibilities: from the one-touch technique, which is designed to be simple and natural, but inherits a degree of imprecision from its simplicity; through to three-touch interaction, which allows precise bimanual simultaneous control of multiple degrees of freedom, but at the cost of simplicity. To understand how these techniques support interaction in shallow-depth 3D, we present a user study that examines the efficiency of, and preferences for, the techniques developed. Results show that users are fastest and most accurate when using the three-touch technique and that their preferences were also strongly in favour of the expressive power available from three-touch."
    },
    {
        "title": "Affordances for manipulation of physical versus digital media on interactive surfaces",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel navigation",
        "data": "April 2007",
        "authors": [
            "Lucia Terrenghi",
            "David Kirk",
            "Abigail Sellen",
            "Shahram Izadi"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240799",
        "citation": "84",
        "abstract": "This work presents the results of a comparative study in which we investigate the ways manipulation of physical versus digital media are fundamentally different from one another. Participants carried out both a puzzle task and a photo sorting task in two different modes: in a physical 3-dimensional space and on a multi-touch, interactive tabletop in which the digital items resembled their physical counterparts in terms of appearance and behavior. By observing the interaction behaviors of 12 participants, we explore the main differences and discuss what this means for designing interactive surfaces which use aspects of the physical world as a design resource."
    },
    {
        "title": "Session details: People, looking at people",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: People, looking at people",
        "data": "April 2007",
        "authors": [
            "Catalina Danis"
        ],
        "DOI": "https://doi.org/10.1145/3258895",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Effects of presenting geographic context on tracking activity between cameras",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: People, looking at people",
        "data": "April 2007",
        "authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Thea Turner",
            "Lynn Wilcox"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240801",
        "citation": "13",
        "abstract": "A common video surveillance task is to keep track of people moving around the space being monitored. It is often difficult to track activity between cameras because locations such as hallways in office buildings can look quite similar and do not indicate the spatial proximity of the cameras. We describe a spatial video player that orients nearby video feeds with the field of view of the main playing video to aid in tracking between cameras. This is compared with the traditional bank of cameras with and without interactive maps for identifying and selecting cameras. We additionally explore the value of static and rotating maps for tracking activity between cameras. The study results show that both the spatial video player and the map improve user performance when compared to the camera-bank interface. Also, subjects change cameras more often with the spatial player than either the camera bank or the map, when available."
    },
    {
        "title": "Dynamic shared visual spaces: experimenting with automatic camera control in a remote repair task",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: People, looking at people",
        "data": "April 2007",
        "authors": [
            "Abhishek Ranjan",
            "Jeremy P. Birnholtz",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240802",
        "citation": "38",
        "abstract": "We present an experimental study of automatic camera control in the performance of collaborative remote repair tasks using video-mediated communication. Twelve pairs of participants, one \"helper\" and one \"worker,\" completed a series of Lego puzzle tasks using both a static camera and an automatic camera system that was guided in part by tracking the worker's hand position. Results show substantial performance benefits for the automatic system, particularly for complex tasks. The implications of these results are discussed, along with some lessons for the use of motion tracking as a driver for camera control."
    },
    {
        "title": "\"Look!\": using the gaze direction of embodied agents",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: People, looking at people",
        "data": "April 2007",
        "authors": [
            "Johann Schrammel",
            "Arjan Geven",
            "Reinhard Sefelin",
            "Manfred Tscheligi"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240803",
        "citation": "1",
        "abstract": "This paper describes the results of three studies investigating an embodied agent that supports its interaction with the user by gazing at corresponding objects within its close environment. Three experiments were conducted in order to research whether users can detect an agent's line of sight, whether the agent's gaze direction can help to guide the users' attention towards designated locations and whether such a setup can be used to improve realistic interaction situations. The results show that a) users can detect the agent's gaze direction quickly (within 200 ms) but not very exactly, b) the use of the agent's gaze direction can speed up but also slow down the detection of objects in dependence on their location and c) that the agent's gaze towards corresponding objects during the interaction can have counterproductive effects in realistic settings."
    },
    {
        "title": "Museum guide robot based on sociological interaction analysis",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: People, looking at people",
        "data": "April 2007",
        "authors": [
            "Yoshinori Kuno",
            "Kazuhisa Sadazuka",
            "Michie Kawashima",
            "Keiichi Yamazaki",
            "Akiko Yamazaki",
            "Hideaki Kuzuoka"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240804",
        "citation": "74",
        "abstract": "We are currently working on a museum guide robot with an emphasis on \"friendly\" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors."
    },
    {
        "title": "Session details: Input techniques",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Input techniques",
        "data": "April 2007",
        "authors": [
            "Gonzalo Ramos"
        ],
        "DOI": "https://doi.org/10.1145/3258896",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Bubbling menus: a selective mechanism for accessing hierarchical drop-down menus",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Input techniques",
        "data": "April 2007",
        "authors": [
            "Theophanis Tsandilas",
            "m. c. schraefel"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240806",
        "citation": "17",
        "abstract": "This paper introduces bubbling menus, a new design for cascading drop-down menus. Bubbling menus combine the bubble cursor [10] with directional mouse-gesture techniques to facilitate the access of certain items in a menu, such as frequently selected items. Through an extensive iterative design process, we explore bubbling menus in the context of adaptive and customizable user interfaces. Unlike other adaptation and customization techniques such as split menus, bubbling menus do not disrupt the original structure of menus and enable the activation of menus far from a menu bar. Results from two evaluation studies presented in the paper show that bubbling menus provide an effective alternative to accelerate menu selections tasks."
    },
    {
        "title": "Command line or pretty lines?: comparing textual and visual interfaces for intrusion detection",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Input techniques",
        "data": "April 2007",
        "authors": [
            "Ramona Su Thompson",
            "Esa M. Rantanen",
            "William Yurcik",
            "Brian P. Bailey"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240807",
        "citation": "20",
        "abstract": "Intrusion detection (ID) is one of network security engineers' most important tasks. Textual (command-line) and visual interfaces are two common modalities used to support engineers in ID. We conducted a controlled experiment comparing a representative textual and visual interface for ID to develop a deeper understanding about the relative strengths and weaknesses of each. We found that the textual interface allows users to better control the analysis of details of the data through the use of rich, powerful, and flexible commands while the visual interface allows better discovery of new attacks by offering an overview of the current state of the network. With this understanding, we recommend designing a hybrid interface that combines the strengths of textual and visual interfaces for the next generation of tools used for intrusion detection."
    },
    {
        "title": "Pointing and beyond: an operationalization and preliminary evaluation of multi-scale searching",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Input techniques",
        "data": "April 2007",
        "authors": [
            "Emmanuel Pietriga",
            "Caroline Appert",
            "Michel Beaudouin-Lafon"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240808",
        "citation": "27",
        "abstract": "A number of experimental studies based on domain-specific tasks have evaluated the efficiency of navigation techniques for searching multi-scale worlds. The discrepancies among their results call for a more generic framework similar in spirit to Fitts' reciprocal pointing task, but adapted to a task that significantly differs from pure pointing. We introduce such a framework based on an abstract task and evaluate how four multi-scale navigation techniques perform in one particular multi-scale world configuration. Experimental findings indicate that, in this context, pan & zoom combined with an overview is the most efficient technique of all four, and that focus + context techniques perform better than classical pan & zoom. We relate these findings to more realistic situations, discuss their applicability, and how the framework can be used to cover a broad range of situations."
    },
    {
        "title": "Session details: Location aware systems",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Location aware systems",
        "data": "April 2007",
        "authors": [
            "Dianne Murray"
        ],
        "DOI": "https://doi.org/10.1145/3258897",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Social practices in location-based collecting",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Location aware systems",
        "data": "April 2007",
        "authors": [
            "Kenton O'Hara",
            "Tim Kindberg",
            "Maxine Glancy",
            "Luciana Baptista",
            "Byju Sukumaran",
            "Gil Kahana",
            "Julie Rowbotham"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240810",
        "citation": "22",
        "abstract": "The use of location-based technology to augment visitor experiences has received considerable attention over the years. In this paper, we take an alternative perspective on these kinds of location-based experiences by focussing on the collecting and keeping of location-based content as opposed to simply the in situ consumption of content. We describe a trial of a location-based experience at London zoo in which mobile camera phones were used to access digital content at particular animal enclosures around the zoo. Through the fieldwork we demonstrate ways in which collecting and keeping have important social values over and above simply consuming the content in situ. More specifically, the role of the collection of location-based content in identity work; in developing a sense of challenge and achievement; in defining a sense of group camaraderie; and in creating a playful sense of competition among group members. Further, we see how narratives told around the collected location-based content over time imbue it with additional value. These narratives become part of the resources through which relationships with family and friends get actively constructed. We discuss how these aspects have different design implications from the in-situ consumption model of location-based experiences and tensions this introduces."
    },
    {
        "title": "Capturing, sharing, and using local place information",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Location aware systems",
        "data": "April 2007",
        "authors": [
            "Pamela J. Ludford",
            "Reid Priedhorsky",
            "Ken Reily",
            "Loren Terveen"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240811",
        "citation": "34",
        "abstract": "With new technology, people can share information about everyday places they go; the resulting data helps others find and evaluate places. Recent applications like Dodgeball and Sharescape repurpose everyday place information: users create local place data for personal use, and the systems display it for public use. We explore both the opportunities -- new local knowledge, and concerns -- privacy risks, raised by this implicit information sharing. We conduct two empirical studies: subjects create place data when using PlaceMail, a location-based reminder system, and elect whether to share it on Sharescape, a community map-building system. We contribute by: (1) showing location-based reminders yield new local knowledge about a variety of places, (2) identifying heuristics people use when deciding what place-related information to share (and their prevalence), (3) detailing how these decision heuristics can inform local knowledge sharing system design, and (4) identifying new uses of shared place information, notably opportunistic errand planning."
    },
    {
        "title": "Show me the way to Monte Carlo: density-based trajectory navigation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Location aware systems",
        "data": "April 2007",
        "authors": [
            "Steven Strachan",
            "John Williamson",
            "Roderick Murray-Smith"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240812",
        "citation": "26",
        "abstract": "We demonstrate the use of uncertain prediction in asystem for pedestrian navigation via audio with a combination ofGlobal Positioning System data, a music player, inertial sensing,magnetic bearing data and Monte Carlo sampling for a densityfollowing task, where a listener's music is modulated according tothe changing predictions of user position with respect to a targetdensity, in this case a trajectory or path. We show that this system enables eyes-free navigation around set trajectories or paths unfamiliar to the user and demonstrate that the system may be used effectively for varying trajectory width and context."
    },
    {
        "title": "Mapmover: a case study of design-oriented research into collective expression and constructed publics",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Location aware systems",
        "data": "April 2007",
        "authors": [
            "Carl DiSalvo",
            "Jeff Maki",
            "Nathan Martin"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240813",
        "citation": "16",
        "abstract": "In this paper we present the MapMover project as a case study into the use and design of an interactive system for collective expression. Informed by analysis and reflection we advance the concept of constructed publics: publics that are established, shaped, and maintained through the actions and influence of others. We conclude by discussing the relevance of constructed publics as a theorectical frame for the analysis and evaluation of projects in the domains of urban computing and exploratory design in HCI."
    },
    {
        "title": "Session details: Social network sharing",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social network sharing",
        "data": "April 2007",
        "authors": [
            "Danyel Fisher"
        ],
        "DOI": "https://doi.org/10.1145/3258898",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Follow the reader: filtering comments on slashdot",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social network sharing",
        "data": "April 2007",
        "authors": [
            "Cliff A.C. Lampe",
            "Erik Johnston",
            "Paul Resnick"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240815",
        "citation": "67",
        "abstract": "Large-scale online communities need to manage the tension between critical mass and information overload. Slashdot is a news and discussion site that has used comment rating to allow massive participation while providing a mechanism for users to filter content. By default, comments with low ratings are hidden. Of users who changed the defaults, more than three times as many chose to use ratings for filtering or sorting as chose to suppress the use of comment ratings. Nearly half of registered users, however, never strayed from the default filtering settings, suggesting that the costs of exploring and selecting custom filter settings exceeds the expected benefit for many users. We recommend leveraging the efforts of the users that actively choose filter settings to reduce the cost of changing settings for all other users. One strategy is to create static schemas that capture the filtering preferences of different groups of readers. Another strategy is to dynamically set filtering thresholds for each conversation thread, based in part on the choices of previous readers. For predicting later readers' choices, the choices of previous readers are far more useful than content features such as the number of comments or the ratings of those comments."
    },
    {
        "title": "Recent shortcuts: using recent interactions to support shared activities",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social network sharing",
        "data": "April 2007",
        "authors": [
            "John C. Tang",
            "James Lin",
            "Jeffrey Pierce",
            "Steve Whittaker",
            "Clemens Drews"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240816",
        "citation": "17",
        "abstract": "We present an empirical study of teams that revealed the amount of extraneous individual work needed to enable collaboration: finding references to other people, finding files to attach to email, managing incoming email attachments, managing the variety of files used in shared activities, and tracking what work is owed to others. Much of this work involves finding recently accessed objects that are needed again in the user's current task focus. These observations led to the design of Recent Shortcuts, a tool to help support coordination by making recently used objects easily accessible. Recent Shortcuts enables quick access to people (including groups of people), received attachments, files, and file folders that the user interacted with recently for re-use in the user's current context. Recent Shortcuts makes it easy to use these objects across applications with no additional user input and minimal changes to the user's applications or work practice. Early user experiences with a working prototype led to an extension that integrates recently accessed objects across multiple devices."
    },
    {
        "title": "Comedia: mobile group media for active spectatorship",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social network sharing",
        "data": "April 2007",
        "authors": [
            "Giulio Jacucci",
            "Antti Oulasvirta",
            "Tommi Ilmonen",
            "John Evans",
            "Antti Salovaara"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240817",
        "citation": "42",
        "abstract": "Previous attempts to support spectators at large-scale events have concentrated separately on real-time event information, awareness cues, or media-sharing applications. CoMedia combines a group media space with event information and integrates reusable awareness elements throughout. In two field trials, one at a rally and the other at a music festival, we found that CoMedia facilitated onsite reporting to offsite members, coordination of group action, keeping up to date with others, spectating remotely, and joking. In these activities, media, awareness cues, and event information were often used in concert, albeit assuming differing roles. We show that the integrated approach better supports continuous interweaving of use with the changing interests and occurrences in large-scale events."
    },
    {
        "title": "Session details: Augmentation, automation & agents",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmentation, automation & agents",
        "data": "April 2007",
        "authors": [
            "Alan Blackwell"
        ],
        "DOI": "https://doi.org/10.1145/3258899",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Demonstrating the viability of automatically generated user interfaces",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmentation, automation & agents",
        "data": "April 2007",
        "authors": [
            "Jeffrey Nichols",
            "Duen Horng Chau",
            "Brad A. Myers"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240819",
        "citation": "25",
        "abstract": "We conducted a user study that demonstrates that automatically generated interfaces can support better usability through increased flexibility in two dimensions. First, we show that automatic generation can improve usability by moving interfaces that are constrained by cost and poor interaction primitives to another device with better interactive capabilities: subjects were twice as fast and four times as successful at completing tasks with automatically generated interfaces on a PocketPC device as with the actual appliance interfaces. Second, we show that an automatic generator can improve usability by automatically ensuring that new interfaces are generated to be consistent with users' previous experience: subjects were also twice as fast using interfaces consistent with their experiences as compared to normally generated interfaces. These two results demonstrate that automatic interface generation is now viable and especially desirable where users will benefit from individualized interfaces or where human designers are constrained by cost and other factors."
    },
    {
        "title": "The role of choice and customization on users' interaction with embodied conversational agents: effects on perception and performance",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmentation, automation & agents",
        "data": "April 2007",
        "authors": [
            "Jun Xiao",
            "John Stasko",
            "Richard Catrambone"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240820",
        "citation": "18",
        "abstract": "We performed an empirical study exploring people's interactions with an embodied conversational agent (ECA) while performing two tasks. Conditions varied with respect to 1) whether participants were allowed to choose an agent and its characteristics and 2) the putative quality or appropriateness of the agent for the tasks. For both tasks, selection combined with the illusion of further customization significantly improved participants' overall subjective impressions of the ECAs while putative quality had little or no effect. Additionally, performance data revealed that the ECA's motivation and persuasion effects were significantly enhanced when participants chose agents to use. We found that user expectations about and perceptions of the interaction between themselves and an ECA depended very much on the individual's preconceived notions and preferences of various ECA characteristics and might deviate greatly from the models that ECA designers intend to portray."
    },
    {
        "title": "Session details: Distributed coordination",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed coordination",
        "data": "April 2007",
        "authors": [
            "John Tang"
        ],
        "DOI": "https://doi.org/10.1145/3258900",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Seconds matter: improving distributed coordination bytracking and visualizing display trajectories",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed coordination",
        "data": "April 2007",
        "authors": [
            "Mike Fraser",
            "Michael R. McCarthy",
            "Muneeb Shaukat",
            "Phillip Smith"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240822",
        "citation": "10",
        "abstract": "Pauses in distributed groupware activity can indicate anything from technical latency through infrastructure failure to a participant's thoughtful contemplation. Unraveling these ambiguities highlights mismatches between unseen off-screen activities and on-screen cursor behaviors. In this paper we suggest that groupware systems have typically been poor at representing off-screen activities, and introduce the concept of display trajectories to bridge the sensor gap between the display and its surrounding space. We consider requirements for display trajectories using the distributed social scientific analysis of video data as an example domain. Drawing on these requirements, we prototype a freeform whiteboard pen tracking and visualization technique around displays using ultrasound. We describe an experiment which inspects the impact of display trajectories on remote response efficiency. Our findings show that visualization of the display trajectory improves participants' ability to coordinate their actions by one second per interaction turn, reducing latency in organizing turn taking by a 'standard maximum' conversation pause."
    },
    {
        "title": "FASTDash: a visual dashboard for fostering awareness in software teams",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed coordination",
        "data": "April 2007",
        "authors": [
            "Jacob T. Biehl",
            "Mary Czerwinski",
            "Greg Smith",
            "George G. Robertson"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240823",
        "citation": "179",
        "abstract": "Software developers spend significant time gaining and maintaining awareness of fellow developers' activities. FASTDash is a new interactive visualization that seeks to improve team activity awareness using a spatial representation of the shared code base that highlights team members' current activities. With FASTDash, a developer can quickly determine which team members have source files checked out, which files are being viewed, and what methods and classes are currently being changed. The visualization can be annotated, allowing programmers to supplement activity information with additional status details. It provides immediate awareness of potential conflict situations, such as two programmers editing the same source file. FASTDash was developed through user-centered design, including surveys, team interviews, and in situ observation. Results from a field study show that FASTDash improved team awareness, reduced reliance on shared artifacts, and increased project-related communication. Additionally, the team that participated in our field study continues to use FASTDash."
    },
    {
        "title": "A study of emergency response work: patterns of mobile phone interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Distributed coordination",
        "data": "April 2007",
        "authors": [
            "Jonas Landgren",
            "Urban Nulden"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240824",
        "citation": "56",
        "abstract": "This paper presents descriptive accounts of time-critical organizing in the domain of emergency response. Patterns of mobile phone interaction in such work is analyzed showing how the dyadic exchange of mobile phone numbers between the actors plays an important role in the social interactions in the organizing and sensemaking of the emergency. Enacted sensemaking is used as an analytical framework. Implications for design of emergency response information technology are outlined and discussed."
    },
    {
        "title": "Session details: Usability",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability",
        "data": "April 2007",
        "authors": [
            "Dennis Wixon"
        ],
        "DOI": "https://doi.org/10.1145/3258901",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "ExperiScope: an analysis tool for interaction data",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability",
        "data": "April 2007",
        "authors": [
            "François Guimbretiére",
            "Morgan Dixon",
            "Ken Hinckley"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240826",
        "citation": "11",
        "abstract": "We present ExperiScope, an analytical tool to help designers and experimenters explore the results of quantitative evaluations of interaction techniques. ExperiScope combines a new visualization incorporating aspects of the KLM and the three-state model with an interface helping users to rapidly cluster similar patterns of interactions. The tool makes it easy to identify and compare key patterns of use encountered during data collection. This promotes a deeper understanding of the results of a given evaluation.We illustrate the advantages of this tool by revisiting the data collected for an experiment conducted by Hinckley et al. [19] which compared different mode switching techniques. Our results show that our tool complements the previously reported results by offering insights about error behavior and the impact of mode switching on user performance.By providing a more fine-grained analysis of the data gathered during empirical evaluations, we hope that our tool will improve researchers' understanding of existing and newly developed interaction techniques."
    },
    {
        "title": "Context & usability testing: user-modeled information presentation in easy and difficult driving conditions",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability",
        "data": "April 2007",
        "authors": [
            "Jiang Hu",
            "Andi Winterboer",
            "Clifford I. Nass",
            "Johanna D. Moore",
            "Rebecca Illowsky"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240827",
        "citation": "4",
        "abstract": "A 2x2 enhanced Wizard-of-Oz experiment (N = 32) was conducted to compare two different approaches to presenting information to drivers in easy and difficult driving conditions. Data of driving safety, evaluation of the spoken dialogue system, and perception of self were analyzed. Results show that the user-modeled summarize-and-refine (UMSR) approach led to more efficient information retrieval than did the summarize-and-refine (SR) approach. However, depending on driving condition, higher efficiency did not always translate into pleasant subjective experience. Implications for usability testing and interface design were presented, followed by discussions of future research directions."
    },
    {
        "title": "Tracking the interaction of users with AJAX applications for usability testing",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability",
        "data": "April 2007",
        "authors": [
            "Richard Atterer",
            "Albrecht Schmidt"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240828",
        "citation": "37",
        "abstract": "In this paper, we introduce an implementation for detailed monitoring of user actions on web pages. It addresses the problem that the log data recorded by standard web servers is not sufficient for the tracking of users on AJAX websites, e.g. to conduct a usability test. Using standard web technologies, our HTTP proxy can record very detailed usage information, such as mouse movements, clicks, key presses and scrolling, together with the exact HTML DOM tree objects involved. As we show in several case studies, the tracking also works across multiple websites, none of which needs to be under our control. This approach is much less invasive than previous efforts: The test person does not need to install software on her computer, and in certain operation modes, no configuration changes at all are required on her computer. Our research indicates that if the technology described in this paper is employed, arbitrary visitors of a website are more likely to take part in a usability test offered by that site -- this facilitates recruiting test participants over the Internet."
    },
    {
        "title": "Session details: Kids & family",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids & family",
        "data": "April 2007",
        "authors": [
            "John Zimmerman"
        ],
        "DOI": "https://doi.org/10.1145/3258902",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Grow and know: understanding record-keeping needs for tracking the development of young children",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids & family",
        "data": "April 2007",
        "authors": [
            "Julie A. Kientz",
            "Rosa I. Arriaga",
            "Marshini Chetty",
            "Gillian R. Hayes",
            "Jahmeilah Richardson",
            "Shwetak N. Patel",
            "Gregory D. Abowd"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240830",
        "citation": "49",
        "abstract": "From birth through age five, children undergo rapid development and learn skills that will influence them their entire lives. Regular visits to the pediatrician and detailed record-keeping can ensure that children are progressing and can identify early warning signs of developmental delay or disability. However, new parents are often overwhelmed with new responsibilities, and we believe there is an opportunity for computing technology to assist in this process. In this paper, we present a qualitative study aimed at uncovering some specific needs for record-keeping and analysis for new parents and their network of caregivers. Through interviews and focus groups, we have confirmed assumptions about the rationales parents have and the functions required for using technology for record-keeping. We also identify new themes, potential prototypes, and design guidelines for this domain."
    },
    {
        "title": "Sharing motion information with close family and friends",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids & family",
        "data": "April 2007",
        "authors": [
            "Frank R. Bentley",
            "Crysta J. Metcalf"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240831",
        "citation": "38",
        "abstract": "We present the Motion Presence application, an augmented phone book style application that allows close friends and family to view each other's current motion status (\"moving\" or \"not moving\") on their mobile phones. We performed a two week long field trial with 10 participants to observe usage and investigate any privacy concerns that might arise. We found that our participants used the motion information to infer location and activity as well as to plan communication, to help in coordinating in-person get-togethers, and to stay connected to patterns in each others' lives. Participants saw the motion data as mostly confirming their existing thoughts about the locations and activities of others and expressed few privacy concerns. In fact, they frequently asked for more information to be shared to make the application more compelling."
    },
    {
        "title": "Comicboarding: using comics as proxies for participatory design with children",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids & family",
        "data": "April 2007",
        "authors": [
            "Neema Moraveji",
            "Jason Li",
            "Jiarong Ding",
            "Patrick O'Kelley",
            "Suze Woolf"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240832",
        "citation": "78",
        "abstract": "Comicboarding is a participatory design method that uses specially created comic books to generate engaging, productive brainstorming sessions with children. By leveraging known plot formats, interaction styles, and characters in comics, researchers can elicit ideas even from children who are not accustomed to brainstorming, such as those from schools were rote learning is the norm. We conducted an experiment using two variants of the comicboarding methodology with 17 children in China, where traditional participatory design may fail in the face of local cultural practices. The results suggest that comicboarding holds promise for co-design with children."
    },
    {
        "title": "Session details: Alternative interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Alternative interaction",
        "data": "April 2007",
        "authors": [
            "Michel Beaudouin-Lafon"
        ],
        "DOI": "https://doi.org/10.1145/3258903",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Pressure marks",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Alternative interaction",
        "data": "April 2007",
        "authors": [
            "Gonzalo A. Ramos",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240834",
        "citation": "37",
        "abstract": "Selections and actions in GUI's are often separated -- i.e. an action or command typically follows a selection. This sequence imposes a lower bound on the interaction time that is equal to or greater than the sum of its parts. In this paper, we introduce pressure marks -- pen strokes where the variations in pressure make it possible to indicate both a selection and an action simultaneously. We propose a series of design guidelines from which we develop a set of four basictypes of pressure marks. We first assess the viability of this set through an exploratory study that looks at the way users draw straight and lasso pressure marks of different sizes and orientations. We then present the results of a quantitative experiment that shows that users perform faster selection-action interactions with pressure marks than with a combination of lassos and pigtails. Based on these results, we present and discuss a number of interaction designs that incorporate pressure marks."
    },
    {
        "title": "Augmenting the mouse with pressure sensitive input",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Alternative interaction",
        "data": "April 2007",
        "authors": [
            "Jared Cechanowicz",
            "Pourang Irani",
            "Sriram Subramanian"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240835",
        "citation": "67",
        "abstract": "In this paper we investigate the use of a uni-pressure and dual-pressure augmented mouse. With a pressure augmented mouse users can simultaneously control cursor positions as well as multiple levels of discrete selection modes for common desktop application tasks. Two or more independent pressure sensors can be mounted onto several locations on the body of the mouse. To highlight the design potential of a pressure augmented mouse we conducted a multi-part study. In the first part we identified the number of maximum discrete levels controllable with a uni-pressure augmented mouse, the most appropriate locations for installing pressure sensors on the mouse, and the design of new interaction techniques to support selection with pressure-based input. In a follow-up design we introduced an additional sensor and two different types of selection techniques to control a larger number of discrete levels with two pressure sensors. Our results show that users can comfortably control up to 64 modes with a dual-pressure augmented mouse. We discuss the findings of our results in the context of several desktop interaction techniques and identify several design recommendations."
    },
    {
        "title": "Earpod: eyes-free menu selection using touch input and reactive audio feedback",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Alternative interaction",
        "data": "April 2007",
        "authors": [
            "Shengdong Zhao",
            "Pierre Dragicevic",
            "Mark Chignell",
            "Ravin Balakrishnan",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240836",
        "citation": "123",
        "abstract": "We present the design and evaluation of earPod: an eyes-free menu technique using touch input and reactive auditory feedback. Studies comparing earPod with an iPod-like visual menu technique on reasonably-sized static menus indicate that they are comparable in accuracy. In terms of efficiency (speed), earPod is initially slower, but outperforms the visual technique within 30 minutes of practice. Our results indicate that earPod is potentially a reasonable eyes-free menu technique for general use, and is a particularly exciting technique for use in mobile device interfaces."
    },
    {
        "title": "Session details: Usability evaluation",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability evaluation",
        "data": "April 2007",
        "authors": [
            "Robin Jeffries"
        ],
        "DOI": "https://doi.org/10.1145/3258904",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "What happened to remote usability testing?: an empirical study of three methods",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability evaluation",
        "data": "April 2007",
        "authors": [
            "Morten Sieker Andreasen",
            "Henrik Villemann Nielsen",
            "Simon Ormholt Schrøder",
            "Jan Stage"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240838",
        "citation": "111",
        "abstract": "The idea of conducting usability tests remotely emerged ten years ago. Since then, it has been studied empirically, and some software organizations employ remote methods. Yet there are still few comparisons involving more than one remote method. This paper presents results from a systematic empirical comparison of three methods for remote usability testing and a conventional laboratory-based think-aloud method. The three remote methods are a remote synchronous condition, where testing is conducted in real time but the test monitor is separated spatially from the test subjects, and two remote asynchronous conditions, where the test monitor and the test subjects are separated both spatially and temporally. The results show that the remote synchronous method is virtually equivalent to the conventional method. Thereby, it has the potential to conveniently involve broader user groups in usability testing and support new development approaches. The asynchronous methods are considerably more time-consuming for the test subjects and identify fewer usability problems, yet they may still be worthwhile."
    },
    {
        "title": "Usability testing: what have we overlooked?",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability evaluation",
        "data": "April 2007",
        "authors": [
            "Gitte Lindgaard",
            "Jarinee Chattratichart"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240839",
        "citation": "66",
        "abstract": "For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed."
    },
    {
        "title": "Touchstone: exploratory design of experiments",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability evaluation",
        "data": "April 2007",
        "authors": [
            "Wendy E. Mackay",
            "Caroline Appert",
            "Michel Beaudouin-Lafon",
            "Olivier Chapuis",
            "Yangzhou Du",
            "Jean-Daniel Fekete",
            "Yves Guiard"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240840",
        "citation": "38",
        "abstract": "Touchstone is an open-source experiment design platform designed to help establish a solid research foundation for HCI in the area of novel interaction techniques. Touchstone includes a design platform for exploring alternative designs of controlled laboratory experiments, a run platform for running subjects and a limited analysis platform for advice and access to on-line statistics packages. Designed for HCI researchers and their students, Touchstone facilitates the process of creating new experiments, as well as replicating and extending experiments in the research literature. We tested Touchstone by designing two controlled experiments. One illustrates how to create a new experiment from scratch. The other replicates and extends a previous study of multiscale pointing interaction techniques: OrthoZoom was fastest, followed by bi-manual Pan & Zoom; SDAZ and traditional Pan & Zoom were consistently slower."
    },
    {
        "title": "Session details: Programming by & with end-users",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by & with end-users",
        "data": "April 2007",
        "authors": [
            "Les Nelson"
        ],
        "DOI": "https://doi.org/10.1145/3258905",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Making mashups with marmite: towards end-user programming for the web",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by & with end-users",
        "data": "April 2007",
        "authors": [
            "Jeffrey Wong",
            "Jason I. Hong"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240842",
        "citation": "208",
        "abstract": "There is a tremendous amount of web content available today, but it is not always in a form that supports end-users' needs. In many cases, all of the data and services needed to accomplish a goal already exist, but are not in a form amenable to an end-user. To address this problem, we have developed an end-user programming tool called Marmite, which lets end-users create so-called mashups that re-purpose and combine existing web content and services. In this paper, we present the design, implementation, and evaluation of Marmite. An informal user study found that programmers and some spreadsheet users had little difficulty using the system."
    },
    {
        "title": "Vio: a mixed-initiative approach to learning and automating procedural update tasks",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by & with end-users",
        "data": "April 2007",
        "authors": [
            "John Zimmerman",
            "Anthony Tomasic",
            "Isaac Simmons",
            "Ian Hargraves",
            "Ken Mohnkern",
            "Jason Cornwell",
            "Robert Martin McGuire"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240843",
        "citation": "19",
        "abstract": "Today many workers spend too much of their time translating their co-workers' requests into structures that information systems can understand. This paper presents the novel interaction design and evaluation of VIO, an agent that helps workers trans late request. VIO monitors requests and makes suggestions to speed up the translation. VIO allows users to quickly correct agent errors. These corrections are used to improve agent performance as it learns to automate work. Our evaluations demonstrate that this type of agent can significantly reduce task completion time, freeing workers from mundane tasks."
    },
    {
        "title": "Storytelling alice motivates middle school girls to learn computer programming",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming by & with end-users",
        "data": "April 2007",
        "authors": [
            "Caitlin Kelleher",
            "Randy Pausch",
            "Sara Kiesler"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240844",
        "citation": "276",
        "abstract": "We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice."
    },
    {
        "title": "Session details: Trust & engagement",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Trust & engagement",
        "data": "April 2007",
        "authors": [
            "Terry Winograd"
        ],
        "DOI": "https://doi.org/10.1145/3258906",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Multiview: improving trust in group video conferencing through spatial faithfulness",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Trust & engagement",
        "data": "April 2007",
        "authors": [
            "David T. Nguyen",
            "John Canny"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240846",
        "citation": "86",
        "abstract": "Video conferencing is still considered a poor alternative to face-to-face meetings. In the business setting, where these systems are most prevalent, the misuse of video conferencing systems can have detrimental results, especially in high-stakes communications. Prior work suggests that spatial distortions of nonverbal cues, particularly gaze and deixis, negatively impact many aspects of effective communication in dyadic communications. However, video conferencing systems are often used for group-to-group meetings where spatial distortions are exacerbated. Meanwhile, its effects on the group dynamic are not well understood. In this study, we examine the effects that spatial distortions of nonverbal cues have on inter-group trust formation. We conducted a large (169 participant) study of group conferencing under various conditions. We found that the use of systems that introduce spatial distortions negatively affect trust formation patterns. On the other hand, these effects are essentially eliminated by using a spatially faithful video conferencing system."
    },
    {
        "title": "Presence and engagement in an interactive drama",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Trust & engagement",
        "data": "April 2007",
        "authors": [
            "Steven Dow",
            "Manish Mehta",
            "Ellie Harmon",
            "Blair MacIntyre",
            "Michael Mateas"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240847",
        "citation": "80",
        "abstract": "In this paper we present the results of a qualitative, empirical study exploring the impact of immersive technologies on presence and engagement, using the interactive drama Façade as the object of study. In this drama, players are situated in a married couple's apartment, and interact primarily through conversation with the characters and manipulation of objects in the space. We present participants' experiences across three different versions of Façade -- augmented reality (AR) and two desktop computing based implementations, one where players communicate using speech and the other using typed keyboard input. Through interviews and observations of players, we find that immersive AR can create an increased sense of presence, confirming generally held expectations. However, we demonstrate that increased presence does not necessarily lead to more engagement. Rather, mediation may be necessary for some players to fully engage with certain interactive media experiences."
    },
    {
        "title": "Engaging constable: revealing art with new technology",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Trust & engagement",
        "data": "April 2007",
        "authors": [
            "Dirk vom Lehn",
            "Jon Hindmarsh",
            "Paul Luff",
            "Christian Heath"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240848",
        "citation": "37",
        "abstract": "Museums increasingly deploy new technologies to enhance visitors' experience of their exhibitions. They primarily rely on touch-screen computer systems, PDAs and digital audio-guides. Tate Britain recently employed two innovative systems in one of their major exhibitions of John Constable's work; a gestural interface and a touch-screen panel, both connected to large projection screens. This paper reports on the analysis of video-recordings and field observations of visitors' action and interaction. It explores how people interact with and around the systems, how they configure the space around the installation and how they examine and discover their properties. It suggests that designers of interfaces and installations developed for museum exhibitions face particular challenges, such as the transparency of the relationship between people's actions and the system' response, the provision of opportunities for individual and collaborative experiences and the interweaving of technological and aesthetic experiences."
    },
    {
        "title": "Session details: Models of mobile interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Models of mobile interaction",
        "data": "April 2007",
        "authors": [
            "Robert St. Amant"
        ],
        "DOI": "https://doi.org/10.1145/3258907",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Modeling human performance of pen stroke gestures",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Models of mobile interaction",
        "data": "April 2007",
        "authors": [
            "Xiang Cao",
            "Shumin Zhai"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240850",
        "citation": "87",
        "abstract": "This paper presents a quantitative human performance model of making single-stroke pen gestures within certain error constraints in terms of production time. Computed from the properties of Curves, Line segments, and Corners (CLC) in a gesture stroke, the model may serve as a foundation for the design and evaluation of existing and future gesture-based user interfaces at the basic motor control efficiency level, similar to the role of previous \"laws of action\" played to pointing, crossing or steering-based user interfaces. We report and discuss our experimental results on establishing and validating the CLC model, together with other basic empirical findings in stroke gesture production."
    },
    {
        "title": "Keystroke-level model for advanced mobile phone interaction",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Models of mobile interaction",
        "data": "April 2007",
        "authors": [
            "Paul Holleis",
            "Friederike Otto",
            "Heinrich Hussmann",
            "Albrecht Schmidt"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240851",
        "citation": "75",
        "abstract": "The design of applications using mobile devices needs a different quality assessment than those known for desktop applications. Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task. For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model (KLM). This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors. Applications can be evaluated with respect to user performance time without having a prototype running on the phone. To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests."
    },
    {
        "title": "An extended keystroke level model (KLM) for predicting the visual demand of in-vehicle information systems",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Models of mobile interaction",
        "data": "April 2007",
        "authors": [
            "Michael Pettitt",
            "Gary Burnett",
            "Alan Stevens"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240852",
        "citation": "26",
        "abstract": "To assess the potential distraction of In-Vehicle Information Systems (IVIS), simple, low cost evaluation methods are required for use in early design stages. The occlusion technique evaluates IVIS tasks in interrupted vision conditions, aiming to predict likely visual demand. However, the technique necessitates performance-focused user trials utilising robust prototypes, and consequently has limitations as an economic evaluation method. HCI practitioners view the Keystroke Level Model (KLM) as a reliable and valid means of modelling human performance, not requiring empirical trials or working prototypes. This paper proposes an extended KLM, which aims to predict measures based on the occlusion protocol. To validate the new method, we compared results of an occlusion study with predictions based on the assumptions of the extended KLM. Analysis revealed significant correlations between observed and predicted results (R=0.93-0.98) and low error rates (7-13%). In conclusion, the extended KLM shows considerable merit as a first-pass design tool."
    },
    {
        "title": "Session details: Color/blind",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Color/blind",
        "data": "April 2007",
        "authors": [
            "Steve Feiner"
        ],
        "DOI": "https://doi.org/10.1145/3258908",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Towards developing assistive haptic feedback for visually impaired internet users",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Color/blind",
        "data": "April 2007",
        "authors": [
            "Ravi Kuber",
            "Wai Yu",
            "Graham McAllister"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240854",
        "citation": "41",
        "abstract": "Haptic technologies are thought to have the potential to help blind individuals overcome the challenges experienced when accessing the Web. This paper proposes a structured participatory-based approach for developing targeted haptic sensations for purposes of web page exploration, and reports preliminary results showing how HTML elements can be represented through the use of force-feedback. Findings are then compared with mappings from previous studies, demonstrating the need for providing tailored haptic sensations for blind Internet users. This research aims to culminate in a framework, encompassing a vocabulary of haptic sensations with accompanying recommendations for designers to reference when developing inclusive web solutions."
    },
    {
        "title": "An interface to support color blind computer users",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Color/blind",
        "data": "April 2007",
        "authors": [
            "Luke Jefferson",
            "Richard Harvey"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240855",
        "citation": "51",
        "abstract": "A new method for adapting digital images so that they are suitable for color blind viewers is presented. In contrast to earlier automatic methods which formulate the problem of adapting images for color blind observers as one of optimization, we demonstrate how it is possible to allow a user to compute a very wide range of adaptations in reasonable time under the control of a single variable. We demonstrate how the algorithm can be delivered as an adaptive technology via a simple interface, and evaluate the efficacy of our method using psychovisual experiments with simulated color blind users and a standard color vision test."
    },
    {
        "title": "An adaptive & adaptable approach to enhance web graphics accessibility for visually impaired people",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Color/blind",
        "data": "April 2007",
        "authors": [
            "Chui Chui Tan",
            "Wai Yu",
            "Graham McAllister"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240856",
        "citation": "2",
        "abstract": "To date, efforts have been made to enable visually impaired people to gain access to graphics on the Internet. However, these studies only offer a solution for a specific type of graphic by using a fixed set of hardware. To address this, a design approach of an adaptive and adaptable architecture is introduced which adapts to different graphical content, input/output devices (including assistive technologies) and user's profile and preferences. This system brings the opportunity to visually impaired people to gain access to graphics via different modalities by providing an adequate accessibility interface and interaction based on their profiles and needs."
    },
    {
        "title": "Session details: Social influence",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social influence",
        "data": "April 2007",
        "authors": [
            "Elizabeth Churchill"
        ],
        "DOI": "https://doi.org/10.1145/3258909",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Modeling the impact of shared visual information on collaborative reference",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social influence",
        "data": "April 2007",
        "authors": [
            "Darren Gergle",
            "Carolyn P. Rose",
            "Robert E. Kraut"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240858",
        "citation": "17",
        "abstract": "A number of recent studies have demonstrated that groups benefit considerably from access to shared visual information. This is due, in part, to the communicative efficiencies provided by the shared visual context. However, a large gap exists between our current theoretical understanding and our existing models. We address this gap by developing a computational model that integrates linguistic cues with visual cues in a way that effectively models reference during tightly-coupled, task-oriented interactions. The results demonstrate that an integrated model significantly outperforms existing language-only and visual-only models. The findings can be used to inform and augment the development of conversational agents, applications that dynamically track discourse and collaborative interactions, and dialogue managers for natural language interfaces."
    },
    {
        "title": "Similarity is more important than expertise: accent effects in speech interfaces",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social influence",
        "data": "April 2007",
        "authors": [
            "Nils Dahlbäck",
            "QianYing Wang",
            "Clifford Nass",
            "Jenny Alwin"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240859",
        "citation": "35",
        "abstract": "In a balanced between-participants experiment (N = 96) American and Swedish participants listened to tourist information on a website about an American or Swedish city presented in English with either an American or Swedish accent and evaluated the speakers' knowledge of the topic, the voice characteristics, and the information characteristics. Users preferred accents similar to their own. Similarity-attraction effects were so powerful that same-accents speakers were viewed as being more knowledgeable than different-accent speakers even when the information would be much better-known by the opposite-accent speaker. Implications for similarity-attraction overwhelming expertise are discussed."
    },
    {
        "title": "Provoking sociability",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social influence",
        "data": "April 2007",
        "authors": [
            "Brooke Foucault",
            "Helena M. Mentis",
            "Phoebe Sengers",
            "Devon Welles"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240860",
        "citation": "7",
        "abstract": "In this study, we explore the potential usefulness of disturbing, uncomfortable systems, demonstrating that provocative technology can have a positive effect on social relationships. We designed and evaluated an agent-based system that collects user information by asking seemingly benign questions, and then uses it to spread false, strange gossip throughout an office space. We show that provocative interaction on-line can improve off-line sociability."
    },
    {
        "title": "Social responses to virtual humans: implications for future interface design",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social influence",
        "data": "April 2007",
        "authors": [
            "Catherine Amine Zanbaka",
            "Amy Catherine Ulinski",
            "Paula Goolkasian",
            "Larry F. Hodges"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240861",
        "citation": "63",
        "abstract": "Do human-human social interactions carry over to human-virtual human social interactions? How does this affect future interface designers? We replicated classical tests of social influence known as the social facilitation and inhibition effects. Social facilitation/inhibition theory states that when in the presence of others, people perform simple tasks better and complex tasks worse. Participants were randomly assigned to perform both simple and complex tasks alone and in the presence of either a real human, a projected virtual human, or a virtual human in a head-mounted display. Our results showed participants were inhibited by the presence of others, whether real or virtual. That is, participants performed worse on the complex task, both in terms of percent correct and reaction times, when in the presence of others than when alone. Social facilitation did not occur with the real or virtual human. We discuss these results and their implications for future interface designers."
    },
    {
        "title": "Session details: Learning",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning",
        "data": "April 2007",
        "authors": [
            "Michael Twidale"
        ],
        "DOI": "https://doi.org/10.1145/3258910",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Hard lessons: effort-inducing interfaces benefit spatial learning",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning",
        "data": "April 2007",
        "authors": [
            "Andy Cockburn",
            "Per Ola Kristensson",
            "Jason Alexander",
            "Shumin Zhai"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240863",
        "citation": "40",
        "abstract": "Interface designers normally strive for a design that minimises the user's effort. However, when the design's objective is to train users to interact with interfaces that are highly dependent on spatial properties (e.g. keypad layout or gesture shapes) we contend that designers should consider explicitly increasing the mental effort of interaction. To test the hypothesis that effort aids spatial memory, we designed a \"frost-brushing\" interface that forces the user to mentally retrieve spatial information, or to physically brush away the frost to obtain visual guidance. We report results from two experiments using virtual keypad interfaces -- the first concerns spatial location learning of buttons on the keypad, and the second concerns both location and trajectory learning of gesture shape. The results support our hypothesis, showing that the frost-brushing design improved spatial learning. The participants' subjective responses emphasised the connections between effort, engagement, boredom, frustration, and enjoyment, suggesting that effort requires careful parameterisation to maximise its effectiveness."
    },
    {
        "title": "Multiple mice for retention tasks in disadvantaged schools",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning",
        "data": "April 2007",
        "authors": [
            "Udai Singh Pawar",
            "Joyojeet Pal",
            "Rahul Gupta",
            "Kentaro Toyama"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240864",
        "citation": "55",
        "abstract": "This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse, a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice."
    },
    {
        "title": "Strategies for accelerating on-line learning of hotkeys",
        "conferenceTitle": "CHI '07: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Learning",
        "data": "April 2007",
        "authors": [
            "Tovi Grossman",
            "Pierre Dragicevic",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1240624.1240865",
        "citation": "77",
        "abstract": "Hotkeys are extremely useful in leveraging expert performance, but learning them is a slow process. This paper investigates alternative menu designs that can motivate and help users remember associations between menu commands and hotkeys. Building upon previous work on paired-associate learning, we suggest that the transition to expert use can be accelerated by manipulating feedback and cost associated with menu selection. We evaluate five designs in a pilot study and then two of the most promising ones in a formal experiment, showing that the speed of hotkey learning can indeed be significantly increased with little modifications to the standard menu/hotkey paradigm."
    }
]