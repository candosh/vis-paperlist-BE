[
    {
        "title": "Session details: Non-Rigid Interaction Surfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Non-Rigid Interaction Surfaces",
        "data": "April 2015",
        "authors": [
            "Jörg Müller"
        ],
        "DOI": "https://doi.org/10.1145/3251786",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "bioLogic: Natto Cells as Nanoactuators for Shape Changing Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Non-Rigid Interaction Surfaces",
        "data": "April 2015",
        "authors": [
            "Lining Yao",
            "Jifei Ou",
            "Chin-Yi Cheng",
            "Helene Steiner",
            "Wen Wang",
            "Guanyun Wang",
            "Hiroshi Ishii"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702611",
        "citation": "138",
        "abstract": "Nature has engineered its own actuators, as well as the efficient material composition, geometry and structure to utilize its actuators and achieve functional transformation. Based on the natural phenomenon of cells' hygromorphic transformation, we introduce the living Bacillus Subtilis natto cell as a humidity sensitive nanoactuator. In this paper, we unfold the process of exploring and comparing cell types that are proper for HCI use, the development of the composite biofilm, the development of the responsive structures, the control setup for actuating biofilms, and a simulation and fabrication platform. Finally, we provide a variety of application designs, with and without computer control to demonstrate the potential of our bio actuators. Through this paper, we intend to enable the use of natto cells and our platform technologies for HCI researchers, designers and bio-hackers. More generally, we try to encourage the research and use of biological responsive materials and interdisciplinary research in HCI."
    },
    {
        "title": "Control of Non-Solid Diffusers by Electrostatic Charging",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Non-Rigid Interaction Surfaces",
        "data": "April 2015",
        "authors": [
            "Deepak Ranjan Sahoo",
            "Diego Martinez Plasencia",
            "Sriram Subramanian"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702363",
        "citation": "7",
        "abstract": "The form factors of displays using fog or water surface are limited by our ability to control the non-solid substances used as the diffuser. We propose a charging technique for polar aerosols (e.g., mist or fog) that allows control of the shape and trajectory of such non-solid diffusers using electric fields. We report experiments that allowed us to design a charging mechanism that produces charged fog aerosols with homogeneous electrical mobility. We illustrate our idea by demonstrating how electric fields can be used to control the shape of a fog display and the trajectory of a bubble display."
    },
    {
        "title": "Investigation of Material Properties for Thermal Imaging-Based Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Non-Rigid Interaction Surfaces",
        "data": "April 2015",
        "authors": [
            "Yomna Abdelrahman",
            "Alireza Sahami Shirazi",
            "Niels Henze",
            "Albrecht Schmidt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702290",
        "citation": "28",
        "abstract": "Recent work demonstrated the exciting opportunities that thermal imaging offers for the development of interactive systems. It was shown that a thermal camera can sense when a user touches a surface, performs gestures in the camera's direct field of view and, in addition, performs gestures outside the camera's direct field of view through thermal reflection. In this paper, we investigate the material properties that should be considered for detecting interaction using thermal imaging considering both in- and outdoor settings. We conducted a study to analyze the recognition performance for different gestures and different surfaces. Using the results, we derive guidelines on material properties of surfaces for detecting on-surface as well as mid-air interaction using a thermal camera. We discuss the constrains that should be taken into account using thermal imaging as the sensing technology. Finally, we present a material space based on our findings. The space depicts surfaces and the required properties that enable the different interaction techniques."
    },
    {
        "title": "ShapeClip: Towards Rapid Prototyping with Shape-Changing Displays for Designers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Non-Rigid Interaction Surfaces",
        "data": "April 2015",
        "authors": [
            "John Hardy",
            "Christian Weichel",
            "Faisal Taher",
            "John Vidler",
            "Jason Alexander"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702599",
        "citation": "68",
        "abstract": "This paper presents ShapeClip: a modular tool capable of transforming any computer screen into a z-actuating shape-changing display. This enables designers to produce dynamic physical forms by \"clipping\" actuators onto screens. ShapeClip displays are portable, scalable, fault-tolerant, and support runtime re-arrangement. Users are not required to have knowledge of electronics or programming, and can develop motion designs with presentation software, image editors, or web-technologies. To evaluate ShapeClip we carried out a full-day workshop with expert designers. Participants were asked to generate shape-changing designs and then construct them using ShapeClip. ShapeClip enabled participants to rapidly and successfully transform their ideas into functional systems."
    },
    {
        "title": "FluxPaper: Reinventing Paper with Dynamic Actuation Powered by Magnetic Flux",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Non-Rigid Interaction Surfaces",
        "data": "April 2015",
        "authors": [
            "Masa Ogata",
            "Masaaki Fukumoto"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702516",
        "citation": "24",
        "abstract": "FluxPaper is a new paper-based medium that enables physical movement and dynamic interaction between a high-power magnetized paper and a programmable magnetic field. FluxPaper has a very thin patterned magnetic layer (0.1 mm) pasted behind the paper. A thin but strong neodymium-based magnet realizes fast, powerful, and precise physical actions while retaining the original characteristics of the paper that is widely used in our daily lives. Owing to an effective magnetic pattern and a computer-controlled magnetic field, FluxPaper can add new interaction modality to ordinary paper. We describe the functions of magnetized paper; challenges through realization; and the interaction scenarios in several applications, such as self-alignment, self-construction, floating on the board, and quickly picking out a target card from a stack."
    },
    {
        "title": "Session details: What do I hear? Communicating with Sound",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: What do I hear? Communicating with Sound",
        "data": "April 2015",
        "authors": [
            "Ian Oakley"
        ],
        "DOI": "https://doi.org/10.1145/3251787",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "TabLETS Get Physical: Non-Visual Text Entry on Tablet Devices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: What do I hear? Communicating with Sound",
        "data": "April 2015",
        "authors": [
            "João Guerreiro",
            "André Rodrigues",
            "Kyle Montague",
            "Tiago Guerreiro",
            "Hugo Nicolau",
            "Daniel Gonçalves"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702373",
        "citation": "31",
        "abstract": "Tablet devices can display full-size QWERTY keyboards similar to the physical ones. Yet, the lack of tactile feedback and the inability to rest the fingers on the home keys result in a highly demanding and slow exploration task for blind users. We present SpatialTouch, an input system that leverages previous experience with physical QWERTY keyboards, by supporting two-handed interaction through multitouch exploration and spatial, simultaneous audio feedback. We conducted a user study, with 30 novice touchscreen participants entering text under one of two conditions: (1) SpatialTouch or (2) mainstream accessibility method Explore by Touch. We show that SpatialTouch enables blind users to leverage previous experience as they do a better use of home keys and perform more efficient exploration paths. Results suggest that although SpatialTouch did not result in faster input rates overall, it was indeed able to leverage previous QWERTY experience in contrast to Explore by Touch."
    },
    {
        "title": "VocalSketch: Vocally Imitating Audio Concepts",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: What do I hear? Communicating with Sound",
        "data": "April 2015",
        "authors": [
            "Mark Cartwright",
            "Bryan Pardo"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702387",
        "citation": "23",
        "abstract": "A natural way of communicating an audio concept is to imitate it with one's voice. This creates an approximation of the imagined sound (e.g. a particular owl's hoot), much like how a visual sketch approximates a visual concept (e.g a drawing of the owl). If a machine could understand vocal imitations, users could communicate with software in this natural way, enabling new interactions (e.g. programming a music synthesizer by imitating the desired sound with one's voice). In this work, we collect thousands of crowd-sourced vocal imitations of a large set of diverse sounds, along with data on the crowd's ability to correctly label these vocal imitations. The resulting data set will help the research community understand which audio concepts can be effectively communicated with this approach. We have released the data set so the community can study the related issues and build systems that leverage vocal imitation as an interaction modality."
    },
    {
        "title": "An Evaluation of Multidimensional Controllers for Sound Design Tasks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: What do I hear? Communicating with Sound",
        "data": "April 2015",
        "authors": [
            "Robert Tubb",
            "Simon Dixon"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702499",
        "citation": "3",
        "abstract": "This paper presents an investigation into musicians' ability to control sound synthesiser parameters using various inter- faces. The principal aim was to compare separate, 1D parameter controls (touchscreen sliders) to multidimensional con- trollers (an XY touchpad for 2D, the Leap Motion for 3D). Subjects had to match a target sound as quickly and accurately as possible. Results show that after about two hours of practice, the XY pad is 9% faster than two sliders for no accuracy loss, and the Leap is 17% faster than 3 sliders with 9% accuracy loss. The multidimensional controllers improved most with practice. A new perspective on Fitts' index of difficulty is presented: \"Index of Search Space Reduction\" (ISSR). ISSR and retrospective accuracy thresholds on the search trajectory are used to obtain straight line plots and throughput values. These plots reveal that the Leap's speed improvement was mainly due to reaction time, but the XY pad traversed the space faster."
    },
    {
        "title": "AnnoTone: Record-time Audio Watermarking for Context-aware Video Editing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: What do I hear? Communicating with Sound",
        "data": "April 2015",
        "authors": [
            "Ryohei Suzuki",
            "Daisuke Sakamoto",
            "Takeo Igarashi"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702358",
        "citation": "6",
        "abstract": "We present a video annotation system called ``AnnoTone', which can embed various contextual information describing a scene, such as geographical location. Then the system allows the user to edit the video using this contextual information, enabling one to, for example, overlay with map or graphical annotations. AnnoTone converts annotation data into high-frequency audio signals (which are inaudible to the human ear), and then transmits them from a smartphone speaker placed near a video camera. This scheme makes it possible to add annotations using standard video cameras with no requirements for specific equipment other than a smartphone. We designed the audio watermarking protocol using dual-tone multi-frequency signaling, and developed a general-purpose annotation framework including an annotation generator and extractor. We conducted a series of performance tests to understand the reliability and the quality of the watermarking method. We then created several examples of video-editing applications using annotations to demonstrate the usefulness of Annotone, including an After Effects plug-in."
    },
    {
        "title": "Exploring Gesture Sonification to Support Reflective Craft Practice",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: What do I hear? Communicating with Sound",
        "data": "April 2015",
        "authors": [
            "Thomas Smith",
            "Simon J. Bowen",
            "Bettina Nissen",
            "Jonathan Hook",
            "Arno Verhoeven",
            "John Bowers",
            "Peter Wright",
            "Patrick Olivier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702497",
        "citation": "15",
        "abstract": "Much of the knowing employed in skilled craft practice is difficult to communicate solely through written or verbal description. Consequently, the reflection and development of a craft practice in this manner may miss important nuances of practitioners' skills and experiences. We created digital technologies to sonify (using audio to perceptualize data) a group of craft practitioners' gestures to explore how we can aid their reflection in and on their craft, and consequently develop it. Over a number of workshops, the design of these sonifications were iterated based on how the practitioners responded to them. We found that direct sonification of gesture (sounds generated directly from motion sensor data) helped practitioners understand and reflect upon their own and each other's practice, encouraged discussion and enabled modification of craft technique."
    },
    {
        "title": "Session details: Rethinking Evaluation for Today's HCI",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Rethinking Evaluation for Today's HCI",
        "data": "April 2015",
        "authors": [
            "Wendy Mackay"
        ],
        "DOI": "https://doi.org/10.1145/3251788",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Remote Paper Prototype Testing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Rethinking Evaluation for Today's HCI",
        "data": "April 2015",
        "authors": [
            "Kevin Chen",
            "Haoqi Zhang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702423",
        "citation": "12",
        "abstract": "To test paper prototypes of mobile applications, we have been experimenting with remote paper prototype testing as an approach and tool for enabling a designer to wizard a paper prototype from afar while a user tests the prototype out of the lab. This paper presents a system for remote paper prototype testing that consists of (1) a video camera placed over a paper prototype, which streams a live audio-visual feed via Google Hangouts to a tester, and (2) Google Glass on the tester, which streams a live audio-visual-data feed to the facilitator and wizard. Results from a pilot study found that remote paper prototype testing helped designers gain valuable insights through use in realistic scenarios."
    },
    {
        "title": "Controlling In-the-Wild Evaluation Studies of Public Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Rethinking Evaluation for Today's HCI",
        "data": "April 2015",
        "authors": [
            "Sandy Claes",
            "Niels Wouters",
            "Karin Slegers",
            "Andrew Vande Moere"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702353",
        "citation": "11",
        "abstract": "In this paper, we investigate the potential of controlled in-the-wild studies as an evaluation methodology that merges the benefits of lab-based and in-the-wild studies. Our exploratory investigation builds upon a comparative, between subject experiment benchmarking different interaction features of a custom public installation that visualized a series of urban datasets. In order to evaluate the usefulness of the in-the-wild versus the controlled in-the-wild methodologies, we compared the resulting findings in terms of participant engagement, insight generation, and social interaction. We propose that a controlled in-the-wild study offers a viable alternative when evaluating more complex interaction methods in public space, hereby potentially reducing the practical efforts of in-the-wild studies to involve participants."
    },
    {
        "title": "Evaluation Probes",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Rethinking Evaluation for Today's HCI",
        "data": "April 2015",
        "authors": [
            "Anna Luusua",
            "Johanna Ylipulli",
            "Marko Jurmu",
            "Henrika Pihlajaniemi",
            "Piia Markkanen",
            "Timo Ojala"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702466",
        "citation": "9",
        "abstract": "We introduce evaluation probes for conducting emic, experiential evaluation of urban technologies \"in the wild\" without direct researcher presence. We commence with a thorough discussion and analysis of the original cultural probes, used by Gaver, Dunne and Pacenti to gain design inspiration, and their subsequent variations. We develop the concept of evaluation probes through careful re-conceptualization and application of the cultural probes in three successive studies conducted in the wild. We recount and reflect on our use of evaluation probes and discuss their merits and limitations in experiential emic evaluation."
    },
    {
        "title": "Real-World Affinity Diagramming Practices: Bridging the Paper-Digital Gap",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Rethinking Evaluation for Today's HCI",
        "data": "April 2015",
        "authors": [
            "Gunnar Harboe",
            "Elaine M. Huang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702561",
        "citation": "83",
        "abstract": "Despite the availability of computer-based alternatives both for desktop and touch screen systems, a number of cooperative work processes still commonly rely on simple paper sticky notes. In this paper, we present the first in-depth investigation of the real-world practices of people who use paper-based affinity diagrams and similar clustering processes in their work, in order to identify challenges and requirements for technology support. Findings from retrospective and artifact-based interviews with 13 participants suggest ways in which the rich interactions and material affordances offered by paper are key to the process. Instead of seeking to replicate interactions with paper on a screen, simpler transfer of information between the physical and digital worlds has the potential to address many of the most pressing problems experienced in practice. We describe different types of technology integration and augmentation, with preliminary recommendations for different situations."
    },
    {
        "title": "Situational Ethics: Re-thinking Approaches to Formal Ethics Requirements for Human-Computer Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Rethinking Evaluation for Today's HCI",
        "data": "April 2015",
        "authors": [
            "Cosmin Munteanu",
            "Heather Molyneaux",
            "Wendy Moncur",
            "Mario Romero",
            "Susan O'Donnell",
            "John Vines"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702481",
        "citation": "81",
        "abstract": "Most Human-Computer Interaction (HCI) researchers are accustomed to the process of formal ethics review for their evaluation or field trial protocol. Although this process varies by country, the underlying principles are universal. While this process is often a formality, for field research or lab-based studies with vulnerable users, formal ethics requirements can be challenging to navigate -- a common occurrence in the social sciences; yet, in many cases, foreign to HCI researchers. Nevertheless, with the increase in new areas of research such as mobile technologies for marginalized populations or assistive technologies, this is a current reality. In this paper we present our experiences and challenges in conducting several studies that evaluate interactive systems in difficult settings, from the perspective of the ethics process. Based on these, we draft recommendations for mitigating the effect of such challenges to the ethical conduct of research. We then issue a call for interaction researchers, together with policy makers, to refine existing ethics guidelines and protocols in order to more accurately capture the particularities of such field-based evaluations, qualitative studies, challenging lab-based evaluations, and ethnographic observations."
    },
    {
        "title": "Session details: Improving Game Experiences",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Improving Game Experiences",
        "data": "April 2015",
        "authors": [
            "Lennart Nacke"
        ],
        "DOI": "https://doi.org/10.1145/3251789",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "The Royal Corgi: Exploring Social Gaze Interaction for Immersive Gameplay",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Improving Game Experiences",
        "data": "April 2015",
        "authors": [
            "Melodie Vidal",
            "Remi Bismuth",
            "Andreas Bulling",
            "Hans Gellersen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702163",
        "citation": "38",
        "abstract": "The eyes are a rich channel for non-verbal communication in our daily interactions. We propose social gaze interaction as a game mechanic to enhance user interactions with virtual characters. We develop a game from the ground-up in which characters are designed to be reactive to the player's gaze in social ways, such as getting annoyed when the player seems distracted or changing their dialogue depending on the player's apparent focus of attention. Results from a qualitative user study provide insights about how social gaze interaction is intuitive for users, elicits deep feelings of immersion, and highlight the players' self-consciousness of their own eye movements through their strong reactions to the characters."
    },
    {
        "title": "Exploring 3D User Interface Technologies for Improving the Gaming Experience",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Improving Game Experiences",
        "data": "April 2015",
        "authors": [
            "Arun Kulshreshth",
            "Joseph J. LaViola"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702138",
        "citation": "6",
        "abstract": "We present the results of a comprehensive video game study which explores how the gaming experience is effected when several 3D user interface technologies are used simultaneously. We custom designed an air-combat game integrating several 3DUI technologies (stereoscopic 3D, head tracking, and finger-count gestures) and studied the combined effect of these technologies on the gaming experience. Our game design was based on existing design principles for optimizing the usage of these technologies in isolation. Additionally, to enhance depth perception and minimize visual discomfort, the game dynamically optimizes stereoscopic 3D parameters (convergence and separation) based on the user's look direction. We conducted a within subjects experiment where we examined performance data and self-reported data on users perception of the game. Our results indicate that participants performed significantly better when all the 3DUI technologies (stereoscopic 3D, head-tracking and finger-count gestures) were available simultaneously with head tracking as a dominant factor. We explore the individual contribution of each of these technologies to the overall gaming experience and discuss the reasons behind our findings."
    },
    {
        "title": "Quantifying and Mitigating the Negative Effects of Local Latencies on Aiming in 3D Shooter Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Improving Game Experiences",
        "data": "April 2015",
        "authors": [
            "Zenja Ivkovic",
            "Ian Stavness",
            "Carl Gutwin",
            "Steven Sutcliffe"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702432",
        "citation": "54",
        "abstract": "Real-time games such as first-person shooters (FPS) are sensitive to even small amounts of lag. The effects of net-work latency have been studied, but less is known about local latency, the lag caused by input devices and displays. While local latency is important to gamers, we do not know how it affects aiming performance and whether we can reduce its negative effects. To explore these issues, we tested local latency in a variety of real-world gaming scenarios and carried out a controlled study focusing on targeting and tracking activities in an FPS game with varying degrees of local latency. In addition, we tested the ability of a lag compensation technique (based on aim assistance) to mitigate the negative effects. Our study found local latencies in the real-world range from 23 to 243 ms which cause significant and substantial degradation in performance (even for latencies as low as 41 ms). The study also showed that our compensation technique worked extremely well, reducing the problems caused by lag in the case of targeting, and removing the problem altogether in the case of tracking. Our work shows that local latency is a real and substantial problem -- but games can mitigate the problem with appropriate compensation methods."
    },
    {
        "title": "First Person vs. Third Person Perspective in Digital Games: Do Player Preferences Affect Immersion?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Improving Game Experiences",
        "data": "April 2015",
        "authors": [
            "Alena Denisova",
            "Paul Cairns"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702256",
        "citation": "76",
        "abstract": "Contemporary digital game developers offer a variety of games for the diverse tastes of their customers. Although the gaming experience often depends on one's preferences, the same may not apply to the level of their immersion. It has been argued whether the player perspective can influence the level of player's involvement with the game. The aim of this study was to research whether interacting with a game in first person perspective is more immersive than playing in the third person point of view (POV). The set up to test the theory involved participants playing a role-playing game in either mode, naming their preferred perspective, and subjectively evaluating their immersive experience. The results showed that people were more immersed in the game play when viewing the game world through the eyes of the character, regardless of their preferred perspectives."
    },
    {
        "title": "VIZMO Game Browser: Accessing Video Games by Visual Style and Mood",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Improving Game Experiences",
        "data": "April 2015",
        "authors": [
            "Jin Ha Lee",
            "Sungsoo (Ray) Hong",
            "Hyerim Cho",
            "Yea-Seul Kim"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702264",
        "citation": "6",
        "abstract": "Despite the growing interests in video games as consumer products as well as objects of research, current methods for accessing video games are limited. We present Vizmo as a new way of browsing video games based on their visual style and mood. In order to test the usability and usefulness of Vizmo, we asked 19 video game experts to evaluate their interaction with the tool. The results show that experts perceived Vizmo as a novel and aesthetically pleasing game discovery tool which would be most useful for game research on historical and aesthetic aspects. We discuss five key points for improving the design of Vizmo as well as our future plan for the next iteration of this prototype game browser."
    },
    {
        "title": "Session details: Facebook Newsfeeds & Friendships",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Facebook Newsfeeds & Friendships",
        "data": "April 2015",
        "authors": [
            "David Shamma"
        ],
        "DOI": "https://doi.org/10.1145/3251790",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "\"I always assumed that I wasn't really that close to [her]\": Reasoning about Invisible Algorithms in News Feeds",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Facebook Newsfeeds & Friendships",
        "data": "April 2015",
        "authors": [
            "Motahhare Eslami",
            "Aimee Rickman",
            "Kristen Vaccaro",
            "Amirhossein Aleyasen",
            "Andy Vuong",
            "Karrie Karahalios",
            "Kevin Hamilton",
            "Christian Sandvig"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702556",
        "citation": "339",
        "abstract": "Our daily digital life is full of algorithmically selected content such as social media feeds, recommendations and personalized search results. These algorithms have great power to shape users' experiences, yet users are often unaware of their presence. Whether it is useful to give users insight into these algorithms' existence or functionality and how such insight might affect their experience are open questions. To address them, we conducted a user study with 40 Facebook users to examine their perceptions of the Facebook News Feed curation algorithm. Surprisingly, more than half of the participants (62.5%) were not aware of the News Feed curation algorithm's existence at all. Initial reactions for these previously unaware participants were surprise and anger. We developed a system, FeedVis, to reveal the difference between the algorithmically curated and an unadulterated News Feed to users, and used it to study how users perceive this difference. Participants were most upset when close friends and family were not shown in their feeds. We also found participants often attributed missing stories to their friends' decisions to exclude them rather than to Facebook News Feed algorithm. By the end of the study, however, participants were mostly satisfied with the content on their feeds. Following up with participants two to six months after the study, we found that for most, satisfaction levels remained similar before and after becoming aware of the algorithm's presence, however, algorithmic awareness led to more active engagement with Facebook and bolstered overall feelings of control on the site."
    },
    {
        "title": "News Feed: What's in it for Me?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Facebook Newsfeeds & Friendships",
        "data": "April 2015",
        "authors": [
            "Paul Lapides",
            "Apoorve Chokshi",
            "Sheelagh Carpendale",
            "Saul Greenberg"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702554",
        "citation": "5",
        "abstract": "Over a billion people use social networking sites like Facebook to maintain awareness of their friends. Facebook's News Feed is the primary mechanism by which people are shown updates about their friends' daily activities on the site in the form of an algorithmically curated list of stories. This paper examines how people browse the News Feed, their perceptions and satisfaction while using it, and the interactions they make with their personal social network. We conducted a qualitative study involving think-aloud semi-structured interviews as the participants casually browsed their own feeds. We observed a wide variation in the use of the News Feed ranging from careful consideration of social conventions, judgment of people, and annoyance and frustration towards certain friends. Our findings suggest that people do not deliberately curate their own News Feed either due to lack of awareness or perceived social repercussions."
    },
    {
        "title": "Understanding User Beliefs About Algorithmic Curation in the Facebook News Feed",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Facebook Newsfeeds & Friendships",
        "data": "April 2015",
        "authors": [
            "Emilee Rader",
            "Rebecca Gray"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702174",
        "citation": "183",
        "abstract": "People are becoming increasingly reliant on online socio-technical systems that employ algorithmic curation to organize, select and present information. We wanted to understand how individuals make sense of the influence of algorithms, and how awareness of algorithmic curation may impact their interaction with these systems. We investigated user understanding of algorithmic curation in Facebook's News Feed, by analyzing open-ended responses to a survey question about whether respondents believe their News Feeds show them every post their Facebook Friends create. Responses included a wide range of beliefs and causal inferences, with different potential consequences for user behavior in the system. Because user behavior is both input for algorithms and constrained by them, these patterns of belief may have tangible consequences for the system as a whole."
    },
    {
        "title": "Session details: Activism in Wikipedia & Beyond",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activism in Wikipedia & Beyond",
        "data": "April 2015",
        "authors": [
            "Gary Hsieh"
        ],
        "DOI": "https://doi.org/10.1145/3251791",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Cross-language Wikipedia Editing of Okinawa, Japan",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activism in Wikipedia & Beyond",
        "data": "April 2015",
        "authors": [
            "Scott A. Hale"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702346",
        "citation": "8",
        "abstract": "This article analyzes users who edit Wikipedia articles about Okinawa, Japan, in English and Japanese. It finds these users are among the most active and dedicated users in their primary languages, where they make many large, high-quality edits. However, when these users edit in their non-primary languages, they tend to make edits of a different type that are overall smaller in size and more often restricted to the narrow set of articles that exist in both languages. Design changes to motivate wider contributions from users in their non-primary languages and to encourage multilingual users to transfer more information across language divides are presented."
    },
    {
        "title": "Societal Controversies in Wikipedia Articles",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activism in Wikipedia & Beyond",
        "data": "April 2015",
        "authors": [
            "Erik Borra",
            "Esther Weltevrede",
            "Paolo Ciuccarelli",
            "Andreas Kaltenbrunner",
            "David Laniado",
            "Giovanni Magni",
            "Michele Mauri",
            "Richard Rogers",
            "Tommaso Venturini"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702436",
        "citation": "30",
        "abstract": "Collaborative content creation inevitably reaches situations where different points of view lead to conflict. We focus on Wikipedia, the free encyclopedia anyone may edit, where disputes about content in controversial articles often reflect larger societal debates. While Wikipedia has a public edit history and discussion section for every article, the substance of these sections is difficult to phantom for Wikipedia users interested in the development of an article and in locating which topics were most controversial. In this paper we present Contropedia, a tool that augments Wikipedia articles and gives insight into the development of controversial topics. Contropedia uses an efficient language agnostic measure based on the edit history that focuses on wiki links to easily identify which topics within a Wikipedia article have been most controversial and when."
    },
    {
        "title": "Barriers to the Localness of Volunteered Geographic Information",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activism in Wikipedia & Beyond",
        "data": "April 2015",
        "authors": [
            "Shilad W. Sen",
            "Heather Ford",
            "David R. Musicant",
            "Mark Graham",
            "Os Keyes",
            "Brent Hecht"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702170",
        "citation": "21",
        "abstract": "Localness is an oft-cited benefit of volunteered geographic information (VGI). This study examines whether localness is a constant, universally shared benefit of VGI, or one that varies depending on the context in which it is produced. Focusing on articles about geographic entities (e.g. cities, points of interest) in 79 language editions of Wikipedia, we examine the localness of both the editors working on articles and the sources of the information they cite. We find extensive geographic inequalities in localness, with the degree of localness varying with the socioeconomic status of the local population and the health of the local media. We also point out the key role of language, showing that information in languages not native to a place tends to be produced and sourced by non-locals. We discuss the implications of this work for our understanding of the nature of VGI and highlight a generalizable technical contribution: an algorithm that determines the home country of the original publisher of online content."
    },
    {
        "title": "The Heart Work of Wikipedia: Gendered, Emotional Labor in the World's Largest Online Encyclopedia",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activism in Wikipedia & Beyond",
        "data": "April 2015",
        "authors": [
            "Amanda Menking",
            "Ingrid Erickson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702514",
        "citation": "89",
        "abstract": "This note explores the issue of women's participation in Wikipedia through the lens of emotional labor. Using a grounded theory approach, we detail the kinds of tasks women Wikipedians choose to do and explore why they choose the work they do. We also explore the emotional costs of their labor and their strategies for coping. Our analysis of 20 interviews leads us to posit that the gendered and emotional labor required of many women to participate in Wikipedia's production renders it, problematically, a space of conflicting public and private spheres, motivated by antithetical open and closed values. In addition to other contributions, we believe this insight sheds light on some of the complex dynamics behind Wikipedia's observed gender gap."
    },
    {
        "title": "How Activists Are Both Born and Made: An Analysis of Users on Change.org",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activism in Wikipedia & Beyond",
        "data": "April 2015",
        "authors": [
            "Shih-Wen Huang",
            "Minhyang (Mia) Suh",
            "Benjamin Mako Hill",
            "Gary Hsieh"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702559",
        "citation": "28",
        "abstract": "E-petitioning has become one of the most important and popular forms of online activism. Although e-petition success is driven by user behavior, users have received relatively little study by HCI and social computing researchers. Drawing from theoretical and empirical work in analogous social computing systems, we identify two potentially competing theories about the trajectories of users in e-petition platforms: (1) \"power\" users in social computing systems are born, not made; and (2) users mature into \"power\" users. In a quantitative analysis of data from Change.org, one of the largest online e-petition platforms, we test and find support for both theories. A follow-up qualitative analysis shows that not only do users learn from their experience, systems also \"learn\" from users to make better recommendations. In this sense, we find that although power users are \"born,\" they are also \"made\" through both processes of personal growth and improved support from the system."
    },
    {
        "title": "Session details: HMDs & Wearables to Overcome Disabilities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs & Wearables to Overcome Disabilities",
        "data": "April 2015",
        "authors": [
            "Shaun Kane"
        ],
        "DOI": "https://doi.org/10.1145/3251792",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Personalized, Wearable Control of a Head-mounted Display for Users with Upper Body Motor Impairments",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs & Wearables to Overcome Disabilities",
        "data": "April 2015",
        "authors": [
            "Meethu Malu",
            "Leah Findlater"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702188",
        "citation": "39",
        "abstract": "Head-mounted displays provide relatively hands-free interaction that could improve mobile computing access for users with motor impairments. To investigate this largely unexplored area, we present two user studies. The first, smaller study evaluated the accessibility of Google Glass, a head-mounted display, with 6 participants. Findings revealed potential benefits of a head-mounted display yet demonstrated the need for alternative means of controlling Glass-3 of the 6 participants could not use it at all. We then conducted a second study with 12 participants to evaluate a potential alternative input mechanism that could allow for accessible control of a head-mounted display: switch-based wearable touchpads that can be affixed to the body or wheelchair. The study assessed input performance with three sizes of touchpad, investigated personalization patterns when participants were asked to place the touchpads on their body or wheelchair, and elicited subjective responses. All 12 participants were able to use the touchpads to control the display, and patterns of touchpad placement point to the value of personalization in providing support for each user's motor abilities."
    },
    {
        "title": "Designing Conversation Cues on a Head-Worn Display to Support Persons with Aphasia",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs & Wearables to Overcome Disabilities",
        "data": "April 2015",
        "authors": [
            "Kristin Williams",
            "Karyn Moffatt",
            "Denise McCall",
            "Leah Findlater"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702484",
        "citation": "22",
        "abstract": "Symbol-based dictionaries of text, images and sound can help individuals with aphasia find the words they need, but are often seen as a last resort because they tend to replace rather than augment the user's natural speech. Through two design investigations, we explore head-worn displays as a means of providing unobtrusive, always-available, and glanceable vocabulary support. The first study used narrative storyboards as a design probe to explore the potential benefits and challenges of a head-worn approach over traditional augmented alternative communication (AAC) tools. The second study then evaluated a proof-of-concept prototype in both a lab setting with the researcher and in situ with unfamiliar conversation partners at a local market. Findings suggest that a head-worn approach could better allow wearers to maintain focus on the conversation, reduce reliance on the availability of external tools (e.g., paper and pen) or people, and minimize visibility of the support by others. These studies should motivate further investigation of head-worn conversational support."
    },
    {
        "title": "Head-Mounted Display Visualizations to Support Sound Awareness for the Deaf and Hard of Hearing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs & Wearables to Overcome Disabilities",
        "data": "April 2015",
        "authors": [
            "Dhruv Jain",
            "Leah Findlater",
            "Jamie Gilkeson",
            "Benjamin Holland",
            "Ramani Duraiswami",
            "Dmitry Zotkin",
            "Christian Vogler",
            "Jon E. Froehlich"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702393",
        "citation": "72",
        "abstract": "Persons with hearing loss use visual signals such as gestures and lip movement to interpret speech. While hearing aids and cochlear implants can improve sound recognition, they generally do not help the wearer localize sound necessary to leverage these visual cues. In this paper, we design and evaluate visualizations for spatially locating sound on a head-mounted display (HMD). To investigate this design space, we developed eight high-level visual sound feedback dimensions. For each dimension, we created 3-12 example visualizations and evaluated these as a design probe with 24 deaf and hard of hearing participants (Study 1). We then implemented a real-time proof-of-concept HMD prototype and solicited feedback from 4 new participants (Study 2). Study 1 findings reaffirm past work on challenges faced by persons with hearing loss in group conversations, provide support for the general idea of sound awareness visualizations on HMDs, and reveal preferences for specific design options. Although preliminary, Study 2 further contextualizes the design probe and uncovers directions for future work."
    },
    {
        "title": "Using Interactive Machine Learning to Support Interface Development Through Workshops with Disabled People",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs & Wearables to Overcome Disabilities",
        "data": "April 2015",
        "authors": [
            "Simon Katan",
            "Mick Grierson",
            "Rebecca Fiebrink"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702474",
        "citation": "32",
        "abstract": "We have applied interactive machine learning (IML) to the creation and customisation of gesturally controlled musical interfaces in six workshops with people with learning and physical disabilities. Our observations and discussions with participants demonstrate the utility of IML as a tool for participatory design of accessible interfaces. This work has also led to a better understanding of challenges in end-user training of learning models, of how people develop personalised interaction strategies with different types of pre-trained interfaces, and of how properties of control spaces and input devices influence people's customisation strategies and engagement with instruments. This work has also uncovered similarities between the musical goals and practices of disabled people and those of expert musicians."
    },
    {
        "title": "Tongue-in-Cheek: Using Wireless Signals to Enable Non-Intrusive and Flexible Facial Gestures Detection",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs & Wearables to Overcome Disabilities",
        "data": "April 2015",
        "authors": [
            "Mayank Goel",
            "Chen Zhao",
            "Ruth Vinisha",
            "Shwetak N. Patel"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702591",
        "citation": "33",
        "abstract": "Serious brain injuries, spinal injuries, and motor neuron diseases often lead to severe paralysis. Individuals with such disabilities can benefit from interaction techniques that enable them to interact with the devices and thereby the world around them. While a number of systems have proposed tongue-based gesture detection systems, most of these systems require intrusive instrumentation of the user's body (e.g., tongue piercing, dental retainers, multiple electrodes on chin). In this paper, we propose a wireless, non-intrusive and non-contact facial gesture detection system using X-band Doppler. The system can accurately differentiate between 8 different facial gestures through non-contact sensing, with an average accuracy of 94.3%."
    },
    {
        "title": "Session details: Visualizing Data",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Data",
        "data": "April 2015",
        "authors": [
            "Christophe Hurter"
        ],
        "DOI": "https://doi.org/10.1145/3251793",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "MatrixWave: Visual Comparison of Event Sequence Data",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Data",
        "data": "April 2015",
        "authors": [
            "Jian Zhao",
            "Zhicheng Liu",
            "Mira Dontcheva",
            "Aaron Hertzmann",
            "Alan Wilson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702419",
        "citation": "86",
        "abstract": "Event sequence data analysis is common in many domains, including web and software development, transportation, and medical care. Few have investigated visualization techniques for comparative analysis of multiple event sequence datasets. Grounded in the real-world characteristics of web clickstream data, we explore visualization techniques for comparison of two clickstream datasets collected on different days or from users with different demographics. Through iterative design with web analysts, we designed MatrixWave, a matrix-based representation that allows analysts to get an overview of differences in traffic patterns and interactively explore paths through the website. We use color to encode differences and size to offer context over traffic volume. User feedback on MatrixWave is positive. Our study participants made fewer errors with MatrixWave and preferred it over the more familiar Sankey diagram."
    },
    {
        "title": "The Effects of Representation and Juxtaposition on Graphical Perception of Matrix Visualization",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Data",
        "data": "April 2015",
        "authors": [
            "Xiaotong Liu",
            "Han-Wei Shen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702217",
        "citation": "12",
        "abstract": "Analyzing multiple networks at once is a common yet difficult task in many domains. Using adjacency matrices for this purpose, however, can be effective because of its superior ability to accommodate dense networks in a small area. We evaluate various representations and juxtaposition designs for visualizing adjacency matrices through a series of controlled experiments. We investigate the effect of using square matrices and triangular matrices on the speed and accuracy of performing graphical-perception tasks. Based on human symmetric perception, we propose two alternative juxtaposition designs to the conventional side-by-side juxtaposition, and study how users perform visual search and comparison tasks regarding different juxtaposition types. Our results show that the matrix representations have similar performance, and the matrix juxtaposition types perform differently. With the design guidelines derived from our studies, we present a compact visualization termed TileMatrix for juxtaposing a large number of matrices, and demonstrate its effectiveness in analyzing multi-faceted, time-varying networks using real-world data."
    },
    {
        "title": "g-Miner: Interactive Visual Group Mining on Multivariate Graphs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Data",
        "data": "April 2015",
        "authors": [
            "Nan Cao",
            "Yu-Ru Lin",
            "Liangyue Li",
            "Hanghang Tong"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702446",
        "citation": "27",
        "abstract": "With the rapid growth of rich network data available through various sources such as social media and digital archives,there is a growing interest in more powerful network visual analysis tools and methods. The rich information about the network nodes and links can be represented as multivariate graphs, in which the nodes are accompanied with attributes to represent the properties of individual nodes. An important task often encountered in multivariate network analysis is to uncover link structure with groups, e.g., to understand why a person fits a specific job or certain role in a social group well.The task usually involves complex considerations including specific requirement of node attributes and link structure, and hence a fully automatic solution is typically not satisfactory.In this work, we identify the design challenges for min-ing groups with complex criteria and present an interactive system, \"g-Miner,\" that enables visual mining of groups on multivariate graph data. We demonstrate the effectiveness of our system through case study and in-depth expert inter-views. This work contributes to understanding the design of systems for leveraging users' knowledge progressively with algorithmic capacity for tackling massive heterogeneous information."
    },
    {
        "title": "Trajectory Bundling for Animated Transitions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Data",
        "data": "April 2015",
        "authors": [
            "Fan Du",
            "Nan Cao",
            "Jian Zhao",
            "Yu-Ru Lin"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702476",
        "citation": "18",
        "abstract": "Animated transition has been a popular design choice for smoothly switching between different visualization views or layouts, in which movement trajectories are created as cues for tracking objects during location shifting. Tracking moving objects, however, becomes difficult when their movement paths overlap or the number of tracking targets increases. We propose a novel design to facilitate tracking moving objects in animated transitions. Instead of simply animating an object along a straight line, we create \"bundled\" movement trajectories for a group of objects that have spatial proximity and share similar moving directions. To study the effect of bundled trajectories, we untangle variations due to different aspects of tracking complexity in a comprehensive controlled user study. The results indicate that using bundled trajectories is particularly effective when tracking more targets (six vs. three targets) or when the object movement involves a high degree of occlusion or deformation. Based on the study, we discuss the advantages and limitations of the new technique, as well as provide design implications."
    },
    {
        "title": "Session details: Interaction in 3D Space",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction in 3D Space",
        "data": "April 2015",
        "authors": [
            "Kening Zhu"
        ],
        "DOI": "https://doi.org/10.1145/3251794",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Physical Loci: Leveraging Spatial, Object and Semantic Memory for Command Selection",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction in 3D Space",
        "data": "April 2015",
        "authors": [
            "Simon T. Perrault",
            "Eric Lecolinet",
            "Yoann Pascal Bourse",
            "Shengdong Zhao",
            "Yves Guiard"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702126",
        "citation": "26",
        "abstract": "Physical Loci, a technique based on an ancient memory technique, allows users to quickly learn a large command set by leveraging spatial, object and verbal/semantic memory to create a cognitive link between individual commands and nearby physical objects in a room (called loci). We first report on an experiment that showed that for learning 25 items Physical Loci outperformed a mid-air Marking Menu baseline. A long-term retention experiment with 48 items then showed that recall was nearly perfect one week later and, surprisingly, independent of whether the command/locus mapping was one's own choice or somebody else's. A final study suggested that recall performance is robust to alterations of the learned mapping, whether systematic or random."
    },
    {
        "title": "LeviPath: Modular Acoustic Levitation for 3D Path Visualisations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction in 3D Space",
        "data": "April 2015",
        "authors": [
            "Themis Omirou",
            "Asier Marzo",
            "Sue Ann Seah",
            "Sriram Subramanian"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702333",
        "citation": "44",
        "abstract": "LeviPath is a modular system to levitate objects across 3D paths. It consists of two opposed arrays of transducers that create a standing wave capable of suspending objects in mid-air. To control the standing wave, the system employs a novel algorithm based on combining basic patterns of movement. Our approach allows the control of multiple beads simultaneously along different 3D paths. Due to the patterns and the use of only two opposed arrays, the system is modular and can scale its interaction space by joining several LeviPaths. In this paper, we describe the hardware architecture, the basic patterns of movement and how to combine them to produce 3D path visualisations."
    },
    {
        "title": "Twist and Learn: Interface Learning in 3DOF Exploration of 3D Scatterplots",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction in 3D Space",
        "data": "April 2015",
        "authors": [
            "Mark Shovman",
            "James Bown",
            "Andrea Szymkowiak",
            "Kenneth C. Scott-Brown"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702201",
        "citation": "3",
        "abstract": "The increasing availability of 3D interfaces brings promise of improved user experience in diverse areas. Our study focuses on visual analytics, testing whether 3D interactivity improves performance in a visual data exploration task. Specifically, we compared scene rotation around vertical axis to a full 3D rotation using a InterSense IS-900 3D controller, in a task involving trivariate trend detection in a 3D scatterplot. We found that, while 3D rotation leads to slower performance, previous exposure to single-axis rotation removes that difference. This shows that an interactive 3D scatterplot can be an effective visual exploration technique for detecting trivariate patterns in the data, and highlights the role of interface learning in design and assessment of novel interfaces."
    },
    {
        "title": "THING: Introducing a Tablet-based Interaction Technique for Controlling 3D Hand Models",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction in 3D Space",
        "data": "April 2015",
        "authors": [
            "Merwan Achibet",
            "Géry Casiez",
            "Anatole Lécuyer",
            "Maud Marchal"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702158",
        "citation": "8",
        "abstract": "The hands of virtual characters are highly complex 3D models that can be tedious and time-consuming to animate with current methods. This paper introduces THING, a novel tablet-based approach that leverages multi-touch interaction for a quick and precise control of a 3D hand's pose. The flexion/extension and abduction/adduction of the virtual fingers can be controlled for each finger individually or for several fingers in parallel through sliding motions on the tablet's surface. We designed two variants of THING: (1) MobileTHING, which maps the spatial location and orientation of the tablet to that of the virtual hand, and (2) DesktopTHING, which combines multi-touch controls of fingers with traditional mouse controls for the hand's global position and orientation. We compared the usability of THING against mouse-only controls and a data glove in two controlled experiments. Results show that DesktopTHING was significantly preferred by users while providing performance similar to data gloves. Together, these results could pave the way to the introduction of novel hybrid user interfaces based on tablets and mice in future animation pipelines."
    },
    {
        "title": "The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction in 3D Space",
        "data": "April 2015",
        "authors": [
            "Gary Perelman",
            "Marcos Serrano",
            "Mathieu Raynal",
            "Celia Picard",
            "Mustapha Derras",
            "Emmanuel Dubois"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702244",
        "citation": "34",
        "abstract": "We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input device that combines the advantages of the mouse (position displacement) and of 3D devices (roll and rotation) to unify 2D and 3D interaction. Our first study explores RPM gesture amplitude and stability for different upper shapes (Hemispherical, Convex) and hand postures. 8 roll directions can be performed precisely and their amplitude is larger on Hemispherical RPM. As minor rolls affect translation, we propose a roll correction algorithm to support stable 2D pointing with RPM. We propose the use of compound gestures for 3D pointing and docking, and evaluate them against a commercial 3D device, the SpaceMouse. Our studies reveal that RPM performs 31% faster than the SpaceMouse for 3D pointing and equivalently for 3D rotation. Finally, we present a proof-of-concept integrated RPM prototype along with discussion on the various technical challenges to overcome to build a final integrated version of RPM."
    },
    {
        "title": "Session details: Understanding & Evaluating Performance",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Evaluating Performance",
        "data": "April 2015",
        "authors": [
            "Richard Davis"
        ],
        "DOI": "https://doi.org/10.1145/3251795",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "ModelTracker: Redesigning Performance Analysis Tools for Machine Learning",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Evaluating Performance",
        "data": "April 2015",
        "authors": [
            "Saleema Amershi",
            "Max Chickering",
            "Steven M. Drucker",
            "Bongshin Lee",
            "Patrice Simard",
            "Jina Suh"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702509",
        "citation": "161",
        "abstract": "Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present ModelTracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with ModelTracker over six months shows ModelTracker is used often and throughout model building. A controlled experiment focusing on ModelTracker's debugging capabilities shows participants prefer ModelTracker over traditional tools without a loss in model performance."
    },
    {
        "title": "How Good is 85%?: A Survey Tool to Connect Classifier Evaluation to Acceptability of Accuracy",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Evaluating Performance",
        "data": "April 2015",
        "authors": [
            "Matthew Kay",
            "Shwetak N. Patel",
            "Julie A. Kientz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702603",
        "citation": "37",
        "abstract": "Many HCI and ubiquitous computing systems are characterized by two important properties: their output is uncertain-it has an associated accuracy that researchers attempt to optimize-and this uncertainty is user-facing-it directly affects the quality of the user experience. Novel classifiers are typically evaluated using measures like the F1 score-but given an F-score of (e.g.) 0.85, how do we know whether this performance is good enough? Is this level of uncertainty actually tolerable to users of the intended application-and do people weight precision and recall equally? We set out to develop a survey instrument that can systematically answer such questions. We introduce a new measure, acceptability of accuracy, and show how to predict it based on measures of classifier accuracy. Out tool allows us to systematically select an objective function to optimize during classifier evaluation, but can also offer new insights into how to design feedback for user-facing classification systems (e.g., by combining a seemingly-low-performing classifier with appropriate feedback to make a highly usable system). It also reveals potential issues with the ubiquitous F1-measure as applied to user-facing systems."
    },
    {
        "title": "Examining the Peak-End Effects of Subjective Experience",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Evaluating Performance",
        "data": "April 2015",
        "authors": [
            "Andy Cockburn",
            "Philip Quinn",
            "Carl Gutwin"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702139",
        "citation": "28",
        "abstract": "Psychological research has shown that 'peak-end' effects influence people's retrospective evaluation of hedonic and affective experience. Rather than objectively reviewing the total amount of pleasure or pain during an experience, people's evaluation is shaped by the most intense moment (the peak) and the final moment (end). We describe an experiment demonstrating that peak-end effects can influence a user's preference for interaction sequences that are objectively identical in their overall requirements. Participants were asked to choose which of two interactive sequences of five pages they preferred. Both sequences required setting a total of 25 sliders to target values, and differed only in the distribution of the sliders across the five pages -- with one sequence intended to induce positive peak-end effects, the other negative. The study found that manipulating only the peak or the end of the series did not significantly change preference, but that a combined manipulation of both peak and end did lead to significant differences in preference, even though all series had the same overall effort."
    },
    {
        "title": "Survival Analysis: Objective assessment of Wait Time in HCI",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Evaluating Performance",
        "data": "April 2015",
        "authors": [
            "Siddhartha Asthana",
            "Pushpendra Singh",
            "Parul Gupta"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702428",
        "citation": "5",
        "abstract": "Waiting for the completion of a system process is an everyday experience. While waiting, system provides feedback to the user about ongoing process through temporal metaphors (Progress bar, Busy icons, etc.). One of the key performance requirement for temporal metaphors is to retain the user till the process completes. Researchers have evaluated these metaphors through subjective means, and objective assessment has not been well explored. In this paper, we present survival analysis as objective assessment method to evaluate temporal metaphors. Through a field experiment, we demonstrate the application of survival analysis and empirically establish that auditory progress bar (temporal metaphor for audio interfaces) works for callers of a distress helpline. To the best of our knowledge, it is the first study on distress callers. The paper further discusses the applicability of survival analysis for evaluating temporal metaphors and wait time experiments for other applications, tasks, and settings."
    },
    {
        "title": "Session details: Music & Art",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Music & Art",
        "data": "April 2015",
        "authors": [
            "Jonathan Hook"
        ],
        "DOI": "https://doi.org/10.1145/3251796",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Deformable Interfaces for Performing Music",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Music & Art",
        "data": "April 2015",
        "authors": [
            "Giovanni Maria Troiano",
            "Esben Warming Pedersen",
            "Kasper Hornbæk"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702492",
        "citation": "31",
        "abstract": "Deformable interfaces offer new possibilities for gestures, some of which have been shown effective in controlled laboratory studies. Little work, however, has attempted to match deformable interfaces to a demanding domain and evaluate them out of the lab. We investigate how musicians use deformable interfaces to perform electronic music. We invited musicians to three workshops, where they explored 10 deformable objects and generated ideas on how to use these objects to perform music. Based on the results from the workshops, we implemented sensors in the five preferred objects and programmed them for controlling sounds. Next, we ran a performance study where six musicians performed music with these objects at their studios. Our results show that (1) musicians systematically map deformations to certain musical parameters, (2) musicians use deformable interfaces especially to filter and modulate sounds, and (3) musicians think that deformable interfaces embody the parameters that they control. We discuss what these results mean to research in deformable interfaces."
    },
    {
        "title": "Sculpting a Mobile Musical Soundtrack",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Music & Art",
        "data": "April 2015",
        "authors": [
            "Adrian Hazzard",
            "Steve Benford",
            "Gary Burnett"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702236",
        "citation": "26",
        "abstract": "We present an in-the-wild project to design and study a mobile musical soundtrack that enhances the experience of visiting a sculpture park. As with soundtracks for films and games, the goal was to enhance the emotional and narrative aspects of the experience while remaining in the background. We describe a compositional approach in which we first established a broad musical landscape before treating specific exhibits with detailed musical trajectories. Our study reveals how our soundtrack dramatically shaped visitors' experiences while they remained largely unaware of its operation. We distil seven experiential factors to be addressed by mobile soundtracks alongside ten compositional guidelines."
    },
    {
        "title": "Walking by Drawing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Music & Art",
        "data": "April 2015",
        "authors": [
            "Daniela K. Rosner",
            "Hidekazu Saegusa",
            "Jeremy Friedland",
            "Allison Chambliss"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702467",
        "citation": "16",
        "abstract": "This paper describes a study of algorithmic living with Trace, a mobile mapping application that generates walking routes based on digital sketches people create and annotate without a map. In addition to creating walking paths, Trace enables people to send the paths to others. We designed Trace to explore the possibility of emphasizing guided wandering over precise, destination-oriented navigation. Studies of sixteen people's use of Trace over roughly one week reveal how walkers find Trace both delightful and disorienting, highlighting moments of surprise, frustration, and identification with GIS routing algorithms. We conclude by discussing how design interventions offers possibilities for understanding the work of mapping and how it might be done differently in HCI."
    },
    {
        "title": "ArtMaps: Interpreting the Spatial Footprints of Artworks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Music & Art",
        "data": "April 2015",
        "authors": [
            "Tim Coughlan",
            "Laura Carletti",
            "Gabriella Giannachi",
            "Steve Benford",
            "Derek McAuley",
            "Dominic Price",
            "Cristina Locatelli",
            "Rebecca Sinker",
            "John Stack"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702281",
        "citation": "5",
        "abstract": "Creating and utilizing simple links between items and locations in map-based systems has become a mainstream component of modern computing. In this paper, we explore support for \"art mapping\", an activity that requires consideration of more complex interpretations of spatial relationships as users engage with identifying locations of relevance to artworks. Through a user study of the ArtMaps platform, and an exploratory study with professional artists, we identify diverse interpretations of spatial meaning in relation to art. We find that art mapping highlights potential for more active engagement with art through technology, but challenges existing systems for spatial representation. Through connecting our findings with work on designing for interpretation, and on space and place in HCI, we contribute new understanding of creating engagement through the spatial interpretation of art, and define potential characteristics and uses of holistic \"footprints\" for artworks."
    },
    {
        "title": "Session details: Supporting Change in Developing Countries",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Change in Developing Countries",
        "data": "April 2015",
        "authors": [
            "Anirudha Joshi"
        ],
        "DOI": "https://doi.org/10.1145/3251797",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Sangeet Swara: A Community-Moderated Voice Forum in Rural India",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Change in Developing Countries",
        "data": "April 2015",
        "authors": [
            "Aditya Vashistha",
            "Edward Cutrell",
            "Gaetano Borriello",
            "William Thies"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702191",
        "citation": "80",
        "abstract": "Interactive voice forums have emerged as a promising platform for people in developing regions to record and share audio messages using low-end mobile phones. However, one of the barriers to the scalability of voice forums is the process of screening and categorizing content, often done by a dedicated team of moderators. We present Sangeet Swara, a voice forum for songs and cultural content that relies on the community of callers to curate high-quality posts that are prioritized for playback to others. An 11-week deployment of Sangeet Swara found broad and impassioned usage, especially among visually impaired users. We also conducted a follow-up experiment, called Talent Hunt, that sought to reduce reliance on toll-free telephone lines. Together, our deployments span about 53,000 calls from 13,000 callers, who submitted 6,000 posts and 150,000 judgments of other content. Using a mixed-methods analysis of call logs, audio content, comparison with outside judges, and 204 automated phone surveys, we evaluate the user experience, the strengths and weaknesses of community moderation, financial sustainability, and the implications for future systems."
    },
    {
        "title": "Mobile Phones for Maternal Health in Rural India",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Change in Developing Countries",
        "data": "April 2015",
        "authors": [
            "Neha Kumar",
            "Richard J. Anderson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702258",
        "citation": "95",
        "abstract": "We present our findings from a mixed methods study of mobile phone practices of rural Indian women. We situate our study in the context of Projecting Health, a public health initiative we deployed in Uttar Pradesh (India) to target the dissemination of health information for mothers and newborns. Adopting the lens of feminist reflexivity, we reconsider our design of Projecting Health by factoring in the mobile media consumption and sharing practices of our target audience. We stress the importance of taking a community-oriented approach and show that although there are strict social conventions and patriarchal norms that constrain various practices of these women, they are able to exercise agency and mobilize help within their communities when needed."
    },
    {
        "title": "Residual Mobilities: Infrastructural Displacement and Post-Colonial Computing in Bangladesh",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Change in Developing Countries",
        "data": "April 2015",
        "authors": [
            "Syed Ishtiaque Ahmed",
            "Nusrat Jahan Mim",
            "Steven J. Jackson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702573",
        "citation": "80",
        "abstract": "This paper explores discrepancies between the founding assumptions of mobile and ubiquitous computing in the western world, and the starkly different experiences of mobility and infrastructure to be found in many post-colonial environments. Based on a field study of forced mobility and technology use among populations displaced by the Hatirjheel waterfront development project in Dhaka, Bangladesh, we make two basic arguments. First, we point to the partial nature of assumptions around mobility that frame the imagination of mainstream HCI research, and argue that different and heretofore residual experiences of mobility must also be accounted for in post-colonial and other marginal computing environments. Second, we document four forms of infrastructural experience -- dispossession, reconstitution, collaboration, and repair -- that characterize real-world engagements with infrastructure in such settings. We conclude with implications for HCI research and design, and reflections on how HCI researchers might better account for such experiences in their work."
    },
    {
        "title": "Más Tecnologia, Más Cambio?: Investigating an Educational Technology Project in Rural Peru",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Change in Developing Countries",
        "data": "April 2015",
        "authors": [
            "Emeline Therias",
            "Jon Bird",
            "Paul Marshall"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702595",
        "citation": "12",
        "abstract": "Providing access to and training in ICTs is seen as key to bridging the digital divide between technology-rich communities and those with poor IT infrastructures. Several projects have focused on providing ICTs for education in developing countries, of which the best known is One Laptop Per Child (OLPC). Although, there has been significant criticism of some of these projects, in particular OLPC, due to its use of a top-down implementation strategy and the limited evidence for its educational benefits, there has been comparatively little analysis of what underlies successful approaches. We aimed to address this deficit by conducting an ethnographic study of community-based projects organised by Blue Sparrow, a small charity that donates refurbished desktop computers to schools in rural Peru, as this organisation has experienced both successes and failures when implementing its educational technology projects. The relative success of Blue Sparrow highlights the benefits of: understanding local contexts; using a bottom up approach; involving stakeholders in setting programme objectives; and empowering communities. We argue that the educational impact of such projects can be improved by: providing teacher training; integrating computers into the wider curriculum; and providing teaching materials and clear objectives for volunteers."
    },
    {
        "title": "Session details: Privacy, Security & Interruptions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy, Security & Interruptions",
        "data": "April 2015",
        "authors": [
            "Emilee Rader"
        ],
        "DOI": "https://doi.org/10.1145/3251798",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Playing the Legal Card: Using Ideation Cards to Raise Data Protection Issues within the Design Process",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy, Security & Interruptions",
        "data": "April 2015",
        "authors": [
            "Ewa Luger",
            "Lachlan Urquhart",
            "Tom Rodden",
            "Michael Golembewski"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702142",
        "citation": "51",
        "abstract": "The regulatory climate is in a process of change. Design, having been implicated for some time, is now explicitly linked to law. This paper recognises the heightened role of designers in the regulation of ambient interactive technologies. Taking account of incumbent legal requirements is difficult. Legal rules are convoluted, uncertain, and not geared towards operationalisable heuristics or development guidelines for system designers. Privacy and data protection are a particular moral, social and legal concern for technologies. This paper seeks to understand how to make emerging European data protection regulation more accessible to our community. Our approach develops and tests a series of data protection ideation cards with teams of designers. We find that, whilst wishing to protect users, regulation is viewed as a compliance issue. Subsequently we argue for the use of instruments, such as our cards, as a means to engage designers in leading a human-centered approach to regulation."
    },
    {
        "title": "Crowdsourced Exploration of Security Configurations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy, Security & Interruptions",
        "data": "April 2015",
        "authors": [
            "Qatrunnada Ismail",
            "Tousif Ahmed",
            "Apu Kapadia",
            "Michael K. Reiter"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702370",
        "citation": "29",
        "abstract": "Smartphone apps today request permission to access a multitude of sensitive resources, which users must accept completely during installation (e.g., on Android) or selectively configure after installation (e.g., on iOS, but also planned for Android). Everyday users, however, do not have the ability to make informed decisions about which permissions are essential for their usage. For enhanced privacy, we seek to leverage crowdsourcing to find minimal sets of permissions that will preserve the usability of the app for diverse users. We advocate an efficient 'lattice-based' crowd-management strategy to explore the space of permissions sets. We conducted a user study (N = 26) in which participants explored different permission sets for the popular Instagram app. This study validates our efficient crowd management strategy and shows that usability scores for diverse users can be predicted accurately, enabling suitable recommendations."
    },
    {
        "title": "Open Book: A Socially-inspired Cloaking Technique that Uses Lexical Abstraction to Transform Messages",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy, Security & Interruptions",
        "data": "April 2015",
        "authors": [
            "Eric Gilbert"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702295",
        "citation": "3",
        "abstract": "Both governments and corporations routinely surveil computer-mediated communication (CMC). Technologists often suggest widespread encryption as a defense mechanism, but CMC encryption schemes have historically faced significant usability and adoption problems. Here, we introduce a novel technique called Open Book designed to address these two problems. Inspired by how people deal with eavesdroppers offline, Open Book uses data mining and natural language processing to transform CMC messages into ones that are vaguer than the original. Specifically, we present: 1) a greedy Open Book algorithm that cloaks messages by transforming them to resemble the average Internet message; 2) an open-source, browser-based instantiation of it called Read Me, designed for Gmail; and, 3) a set of experiments showing that intended recipients can decode Open Book messages, but that unintended human- and machine-recipients cannot. Finally, we reflect on some open questions raised by this approach, such as recognizability and future side-channel attacks."
    },
    {
        "title": "Sensors Know When to Interrupt You in the Car: Detecting Driver Interruptibility Through Monitoring of Peripheral Interactions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy, Security & Interruptions",
        "data": "April 2015",
        "authors": [
            "SeungJun Kim",
            "Jaemin Chun",
            "Anind K. Dey"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702409",
        "citation": "27",
        "abstract": "Interruptions while driving can be quite dangerous, whether these are self-interruptions or external interruptions. They increase driver workload and reduce performance on the primary driving task. Being able to identify when a driver is interruptible is critical for building systems that can mediate these interruptions. In this paper, we collect sensor and human-annotated data from 15 drivers, including vehicle motion, traffic states, physiological responses and driver motion. We demonstrate that this data can be used to build a machine learning classifier that can determine interruptibility every second with a 94% accuracy. We present both population and individual models and discuss the features that contribute to the high performance of this system. Such a classifier can be used to build systems that mediate when drivers use technology to self-interrupt and when drivers are interrupted by technology."
    },
    {
        "title": "Session details: Making & Sharing Assistive Technologies",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Making & Sharing Assistive Technologies",
        "data": "April 2015",
        "authors": [
            "Suranga Nanayakkara"
        ],
        "DOI": "https://doi.org/10.1145/3251799",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "LApp: A Speech Loudness Application for People with Parkinson's on Google Glass",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Making & Sharing Assistive Technologies",
        "data": "April 2015",
        "authors": [
            "Roisin McNaney",
            "Ivan Poliakov",
            "John Vines",
            "Madeline Balaam",
            "Pengfei Zhang",
            "Patrick Olivier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702292",
        "citation": "17",
        "abstract": "Reduced vocal volume in Parkinson's is extremely common and can have significant social and emotional impact. We describe the development and evaluation of LApp--an application for Google Glass to help people with Parkinson's (PwP) monitor their speech volume and cue themselves to speak louder when necessary. Our findings highlight enthusiasm for using the application both at home as a volume training tool and in public social settings as a situated cueing device. We contribute insights to the literature on how eyewear technologies can provide assistance to people with health conditions and offer insights for the design of future self-monitoring and management applications on Google Glass."
    },
    {
        "title": "Designing for and with People with Parkinson's: A Focus on Exergaming",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Making & Sharing Assistive Technologies",
        "data": "April 2015",
        "authors": [
            "Roisin McNaney",
            "Madeline Balaam",
            "Amey Holden",
            "Guy Schofield",
            "Daniel Jackson",
            "Mary Webster",
            "Brook Galna",
            "Gillian Barry",
            "Lynn Rochester",
            "Patrick Olivier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702310",
        "citation": "30",
        "abstract": "Parkinson's is a complex and multifaceted condition with a myriad of symptoms, thus, designing for and with this user group requires careful consideration. We reflect upon two studies, employing different design methodologies, relating to the design of rehabilitative exergames in Parkinson's. The first explored the concept of designing 'for' People with Parkinson's (PwP) and focused on specifications outlined by clinical stakeholders. The second used a designing 'with' approach and modified a pre-established participatory design method for use with PwP. We call attention to the importance of carrying out design work with PwP and contribute; an empathic understanding of living with Parkinson's, a set of recommendations for how to design with PwP and a set of wider considerations for developing rehabilitative exergames for PwP."
    },
    {
        "title": "Being Seen: Co-Interpreting Parkinson's Patient's Movement Ability in Deep Brain Stimulation Programming",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Making & Sharing Assistive Technologies",
        "data": "April 2015",
        "authors": [
            "Helena M. Mentis",
            "Rita Shewbridge",
            "Sharon Powell",
            "Paul Fishman",
            "Lisa Shulman"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702342",
        "citation": "9",
        "abstract": "The purpose of this study is to address the use of movement assessment sensors for clinical diagnosis and treatment. Eleven patients with Parkinson's disease who had under-gone deep brain stimulation (DBS) surgery were observed during follow-up appointments for adjustments to the stimulation settings. We examine the ways in which the patients and clinicians assess movement ability together in the clinic and how these assessments relate to the treatment of functional disability through DBS. We have found that effective assessment of movement and treatment efficacy is a collaborative and interpretive process (co-interpretation) that relies on input from patients, clinicians, and caregivers. From these findings we describe the design directions for movement sensors to support co-interpretation of movement in a clinical context as opposed to simply movement definition."
    },
    {
        "title": "The Virtual Meditative Walk: Virtual Reality Therapy for Chronic Pain Management",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Making & Sharing Assistive Technologies",
        "data": "April 2015",
        "authors": [
            "Diane Gromala",
            "Xin Tong",
            "Amber Choo",
            "Mehdi Karamnejad",
            "Chris D. Shaw"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702344",
        "citation": "104",
        "abstract": "Because the nature of chronic pain is complex, pharmacological analgesics are often not enough to achieve an ideal treatment plan. Virtual Reality (VR) technologies have emerged within medical research in recent years for treating acute pain, and proved to be an effective strategy based on pain distraction. This paper describes a VR system designed for chronic pain patients. The system incorporates biofeedback sensors, an immersive virtual environment, and stereoscopic sound titled the \"Virtual Meditative Walk\" (VMW). It was designed to enable chronic pain patients to learn Mindfulness-based stress reduction (MBSR), a form of meditation. By providing real-time visual and sonic feedback, VMW enables patients to learn how to manage their pain. A proof-of-concept user study was conducted to investigate the effectiveness of the VR system with chronic pain patients in clinical settings. Results show that the VMW was more effective in reducing perceived pain compared to the non-VR control condition."
    },
    {
        "title": "Sharing is Caring: Assistive Technology Designs on Thingiverse",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Making & Sharing Assistive Technologies",
        "data": "April 2015",
        "authors": [
            "Erin Buehler",
            "Stacy Branham",
            "Abdullah Ali",
            "Jeremy J. Chang",
            "Megan Kelly Hofmann",
            "Amy Hurst",
            "Shaun K. Kane"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702525",
        "citation": "132",
        "abstract": "An increasing number of online communities support the open-source sharing of designs that can be built using rapid prototyping to construct physical objects. In this paper, we examine the designs and motivations for assistive technology found on Thingiverse.com, the largest of these communities at the time of this writing. We present results from a survey of all assistive technology that has been posted to Thingiverse since 2008 and a questionnaire distributed to the designers exploring their relationship with assistive technology and the motivation for creating these designs. The majority of these designs are intended to be manufactured on a 3D printer and include assistive devices and modifications for individuals with disabilities, older adults, and medication management. Many of these designs are created by the end-users themselves or on behalf of friends and loved ones. These designers frequently have no formal training or expertise in the creation of assistive technology. This paper discusses trends within this community as well as future opportunities and challenges."
    },
    {
        "title": "Session details: Matching & Facilitating Social Interactions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Matching & Facilitating Social Interactions",
        "data": "April 2015",
        "authors": [
            "Jofish Kaye"
        ],
        "DOI": "https://doi.org/10.1145/3251800",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Understanding the Role of Community in Online Dating",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Matching & Facilitating Social Interactions",
        "data": "April 2015",
        "authors": [
            "Christina Masden",
            "W. Keith Edwards"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702417",
        "citation": "40",
        "abstract": "Online dating sites have become a common means of finding a romantic partner. And yet, these sites differ greatly from many other socially oriented websites: perhaps most notably, the pairwise style of interaction afforded by these sites prevents a robust online community from forming. Users, however, have taken matters into their own hands by creating thriving external forums for discussion of specific dating sites. We report on a multiple methods study of two online dating services, via observation and interviews with users of the forums associated with these sites. Our findings suggest that these forums play an essential role in creating an \"outsourced community\" for the dating sites, and also reveal practices around how some users \"game the system\" in online dating, the prevalence of harassment in online dating, and users' frustrations with current dating sites. We conclude with a number of recommendations for system design."
    },
    {
        "title": "Making Social Matching Context-Aware: Design Concepts and Open Challenges",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Matching & Facilitating Social Interactions",
        "data": "April 2015",
        "authors": [
            "Julia M. Mayer",
            "Starr Roxanne Hiltz",
            "Quentin Jones"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702343",
        "citation": "31",
        "abstract": "Social matching systems recommend people to people. In an ideal world, such systems could be context-aware, in that they would introduce users to each other in situations where they are mutually interested, available and open to meeting (i.e., facilitate a valuable encounter). Unfortunately, today's systems primarily match individuals based on simple similarity and proximity metrics. This paper explores how contextual information available on today's mobile phones could be used to identify opportunities for people to make valuable new connections. Three types of context that are relevant for this work are: relational, social and personal. We present insights gained from several iterations of semi-structured interviewing (N=58) exploring these three types of contexts and propose novel context-aware social matching concepts such as: sociability of others as an indicator of opportune social context; activity involvement as an indicator of opportune personal context; and contextual rarity as an indicator of opportune relational context."
    },
    {
        "title": "The Known Stranger: Supporting Conversations between Strangers with Personalized Topic Suggestions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Matching & Facilitating Social Interactions",
        "data": "April 2015",
        "authors": [
            "Tien T. Nguyen",
            "Duyen T. Nguyen",
            "Shamsi T. Iqbal",
            "Eyal Ofek"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702411",
        "citation": "29",
        "abstract": "Striking up a good conversation with new acquaintances is often a difficult problem. In this paper we report on the perceptions of wearable device users who were given real-time personalized topic suggestions during a conversation with a person they just met. Suggestions were generated using a ranking recommendation algorithm, and were delivered via Google Glasses. We conducted a study with 38 pairs of strangers, who received such suggestions while conversing for the first time. Participants found the suggestions to be helpful, but only at the right moments, and for certain types of speakers. Our results contribute to the understanding of how communication interventions influence people's experience and behaviors, and enhance interpersonal interactions. Our study also presents design implications for applications on wearable devices to facilitate conversations between strangers."
    },
    {
        "title": "Augmenting Social Interactions: Realtime Behavioural Feedback using Social Signal Processing Techniques",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Matching & Facilitating Social Interactions",
        "data": "April 2015",
        "authors": [
            "Ionut Damian",
            "Chiew Seng (Sean) Tan",
            "Tobias Baur",
            "Johannes Schöning",
            "Kris Luyten",
            "Elisabeth André"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702314",
        "citation": "92",
        "abstract": "Nonverbal and unconscious behaviour is an important component of daily human-human interaction. This is especially true in situations such as public speaking, job interviews or information sensitive conversations, where researchers have shown that an increased awareness of one's behaviour can improve the outcome of the interaction. With wearable technology, such as Google Glass, we now have the opportunity to augment social interactions and provide realtime feedback on one's behaviour in an unobtrusive way. In this paper we present Logue, a system that provides realtime feedback on the presenters' openness, body energy and speech rate during public speaking. The system analyses the user's nonverbal behaviour using social signal processing techniques and gives visual feedback on a head-mounted display. We conducted two user studies with a staged and a real presentation scenario which yielded that Logue's feedback was perceived helpful and had a positive impact on the speaker's performance."
    },
    {
        "title": "Session details: Reflecting Upon Design Reflection",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Reflecting Upon Design Reflection",
        "data": "April 2015",
        "authors": [
            "Ron Wakkary"
        ],
        "DOI": "https://doi.org/10.1145/3251801",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Understanding Long-Term Interactions with a Slow Technology: an Investigation of Experiences with FutureMe",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Reflecting Upon Design Reflection",
        "data": "April 2015",
        "authors": [
            "William Odom"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702221",
        "citation": "40",
        "abstract": "Emerging over a decade ago, slow technology is a design philosophy aimed at supporting experiences of reflection through and on technology in everyday life. Recent research has suggested that slow technologies can open up new forms of interaction with digital content that support self-reflection and re-visitation of the past. However, little work has investigated people's long-term interactions with systems that embody this design strategy. To investigate, a qualitative study with 31 participants was conducted to understand their long-term experiences with FutureMe-a slow technology that has been in use for over twelve years by more than one million people. Findings reveal that, despite its simplicity, FutureMe produced a range of outcomes-from profound reminiscence to unsettling encounters. Findings are interpreted to present opportunities and implications for future research and practice initiatives."
    },
    {
        "title": "Reflective Informatics: Conceptual Dimensions for Designing Technologies of Reflection",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Reflecting Upon Design Reflection",
        "data": "April 2015",
        "authors": [
            "Eric P.S. Baumer"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702234",
        "citation": "134",
        "abstract": "Despite demonstrated interest in designing for reflection, relatively little work provides a detailed explication of what exactly is meant by reflection or how to design around it. This paper fills that gap by reviewing and engaging with conceptual and theoretical models of reflection, organized by the disciplinary and epistemological perspectives each embodies. Synthesizing across this theoretical background, the paper identifies three dimensions of reflection: breakdown, inquiry, and transformation. Together, these dimensions serve as the foundation for reflective informatics, a conceptual approach that helps bring clarity and guidance to the discussion of designing for reflection. The paper distinguishes reflective informatics by demonstrating how it both differs from and complements existing related work. Finally, the paper provides a critically reflexive consideration of its own latent assumptions, especially about the value of reflection, and how they might impact work on designing for reflection."
    },
    {
        "title": "Stock Lamp: An Engagement-Versatile Visualization Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Reflecting Upon Design Reflection",
        "data": "April 2015",
        "authors": [
            "Yuzuru Tanahashi",
            "Kwan-Liu Ma"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702323",
        "citation": "6",
        "abstract": "Design methodologies for information visualizations are typically based on the assumption that the users will be fully engaged in the visual exploration of the displayed information. However, recent research suggests that there is an increasing diversity in how users engage with modern visualizations, and that the traditional design theories do not always satisfy the varied users needs. In this paper, we present a new design concept, engagement-versatile design, for visualizations that target users with a variety of engagement styles. Without losing generality, we demonstrate the feasibility of this concept through the designing of a system called Stock Lamp, an engagement-versatile visualization that helps users keep track of the stock market in real-time. This design process includes identifying different modes of engagement, deriving design implications from each engagement-mode, and applying them to the visualization's design. Our user study shows that Stock Lamp is able to consistently relay market information even when the users are multi-tasking. We believe this study establishes a new concept that promotes a systematic design approach that leverages both theoretical and empirical design methodologies for future visualization development."
    },
    {
        "title": "Real-Time Representation Versus Response Elicitation in Biosensor Data",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Reflecting Upon Design Reflection",
        "data": "April 2015",
        "authors": [
            "Mark Matthews",
            "Jaime Snyder",
            "Lindsay Reynolds",
            "Jacqueline T. Chien",
            "Adam Shih",
            "Jonathan W. Lee",
            "Geri Gay"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702485",
        "citation": "19",
        "abstract": "Recognized stress management techniques include cultivating mindfulness, breathing exercises, and meditation. While these approaches have been shown to mitigate the negative effects of stress, they can be difficult to learn or consistently apply. To support these techniques, we developed MoodLight, a playful system that uses ambient colored light to provide feedback regarding an individual's current arousal levels. Like many affective computing systems, MoodLight was designed to help users observe their internal state and learn to relax. However, our findings indicate that prompting or leading feedback can be more effective than real time feedback in helping users relax. This work contributes to affective computing by suggesting alternative approaches to designing biofeedback systems for stress management."
    },
    {
        "title": "Session details: Makers & Hackers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Makers & Hackers",
        "data": "April 2015",
        "authors": [
            "Ellen Yi-Luen Do"
        ],
        "DOI": "https://doi.org/10.1145/3251802",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Tutorial Authorship and Hybrid Designers: The Joy (and Frustration) of DIY Tutorials",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Makers & Hackers",
        "data": "April 2015",
        "authors": [
            "Ron Wakkary",
            "Markus Lorenz Schilling",
            "Matthew A. Dalton",
            "Sabrina Hauser",
            "Audrey Desjardins",
            "Xiao Zhang",
            "Henry W.J. Lin"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702550",
        "citation": "25",
        "abstract": "Tutorials are critical to the success and vitality of DIY practices. In this paper, we elevate the importance of tutorial authorship as one way to maintain and improve the quality of tutorials in DIY. We discuss the role interaction designers can play as hybrid designers, mediating between author and audience to contribute to the improvement of practices of tutorial authorship in DIY. We examine the quality of tutorials through the building and analysis of ten DIY projects and tutorials. We analyze key issues across three categories: 1) competences, components and tools, 2) sequencing, 3) and communication. We offer findings that are both practical guidelines for detailed improvements of tutorials and structural themes for improving tutorial authorship including the themes of accurate information, competences and tools, and tutorial format. In conclusion, we discuss the potential for interaction designers to simultaneously mediate and shape tutorials and tools in a form of hybrid design."
    },
    {
        "title": "Hybrid Practice in the Kalahari: Design Collaboration through Digital Tools and Hunter-Gatherer Craft",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Makers & Hackers",
        "data": "April 2015",
        "authors": [
            "Jennifer Jacobs",
            "Amit Zoran"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702362",
        "citation": "33",
        "abstract": "People have been making things for a long time, yet digital making has developed mostly within an industrial context. We question how non-digital craft cultures can inform the design of digital tools. Furthermore, what methods can help us understand these cultures in ways that are relevant to digital practice? As makers ourselves, we see potential for collaborative making to mitigate barriers in communication and provide insight into non-digital practices and values. To evaluate this approach, we visited a hunter-gatherer community that preserves an ancient craft, bringing with us digital design and fabrication tools. Working together, we merged digital tools with ostrich eggshell jewelry craft. We use this experience to draw conclusions about making as a form of communication, the importance of supporting appropriation and immediacy in collaborations, the challenge of combining abstract design tools with concrete approaches, and the value of incorporating design and making into communal life."
    },
    {
        "title": "The Proper Care and Feeding of Hackerspaces: Care Ethics and Cultures of Making",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Makers & Hackers",
        "data": "April 2015",
        "authors": [
            "Austin L. Toombs",
            "Shaowen Bardzell",
            "Jeffrey Bardzell"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702522",
        "citation": "116",
        "abstract": "Communities of making have been at the center of attention in popular, business, political, and academic research circles in recent years. In HCI, they seem to carry the promise of new forms of computer use, education, innovation, and even ways of life. In the West in particular, the maker manifestos of these communities have shown strong elements of a neoliberal ethos, one that prizes self-determination, tech-savvy, independence, freedom from government, suspicion of authority, and so forth. Yet such communities, to function as communities, also require values of collaboration, cooperation, interpersonal support-in a word, care. In this ethnographic study, we studied and participated as members of a hackerspace for 19 months, focusing in particular not on their technical achievements, innovations, or for glimmers of a more sustainable future, but rather to make visible and to analyze the community maintenance labor that helps the hackerspace support the practices that its members, society, and HCI research are so interested in. We found that the maker ethic entails a complex negotiation of both a neoliberal libertarian ethos and a care ethos."
    },
    {
        "title": "Patterns of Physical Design Remixing in Online Maker Communities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Makers & Hackers",
        "data": "April 2015",
        "authors": [
            "Lora Oehlberg",
            "Wesley Willett",
            "Wendy E. Mackay"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702175",
        "citation": "60",
        "abstract": "Makers participate in remixing culture by drawing inspiration from, combining, and adapting designs for physical objects. To examine how makers remix each others' designs on a community scale, we analyzed metadata from over 175,000 digital designs from Thingiverse, the largest online design community for digital fabrication. Remixed designs on Thingiverse are predominantly generated designs from Customizer a built-in web app for adjusting parametric designs. However, we find that these designs do not elicit subsequent user activity and the authors who generate them tend not to contribute additional content to Thingiverse. Outside of Customizer, influential sources of remixing include complex assemblies and design primitives, as well as non-physical resources posing as physical designs. Building on our findings, we discuss ways in which online maker communities could become more than just design repositories and better support collaborative remixing."
    },
    {
        "title": "Session details: How Fast Can you Type on your Phone?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: How Fast Can you Type on your Phone?",
        "data": "April 2015",
        "authors": [
            "Michael Rohs"
        ],
        "DOI": "https://doi.org/10.1145/3251803",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Effects of Language Modeling and its Personalization on Touchscreen Typing Performance",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: How Fast Can you Type on your Phone?",
        "data": "April 2015",
        "authors": [
            "Andrew Fowler",
            "Kurt Partridge",
            "Ciprian Chelba",
            "Xiaojun Bi",
            "Tom Ouyang",
            "Shumin Zhai"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702503",
        "citation": "58",
        "abstract": "Modern smartphones correct typing errors and learn user-specific words (such as proper names). Both techniques are useful, yet little has been published about their technical specifics and concrete benefits. One reason is that typing accuracy is difficult to measure empirically on a large scale. We describe a closed-loop, smart touch keyboard (STK) evaluation system that we have implemented to solve this problem. It includes a principled typing simulator for generating human-like noisy touch input, a simple-yet-effective decoder for reconstructing typed words from such spatial data, a large web-scale background language model (LM), and a method for incorporating LM personalization. Using the Enron email corpus as a personalization test set, we show for the first time at this scale that a combined spatial-language model reduces word error rate from a pre-model baseline of 38.4% down to 5.7%, and that LM personalization can improve this further to 4.6%."
    },
    {
        "title": "VelociTap: Investigating Fast Mobile Text Entry using Sentence-Based Decoding of Touchscreen Keyboard Input",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: How Fast Can you Type on your Phone?",
        "data": "April 2015",
        "authors": [
            "Keith Vertanen",
            "Haythem Memmi",
            "Justin Emge",
            "Shyam Reyal",
            "Per Ola Kristensson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702135",
        "citation": "86",
        "abstract": "We present VelociTap: a state-of-the-art touchscreen keyboard decoder that supports a sentence-based text entry approach. VelociTap enables users to seamlessly choose from three word-delimiter actions: pushing a space key, swiping to the right, or simply omitting the space key and letting the decoder infer spaces automatically. We demonstrate that VelociTap has a significantly lower error rate than Google's keyboard while retaining the same entry rate. We show that intermediate visual feedback does not significantly affect entry or error rates and we find that using the space key results in the most accurate results. We also demonstrate that enabling flexible word-delimiter options does not incur an error rate penalty. Finally, we investigate how small we can make the keyboard when using VelociTap. We show that novice users can reach a mean entry rate of 41 wpm on a 40 mm wide smartwatch-sized keyboard at a 3% character error rate."
    },
    {
        "title": "Text Entry on Tiny QWERTY Soft Keyboards",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: How Fast Can you Type on your Phone?",
        "data": "April 2015",
        "authors": [
            "Luis A. Leiva",
            "Alireza Sahami",
            "Alejandro Catala",
            "Niels Henze",
            "Albrecht Schmidt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702388",
        "citation": "74",
        "abstract": "The advent of wearables (e.g., smartwatches, smartglasses, and digital jewelry) anticipates the need for text entry methods on very small devices. We conduct fundamental research on this topic using 3 qwerty-based soft keyboards for 3 different screen sizes, motivated by the extensive training that users have with qwerty keyboards. In addition to ZoomBoard (a soft keyboard for diminutive screens), we propose a callout-based soft keyboard and ZShift, a novel extension of the Shift pointing technique. We conducted a comprehensive user study followed by extensive analyses on performance, usability, and short-term learning. Our results show that different small screen sizes demand different types of assistance. In general, manufacturers can benefit from these findings by selecting an appropriate qwerty soft keyboard for their devices. Ultimately, this work provides designers, researchers, and practitioners with new understanding of qwerty soft keyboard design space and its scalability for tiny touchscreens."
    },
    {
        "title": "Performance and User Experience of Touchscreen and Gesture Keyboards in a Lab Setting and in the Wild",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: How Fast Can you Type on your Phone?",
        "data": "April 2015",
        "authors": [
            "Shyam Reyal",
            "Shumin Zhai",
            "Per Ola Kristensson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702597",
        "citation": "65",
        "abstract": "We study the performance and user experience of two popular mainstream mobile text entry methods: the Smart Touch Keyboard (STK) and the Smart Gesture Keyboard (SGK). Our first study is a lab-based ten-session text entry experiment. In our second study we use a new text entry evaluation methodology based on the experience sampling method (ESM). In the ESM study, participants installed an Android app on their own mobile phones that periodically sampled their text entry performance and user experience amid their everyday activities for four weeks. The studies show that text can be entered at an average speed of 28 to 39 WPM, depending on the method and the user's experience, with 1.0% to 3.6% character error rates remaining. Error rates of touchscreen input, particularly with SGK, are a major challenge; and reducing out-of-vocabulary errors is particularly important. Both SGK and STK have strengths, weaknesses, and different individual awareness and preferences. Two-thumb touch typing in a focused setting is particularly effective on STK, whereas one-handed SGK typing with the thumb is particularly effective in more mobile situations. When exposed to both, users tend to migrate from STK to SGK. We also conclude that studies in the lab and in the wild can both be informative to reveal different aspects of keyboard experience, but used in conjunction is more reliable in comprehensively assessing input technologies of current and future generations."
    },
    {
        "title": "Session details: Understand & Enhancing Learning",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understand & Enhancing Learning",
        "data": "April 2015",
        "authors": [
            "Chris Quintana"
        ],
        "DOI": "https://doi.org/10.1145/3251804",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understand & Enhancing Learning",
        "data": "April 2015",
        "authors": [
            "Yi-Chieh Lee",
            "Wen-Chieh Lin",
            "Fu-Yin Cherng",
            "Hao-Chuan Wang",
            "Ching-Ying Sung",
            "Jung-Tai King"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702349",
        "citation": "43",
        "abstract": "Online learning is increasingly prevalent as an option for self-learning and as a resource for instructional design. Prerecorded video is currently the main medium of online education content delivery and instruction; this affords asynchronicity and flexibility, and enables the dissemination of lecture content in a distributed and scalable manner. However, the same properties may impede learners' engagement due to the lack of social interaction and peer support. In this paper, we propose a time-anchored commenting interface to allow online learners who watch the same video clips to exchange comments on them. Comments left by previous learners at specific time points of a video are displayed to new learners when they watch the same video and reach those time points. We investigated how the display of time-anchored comments (dynamic or static) and type of comments (content-related or social-oriented) influenced users' perceived engagement, perceived social interactivity, and learning outcomes. Our results show that dynamically displaying time-anchored comments can indeed enhance learners' perceived social interactivity. Moreover, the content of comments would further affect learners' intention of commenting. Based on our findings, we make various recommendations for the improvement of social interaction and learning experience in online education."
    },
    {
        "title": "Designing a Physical Aid to Support Active Reading on Tablets",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understand & Enhancing Learning",
        "data": "April 2015",
        "authors": [
            "Andrea Bianchi",
            "So-Ryang Ban",
            "Ian Oakley"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702303",
        "citation": "16",
        "abstract": "Tablet computers and portable eReaders are gradually becoming the preferred platform for the consumption of textual materials. However, although these technologies are powerful, it is widely acknowledged that print documents better support the advanced active reading tasks necessary to gain a deep understanding of a text. While prior work to address this issue has aimed improve digital eReaders by either leveraging familiar physical affordances or by extending paper's capabilities with digital tools, in this paper we propose a juncture of these two approaches. We first present a formative study that captures the needs and requirements of users during active reading tasks with tablets. We instantiate the findings in the design of a simple physical aid to support active reading: a smart bookmark. We then define an interaction space for this device, describe a set of interfaces designed to facilitate active reading and close with a user study that assesses the potential of the bookmark device and interaction techniques."
    },
    {
        "title": "Session details: Family Communication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Family Communication",
        "data": "April 2015",
        "authors": [
            "Siân Lindley"
        ],
        "DOI": "https://doi.org/10.1145/3251805",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Couples' Communication Channels: What, When & Why?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Family Communication",
        "data": "April 2015",
        "authors": [
            "Henriette Cramer",
            "Maia L. Jacobs"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702356",
        "citation": "15",
        "abstract": "An overwhelming variety of communication channels are available to consumers. Here, we present an overview of the aspects that need to be accounted for when intimate partners select a communication channel. We present interviews with 10 cohabiting couples (20 participants) and an 8-day diary study of communication and coordination. Using reported instances of within-couple communication, triggered by relationship-oriented or practical household needs, we identify why particular channels are chosen or sequenced. Extending media richness critiques, we identify additional factors that influence communication choice such as intimate knowledge of the others' habits, possibilities to add emotional meaning, and couples' shared needs as an identifiable unit. We also extend the notion of network effects on channel choice, and discuss the ecology of channel, networks, devices and device settings involved between partners. Finally, channel choice is not an all-or-nothing game; multiple channels can, and must, co-exist."
    },
    {
        "title": "The Messaging Kettle: Prototyping Connection over a Distance between Adult Children and Older Parents",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Family Communication",
        "data": "April 2015",
        "authors": [
            "Margot Brereton",
            "Alessandro Soro",
            "Kate Vaisutis",
            "Paul Roe"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702462",
        "citation": "82",
        "abstract": "A prototype \"messaging kettle\" is described. The connected kettle aims to foster communication and engagement with an older friend or relative who lives remotely, during the routine of boiling the kettle. We describe preliminary encounters and findings from demonstrating a working prototype in morning tea gatherings of people in their 50s-late 70s and from introducing it into the homes of two people in their 80s who live on another continent. Key findings are that: The concept of keeping in touch around a \"habituated object\" such as a kettle was well received; Simple and varied interaction modalities that allow asymmetric forms of communication are needed; Designing for use across different time zones requires attention; And, that even when augmenting a habituated object, the process of introduction, appropriation and habituation still needs significant attention and investigation."
    },
    {
        "title": "The Effect of Signal Expense and Dependability on Family Communication in Rural and Northern Canada",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Family Communication",
        "data": "April 2015",
        "authors": [
            "Roberta M. Melvin",
            "Andrea Bunt",
            "Erick Oduor",
            "Carman Neustaedter"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702301",
        "citation": "10",
        "abstract": "Family communication and technology designed to support it is a widely studied topic. However, most research that focuses on family communication in North America tends to assume high degrees of connectivity and Internet access. We present a study of family communication practices in rural and northern areas of Manitoba, Canada where Internet connectivity is intermittent or severely limited in some communities. Our results show the ways in which individuals stay connected with outside relatives can be hampered by communication infrastructure challenges. In particular, these challenges can dictate how, where and how often conversations with loved ones take place. Our results also indicate that these experiences, many of which are negative, can create lasting impressions that may be difficult to alter as infrastructure improves. This suggests opportunities for designing family communication technologies for outdoor locations with better connectivity, scheduling communication during times with better connectivity, and combating social isolation."
    },
    {
        "title": "Texting while Parenting: How Adults Use Mobile Phones while Caring for Children at the Playground",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Family Communication",
        "data": "April 2015",
        "authors": [
            "Alexis Hiniker",
            "Kiley Sobel",
            "Hyewon Suh",
            "Yi-Chen Sung",
            "Charlotte P. Lee",
            "Julie A. Kientz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702199",
        "citation": "90",
        "abstract": "Child development research suggests that using phones while caring for children can be problematic, but limited prior work in this space makes defining appropriate use challenging. We conducted the first exploration of whether adults feel pressure to limit phone use in this context and whether they choose to do so. Through mixed methods, we collected data from 466 adult caregivers at playgrounds. We found that phone use was a small part of playground time, yet a notable source of guilt. Adults engaged in systematic and specific phone-use and phone-non-use behaviors in order to prioritize their children above themselves. Our results indicate that caregiver values and self-control together predict behavior and can be used to model phone use in this context. Users' mixed success with engaging in intentional periods of non-use suggests that a design agenda which prioritizes cycles of engagement, disengagement, and re-engagement may be of value to this group."
    },
    {
        "title": "Exploring Time-Dependent Concerns about Pregnancy and Childbirth from Search Logs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Family Communication",
        "data": "April 2015",
        "authors": [
            "Adam Fourney",
            "Ryen W. White",
            "Eric Horvitz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702427",
        "citation": "24",
        "abstract": "We study time-dependent patterns of information seeking about pregnancy, birth, and the first several weeks of caring for newborns via analyses of queries drawn from anonymized search engine logs. We show how we can detect and align web search behavior for a population of searchers with the natural clock of gestational physiology via proxies for ground truth based on searchers' self-report queries (e.g., [I am 30 weeks pregnant and my baby is moving a lot]). Then, we present a methodology for performing additional alignments, that are valuable for learning about the concerns, curiosities, and needs that arise over time with pregnancy and early parenting. Our findings have implications for learning about the temporal dynamics of pregnancy-related interests and concerns, and also for the design of systems that tailor their responses to point estimates of each searcher's current stage in pregnancy."
    },
    {
        "title": "Session details: Crowdsourcing Fans & Friends",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Crowdsourcing Fans & Friends",
        "data": "April 2015",
        "authors": [
            "Shaun Lawson"
        ],
        "DOI": "https://doi.org/10.1145/3251806",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Run Spot Run: Capturing and Tagging Footage of a Race by Crowds of Spectators",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Crowdsourcing Fans & Friends",
        "data": "April 2015",
        "authors": [
            "Martin D. Flintham",
            "Raphael Velt",
            "Max L. Wilson",
            "Edward J. Anstead",
            "Steve Benford",
            "Anthony Brown",
            "Timothy Pearce",
            "Dominic Price",
            "James Sprinks"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702463",
        "citation": "15",
        "abstract": "There has been a massive growth in the number of people who film and upload amateur footage of events to services such as Facebook and Youtube, or even stream live to services such as LiveStream. We present an exploratory study that investigates the potential of these spectators in creating footage en masse; in this case, during a live trial at a local marathon. We deployed a prototype app, RunSpotRun, as a technology probe to see what kinds of footage spectators would produce. We present an analysis of this footage in terms of its coverage, quality, and contents, and also discuss the implications for a) spectators enjoying the race, and b) extracting the stories of individual runners throughout the race. We conclude with a discussion of the challenges that remain for deploying such technology at a larger scale."
    },
    {
        "title": "Crowdsourcing Synchronous Spectator Support: (go on, go on, you're the best)n-1",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Crowdsourcing Fans & Friends",
        "data": "April 2015",
        "authors": [
            "Franco Curmi",
            "Maria Angela Ferrario",
            "Jon Whittle",
            "Florian 'Floyd' Mueller"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702338",
        "citation": "9",
        "abstract": "Many studies have shown that crowd-support, such as cheering during sport events, can have a positive impact on athletes' performance. However, up until recently this support was only possible if the supporters and the athletes were geographically co-located. Can cheering be done remotely and would this be effective? In this paper we investigate the effect and possibilities of live remote cheering on co-located athletes and online supporting crowds that have a weak social tie and no social tie with the athlete. We recruit 140 online spectators and 5 athletes for an ad-hoc 5km road race. Results indicate that crowds socially closer to the athletes are significantly more engaged in the support. The athletes were excited by live remote cheering from friendsourced spectators and cheering from unknown crowdsourced participants indicating that remote friends and outsourced spectators could be an important source of support."
    },
    {
        "title": "Bootlegger: Turning Fans into Film Crew",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Crowdsourcing Fans & Friends",
        "data": "April 2015",
        "authors": [
            "Guy Schofield",
            "Tom Bartindale",
            "Peter Wright"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702229",
        "citation": "32",
        "abstract": "Bootlegger is a system for creating multi-camera films of live music events using mobile devices. Using readily available technology and a synthesis of film-making conventions, the system coordinates music fans at live shows into an improvised film crew, suggesting shots, collating footage and generating rich metadata in real time. Bootlegger is part of a research project exploring adapting professional media workflows to amateur contexts in order to lower the bar to entry for media production. By enabling concert-goers to contribute to high-quality concert films, the system leverages mobile phone 'bootlegging' practices to support emerging musicians."
    },
    {
        "title": "In-group Questions and Out-group Answers: Crowdsourcing Daily Living Advice for Individuals with Autism",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Crowdsourcing Fans & Friends",
        "data": "April 2015",
        "authors": [
            "Hwajung Hong",
            "Eric Gilbert",
            "Gregory D. Abowd",
            "Rosa I. Arriaga"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702402",
        "citation": "21",
        "abstract": "Difficulty in navigating daily life can lead to frustration and decrease independence for people with autism. While they turn to online autism communities for information and advice for coping with everyday challenges, these communities may present only a limited perspective because of their in-group nature. Obtaining support from out-group sources beyond the in-group community may prove valuable in dealing with challenging situations such as public anxiety and workplace conflicts. In this paper, we explore the value of supplementary out-group support from crowdsourced responders added to in-group support from a community of members. We find that out-group sources provide relatively rapid, concise responses with direct and structured information, socially appropriate coping strategies without compromising emotional value. Using an autism community as a motivating example, we conclude by providing design implications for combining in-group and out-group resources that may enhance the question-and-answer experience."
    },
    {
        "title": "Session details: Managing Personal Privacy",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing Personal Privacy",
        "data": "April 2015",
        "authors": [
            "Sameer Patil"
        ],
        "DOI": "https://doi.org/10.1145/3251807",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Your Location has been Shared 5,398 Times!: A Field Study on Mobile App Privacy Nudging",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing Personal Privacy",
        "data": "April 2015",
        "authors": [
            "Hazim Almuhimedi",
            "Florian Schaub",
            "Norman Sadeh",
            "Idris Adjerid",
            "Alessandro Acquisti",
            "Joshua Gluck",
            "Lorrie Faith Cranor",
            "Yuvraj Agarwal"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702210",
        "citation": "227",
        "abstract": "Smartphone users are often unaware of the data collected by apps running on their devices. We report on a study that evaluates the benefits of giving users an app permission manager and sending them nudges intended to raise their awareness of the data collected by their apps. Our study provides both qualitative and quantitative evidence that these approaches are complementary and can each play a significant role in empowering users to more effectively control their privacy. For instance, even after a week with access to the permission manager, participants benefited from nudges showing them how often some of their sensitive data was being accessed by apps, with 95% of participants reassessing their permissions, and 58% of them further restricting some of their permissions. We discuss how participants interacted both with the permission manager and the privacy nudges, analyze the effectiveness of both solutions, and derive some recommendations."
    },
    {
        "title": "Can an Algorithm Know the \"Real You\"?: Understanding People's Reactions to Hyper-personal Analytics Systems",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing Personal Privacy",
        "data": "April 2015",
        "authors": [
            "Jeffrey Warshaw",
            "Tara Matthews",
            "Steve Whittaker",
            "Chris Kau",
            "Mateo Bengualid",
            "Barton A. Smith"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702274",
        "citation": "26",
        "abstract": "Recent research has developed analytics that threaten online self-presentation and privacy by automatically generating profiles of individuals' most personal traits-their personality, values, motivations, and so on. But we know little about people's reactions to personal traits profiles of themselves, or what influences their decisions to share such profiles. We present an early qualitative study of people's reactions to a working hyper-personal analytics system. The system lets them see their personality and values profile derived from their own social media text. Our results reveal a paradox. Participants found their personal traits profiles creepily accurate and did not like sharing them in many situations. However, they felt pressured by the social risks of not sharing and showed signs of learned helplessness, leading them to share despite their misgivings. Further, they felt unqualified to significantly modify their profile contents due to a surprising trust in the \"expert\" algorithm. We explore design implications for hyper-personal analytics systems that consider the needs and preferences of the people being profiled, suggesting ways to enhance the control they feel and the benefits they reap."
    },
    {
        "title": "Privacy Tipping Points in Smartphones Privacy Preferences",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing Personal Privacy",
        "data": "April 2015",
        "authors": [
            "Fuming Shih",
            "Ilaria Liccardi",
            "Daniel Weitzner"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702404",
        "citation": "48",
        "abstract": "The aim of this research was to understand what affects people's privacy preferences in smartphone apps. We ran a four-week study in the wild with 34 participants. Participants were asked to answer questions, which were used to gather their personal context and to measure their privacy preferences by varying app name and purpose of data collection. Our results show that participants shared the most when no information about data access or purpose was given, and shared the least when both of these details were specified. When just one of either purpose or the requesting app was shown, participants shared less when just the purpose was specified than when just the app name was given. We found that the purpose for data access was the predominant factor affecting users' choices. In our study the purpose condition vary from being not specified, to vague to be very specific. Participants were more willing to disclose data when no purpose was specified. When a vague purpose was shown, participants became more privacy-aware and were less willing to disclose their information. When specific purposes were shown participants were more willing to disclose when the purpose for requesting the information appeared to be beneficial to them, and shared the least when the purpose for data access was solely beneficial to developers."
    },
    {
        "title": "VeilMe: An Interactive Visualization Tool for Privacy Configuration of Using Personality Traits",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing Personal Privacy",
        "data": "April 2015",
        "authors": [
            "Yang Wang",
            "Liang Gou",
            "Anbang Xu",
            "Michelle X. Zhou",
            "Huahai Yang",
            "Hernan Badenes"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702293",
        "citation": "16",
        "abstract": "With the recent advances in using data analytics to automatically infer one's personality traits from their social media data, users are facing a growing tension between the use of the technology to aid self development in workplace and the privacy concerns of such use. Given the richness of personality data that can be derived today and the varied sensitivity of revealing such data, it is a non-trivial task for users to configure their privacy settings for sharing and protecting their derived personality data. Here we present the design, development, and evaluation of an interactive visualization tool, VeilMe, which helps users configure the privacy settings for the use of their personality portraits derived from social media. Unlike other privacy configuration tools, our tool offers two distinct advantages. First, it presents a novel and intuitive visual interface that aids users in understanding and exploring their own personality traits derived from their social media data, and configuring their privacy preferences. Second, our tool helps users to jump start their privacy settings by suggesting initial sharing strategies based on a set of factors, including the users' personality and target audience. We have evaluated the use of our tool with 124 participants in an enterprise context. Our results show that VeilMe effectively supports various user privacy configuration tasks, and also suggest several design implications, including the approaches to personalized privacy configurations."
    },
    {
        "title": "Session details: Health Sensors & Monitoring",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Health Sensors & Monitoring",
        "data": "April 2015",
        "authors": [
            "Regan Mandryk"
        ],
        "DOI": "https://doi.org/10.1145/3251808",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "No News is Good News: Remote Monitoring of Implantable Cardioverter-Defibrillator Patients",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Health Sensors & Monitoring",
        "data": "April 2015",
        "authors": [
            "Mikael B. Skov",
            "Pauline G. Johansen",
            "Charlotte S. Skov",
            "Astrid Lauberg"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702192",
        "citation": "18",
        "abstract": "Implantable cardioverter-defibrillator (ICD) patients have increased safety when connected to remote monitoring as ICD problems and issues are instantly discovered compared to patients without a monitor. While remote monitoring is intrusive in the domestic environment, little HCI research has investigated how people live and interact with such monitoring technologies. We conducted a study with 19 ICD patients and their spouses using diaries and interviews. Our findings illustrate that our participants were satisfied with the monitoring despite the fact that they had almost no knowledge of the data collected and they lacked feedback from the monitor on transmission and operation. Based on our findings, we describe a safety paradox for remote monitoring as participants experienced less safety while being safer, and identify privacy and surveillance concerns in the unequal monitoring of ICD patients."
    },
    {
        "title": "Smart Homes that Monitor Breathing and Heart Rate",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Health Sensors & Monitoring",
        "data": "April 2015",
        "authors": [
            "Fadel Adib",
            "Hongzi Mao",
            "Zachary Kabelac",
            "Dina Katabi",
            "Robert C. Miller"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702200",
        "citation": "574",
        "abstract": "The evolution of ubiquitous sensing technologies has led to intelligent environments that can monitor and react to our daily activities, such as adapting our heating and cooling systems, responding to our gestures, and monitoring our elderly. In this paper, we ask whether it is possible for smart environments to monitor our vital signs remotely, without instrumenting our bodies. We introduce Vital-Radio, a wireless sensing technology that monitors breathing and heart rate without body contact. Vital-Radio exploits the fact that wireless signals are affected by motion in the environment, including chest movements due to inhaling and exhaling and skin vibrations due to heartbeats. We describe the operation of Vital-Radio and demonstrate through a user study that it can track users' breathing and heart rates with a median accuracy of 99%, even when users are 8~meters away from the device, or in a different room. Furthermore, it can monitor the vital signs of multiple people simultaneously. We envision that Vital-Radio can enable smart homes that monitor people's vital signs without body instrumentation, and actively contribute to their inhabitants' well-being."
    },
    {
        "title": "Balancing Accuracy and Fun: Designing Camera Based Mobile Games for Implicit Heart Rate Monitoring",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Health Sensors & Monitoring",
        "data": "April 2015",
        "authors": [
            "Teng Han",
            "Xiang Xiao",
            "Lanfei Shi",
            "John Canny",
            "Jingtao Wang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702502",
        "citation": "36",
        "abstract": "Heart rate monitoring is widely used in clinical care, fitness training, and stress management. However, tracking individuals' heart rates faces two major challenges, namely equipment availability and user motivation. In this paper, we present a novel technique, LivePulse Games (LPG), to measure users' heart rates in real time by having them play games on unmodified mobile phones. With LPG, the heart rate is calculated by detecting changes in transparency of users' fingertips via the built-in camera of a mobile device. More importantly, LPG integrate users' camera lens covering actions as an essential control mechanism in game play, and detect heart rates implicitly from intermittent lens covering actions. We explore the design space and trade-offs of LPG through three rounds of iterative design. In a 12-subject user study, we found that LPG are fun to play and can measure heart rates accurately. We also report the insights for balancing measurement speed, accuracy, and entertainment value in LPG."
    },
    {
        "title": "Measuring Photoplethysmogram-Based Stress-Induced Vascular Response Index to Assess Cognitive Load and Stress",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Health Sensors & Monitoring",
        "data": "April 2015",
        "authors": [
            "Yongqiang Lyu",
            "Xiaomin Luo",
            "Jun Zhou",
            "Chun Yu",
            "Congcong Miao",
            "Tong Wang",
            "Yuanchun Shi",
            "Ken-ichi Kameyama"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702399",
        "citation": "36",
        "abstract": "Quantitative assessment for cognitive load and mental stress is very important in optimizing human-computer system designs to improve performance and efficiency. Traditional physiological measures, such as heart rate variation (HRV), blood pressure and electrodermal activity (EDA), are widely used but still have limitations in sensitivity, reliability and usability. In this study, we propose a novel photoplethysmogram-based stress induced vascular index (sVRI) to measure cognitive load and stress. We also provide the basic methodology and detailed algorithm framework. We employed a classic experiment with three levels of task difficulty and three stages of testing period to verify the new measure. Compared with the blood pressure, heart rate and HRV components recorded simultaneously, the sVRI reached the same level of significance on the effect of task difficulty/period as the most significant other measure. Our findings showed sVRI's potential as a sensitive, reliable and usable parameter."
    },
    {
        "title": "Session details: Collaborative Tables, Walls & Rooms",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaborative Tables, Walls & Rooms",
        "data": "April 2015",
        "authors": [
            "Harald Reiterer"
        ],
        "DOI": "https://doi.org/10.1145/3251809",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Fluid Grouping: Quantifying Group Engagement around Interactive Tabletop Exhibits in the Wild",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaborative Tables, Walls & Rooms",
        "data": "April 2015",
        "authors": [
            "Florian Block",
            "James Hammerman",
            "Michael Horn",
            "Amy Spiegel",
            "Jonathan Christiansen",
            "Brenda Phillips",
            "Judy Diamond",
            "E. Margaret Evans",
            "Chia Shen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702231",
        "citation": "34",
        "abstract": "Interactive surfaces are increasingly common in museums and other informal learning environments where they are seen as a medium for promoting social engagement. However, despite their increasing prevalence, we know very little about factors that contribute to collaboration and learning around interactive surfaces. In this paper we present analyses of visitor engagement around several multi-touch tabletop science exhibits. Observations of 629 visitors were collected through two widely used techniques: video study and shadowing. We make four contributions: 1) we present an algorithm for identifying groups within a dynamic flow of visitors through an exhibit hall; 2) we present measures of group-level engagement along with methods for statistically analyzing these measures; 3) we assess the effect of observational techniques on visitors' engagement, demonstrating that consented video studies do not necessarily reflect visitor behavior in more naturalistic circumstances; and 4) we present an analysis showing that groups of two, groups with both children and adults, and groups that take turns spend longer at the exhibits and engage more with scientific concepts."
    },
    {
        "title": "Flexible Ecologies And Incongruent Locations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaborative Tables, Walls & Rooms",
        "data": "April 2015",
        "authors": [
            "Paul K. Luff",
            "Naomi Yamashita",
            "Hideaki Kuzuoka",
            "Christian Heath"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702286",
        "citation": "12",
        "abstract": "In this paper we report on some experiments with a high fidelity media space, t-Room, an immersive system that presents full scale, real-time images of co-participants. The system has been enhanced to provide more flexibility in the ways participants could organise themselves and the materials they are working on. Drawing on some quasi-naturalistic experiments, where the participants were required to undertake a range of complex tasks, we consider the formations they adopt and the issues and problems that arise when they attempt to establish and preserve a common focus and alignment. We conclude by briefly discussing the consequences for developing advanced spaces to support collaborative work and understanding complex video-mediated interaction."
    },
    {
        "title": "Mapping out Work in a Mixed Reality Project Room",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collaborative Tables, Walls & Rooms",
        "data": "April 2015",
        "authors": [
            "Derek Reilly",
            "Andy Echenique",
            "Andy Wu",
            "Anthony Tang",
            "W. Keith Edwards"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702506",
        "citation": "3",
        "abstract": "We present results from a study examining how the physical layout of a project room and task affect the cognitive maps acquired of a connected virtual environment during mixed-presence collaboration. Results indicate that a combination of physical layout and task impacts cognitive maps of the virtual space. Participants did not form a strong model of how different physical work regions were situated relative to each other in the virtual world when the tasks performed in each region differed. Egocentric perspectives of multiple displays enforced by different furniture arrangements encouraged cognitive maps of the virtual world that reflected these perspectives, when the displays were used for the same task. These influences competed or coincided with document-based, audiovisual and interface cues, influencing collaboration. We consider the implications of our findings on WYSIWIS mappings between real and virtual for mixed-presence collaboration."
    },
    {
        "title": "Session details: The Value of Things",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of Things",
        "data": "April 2015",
        "authors": [
            "Mark Blythe"
        ],
        "DOI": "https://doi.org/10.1145/3251810",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "On Vintage Values: The Experience of Secondhand Fashion Reacquisition",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of Things",
        "data": "April 2015",
        "authors": [
            "Anne E. Bowser",
            "Oliver L. Haimson",
            "Edward F. Melcer",
            "Elizabeth F. Churchill"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702394",
        "citation": "5",
        "abstract": "Secondhand fashion is a rapidly growing, lucrative market with both off- and online outlets. Studies of secondhand consumption have focused primarily on people's motivations for secondhand shopping, highlighting sustainability and/or thrift. We extend this work by looking at the motivations and practices of secondhand shoppers who are driven instead by style, playfulness and treasure-hunting. We present findings from ethnographic observation and interviews with 13 secondhand shoppers. Three secondhand shopping orientations emerged. Perfection Seeking involves seeking items that fit with an individual look or personal brand. These items are seen as unique, and demonstrate an alternative to mainstream fashion and consumption. Casual curiosity is less focused, more engaged in browsing, and driven by both secondhand objects and the secondhand experience itself. Digging involves the focused pursuit of hidden \"gems\" or treasures, following the belief that unusual items are waiting to be found. We offer ideas for designing secondhand shopping experiences to support the needs for storytelling, experiential pleasure, and negotiation around durable value."
    },
    {
        "title": "Your Money's No Good Here: The Elimination of Cash Payment on London Buses",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of Things",
        "data": "April 2015",
        "authors": [
            "Gary Pritchard",
            "John Vines",
            "Patrick Olivier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702137",
        "citation": "38",
        "abstract": "As digital payments become increasingly important features of economic exchange, traditional forms of payment such as cash are becoming phased out in certain settings. We study one such context-the elimination of cash payment on London buses in July 2014. We conducted ethnographic fieldwork, interviews with drivers and collected online and social media comments before, during and shortly after the introduction of cashless fares. We explore how drivers and passengers were fearful of the change due in part to a lack of information and communication, the anticipation of negative effects on vulnerable passengers and a compromise in freedom, flexibility and surveillance. We highlight the ways cashless payments can alter the social function of money, create new forms of work for drivers and passengers, and if not carefully introduced can cause emotional stress and fears of state surveillance and control."
    },
    {
        "title": "Informing and Improving Retirement Saving Performance using Behavioral Economics Theory-driven User Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of Things",
        "data": "April 2015",
        "authors": [
            "Junius Gunaratne",
            "Oded Nov"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702408",
        "citation": "21",
        "abstract": "Can human-computer interaction help people make informed and effective decisions about their retirement savings? We applied the behavioral economic theories of endowment effect and loss aversion to the design of novel retirement saving user interfaces. To examine effectiveness, we conducted an experiment in which 487 participants were exposed to one of three experimental user interface designs of a retirement saving simulator, representing endowment effect, loss aversion and control. Users made 34 yearly asset allocation decisions. We found that designs informed by the endowment effect and loss aversion theories and which communicated to savers the long-term implications of their asset allocation choices, led users to adjust their behavior, make larger and more frequent asset allocation changes, and achieve their saving goals more effectively."
    },
    {
        "title": "Session details: Muscle-Computer Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Muscle-Computer Interfaces",
        "data": "April 2015",
        "authors": [
            "Chris Harrison"
        ],
        "DOI": "https://doi.org/10.1145/3251696",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Advancing Muscle-Computer Interfaces with High-Density Electromyography",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Muscle-Computer Interfaces",
        "data": "April 2015",
        "authors": [
            "Christoph Amma",
            "Thomas Krings",
            "Jonas Böer",
            "Tanja Schultz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702501",
        "citation": "106",
        "abstract": "In this paper we present our results on using electromyographic (EMG) sensor arrays for finger gesture recognition. Sensing muscle activity allows to capture finger motion without placing sensors directly at the hand or fingers and thus may be used to build unobtrusive body-worn interfaces. We use an electrode array with 192 electrodes to record a high-density EMG of the upper forearm muscles. We present in detail a baseline system for gesture recognition on our dataset, using a naive Bayes classifier to discriminate the 27 gestures. We recorded 25 sessions from 5 subjects. We report an average accuracy of 90% for the within-session scenario, showing the feasibility of the EMG approach to discriminate a large number of subtle gestures. We analyze the effect of the number of used electrodes on the recognition performance and show the benefit of using high numbers of electrodes. Cross-session recognition typically suffers from electrode position changes from session to session. We present two methods to estimate the electrode shift between sessions based on a small amount of calibration data and compare it to a baseline system with no shift compensation. The presented methods raise the accuracy from 59% baseline accuracy to 75% accuracy after shift compensation. The dataset is publicly available."
    },
    {
        "title": "Proprioceptive Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Muscle-Computer Interfaces",
        "data": "April 2015",
        "authors": [
            "Pedro Lopes",
            "Alexandra Ion",
            "Willi Mueller",
            "Daniel Hoffmann",
            "Patrik Jonell",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702461",
        "citation": "81",
        "abstract": "We propose a new way of eyes-free interaction for wearables. It is based on the user's proprioceptive sense, i.e., rather than seeing, hearing, or feeling an outside stimulus, users feel the pose of their own body. We have implemented a wearable device called Pose-IO that offers input and output based on proprioception. Users communicate with Pose-IO through the pose of their wrists. Users enter information by performing an input gesture by flexing their wrist, which the device senses using a 3-axis accelerometer. Users receive output from Pose-IO by find-ing their wrist posed in an output gesture, which Pose-IO actuates using electrical muscle stimulation. This mechanism allows users to interact with Pose-IO without visual or auditory senses, but through the proprioceptive sense alone. We developed three simple applications that demonstrate symmetric proprioceptive interaction, where input and output occur through the same limb, as well as asymmetric interaction, where input and output occur through different limbs. In a first user study, participants using a symmetric proprioceptive interface re-entered poses received from Pose-IO with an average accuracy of 5.8° despite the minimal bandwidth offered by the device. In a second, exploratory study, we investigated participants' emotional response to asymmetric proprioceptive interaction and the concept of the user's body serving as interface. Participants reported to enjoy the experience (4.6 out of 5)."
    },
    {
        "title": "Session details: Phones for more than Just Talking & Text",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Phones for more than Just Talking & Text",
        "data": "April 2015",
        "authors": [
            "Naomi Yamashita"
        ],
        "DOI": "https://doi.org/10.1145/3251697",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "AudioScope: Smartphones as Directional Microphones in Mobile Audio Augmented Reality Systems",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Phones for more than Just Talking & Text",
        "data": "April 2015",
        "authors": [
            "Florian Heller",
            "Jan Borchers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702159",
        "citation": "7",
        "abstract": "Mobile audio augmented reality systems (MAARS) provide a new and engaging modality to present information or to create playful experiences. Using special filters, spatial audio rendering creates the impression that the sound of a virtual source emanates from a certain position in the physical space. So far, most of the implementations of such systems rely on head tracking to create a realistic effect, which requires additional hardware. Recent results indicate that the built-in sensors of a smartphone can be used as source for orientation measurement, reducing deployment to a simple app download. AudioScope presents an alternative interaction technique to create such an experience, using the metaphor of pointing a directional microphone at the environment. In an experiment with 20 users, we compared the time to locate a proximate audio source and the perceived presence in the virtual environment. Results show that there is no significant difference between head-orientation measurement and AudioScope regarding accuracy and perceived presence. This means that MAARS, such as audio guides for museums, do not require special hardware but can run on the visitor's smartphones with standard headphones."
    },
    {
        "title": "ScanShot: Detecting Document Capture Moments and Correcting Device Orientation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Phones for more than Just Talking & Text",
        "data": "April 2015",
        "authors": [
            "Jeungmin Oh",
            "Woohyeok Choi",
            "Joohyun Kim",
            "Uichin Lee"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702440",
        "citation": "3",
        "abstract": "Document capturing with smartphone cameras is performed increasingly often in our daily lives. However, our user study results (n=10) showed that more than 80% of landscape tasks had incorrect orientations. To solve this problem, we systematically analyzed user behavior of document capturing and proposed a novel solution called ScanShot that detects document capturing moments to help users correct the orientation errors. ScanShot tracks the gravity direction to capture document capturing moments, analyzes logged gyroscope data to automatically update orientation changes, and provides visual feedback of the inferred orientation for manual correction. Our user study results (n=20) confirmed that capturing moments can be recognized with accuracy of 97.5%, our update mechanism can reduce the orientation errors by 59 percentage points."
    },
    {
        "title": "Mechanics of Camera Work in Mobile Video Collaboration",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Phones for more than Just Talking & Text",
        "data": "April 2015",
        "authors": [
            "Brennan Jones",
            "Anna Witcraft",
            "Scott Bateman",
            "Carman Neustaedter",
            "Anthony Tang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702345",
        "citation": "60",
        "abstract": "Mobile video conferencing, where one or more participants are moving about in the real world, enables entirely new interaction scenarios (e.g., asking for help to construct or repair an object, or showing a physical location). While we have a good understanding of the challenges of video conferencing in office or home environments, we do not fully understand the mechanics of camera work-how people use mobile devices to communicate with one another-during mobile video calls. To provide an understanding of what people do in mobile video collaboration, we conducted an observational study where pairs of participants completed tasks using a mobile video conferencing system. Our analysis suggests that people use the camera view deliberately to support their interactions-for example, to convey a message or to ask questions-but the limited field of view, and the lack of camera control can make it a frustrating experience."
    },
    {
        "title": "Reducing the Stress of Coordination: Sharing Travel Time Information Between Contacts on Mobile Phones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Phones for more than Just Talking & Text",
        "data": "April 2015",
        "authors": [
            "Frank R. Bentley",
            "Ying-Yu Chen",
            "Christian Holz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702208",
        "citation": "10",
        "abstract": "We explore the everyday use of a new abstraction for mo-bile location-sharing. By sharing the travel time between contacts calculated for walking, transit, and driving, we have enabled users to more easily coordinate meeting up and planning family obligations. Specifically, our participants reported that the information helped to lower the stress of these activities and provided reassurance of the arrival times of their close friends and family. In this paper, we describe our system, motivate its design, and explore results from a 20-user, 21-day field trial showing the use-fulness of the abstraction as well as attitudes towards privacy when sharing travel times with close friends or family."
    },
    {
        "title": "You Can't Smoke Here: Towards Support for Space Usage Rules in Location-aware Technologies",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Phones for more than Just Talking & Text",
        "data": "April 2015",
        "authors": [
            "Pavel Andreevich Samsonov",
            "Xun Tang",
            "Johannes Schöning",
            "Werner Kuhn",
            "Brent Hecht"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702269",
        "citation": "8",
        "abstract": "Recent work has identified the lack of space usage rule (SUR) data -- e.g. \"no smoking\", \"no campfires\" -- as an important limitation of online/mobile maps that presents risks to user safety and the environment. In order to address this limitation, a large-scale means of mapping SURs must be developed. In this paper, we introduce and motivate the problem of mapping space usage rules and take the first steps towards identifying solutions. We show how computer vision can be employed to identify SUR indicators in the environment (e.g. \"No Smoking\" signs) with reasonable accuracy and describe techniques that can assign each rule to the appropriate geographic feature."
    },
    {
        "title": "Session details: Search & Recommendations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search & Recommendations",
        "data": "April 2015",
        "authors": [
            "Susan Dumais"
        ],
        "DOI": "https://doi.org/10.1145/3251698",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Blended Recommending: Integrating Interactive Information Filtering and Algorithmic Recommender Techniques",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search & Recommendations",
        "data": "April 2015",
        "authors": [
            "Benedikt Loepp",
            "Katja Herrmanny",
            "Jürgen Ziegler"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702496",
        "citation": "39",
        "abstract": "We present a novel approach that integrates algorithmic recommender techniques with interactive faceted filtering methods. We refer to this approach as blended recommending. It allows users to interact with a set of filter facets representing criteria that can serve as input for different recommendation methods including both collaborative and content-based filtering. Users can select filter criteria from these facets and weight them to express their preferences and to exert control over the hybrid recommendation process. In contrast to hard Boolean filtering, the method aggregates the weighted criteria and calculates a ranked list of recommendations that is visualized and immediately updated when users change the filter settings. Based on this approach, we implemented an interactive movie recommender, MyMovieMixer. In a user study, we compared the system with a conventional faceted filtering system that served as a baseline to obtain insights into user interaction behavior and to assess recommendation quality for our system. The results indicate, among other findings, a higher level of perceived user control, more detailed preference settings, and better suitability when the search goal is vague."
    },
    {
        "title": "A Large-Scale Study of User Image Search Behavior on the Web",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search & Recommendations",
        "data": "April 2015",
        "authors": [
            "Jaimie Y. Park",
            "Neil O'Hare",
            "Rossano Schifanella",
            "Alejandro Jaimes",
            "Chin-Wan Chung"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702527",
        "citation": "28",
        "abstract": "In this study, we analyze user image search behavior from a large-scale Yahoo! Image Search query log, based on the hypothesis that behavior is dependent on query type. We categorize queries using two orthogonal taxonomies (subject-based and facet-based) and identify important query types at the intersection of these taxonomies. We study user search behavior on a large-scale set of search sessions for each query type, examining characteristics of sessions, query reformulation patterns, click patterns, and page view patterns. We identify important behavioral differences across query types, in particular showing that some query types are more exploratory, while others correspond to focused search. We also supplement our study with a survey to link the behavioral differences to users' intent. Our findings shed light on the importance of considering query categories to better understand user behavior on image search platforms."
    },
    {
        "title": "DynamicMaps: Similarity-based Browsing through a Massive Set of Images",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search & Recommendations",
        "data": "April 2015",
        "authors": [
            "Yanir Kleiman",
            "Joel Lanir",
            "Dov Danon",
            "Yasmin Felberbaum",
            "Daniel Cohen-Or"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702224",
        "citation": "15",
        "abstract": "We present a novel system for browsing through a very large set of images according to similarity. The images are dynamically placed on a 2D canvas next to their nearest neighbors in a high-dimensional feature space. The layout and choice of images is generated on-the-fly during user interaction, reflecting the user's navigation tendencies and interests. This intuitive solution for image browsing provides a continuous experience of navigating through an infinite 2D grid arranged by similarity. In contrast to common multidimensional embedding methods, our solution does not entail an upfront creation of a full global map. Image map generation is dynamic, fast and scalable, independent of the number of images in the dataset, and seamlessly supports online updates to the dataset. Thus, the technique is a viable solution for massive and constantly varying datasets consisting of millions of images. Evaluation of our approach shows that when using DynamicMaps, users viewed many more images per minute compared to a standard relevance feedback interface, suggesting that it supports more fluid and natural interaction that enables easier and faster movement in the image space. Most users preferred DynamicMaps, indicating it is more exploratory, better supports serendipitous browsing and more fun to use"
    },
    {
        "title": "S.O.S.: Does Your Search Engine Results Page (SERP) Need Help?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search & Recommendations",
        "data": "April 2015",
        "authors": [
            "Maximilian Speicher",
            "Andreas Both",
            "Martin Gaedke"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702568",
        "citation": "6",
        "abstract": "Over the past 20 years, search engines have become emph{the} entry point of the WWW. Due to evolving needs for different and new kinds of information, the interfaces of search engine results pages (SERPs) change over time. Thus, their usability must be continuously evaluated to ensure user satisfaction and competitive edge. As no complete solution exists, we present emph{S.O.S.:} the emph{SERP Optimization Suite}. Our approach comprises (a) emph{WaPPU}, which is a near real-time tool for evaluating web interfaces based on usability scores, and (b) a emph{catalog of best practices} that maps bad scores to potential causes and corresponding adjustments for optimization. During a case study in which we assessed and optimized a real-world SERP, S.O.S. has proven its feasibility and effectiveness by significantly improving the SERP's usability."
    },
    {
        "title": "Session details: Kids Haptic, Wearable, Tangible Learning",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Haptic, Wearable, Tangible Learning",
        "data": "April 2015",
        "authors": [
            "Shuli Gilutz"
        ],
        "DOI": "https://doi.org/10.1145/3251699",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "FeelSleeve: Haptic Feedback to Enhance Early Reading",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Haptic, Wearable, Tangible Learning",
        "data": "April 2015",
        "authors": [
            "Nesra Yannier",
            "Ali Israr",
            "Jill Fain Lehman",
            "Roberta L. Klatzky"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702396",
        "citation": "33",
        "abstract": "Engaging children with traditional approaches in education, especially reading, grows ever more difficult in the face of their attachment to tablets and computer games. We explore the possibility of making the story reading experience more interesting and memorable for children using haptic augmentation. In this paper, we present FeelSleeve, an interface that allows children to feel story events in their hands while they are reading on a mobile device. FeelSleeve uses transducers and audio output from the tablet within a gloved attachment to create vibratory effects that are meaningfully related to story content. We describe a study investigating whether embedding such haptic feedback into stories enhances reading for six to nine year olds. Our results indicate that story events accompanied by haptic feedback are better comprehended and appear to be more salient in memory. These results provide evidence that haptic effects have the potential to improve children's reading experience and make it more memorable."
    },
    {
        "title": "BodyVis: A New Approach to Body Learning Through Wearable Sensing and Visualization",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Haptic, Wearable, Tangible Learning",
        "data": "April 2015",
        "authors": [
            "Leyla Norooz",
            "Matthew Louis Mauriello",
            "Anita Jorgensen",
            "Brenna McNally",
            "Jon E. Froehlich"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702299",
        "citation": "44",
        "abstract": "Internal organs are hidden and untouchable, making it difficult for children to learn their size, position, and function. Traditionally, human anatomy (body form) and physiology (body function) are taught using techniques ranging from worksheets to three-dimensional models. We present a new approach called BodyVis, an e-textile shirt that combines biometric sensing and wearable visualizations to reveal otherwise invisible body parts and functions. We describe our 15-month iterative design process including lessons learned through the development of three prototypes using participatory design and two evaluations of the final prototype: a design probe interview with seven elementary school teachers and three single-session deployments in after-school programs. Our findings have implications for the growing area of wearables and tangibles for learning."
    },
    {
        "title": "Exploring Expressive Augmented Reality: The FingAR Puppet System for Social Pretend Play",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Haptic, Wearable, Tangible Learning",
        "data": "April 2015",
        "authors": [
            "Zhen Bai",
            "Alan F. Blackwell",
            "George Coulouris"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702250",
        "citation": "41",
        "abstract": "We present \"FingAR Puppet\", an Augmented Reality (AR) system enhancing social pretend play by young children. Unlike goal-oriented AR systems that augment reality with informative instructions, FingAR Puppet helps children associate expressive interpretations with immediate reality. Empirical results show that FingAR Puppet promotes reasoning about emotional states, communication and divergent thinking during social pretend play for children 4-6 years old. We suggest that this study opens an interesting space for future AR systems to support complex cognitive and social development in early childhood. We also identify broader implications from using theories of cognitive development to guide the design of tangible and augmented interactions."
    },
    {
        "title": "Learning from Mixed-Reality Games: Is Shaking a Tablet as Effective as Physical Observation?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Haptic, Wearable, Tangible Learning",
        "data": "April 2015",
        "authors": [
            "Nesra Yannier",
            "Kenneth R. Koedinger",
            "Scott E. Hudson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702397",
        "citation": "26",
        "abstract": "The possibility of leveraging technology to support children's learning in the real world is both appealing and technically challenging. We have been exploring factors in tangible games that may contribute to both learning and enjoyment with an eye toward technological feasibility and scalability. Previous research found that young children learned early physics principles better when interactively predicting and observing experimental comparisons on a physical earthquake table than when seeing a video of the same. Immersing children in the real world with computer vision-based feedback appears to evoke embodied cognition that enhances learning. In the current experiment, we replicated this intriguing result of the mere difference between observing the real world versus a flat-screen. Further, we explored whether a simple and scalable addition of physical control (such as shaking a tablet) would yield an increase in learning and enjoyment. Our 2x2 experiment found no evidence that adding simple forms of hands-on control enhances learning, while demonstrating a large impact of physical observation. A general implication for educational game design is that affording physical observation in the real world accompanied by interactive feedback may be more important than affording simple hands-on control on a tablet."
    },
    {
        "title": "Session details: Motivation & Participation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Motivation & Participation",
        "data": "April 2015",
        "authors": [
            "Meredith Morris"
        ],
        "DOI": "https://doi.org/10.1145/3251700",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Gauging Receptiveness to Social Microvolunteering",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Motivation & Participation",
        "data": "April 2015",
        "authors": [
            "Erin Brady",
            "Meredith Ringel Morris",
            "Jeffrey P. Bigham"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702329",
        "citation": "53",
        "abstract": "Crowd-powered systems that help people are difficult to scale and sustain because human labor is expensive and worker pools are difficult to grow. To address this problem we introduce the idea of social microvolunteering, a type of intermediated friendsourcing in which a person can provide access to their friends as potential workers for microtasks supporting causes that they care about. We explore this idea by creating Visual Answers, an exemplar social microvolunteering application for Facebook that posts visual questions from people who are blind. We present results of a survey of 350 participants on the concept of social microvolunteering, and a deployment of the Visual Answers application with 91 participants, which collected 618 high-quality answers to questions asked over 12 days, illustrating the feasibility of the approach."
    },
    {
        "title": "Mobile Gamification for Crowdsourcing Data Collection: Leveraging the Freemium Model",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Motivation & Participation",
        "data": "April 2015",
        "authors": [
            "Kristen Dergousoff",
            "Regan L. Mandryk"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702296",
        "citation": "21",
        "abstract": "Classic ways of gathering data on human behaviour are time-consuming, costly and are subject to limited participant pools. Crowdsourcing offers a reduction in operating costs and access to a diverse and large participant pool; however issues arise concerning low worker pay and questions about data quality. Gamification provides a motivation to participate, but also requires the development of specialized, research-question specific games that can be costly to produce. Our solution combines gamification and crowdsourcing in a smartphone-based system that emulates the popular Freemium model of play to motivate voluntary participation through in-game rewards, using a robust framework to study multiple unrelated research questions within the same system. We deployed our game on the Android store and compared it to a gamified laboratory version and a non-gamified laboratory version, and found that players who used the in-game rewards were motivated to do experimental tasks. There was no difference between the systems for performance on a motor task; however, performance on the cognitive task was worse for the crowdsourced game. We discuss options for improving performance on tasks requiring attention."
    },
    {
        "title": "Unequal Time for Unequal Value: Implications of Differing Motivations for Participation in Timebanking",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Motivation & Participation",
        "data": "April 2015",
        "authors": [
            "Patrick C. Shih",
            "Victoria Bellotti",
            "Kyungsik Han",
            "John M. Carroll"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702560",
        "citation": "35",
        "abstract": "Timebanking is a service-based community currency, built on the principle that everyone's time is valued equally. It has potential for community building and reenergizing neighborhoods, but it faces several adoption challenges. We report on the largest investigation of timebanking practices to date by analyzing a combination of service exchange records from the three largest hOurworld timebanks with over 3,500 members with 33,000 completed service exchanges, and a survey of 446 members of over 120 hOurworld timebanks. Our findings suggest that the ideal of 'equal time, equal value' that is at the foundation of timebanking is a source of tension between members with instrumental versus idealistic and altruistic motivations. We suggest that future peer-to-peer systems must incorporate different rewards and incentives in order to accommodate users with different motivations."
    },
    {
        "title": "A Muddle of Models of Motivation for Using Peer-to-Peer Economy Systems",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Motivation & Participation",
        "data": "April 2015",
        "authors": [
            "Victoria Bellotti",
            "Alexander Ambard",
            "Daniel Turner",
            "Christina Gossmann",
            "Kamila Demkova",
            "John M. Carroll"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702272",
        "citation": "123",
        "abstract": "This paper reports on a study of motivations for the use of peer-to-peer or sharing economy services. We interviewed both users and providers of these systems to obtain different perspectives and to determine if providers are matching their system designs to the most important drivers of use. We found that the motivational models implicit in providers' explanations of their systems' designs do not match well with what really seems to motivate users. Providers place great emphasis on idealistic motivations such as creating a better community and increasing sustainability. Users, on the other hand are looking for services that provide what they need whilst increasing value and convenience. We discuss the divergent models of providers and users and offer design implications for peer system providers."
    },
    {
        "title": "Session details: Sustainability & Recycling",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sustainability & Recycling",
        "data": "April 2015",
        "authors": [
            "Adrian Clear"
        ],
        "DOI": "https://doi.org/10.1145/3251701",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Analysis of Recycling Capabilities of Individuals and Crowds to Encourage and Educate People to Separate Their Garbage Playfully",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sustainability & Recycling",
        "data": "April 2015",
        "authors": [
            "Pascal Lessel",
            "Maximilian Altmeyer",
            "Antonio Krüger"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702309",
        "citation": "24",
        "abstract": "Sorting garbage is a relevant topic in many countries as it contributes to environmental protection. Empirical evidence suggests that not all people separate waste, potentially because they do not know how to do it correctly or are simply not motivated enough. We present the results of an online study (N=184) investigating people's capabilities for classifying waste, their capabilities to improve in this task over time and their current garbage separation behavior. The study confirms that the Wisdom of Crowds is applicable in this context as the crowd produces only half as many errors as the individual and feedback helps participants to improve. Based on this, we introduce the idea of a crowd classifying waste in a game, with their classification result then being used as feedback on gamified public trash cans to educate both the crowd playing the game and people using the trash can playfully."
    },
    {
        "title": "Why and what did we throw out?: Probing on Reflection through the Food Waste Diary",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sustainability & Recycling",
        "data": "April 2015",
        "authors": [
            "Eva Ganglbauer",
            "Geraldine Fitzpatrick",
            "Florian Güldenpfennig"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702284",
        "citation": "30",
        "abstract": "Issues of consumer food waste in industrialised countries are becoming an increasing concern and this is paralleled by a growing interest in HCI to support more sustainable consumption practices. In this paper we report on a mobile food waste diary application that was made available on app stores, with the aim of enabling motivated people to reflect on their moments of food waste and to explore rationales. Through analysis of the entries submitted by users of the diary application, we identify instances of reflection located on different levels. The intention of supporting reflection was visible in instances of submitted diary entries where deeper in- sights about the relationships between food waste, previous experiences, habits, knowledge, occurrences and intentions to change were offered."
    },
    {
        "title": "Energy Babble: Mixing Environmentally-Oriented Internet Content to Engage Community Groups",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sustainability & Recycling",
        "data": "April 2015",
        "authors": [
            "William Gaver",
            "Mike Michael",
            "Tobie Kerridge",
            "Alex Wilkie",
            "Andy Boucher",
            "Liliana Ovalle",
            "Matthew Plummer-Fernandez"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702546",
        "citation": "39",
        "abstract": "The Energy Babble is a kind of automated talk-radio that is obsessed with energy and the environment. We developed it with, and deployed it to, a number of existing \"energy communities\" in the UK. The system gathers content from a variety of online sources, including Twitter? feeds from the communities, from governmental departments, and from the National Grid, and chats about it continually using a number of synthesised voices interspersed with a variety of jingles and sound effects. Designed to playfully reflect and comment on the existing state of discourse and reports of practice in the UK, the Babble can be considered both as a product and as a research tool, in which role it worked to highlight issues, understandings, practices and difficulties in the communities with whom we worked."
    },
    {
        "title": "Beyond the Individual: The Contextual Wheel of Practice as a Research Framework for Sustainable HCI",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sustainability & Recycling",
        "data": "April 2015",
        "authors": [
            "Johanne Mose Entwistle",
            "Mia Kruse Rasmussen",
            "Nervo Verdezoto",
            "Robert S. Brewer",
            "Mads Schaarup Andersen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702232",
        "citation": "34",
        "abstract": "Addressing human impact on the environment by focusing on shared everyday practices, rather than just individual behavior is an approach that shows promise. However, it can be challenging to put this approach into concrete use, especially in teams unfamiliar with the practice orientation. To support the practice approach, we introduce the Contextual Wheel of Practice (COWOP), a framework that can: 1) help researchers and designers to better understand practices, 2) design effective interventions, and 3) facilitate collaboration between team members from different disciplines, who may not be familiar with the practice orientation. We describe how COWOP was developed, and our experiences using COWOP in three different cases. We then position COWOP as part of the \"turn to practice\" in HCI, and discuss how it can be useful to HCI researchers and be applied in domains beyond sustainability, such as healthcare and privacy."
    },
    {
        "title": "Session details: The Value of the Village in Caregiving",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of the Village in Caregiving",
        "data": "April 2015",
        "authors": [
            "Lena Mamykina"
        ],
        "DOI": "https://doi.org/10.1145/3251702",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Effects of Public Commitments and Accountability in a Technology-Supported Physical Activity Intervention",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of the Village in Caregiving",
        "data": "April 2015",
        "authors": [
            "Sean A. Munson",
            "Erin Krupka",
            "Caroline Richardson",
            "Paul Resnick"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702524",
        "citation": "32",
        "abstract": "Walking and other forms of physical activity have many health benefits, but people often fail to follow through on their own goals of being more active. To address gaps in current understanding of how to design technology-supported physical activity interventions, we conducted a randomized field experiment of a commitment device: making public announcements. In a control condition, weekly commitments were kept private. In two treatment conditions, they were announced on Facebook and by email. In one of the two, the announcements also included results: whether the previous week's commitment was kept. We find that, with or without public results, these posts can elicit supportive replies from the poster's social networks. People in both public announcements conditions were less likely to make commitments. We conclude that the prospect of public accountability may suppress the making of commitments in a way that counteracts the benefits of that accountability. Designers will need to address this limitation in order to make effective use of public accountability as a commitment device."
    },
    {
        "title": "Rare World: Towards Technology for Rare Diseases",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of the Village in Caregiving",
        "data": "April 2015",
        "authors": [
            "Haley MacLeod",
            "Kim Oakes",
            "Danika Geisler",
            "Kay Connelly",
            "Katie Siek"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702494",
        "citation": "41",
        "abstract": "Researchers have created innovative technological solutions to support people with common chronic illnesses. In this study, we investigate design opportunities for people with rare diseases who are not well studied or have smaller populations to work with, because although an individual's disease may be rare, the number of people living with a rare disease is substantial. We conducted an interview study with 19 individuals with rare diseases from around the world to understand common problems and experiences that could be supported through design. We found that communicating with friends, family, and providers about her disease were challenges for participants. Additionally, participants thought of their disease as being a large part of who they were. We discuss these findings in the context of prior work on common chronic illnesses, addressing the potential relevance of existing technological interventions for people with rare diseases."
    },
    {
        "title": "Looking for Respite and Support: Technological Opportunities for Spousal Caregivers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of the Village in Caregiving",
        "data": "April 2015",
        "authors": [
            "Matthieu Tixier",
            "Myriam Lewkowicz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702563",
        "citation": "22",
        "abstract": "Our research aims at informing the design of technological solutions to alleviate the stress resulting from the involvement of spouses of Alzheimer's disease patients as caregivers. For so doing, we have observed and analyzed the different offline solutions that are offered by a healthcare network in the Aube region (North-East of France). We discuss the key factors that we have identified for building an effective support network and identify five perspectives for the development of an online social support platform to lower the burden of spousal caregivers."
    },
    {
        "title": "Barriers and Negative Nudges: Exploring Challenges in Food Journaling",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Value of the Village in Caregiving",
        "data": "April 2015",
        "authors": [
            "Felicia Cordeiro",
            "Daniel A. Epstein",
            "Edison Thomaz",
            "Elizabeth Bales",
            "Arvind K. Jagannathan",
            "Gregory D. Abowd",
            "James Fogarty"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702155",
        "citation": "157",
        "abstract": "Although food journaling is understood to be both important and difficult, little work has empirically documented the specific challenges people experience with food journals. We identify key challenges in a qualitative study combining a survey of 141 current and lapsed food journalers with analysis of 5,526 posts in community forums for three mobile food journals. Analyzing themes in this data, we find and discuss barriers to reliable food entry, negative nudges caused by current techniques, and challenges with social features. Our results motivate research exploring a wider range of approaches to food journal design and technology."
    },
    {
        "title": "Session details: I Like What I See - Interface Aesthetics",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: I Like What I See - Interface Aesthetics",
        "data": "April 2015",
        "authors": [
            "Simon Bowen"
        ],
        "DOI": "https://doi.org/10.1145/3251703",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Computation of Interface Aesthetics",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: I Like What I See - Interface Aesthetics",
        "data": "April 2015",
        "authors": [
            "Aliaksei Miniukovich",
            "Antonella De Angeli"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702575",
        "citation": "52",
        "abstract": "People prefer attractive interfaces. Designers strive to outmatch competitors, and create apps and websites that stand out. However, significant expenses on design are unaffordable to small companies; instead, they could adopt automatic tools of interface aesthetics evaluation, a cheaper strategy to good design. This paper describes an important step towards such a tool; it presents eight automatic metrics of graphical user interface (GUI) aesthetics. We tested the metrics in two exploratory studies -- on desktop webpages (N = 62) and on iPhone apps (N = 53) -- and found them to function on both GUI types and for both immediate (150ms exposure) and deliberate (4s exposure) aesthetics impressions. Our best-fit regression models explained up to 49% of variance in webpage aesthetics and up to 32% (if app genre is considered) of variance in iPhone app aesthetics. These results confirm past results and suggest the metrics are valid and reliable enough to be widely discussed, and possibly, to be embedded in our prospective GUI evaluation tool, tLight."
    },
    {
        "title": "Patina Engraver: Visualizing Activity Logs as Patina in Fashionable Trackers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: I Like What I See - Interface Aesthetics",
        "data": "April 2015",
        "authors": [
            "Moon-Hwan Lee",
            "Seijin Cha",
            "Tek-Jin Nam"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702213",
        "citation": "29",
        "abstract": "Despite technological improvements in commercial activity trackers, little attention has been given to their emotional, social, or fashion-related qualities, such as their visual aesthetics and their relationship to self-expression and social connection. As an alternative integrated approach incorporating HCI, fashion, and product design, our project made use of the characteristics of patina to improve activity trackers as fashionable wearables. We developed the Patina Engraving System, which engraves patina-like patterns on an activity tracker according to a user's activity logs. Using a piercing technique, the patina of activity logs has been made abstract, visually rich, gradually emerging, and historically accumulated. During the field trial, we found that the patina motivated the participants to increase exercises for engraving aesthetic patinas. A tracker with patina triggered spontaneous social interactions in face-to-face situations. The participants also cherished the trackers that held their own history. Based on the field trial, we discuss design implications for utilizing patina in designing future fashionable technologies."
    },
    {
        "title": "Real-time Guidance Camera Interface to Enhance Photo Aesthetic Quality",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: I Like What I See - Interface Aesthetics",
        "data": "April 2015",
        "authors": [
            "Yan Xu",
            "Joshua Ratcliff",
            "James Scovell",
            "Gheric Speiginer",
            "Ronald Azuma"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702418",
        "citation": "14",
        "abstract": "This paper explores whether it is effective to use real-time on-screen guidance to help users take better photos with mobile devices. Using a three-camera array, we developed a photo-taking interface that provides real-time feedback on how to position the subject-of-interest according to a photography composition rule: rule-of-thirds. We conduct a user study to compare the aesthetic quality of photos taken with our real-time guidance interface against a static gridline interface common to existing digital cameras. Expert photographers and Mechanical Turk workers rate the aesthetic quality of these pairs of photos. Results indicate the photos taken with our real-time guidance interface have significantly higher aesthetics scores. This study shows the potential in using camera array, computational photography, and real-time guidance interface to help non-expert users take better photos."
    },
    {
        "title": "Infographic Aesthetics: Designing for the First Impression",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: I Like What I See - Interface Aesthetics",
        "data": "April 2015",
        "authors": [
            "Lane Harrison",
            "Katharina Reinecke",
            "Remco Chang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702545",
        "citation": "71",
        "abstract": "Information graphics, or infographics, combine elements of data visualization with design and have become an increasingly popular means for disseminating data. While several studies have suggested that aesthetics in visualization and infographics relate to desirable outcomes like engagement and memorability, it remains unknown how quickly aesthetic impressions are formed, and what it is that makes an infographic appealing. We address these questions by analyzing 1,278 participants' ratings on appeal after seeing infographics for 500ms. Our results establish that: 1) people form a reliable first impression of the appeal of an infographic based on a mere exposure effect, 2) this first impression is largely based on colorfulness and visual complexity, and 3) age, gender, and education level influence the preferred level of colorfulness and complexity. More generally, these findings suggest that outcomes such as engagement and memorability might be determined much earlier than previously thought."
    },
    {
        "title": "ISOTYPE Visualization: Working Memory, Performance, and Engagement with Pictographs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: I Like What I See - Interface Aesthetics",
        "data": "April 2015",
        "authors": [
            "Steve Haroz",
            "Robert Kosara",
            "Steven L. Franconeri"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702275",
        "citation": "84",
        "abstract": "Although the infographic and design communities have used simple pictographic representations for decades, it is still unclear whether they can make visualizations more effective. Using simple charts, we tested how pictographic representations impact (1) memory for information just viewed, as well as under the load of additional information, (2) speed of finding information, and (3) engagement and preference in seeking out these visualizations. We find that superfluous images can distract. But we find no user costs -- and some intriguing benefits -- when pictographs are used to represent the data."
    },
    {
        "title": "Session details: Supporting Creativity through UX Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Creativity through UX Design",
        "data": "April 2015",
        "authors": [
            "Luciano Gamberini"
        ],
        "DOI": "https://doi.org/10.1145/3251704",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "GEM-NI: A System for Creating and Managing Alternatives In Generative Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Creativity through UX Design",
        "data": "April 2015",
        "authors": [
            "Loutfouz Zaman",
            "Wolfgang Stuerzlinger",
            "Christian Neugebauer",
            "Rob Woodbury",
            "Maher Elkhaldi",
            "Naghmi Shireen",
            "Michael Terry"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702398",
        "citation": "36",
        "abstract": "We present GEM-NI -- a graph-based generative-design tool that supports parallel exploration of alternative designs. Producing alternatives is a key feature of creative work, yet it is not strongly supported in most extant tools. GEM-NI enables various forms of exploration with alternatives such as parallel editing, recalling history, branching, merging, comparing, and Cartesian products of and for alternatives. Further, GEM-NI provides a modal graphical user interface and a design gallery, which both allow designers to control and manage their design exploration. We conducted an exploratory user study followed by in-depth one-on-one interviews with moderately and highly skills participants and obtained positive feedback for the system features, showing that GEM-NI supports creative design work well."
    },
    {
        "title": "Motif: Supporting Novice Creativity through Expert Patterns",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Creativity through UX Design",
        "data": "April 2015",
        "authors": [
            "Joy Kim",
            "Mira Dontcheva",
            "Wilmot Li",
            "Michael S. Bernstein",
            "Daniela Steinsapir"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702507",
        "citation": "27",
        "abstract": "Creating personal narratives helps people build meaning around their experiences. However, novices lack the knowledge and experience to create stories with strong narrative structure. Current storytelling tools often structure novice work through templates, enforcing a linear creative process that asks novices for materials they may not have. In this paper, we propose scaffolding creative work using storytelling patterns extracted from stories created by experts. Patterns are modular sets of related camera shots that expert videographers commonly use to achieve a specific narrative function. After identifying a set of patterns from high-quality storytelling videos, we created Motif, a mobile video storytelling application that allows users to construct video stories by combining these patterns. By making existing solutions used by experts available to novices, we encourage capturing shots with story structure and narrative goals in mind. In a controlled study where we asked participants to create travel video stories, videos created with patterns conveyed stronger narrative structure and were considered higher quality by expert evaluators than videos created without patterns."
    },
    {
        "title": "DesignScape: Design with Interactive Layout Suggestions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Creativity through UX Design",
        "data": "April 2015",
        "authors": [
            "Peter O'Donovan",
            "Aseem Agarwala",
            "Aaron Hertzmann"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702149",
        "citation": "107",
        "abstract": "Creating graphic designs can be challenging for novice users. This paper presents DesignScape, a system which aids the design process by making interactive layout suggestions, i.e., changes in the position, scale, and alignment of elements. The system uses two distinct but complementary types of suggestions: refinement suggestions, which improve the current layout, and brainstorming suggestions, which change the style. We investigate two interfaces for interacting with suggestions. First, we develop a suggestive interface, where suggestions are previewed and can be accepted. Second, we develop an adaptive interface where elements move automatically to improve the layout. We compare both interfaces with a baseline without suggestions, and show that for novice designers, both interfaces produce significantly better layouts, as evaluated by other novices."
    },
    {
        "title": "Using Game Principles in UX Research: A Board Game for Eliciting Future User Needs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Supporting Creativity through UX Design",
        "data": "April 2015",
        "authors": [
            "Karin Slegers",
            "Sanne Ruelens",
            "Jorick Vissers",
            "Pieter Duysburgh"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702166",
        "citation": "12",
        "abstract": "This paper presents a board game approach as a UX research technique to assess potential user experiences regarding a future product. It discusses how the use of a board game may provide a) a safe research environment in which participants feel comfortable to share their thoughts and experiences in a group setting, and b) a tool to facilitate users to think about their needs regarding a future product. The use of the board game approach is illustrated by a case study in the context of developing a new train information system. The design of the board game that was used is described in detail, as well as how the game was used to elicit potential future experiences. A survey amongst the participants showed that the board game was appreciated as a surprising, pleasant and \"safe\" research method."
    },
    {
        "title": "Session details: Smartwatch Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smartwatch Interaction",
        "data": "April 2015",
        "authors": [
            "Daniel Ashbrook"
        ],
        "DOI": "https://doi.org/10.1145/3251705",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Investigating the Information Transfer Efficiency of a 3x3 Watch-back Tactile Display",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smartwatch Interaction",
        "data": "April 2015",
        "authors": [
            "Jaeyeon Lee",
            "Jaehyun Han",
            "Geehyuk Lee"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702530",
        "citation": "37",
        "abstract": "A watch-back tactile display (WBTD) is expected to be a viable supplement to the user interface limitations of a smartwatch. However, its design requires that many design parameters such as tactor types and stimulus patterns be determined. We conducted a series of experiments to explore the design space of a WBTD consisting of 3×3 tactors. We demonstrated that tactor types and the temporal patterns and locus of a stimulus produce statistically significant effects on the efficiency of a WBTD. The experimental results can act as a practical guideline for the design of an efficient WBTD."
    },
    {
        "title": "SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smartwatch Interaction",
        "data": "April 2015",
        "authors": [
            "Jonggi Hong",
            "Seongkook Heo",
            "Poika Isokoski",
            "Geehyuk Lee"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702273",
        "citation": "72",
        "abstract": "Text entry on a smartwatch is a challenging problem due to the device's limited screen area. In this paper, we introduce the SplitBoard, which is a soft keyboard designed for a smartwatch. As the user flicks left or right on the keyboard, it switches between the left and right halves of a QWERTY keyboard. We report the results of two user experiments where the SplitBoard was compared to an ordinary QWERTY keyboard, the ZoomBoard, SlideBoard, and Qwerty-like keypad. We measured the initial performance with new users for each method. The SplitBoard outperformed all other techniques in the experiments. The SplitBoard is expected to be a viable option for smartwatch text entry because of its light processing requirements, good performance, and immediate learnability."
    },
    {
        "title": "Beats: Tapping Gestures for Smart Watches",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smartwatch Interaction",
        "data": "April 2015",
        "authors": [
            "Ian Oakley",
            "DoYoung Lee",
            "MD. Rasel Islam",
            "Augusto Esteves"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702226",
        "citation": "45",
        "abstract": "Interacting with smartwatches poses new challenges. Although capable of displaying complex content, their extremely small screens poorly match many of the touchscreen interaction techniques dominant on larger mobile devices. Addressing this problem, this paper presents beating gestures, a novel form of input based on pairs of simultaneous or rapidly sequential and overlapping screen taps made by the index and middle finger of one hand. Distinguished simply by their temporal sequence and relative left/right position these gestures are designed explicitly for the very small screens (approx. 40mm square) of smartwatches and to operate without interfering with regular single touch input. This paper presents the design of beating gestures and a rigorous empirical study that characterizes how users perform them -- in a mean of 355ms and with an error rate of 5.5%. We also derive thresholds for reliably distinguishing between simultaneous (under 30ms) and sequential (under 400ms) pairs of screen touches or releases. We then present five interface designs and evaluate them in a qualitative study in which users report valuing the speed and ready availability of beating gestures."
    },
    {
        "title": "WatchConnect: A Toolkit for Prototyping Smartwatch-Centric Cross-Device Applications",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smartwatch Interaction",
        "data": "April 2015",
        "authors": [
            "Steven Houben",
            "Nicolai Marquardt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702215",
        "citation": "83",
        "abstract": "People increasingly use smartwatches in tandem with other devices such as smartphones, laptops or tablets. This allows for novel cross-device applications that use the watch as both input device and output display. However, despite the increasing availability of smartwatches, prototyping cross-device watch-centric applications remains a challenging task. Developers are limited in the applications they can explore as available toolkits provide only limited access to different types of input sensors for cross-device interactions. To address this problem, we introduce WatchConnect, a toolkit for rapidly prototyping cross-device applications and interaction techniques with smartwatches. The toolkit provides developers with (i) an extendable hardware platform that emulates a smartwatch, (ii) a UI framework that integrates with an existing UI builder, and (iii) a rich set of input and output events using a range of built-in sensor mappings. We demonstrate the versatility and design space of the toolkit with five interaction techniques and applications."
    },
    {
        "title": "It's About Time: Smartwatches as Public Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smartwatch Interaction",
        "data": "April 2015",
        "authors": [
            "Jennifer Pearson",
            "Simon Robinson",
            "Matt Jones"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702247",
        "citation": "44",
        "abstract": "Current uses of smartwatches are focused solely around the wearer's content, viewed by the wearer alone. When worn on a wrist, however, watches are often visible to many other people, making it easy to quickly glance at their displays. We explore the possibility of extending smartwatch interactions to turn personal wearables into more public displays. We begin opening up this area by investigating fundamental aspects of this interaction form, such as the social acceptability and noticeability of looking at someone else's watch, as well as the likelihood of a watch face being visible to others. We then sketch out interaction dimensions as a design space, evaluating each aspect via a web-based study and a deployment of three potential designs. We conclude with a discussion of the findings, implications of the approach and ways in which designers in this space can approach public wrist-worn wearables."
    },
    {
        "title": "Session details: Tangible Interactions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interactions",
        "data": "April 2015",
        "authors": [
            "Otmar Hilliges"
        ],
        "DOI": "https://doi.org/10.1145/3251706",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "TUIkit: Evaluating Physical and Functional Experiences of Tangible User Interface Prototypes",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interactions",
        "data": "April 2015",
        "authors": [
            "Jorick Vissers",
            "David Geerts"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702478",
        "citation": "5",
        "abstract": "This paper describes TUIkit, a new method for evaluating both physical and functional experiences of users with early TUI prototypes. By means of a study to evaluate interactive dice prototypes, TUIkit's appropriateness for tracing the effect of different physical attributes (e.g. shape, size, weight, material, texture) on the functional and thus overall user experience was investigated. The results show that separating physical and functional experiences first and joining these afterwards, enhanced the evaluation of TUI prototypes. By applying this approach, participants became more aware of how they physically experienced the prototypes, rather than focusing solely on the functional value of the prototypes. This awareness supports earlier studies that suggest that TUIs consist of more than just interaction, and that form and materiality has a strong impact on their user experience. Finally, we suggest some future adjustments of the TUIkit method."
    },
    {
        "title": "Lamello: Passive Acoustic Sensing for Tangible Input Components",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interactions",
        "data": "April 2015",
        "authors": [
            "Valkyrie Savage",
            "Andrew Head",
            "Björn Hartmann",
            "Dan B. Goldman",
            "Gautham Mysore",
            "Wilmot Li"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702207",
        "citation": "46",
        "abstract": "We describe Lamello, an approach for creating tangible input components that recognize user interaction via passive acoustic sensing. Lamello employs comb-like structures with varying-length tines at interaction points (e.g., along slider paths). Moving a component generates tine strikes; a real-time audio processing pipeline analyzes the resultant sounds and emits high-level interaction events. Our main contributions are in the co-design of the tine structures, information encoding schemes, and audio analysis. We demonstrate 3D printed Lamello-powered buttons, sliders, and dials."
    },
    {
        "title": "WonderLens: Optical Lenses and Mirrors for Tangible Interactions on Printed Paper",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interactions",
        "data": "April 2015",
        "authors": [
            "Rong-Hao Liang",
            "Chao Shen",
            "Yu-Chien Chan",
            "Guan-Ting Chou",
            "Liwei Chan",
            "De-Nian Yang",
            "Mike Y. Chen",
            "Bing-Yu Chen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702434",
        "citation": "7",
        "abstract": "This work presents WonderLens, a system of optical lenses and mirrors for enabling tangible interactions on printed paper. When users perform spatial operations on the optical components, they deform the visual content that is printed on paper, and thereby provide dynamic visual feedback on user interactions without any display devices. The magnetic unit that is embedded in each lens and mirror allows the unit to be identified and tracked using an analog Hall-sensor grid that is placed behind the paper, so the system provides additional auditory and visual feedback through different levels of embodiment, further enhancing the interactivity with the printed content on the physical paper."
    },
    {
        "title": "FugaciousFilm: Exploring Attentive Interaction with Ephemeral Material",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interactions",
        "data": "April 2015",
        "authors": [
            "Hyosun Kwon",
            "Shashank Jaiswal",
            "Steve Benford",
            "Sue Ann Seah",
            "Peter Bennett",
            "Boriana Koleva",
            "Holger Schnädelbach"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702206",
        "citation": "9",
        "abstract": "This paper introduces FugaciousFilm, a soap film based touch display, as a platform for Attentive Interaction that encourages the user to be highly focused throughout the use of the interface. Previous work on ephemeral user interfaces has primarily focused on the development of ambient and peripheral displays. In contrast, FugaciousFilm is an ephemeral display that aims to promote highly attentive interaction. We present the iterative process of developing this interface, spanning technical explorations, prototyping and a user study. We report lessons learnt when designing the interface; ranging from the soap film mixture to the impact of frames and apertures. We then describe developing the touch, push, pull and pop interactions. Our user study shows how FugaciousFilm led to focused and attentive interactions during a tournament of enhanced Tic-Tac-Toe. We then finish by discussing how the principles of vulnerability and delicacy can motivate the design of attentive ephemeral interfaces."
    },
    {
        "title": "3D Printing Pneumatic Device Controls with Variable Activation Force Capabilities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interactions",
        "data": "April 2015",
        "authors": [
            "Marynel Vázquez",
            "Eric Brockmeyer",
            "Ruta Desai",
            "Chris Harrison",
            "Scott E. Hudson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702569",
        "citation": "61",
        "abstract": "We explore 3D printing physical controls whose tactile response can be manipulated programmatically through pneumatic actuation. In particular, by manipulating the internal air pressure of various pneumatic elements, we can create mechanisms that require different levels of actuation force and can also change their shape. We introduce and discuss a series of example 3D printed pneumatic controls, which demonstrate the feasibility of our approach. This includes conventional controls, such as buttons, knobs and sliders, but also extends to domains such as toys and deformable interfaces. We describe the challenges that we faced and the methods that we used to overcome some of the limitations of current 3D printing technology. We conclude with example applications and thoughts on future avenues of research."
    },
    {
        "title": "Session details: New Evaluation Approaches",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: New Evaluation Approaches",
        "data": "April 2015",
        "authors": [
            "David England"
        ],
        "DOI": "https://doi.org/10.1145/3251707",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Bridging the Theory-Practice Gap: Lessons and Challenges of Applying the Attachment Framework for Sustainable HCI Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: New Evaluation Approaches",
        "data": "April 2015",
        "authors": [
            "Christian Remy",
            "Silke Gegenbauer",
            "Elaine M. Huang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702567",
        "citation": "25",
        "abstract": "Despite significant progress in sustainable HCI towards theoretical frameworks to guide design, there is a gap between theory and practice, so that the impact of such frameworks is limited. As an initial exploration in bridging the theory-practice gap, we conducted a study using one well-established design framework, the Attachment Framework, to evaluate its applicability in use. We conducted a comparative study with 14 designers to explore the effect of the Attachment Framework on design, and evaluated their designs with 10 design experts using a set of six design criteria. Our results indicated a positive effect on the criterion of novelty, with mixed effects on attachment, presentation, aesthetics, usefulness, and feasibility. We contribute a set of challenges in the application of design frameworks to practice and offer a critical reflection on how researchers can more effectively communicate sustainable HCI design frameworks to practitioners."
    },
    {
        "title": "The Transfer of Learning as HCI Similarity: Towards an Objective Assessment of the Sensory-Motor Basis of Naturalness",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: New Evaluation Approaches",
        "data": "April 2015",
        "authors": [
            "François Bérard",
            "Amélie Rochet-Capellan"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702359",
        "citation": "14",
        "abstract": "Human-computer interaction should be natural. However, the notion of natural is questioned due to a lack of theoretical background and methods to objectively measure the naturalness of a HCI. A frequently cited aspect of natural HCIs is their ability to benefit from knowledge and skills that users develop in their interaction with the real (non-digital) world. Among these skills, sensory-motor abilities are essential to operate many HCIs. This suggests that the transfer of these abilities between physical and digital interactions could be used as an experimental tool to assess the sensory-motor similarity between interactions, and could be considered as an objective measurement of the sensory-motor grounding of naturalness. In this framework, we introduce a new experimental paradigm inspired by motor learning research to assess sensory-motor similarity, as revealed by the transfer of learning. We tested this paradigm in an empirical study to question the naturalness of three HCIs: direct-touch, mouse pointing and absolute indirect-touch. The study revealed how skill learning transfers from these three digital interactions towards an equivalent physical interaction. We observed strong transfer of skill between direct-touch and physical interaction, but no transfer from the other two interactions. This work provides a first objective assessment of the sensory-motor basis of direct-touch naturalness, and a new empirical path to question HCI similarity and naturalness."
    },
    {
        "title": "Formalizing Agreement Analysis for Elicitation Studies: New Measures, Significance Test, and Toolkit",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: New Evaluation Approaches",
        "data": "April 2015",
        "authors": [
            "Radu-Daniel Vatavu",
            "Jacob O. Wobbrock"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702223",
        "citation": "145",
        "abstract": "We address in this work the process of agreement rate analysis for characterizing the level of consensus between participants' proposals elicited during guessability studies. Two new measures, i.e., disagreement rate for referents and coagreement rate between referents, are proposed to accompany the widely-used agreement rate formula of Wobbrock et al. [37] when reporting participants' consensus for symbolic input. A statistical significance test for comparing the agreement rates of k>=2 referents is presented in analogy with Cochran's success/failure Q test [5], for which we express the test statistic in terms of agreement and coagreement rates. We deliver a toolkit to assist practitioners to compute agreement, disagreement, and coagreement rates, and run statistical tests for agreement rates at p=.05, .01, and .001 levels of significance. We validate our theoretical development of agreement rate analysis in relation with several previously published elicitation studies. For example, when we present the probability distribution function of the agreement rate measure, we also use it (1) to explain the magnitude of agreement rates previously reported in the literature, and (2) to propose qualitative interpretations for agreement rates, in analogy with Cohen's guidelines for effect sizes [6]. We also re-examine previously published elicitation data from the perspective of the agreement rate test statistic, and highlight new findings on the effect of referents over agreement rates, unattainable prior to this work. We hope that our contributions will advance the current knowledge in agreement rate analysis, providing researchers and practitioners with new techniques and tools to help them understand user-elicited data at deeper levels of detail and sophistication."
    },
    {
        "title": "Exploring the Effect of Pre-operational Priming Intervention on Number Entry Errors",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: New Evaluation Approaches",
        "data": "April 2015",
        "authors": [
            "Yunqiu Li",
            "Patrick Oladimeji",
            "Harold Thimbleby"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702477",
        "citation": "2",
        "abstract": "Managing and reducing error in number entry tasks is important, especially in safety critical contexts. Understanding factors that can affect number entry accuracy could help the design of more dependable systems. We present three interventions for number entry tasks, inspired by known priming effects (where exposure to prior stimuli can impact task performance). The interventions were questions for the operator to answer before entering each number. Questions related to the value/size of the number, its structure, and the context of the number entry task respectively. Results of a within-subject study show that although there was no significant difference amongst performance across interventions, all three interventions helped to improve the accuracy of number entry by reducing entry errors (by up to 40.8%) and unnoticed errors (by up to 60.7%). These are impressive gains and suggest the importance of more work in this area."
    },
    {
        "title": "Session details: Evaluating Crowdsourcing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Evaluating Crowdsourcing",
        "data": "April 2015",
        "authors": [
            "Bongwon Suh"
        ],
        "DOI": "https://doi.org/10.1145/3251708",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Comparing Person- and Process-centric Strategies for Obtaining Quality Data on Amazon Mechanical Turk",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Evaluating Crowdsourcing",
        "data": "April 2015",
        "authors": [
            "Tanushree Mitra",
            "C.J. Hutto",
            "Eric Gilbert"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702553",
        "citation": "61",
        "abstract": "In the past half-decade, Amazon Mechanical Turk has radically changed the way many scholars do research. The availability of a massive, distributed, anonymous crowd of individuals willing to perform general human-intelligence micro-tasks for micro-payments is a valuable resource for researchers and practitioners. This paper addresses the challenges of obtaining quality annotations for subjective judgment oriented tasks of varying difficulty. We design and conduct a large, controlled experiment (N=68,000) to measure the efficacy of selected strategies for obtaining high quality data annotations from non-experts. Our results point to the advantages of person-oriented strategies over process-oriented strategies. Specifically, we find that screening workers for requisite cognitive aptitudes and providing training in qualitative coding techniques is quite effective, significantly outperforming control and baseline conditions. Interestingly, such strategies can improve coder annotation accuracy above and beyond common benchmark strategies such as Bayesian Truth Serum (BTS)."
    },
    {
        "title": "Crowdsourced Feedback With Imagery Rather Than Text: Would Designers Use It?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Evaluating Crowdsourcing",
        "data": "April 2015",
        "authors": [
            "David A. Robb",
            "Stefano Padilla",
            "Britta Kalkreuter",
            "Mike J. Chantler"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702470",
        "citation": "11",
        "abstract": "Cognitive styles theories suggest that we divide into visual and verbal thinkers. In this paper we describe a method designed to encourage visual communication between designers and their audiences. This new visual feedback method is based on enabling fast intuitive selections by the crowd from image banks when responding to an idea. Visual summarization reduces the massed image choices to a small number of representative images. These summaries are then consumed at a glance by designers receiving the feedback leading to thoughtful reflection on their designs. We report an evaluation using two types of imagery for feedback. Twelve designers took part, receiving visual feedback in response to their designs. In semi-structured interviews they described their interpretation of the feedback, how it inspired them to change their designs and contrasted it with text feedback. Eleven of the twelve designers revealed that they would be enthusiastic users of a service providing this new mode of feedback."
    },
    {
        "title": "Measuring Crowdsourcing Effort with Error-Time Curves",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Evaluating Crowdsourcing",
        "data": "April 2015",
        "authors": [
            "Justin Cheng",
            "Jaime Teevan",
            "Michael S. Bernstein"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702145",
        "citation": "38",
        "abstract": "Crowdsourcing systems lack effective measures of the effort required to complete each task. Without knowing how much time workers need to execute a task well, requesters struggle to accurately structure and price their work. Objective measures of effort could better help workers identify tasks that are worth their time. We propose a data-driven effort metric, ETA (error-time area), that can be used to determine a task's fair price. It empirically models the relationship between time and error rate by manipulating the time that workers have to complete a task. ETA reports the area under the error-time curve as a continuous metric of worker effort. The curve's 10th percentile is also interpretable as the minimum time most workers require to complete the task without error, which can be used to price the task. We validate the ETA metric on ten common crowdsourcing tasks, including tagging, transcription, and search, and find that ETA closely tracks how workers would rank these tasks by effort. We also demonstrate how ETA allows requesters to rapidly iterate on task designs and measure whether the changes improve worker efficiency. Our findings can facilitate the process of designing, pricing, and allocating crowdsourcing tasks."
    },
    {
        "title": "The Effects of Sequence and Delay on Crowd Work",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Evaluating Crowdsourcing",
        "data": "April 2015",
        "authors": [
            "Walter S. Lasecki",
            "Jeffrey M. Rzeszotarski",
            "Adam Marcus",
            "Jeffrey P. Bigham"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702594",
        "citation": "18",
        "abstract": "A common approach in crowdsourcing is to break large tasks into small microtasks so that they can be parallelized across many crowd workers and so that redundant work can be more easily compared for quality control. In practice, this can result in the microtasks being presented out of their natural order and often introduces delays between individual microtasks. In this paper, we demonstrate in a study of 338 crowd workers that non-sequential microtasks and the introduction of delays significantly decreases worker performance. We show that interruptions where a large delay occurs between two related tasks can cause up to a 102% slowdown in completion time, and interruptions where workers are asked to perform different tasks in sequence can slow down completion time by 57%. We conclude with a set of design guidelines to improve both worker performance and realized pay, and instructions for implementing these changes in existing interfaces for crowd work."
    },
    {
        "title": "Crowd Size, Diversity and Performance",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Evaluating Crowdsourcing",
        "data": "April 2015",
        "authors": [
            "Lionel Robert",
            "Daniel M. Romero"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702469",
        "citation": "28",
        "abstract": "Crowds are increasingly being adopted to solve complex problems. Size and diversity are two key characteristics of crowds; however their relationship to performance is often paradoxical. To better understand the effects of crowd size and diversity on crowd performance we conducted a study on the quality of 4,317 articles in the WikiProject Film community. The results of our study suggest that crowd size leads to better performance when crowds are more diverse. However, there is a break-even point -- smaller, less diverse crowds can outperform more diverse crowds of similar size. Our results offer new insights into the effects of size and diversity on the performance of crowds."
    },
    {
        "title": "Session details: Smart Smartphone Authentication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smart Smartphone Authentication",
        "data": "April 2015",
        "authors": [
            "Andrea Bianchi"
        ],
        "DOI": "https://doi.org/10.1145/3251709",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "I Know What You Did Last Week! Do You?: Dynamic Security Questions for Fallback Authentication on Smartphones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smart Smartphone Authentication",
        "data": "April 2015",
        "authors": [
            "Alina Hang",
            "Alexander De Luca",
            "Heinrich Hussmann"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702131",
        "citation": "21",
        "abstract": "In this paper, we present the design and evaluation of dynamic security questions for fallback authentication. In case users lose access to their device, the system asks questions about their usage behavior (e.g. calls, text messages or app usage). We performed two consecutive user studies with real users and real adversaries to identify questions that work well in the sense that they are easy to answer for the genuine user, but hard to guess for an adversary. The results show that app installations and communication are the most promising categories of questions. Using three questions from the evaluated categories was sufficient to get an accuracy of 95.5% - 100%."
    },
    {
        "title": "Improving Accuracy, Applicability and Usability of Keystroke Biometrics on Mobile Touchscreen Devices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smart Smartphone Authentication",
        "data": "April 2015",
        "authors": [
            "Daniel Buschek",
            "Alexander De Luca",
            "Florian Alt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702252",
        "citation": "91",
        "abstract": "Authentication methods can be improved by considering implicit, individual behavioural cues. In particular, verifying users based on typing behaviour has been widely studied with physical keyboards. On mobile touchscreens, the same concepts have been applied with little adaptations so far. This paper presents the first reported study on mobile keystroke biometrics which compares touch-specific features between three different hand postures and evaluation schemes. Based on 20.160 password entries from a study with 28 participants over two weeks, we show that including spatial touch features reduces implicit authentication equal error rates (EER) by 26.4 - 36.8% relative to the previously used temporal features. We also show that authentication works better for some hand postures than others. To improve applicability and usability, we further quantify the influence of common evaluation assumptions: known attacker data, training and testing on data from a single typing session, and fixed hand postures. We show that these practices can lead to overly optimistic evaluations. In consequence, we describe evaluation recommendations, a probabilistic framework to handle unknown hand postures, and ideas for further improvements."
    },
    {
        "title": "SwiPIN: Fast and Secure PIN-Entry on Smartphones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smart Smartphone Authentication",
        "data": "April 2015",
        "authors": [
            "Emanuel von Zezschwitz",
            "Alexander De Luca",
            "Bruno Brunkow",
            "Heinrich Hussmann"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702212",
        "citation": "88",
        "abstract": "In this paper, we present SwiPIN, a novel authentication system that allows input of traditional PINs using simple touch gestures like up or down and makes it secure against human observers. We present two user studies which evaluated different designs of SwiPIN and compared it against traditional PIN. The results show that SwiPIN performs adequately fast (3.7 s) to serve as an alternative input method for risky situations. Furthermore, SwiPIN is easy to use, significantly more secure against shoulder surfing attacks and switching between PIN and SwiPIN feels natural."
    },
    {
        "title": "Glass Unlock: Enhancing Security of Smartphone Unlocking through Leveraging a Private Near-eye Display",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smart Smartphone Authentication",
        "data": "April 2015",
        "authors": [
            "Christian Winkler",
            "Jan Gugenheimer",
            "Alexander De Luca",
            "Gabriel Haas",
            "Philipp Speidel",
            "David Dobbelstein",
            "Enrico Rukzio"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702316",
        "citation": "30",
        "abstract": "This paper presents Glass Unlock, a novel concept using smart glasses for smartphone unlocking, which is theoretically secure against smudge attacks, shoulder-surfing, and camera attacks. By introducing an additional temporary secret like the layout of digits that is only shown on the private near-eye display, attackers cannot make sense of the observed input on the almost empty phone screen. We report a user study with three alternative input methods and compare them to current state-of-the-art systems. Our findings show that Glass Unlock only moderately increases authentication times and that users favor the input method yielding the slowest input times as it avoids focus switches between displays."
    },
    {
        "title": "I Feel Like I'm Taking Selfies All Day!: Towards Understanding Biometric Authentication on Smartphones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smart Smartphone Authentication",
        "data": "April 2015",
        "authors": [
            "Alexander De Luca",
            "Alina Hang",
            "Emanuel von Zezschwitz",
            "Heinrich Hussmann"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702141",
        "citation": "57",
        "abstract": "We present the results of an MTurk survey (n=383) on the reasons for using and not using biometric authentication systems on smartphones. We focused on Apple's Touch ID as well as Android's Face Unlock as they are the most prevalent systems on the market. For both systems, we categorized the participants as a) current users, b) former users that deactivated it at some point and c) nonusers. The results show that usability is one of the main factors that influences the decision on whether or not to use biometric verification on the smartphone. To our surprise and as opposed to previous research on biometric authentication, privacy and trust issues were not among the most important decision factors."
    },
    {
        "title": "Interrupt Now or Inform Later?: Comparing Immediate and Delayed Privacy Feedback",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Smart Smartphone Authentication",
        "data": "April 2015",
        "authors": [
            "Sameer Patil",
            "Roberto Hoyle",
            "Roman Schlegel",
            "Apu Kapadia",
            "Adam J. Lee"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702165",
        "citation": "26",
        "abstract": "Feedback about privacy-affecting system operations is important for informed end-user privacy management. While feedback is most relevant if provided immediately, such delivery interrupts the user and risks disrupting ongoing tasks. The timing, volume, and nature of feedback is therefore critical for avoiding inopportune interruption. We varied the timing and actionability of feedback regarding accesses to a user's physical location. We found that the sense of privacy violation was heightened when feedback was immediate, but not actionable. While immediate and actionable feedback may sometimes be necessary, our findings suggest that moderately delayed feedback is often acceptable. A moderate delay may serve as a compromise to minimize interruption and avoid overly alarming reaction to immediate feedback. However, immediate and actionable feedback could still be beneficial when privacy sensitivity is high or ambiguous."
    },
    {
        "title": "Session details: Healthcare Bias, Engagement & Adaptation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Healthcare Bias, Engagement & Adaptation",
        "data": "April 2015",
        "authors": [
            "Tae-Jung Yun"
        ],
        "DOI": "https://doi.org/10.1145/3251710",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "From Care Plans to Care Coordination: Opportunities for Computer Support of Teamwork in Complex Healthcare",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Healthcare Bias, Engagement & Adaptation",
        "data": "April 2015",
        "authors": [
            "Ofra Amir",
            "Barbara J. Grosz",
            "Krzysztof Z. Gajos",
            "Sonja M. Swenson",
            "Lee M. Sanders"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702320",
        "citation": "30",
        "abstract": "Children with complex health conditions require care from a large, diverse team of caregivers that includes multiple types of medical professionals, parents and community support organizations. Coordination of their outpatient care, essential for good outcomes, presents major challenges. Extensive healthcare research has shown that the use of integrated, team-based care plans improves care coordination, but such plans are rarely deployed in practice. This paper reports on a study of care teams treating children with complex conditions at a major university tertiary care center. This study investigated barriers to plan implementation and resultant care coordination problems. It revealed the complex nature of teamwork in complex care, which poses challenges to team coordination that extend beyond those identified in prior work and handled by existing coordination systems. The paper builds on a computational teamwork theory to identify opportunities for technology to support increased plan-based complex-care coordination and to propose design approaches for systems that enable and enhance such coordination."
    },
    {
        "title": "Engaging Pregnant Women in Kenya with a Hybrid Computer-Human SMS Communication System",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Healthcare Bias, Engagement & Adaptation",
        "data": "April 2015",
        "authors": [
            "Trevor Perrier",
            "Nicola Dell",
            "Brian DeRenzi",
            "Richard Anderson",
            "John Kinuthia",
            "Jennifer Unger",
            "Grace John-Stewart"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702124",
        "citation": "77",
        "abstract": "A growing body of HCI4D research studies the use of SMS communication to deliver health and information services to underserved populations. This paper contributes a novel dimension to this field of study by examining if a hybrid computer-human SMS system can engage pregnant women in Kenya in health-related communication. Our approach leverages the different strengths of both the computer and the human. The computer automates the bulk-sending of personalized messages to patients, allowing the human to read patients' replies and respond to those in need of attention. Findings from a 12-month deployment with 100 women show that our approach is capable of engaging the majority of participants in health-related conversations. We show that receiving messages from the system triggers participant communication and the amount of communication increases as participants approach their expected due date. In addition, analysis of participants' messages shows that they often contain sensitive health information conveyed through a complex mixture of languages and 'txting' abbreviations, all of which highlight the benefits of including a human in the workflow. Our findings are relevant for HCI researchers and practitioners interested in understanding or engaging underserved populations."
    },
    {
        "title": "It Is All About Perspective: An Exploration of Mitigating Selective Exposure with Aspect Indicators",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Healthcare Bias, Engagement & Adaptation",
        "data": "April 2015",
        "authors": [
            "Q. Vera Liao",
            "Wai-Tat Fu",
            "Sri Shilpa Mamidi"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702570",
        "citation": "16",
        "abstract": "Selective exposure, the preferential seeking of confirmatory information, can potentially exacerbate fragmentation of online opinions and lead to biased decisions. We tested whether features that allowed users to better distinguish information about different issue aspects would encourage them to take different perspectives, thereby moderating the negative influence of pre-existing beliefs on information seeking. Using an information aggregator that provided drug related comments, we conducted an experiment to study the impact of aspect indicators (indicating whether the comment was about effectiveness or side effects) on moderating selective exposure. We found that, when participants were asked to decide between medications for high-risk diseases, and had preexisting biased beliefs in their effectiveness (one medication was less effective than the other), without aspect indicators they exhibited selective exposure to both types of comments (effectiveness and side effects) and were biased to choose the medication in confirmation of their pre-existing beliefs. With aspect indicators, we found reduced selective exposure to information about side effects of the medications, and as a result their overall decision bias was mitigated. However, the effect of aspect indicators in reducing selective exposure was moderated by the decision contexts, including the perceived risk of the diseases and whether the aspect was perceived to be critical to the decision."
    },
    {
        "title": "Session details: Storytelling in InfoVis",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Storytelling in InfoVis",
        "data": "April 2015",
        "authors": [
            "Charles Perin"
        ],
        "DOI": "https://doi.org/10.1145/3251711",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Storytelling in Information Visualizations: Does it Engage Users to Explore Data?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Storytelling in InfoVis",
        "data": "April 2015",
        "authors": [
            "Jeremy Boy",
            "Francoise Detienne",
            "Jean-Daniel Fekete"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702452",
        "citation": "76",
        "abstract": "We present the results of three web-based field experiments, in which we evaluate the impact of using initial narrative visualization techniques and storytelling on user-engagement with exploratory information visualizations. We conducted these experiments on a popular news and opinion outlet, and on a popular visualization gallery website. While data-journalism exposes visualizations to a large public, we do not know how effectively this public makes sense of interactive graphics, and in particular if people explore them to gain additional insight to that provided by the journalists. In contrast to our hypotheses, our results indicate that augmenting exploratory visualizations with introductory 'stories' does not seem to increase user-engagement in exploration."
    },
    {
        "title": "Understanding Data Videos: Looking at Narrative Visualization through the Cinematography Lens",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Storytelling in InfoVis",
        "data": "April 2015",
        "authors": [
            "Fereshteh Amini",
            "Nathalie Henry Riche",
            "Bongshin Lee",
            "Christophe Hurter",
            "Pourang Irani"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702431",
        "citation": "91",
        "abstract": "Data videos, motion graphics that incorporate visualizations about facts, are increasingly gaining popularity as a means of telling stories with data. However, very little is systematically recorded about (a) what elements are featured in data videos and (b) the processes used to create them. In this article, we provide initial insights to build this knowledge. We first report on a qualitative analysis of 50 professionally designed data videos, extracting and exposing their most salient constituents. Second, we report on a series of workshops with experienced storytellers from cinematography, graphics design and screenplay writing. We provided them with a set of data facts and visualizations and observed them create storyboards for data videos. From these exploratory studies, we derive broader implications for the design of an authoring tool to enable a wide audience to create data videos. Our findings highlight the importance of providing a flexible tool supporting a non-linear creation process and allowing users to iteratively go back to different phases of the process."
    },
    {
        "title": "How Deceptive are Deceptive Visualizations?: An Empirical Analysis of Common Distortion Techniques",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Storytelling in InfoVis",
        "data": "April 2015",
        "authors": [
            "Anshul Vikram Pandey",
            "Katharina Rall",
            "Margaret L. Satterthwaite",
            "Oded Nov",
            "Enrico Bertini"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702608",
        "citation": "70",
        "abstract": "In this paper, we present an empirical analysis of deceptive visualizations. We start with an in-depth analysis of what deception means in the context of data visualization, and categorize deceptive visualizations based on the type of deception they lead to. We identify popular distortion techniques and the type of visualizations those distortions can be applied to, and formalize why deception occurs with those distortions. We create four deceptive visualizations using the selected distortion techniques, and run a crowdsourced user study to identify the deceptiveness of those visualizations. We then present the findings of our study and show how deceptive each of these visual distortion techniques are, and for what kind of questions the misinterpretation occurs. We also analyze individual differences among participants and present the effect of some of those variables on participants' responses. This paper presents a first step in empirically studying deceptive visualizations, and will pave the way for more research in this direction."
    },
    {
        "title": "STRATOS: Using Visualization to Support Decisions in Strategic Software Release Planning",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Storytelling in InfoVis",
        "data": "April 2015",
        "authors": [
            "Bon Adriel Aseniero",
            "Tiffany Wun",
            "David Ledo",
            "Guenther Ruhe",
            "Anthony Tang",
            "Sheelagh Carpendale"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702426",
        "citation": "15",
        "abstract": "Software is typically developed incrementally and released in stages. Planning these releases involves deciding which features of the system should be implemented for each release. This is a complex planning process involving numerous trade-offs-constraints and factors that often make decisions difficult. Since the success of a product depends on this plan, it is important to understand the trade-offs between different release plans in order to make an informed choice. We present STRATOS, a tool that simultaneously visualizes several software release plans. The visualization shows several attributes about each plan that are important to planners. Multiple plans are shown in a single layout to help planners find and understand the trade-offs between alternative plans. We evaluated our tool via a qualitative study and found that STRATOS enables a range of decision-making processes, helping participants decide on which plan is most optimal."
    },
    {
        "title": "Session details: Grip, Move & Tilt: Novel Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Grip, Move & Tilt: Novel Interaction",
        "data": "April 2015",
        "authors": [
            "Jessica Cauchard"
        ],
        "DOI": "https://doi.org/10.1145/3251712",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Supporting Subtlety with Deceptive Devices and Illusory Interactions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Grip, Move & Tilt: Novel Interaction",
        "data": "April 2015",
        "authors": [
            "Fraser Anderson",
            "Tovi Grossman",
            "Daniel Wigdor",
            "George Fitzmaurice"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702336",
        "citation": "34",
        "abstract": "Mobile devices offer constant connectivity to the world, which can negatively affect in-person interaction. Current approaches to minimizing the social disruption and improving the subtlety of interactions tend to focus on the development of inconspicuous devices that provide basic input or output. This paper presents a more general approach to subtle interaction and demonstrates how a number of principles from magic can be leveraged to improve subtlety. It also presents a framework that can be used to classify subtle interfaces along with a modular set of novel interfaces that fit within this framework. Lastly, the paper presents a new evaluation paradigm specifically designed to assess the subtlety of interactions. This paradigm is used to compare traditional approaches to our new subtle approaches. We find our new approaches are over five times more subtle than traditional interactions, even when participants are aware of the technologies being used."
    },
    {
        "title": "Understanding Users' Touch Behavior on Large Mobile Touch-Screens and Assisted Targeting by Tilting Gesture",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Grip, Move & Tilt: Novel Interaction",
        "data": "April 2015",
        "authors": [
            "Youli Chang",
            "Sehi L'Yi",
            "Kyle Koh",
            "Jinwook Seo"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702425",
        "citation": "34",
        "abstract": "As large-screen smartphones are trending, they bring a new set of challenges such as acquiring unreachable screen targets using one hand. To understand users' touch behavior on large mobile touchscreens, we conducted an empirical experiment to discover their usage patterns of tilting devices toward their thumbs to touch screen regions. Exploiting this natural tilting behavior, we designed three novel mobile interaction techniques: TiltSlide, TiltReduction, and TiltCursor. We conducted a controlled experiment to compare our methods with other existing methods, and then evaluated them in real mobile phone scenarios such as sending an e-mail and web surfing. We constructed a design space for one-hand targeting interactions and proposed design considerations for one-hand targeting in real mobile phone circumstances."
    },
    {
        "title": "One-Handed Bend Interactions with Deformable Smartphones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Grip, Move & Tilt: Novel Interaction",
        "data": "April 2015",
        "authors": [
            "Audrey Girouard",
            "Jessica Lo",
            "Md Riyadh",
            "Farshad Daliri",
            "Alexander Keith Eady",
            "Jerome Pasquero"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702513",
        "citation": "27",
        "abstract": "Smartphones are becoming larger, mainly because bigger screens offer a better experience for viewing content. One drawback of larger screens is that they make single-hand interactions difficult because of hard to reach touch targets and of the need to re-grip the device, both factors significantly reducing their usability. Flexible smartphones offer an opportunity for addressing this issue. We first set out to determine the use of common single-hand mobile interactions through an online survey. Then, we designed and evaluated one-handed deformable gestures that offer the potential for addressing the finger reach limitation on large smartphones. We identified that the top right up bend and the center squeeze up gestures are the fastest and preferred gestures. We found no hand preference, which indicates that the gestures could be implemented to fit the needs of a wider range of the population, instead of favoring right-handed users. Finally, we discuss the impact on deformable gestures on one-handed interactions issues."
    },
    {
        "title": "Grip Change as an Information Side Channel for Mobile Touch Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Grip, Move & Tilt: Novel Interaction",
        "data": "April 2015",
        "authors": [
            "Matei Negulescu",
            "Joanna McGrenere"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702185",
        "citation": "22",
        "abstract": "In order to reach targets with one hand on common large mobile touch displays, users tilt and shift the device in their hand. In this work, we use this grip change as a continuous information stream for detecting where the user will touch while their finger is still en-route. We refer to this as in the air prediction. We show that grip change detected using standard mobile motion sensors produces similar in the air touch point predictions to techniques that use auxiliary sensor arrays, even in varying physical scenarios such as interacting in a moving vehicle. Finally, our model that combines grip change and the resulting touch point predicted where users intended to land, lowering error rates by 41%."
    },
    {
        "title": "An Experimental Comparison of Vertical and Horizontal Dynamic Peephole Navigation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Grip, Move & Tilt: Novel Interaction",
        "data": "April 2015",
        "authors": [
            "Jens Müller",
            "Roman Rädle",
            "Hans-Christian Jetter",
            "Harald Reiterer"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702227",
        "citation": "10",
        "abstract": "Dynamic peephole navigation represents a technique for navigating large information spaces in an egocentric way. Studies have shown cognitive benefits for a vertical peephole orientation, when compared to non-egocentric interaction styles. To see how the aspect of canvas orientation effects user performance, we conducted a study (N=16) which revealed that canvas orientation has no significant effect on either navigation performance or spatial memory. We also found a significantly lower physical demand and a higher mental demand in the horizontal orientation. For short-term activities we therefore propose a vertical orientation, while for long-term activities horizontal dynamic peephole navigation is more suitable."
    },
    {
        "title": "Session details: Interactive Video & Collaborative Annotations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive Video & Collaborative Annotations",
        "data": "April 2015",
        "authors": [
            "Amy Ogan"
        ],
        "DOI": "https://doi.org/10.1145/3251713",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "RIMES: Embedding Interactive Multimedia Exercises in Lecture Videos",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive Video & Collaborative Annotations",
        "data": "April 2015",
        "authors": [
            "Juho Kim",
            "Elena L. Glassman",
            "Andrés Monroy-Hernández",
            "Meredith Ringel Morris"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702186",
        "citation": "36",
        "abstract": "Teachers in conventional classrooms often ask learners to express themselves and show their thought processes by speaking out loud, drawing on a whiteboard, or even using physical objects. Despite the pedagogical value of such activities, interactive exercises available in most online learning platforms are constrained to multiple-choice and short answer questions. We introduce RIMES, a system for easily authoring, recording, and reviewing interactive multimedia exercises embedded in lecture videos. With RIMES, teachers can prompt learners to record their responses to an activity using video, audio, and inking while watching lecture videos. Teachers can then review and interact with all the learners' responses in an aggregated gallery. We evaluated RIMES with 19 teachers and 25 students. Teachers created a diverse set of activities across multiple subjects that tested deep conceptual and procedural knowledge. Teachers found the exercises useful for capturing students' thought processes, identifying misconceptions, and engaging students with content."
    },
    {
        "title": "A Framework for Automatically Generating Interactive Instructional Scaffolding",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive Video & Collaborative Annotations",
        "data": "April 2015",
        "authors": [
            "Eleanor O'Rourke",
            "Erik Andersen",
            "Sumit Gulwani",
            "Zoran Popović"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702580",
        "citation": "11",
        "abstract": "Interactive learning environments such as intelligent tutoring systems and software tutorials often teach procedures with step-by-step demonstrations. This instructional scaffolding is typically authored by hand, and little can be reused across problem domains. In this work, we present a framework for generating interactive tutorials from an algorithmic representation of the problem-solving thought process. Given a set of mappings between programming language constructs and user interface elements, we step through this algorithm line-by-line to trigger visual explanations of each step. This approach allows us to automatically generate tutorials for any example problem that can be solved with this algorithm. We describe two prototype implementations in the domains of K-12 mathematics and educational games, and present results from two user studies showing that educational technologists can author thought-process procedures and that generated tutorials can effectively teach a new procedure to students."
    },
    {
        "title": "Mudslide: A Spatially Anchored Census of Student Confusion for Online Lecture Videos",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive Video & Collaborative Annotations",
        "data": "April 2015",
        "authors": [
            "Elena L. Glassman",
            "Juho Kim",
            "Andrés Monroy-Hernández",
            "Meredith Ringel Morris"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702304",
        "citation": "35",
        "abstract": "Educators have developed an effective technique to get feedback after in-person lectures, called \"muddy cards.\" Students are given time to reflect and write the \"muddiest\" (least clear) point on an index card, to hand in as they leave class. This practice of assigning end-of-lecture reflection tasks to generate explicit student feedback is well suited for adaptation to the challenge of supporting feedback in online video lectures. We describe the design and evaluation of Mudslide, a prototype system that translates the practice of muddy cards into the realm of online lecture videos. Based on an in-lab study of students and teachers, we find that spatially contextualizing students' muddy point feedback with respect to particular lecture slides is advantageous to both students and teachers. We also reflect on further opportunities for enhancing this feedback method based on teachers' and students' experiences with our prototype."
    },
    {
        "title": "Making Software Tutorial Video Responsive",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive Video & Collaborative Annotations",
        "data": "April 2015",
        "authors": [
            "Cuong Nguyen",
            "Feng Liu"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702209",
        "citation": "19",
        "abstract": "Tutorial videos are widely available to help people use software. These videos, however, are viewed by users as captured and offer little direct interaction between users and software. This paper presents a video navigation method that allows users to interact with software tutorial video as if they were using the software. To make the tutorial video responsive, our method records the user interaction events like mouse click and drag during capturing the video. Our method then analyzes, selects, and visualizes these user interaction events at the event locations. When a user directly interacts with an event visualization, our method automatically navigates to the proper video frame to provide the visual feedback as if the software were responding to the user input. Thus, our method provides the experience of interacting with the software through directly manipulating the tutorial video. Our study shows our method can better help users follow tutorial videos to complete tasks than the baseline timeline interface."
    },
    {
        "title": "Gaze-Based Annotations for Reading Comprehension",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive Video & Collaborative Annotations",
        "data": "April 2015",
        "authors": [
            "Shiwei Cheng",
            "Zhiqiang Sun",
            "Lingyun Sun",
            "Kirsten Yee",
            "Anind K. Dey"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702271",
        "citation": "23",
        "abstract": "We study eye gaze movement behavior during paper reading and generate a series of annotations from a user's reading features: gray shading to indicate reading speed, borders to indicate frequency of re-reading, and lines to indicate transitions between sections of a document. Through a user study, we validate that our SocialReading system that shares teachers' gaze data for an academic paper can improve students' reading comprehension of that paper."
    },
    {
        "title": "Session details: HCI for the Elderly",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for the Elderly",
        "data": "April 2015",
        "authors": [
            "Maria Wolters"
        ],
        "DOI": "https://doi.org/10.1145/3251714",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Long-Term Use of Motion-Based Video Games in Care Home Settings",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for the Elderly",
        "data": "April 2015",
        "authors": [
            "Kathrin M. Gerling",
            "Regan L. Mandryk",
            "Conor Linehan"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702125",
        "citation": "39",
        "abstract": "Recent research suggests that motion-based video games have the potential to provide both mental and physical stimulation for older adults in residential care. However, little research has explored the practical challenges and opportunities that arise from integrating these games within existing schedules of activities in these contexts. In our work, we report on a qualitative enquiry that was conducted over a three month period at two long-term care facilities. Findings suggest that older adults enjoyed playing video games, and that games can be a valuable means of re-introducing challenge in late life, but that the impact of age-related changes and impairment can influence people's ability to engage with games in a group setting. We outline core challenges in the design for care context and discuss implications of our work regarding the suitability of games as a self-directed leisure activity."
    },
    {
        "title": "CoFaçade: A Customizable Assistive Approach for Elders and Their Helpers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for the Elderly",
        "data": "April 2015",
        "authors": [
            "Jason Chen Zhao",
            "Richard C. Davis",
            "Pin Sym Foong",
            "Shengdong Zhao"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702588",
        "citation": "5",
        "abstract": "We present CoFaçade, a novel approach to helping elders reach their goals with IT products by working collaboratively with helpers. In this approach, the elder uses an interface with a small number of triggers, where each trigger is a single button (or card) that can execute a procedure. The helper uses a customization interface to link triggers to procedures that accomplish frequently-recurring high-level goals with IT products. Customization can be done either locally or remotely. We conducted an experiment to compare the CoFaçade approach with a baseline approach where helpers taught elders to perform IT tasks. Our results showed that CoFaçade can reduce helpers' time and effort, reduce elders' frustration, and improve elders' success rate in completing IT tasks."
    },
    {
        "title": "\"My Hand Doesn't Listen to Me!\": Adoption and Evaluation of a Communication Technology for the 'Oldest Old'",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for the Elderly",
        "data": "April 2015",
        "authors": [
            "Barbara Barbosa Neves",
            "Rachel L. Franz",
            "Cosmin Munteanu",
            "Ronald Baecker",
            "Mags Ngo"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702430",
        "citation": "80",
        "abstract": "Adoption and use of novel technology by the institutionalized 'oldest old' (80+) is understudied. This population is the fastest growing demographic group in developed countries, providing design opportunities and challenges for HCI. Since the recruitment of oldest old people is challenging, research tends to focus on older adults (65+) and their use of and attitudes towards existing communication technologies, or on their caregivers and social ties. Our study deployed a novel communication appliance among five frail oldest old people living in a long-term care facility, which included field observations and usability and accessibility tests. Our findings suggest factors that facilitate and hinder the adoption of communication technologies, such as social, attitudinal, digital literacy, physical, and usability. We also discuss issues that arise in studying technology adoption by the oldest old, including usability and accessibility testing, and suggest solutions that may be helpful to HCI researchers working with this population."
    },
    {
        "title": "Session details: The Impact of Crowd Work on Workers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Impact of Crowd Work on Workers",
        "data": "April 2015",
        "authors": [
            "Jaime Teevan"
        ],
        "DOI": "https://doi.org/10.1145/3251715",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Working with Machines: The Impact of Algorithmic and Data-Driven Management on Human Workers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Impact of Crowd Work on Workers",
        "data": "April 2015",
        "authors": [
            "Min Kyung Lee",
            "Daniel Kusbit",
            "Evan Metsky",
            "Laura Dabbish"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702548",
        "citation": "352",
        "abstract": "Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed."
    },
    {
        "title": "TurkBench: Rendering the Market for Turkers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Impact of Crowd Work on Workers",
        "data": "April 2015",
        "authors": [
            "Benjamin V. Hanrahan",
            "Jutta K. Willamowski",
            "Saiganesh Swaminathan",
            "David B. Martin"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702279",
        "citation": "18",
        "abstract": "Crowdsourcing is a relatively new model of labor where both the workers and work providers are experiencing its growing pains. A dominant platform that implements this model of labor is Amazon Mechanical Turk (AMT). While AMT has evolved over the years, the changes have focused mainly on work providers and have not addressed the problems workers face (e.g. dealing with market volatility and unpaid time searching for work). In this paper we present emph{TurkBench}, a tool meant to provide workers with personalized market visualization and session management. We discuss the design philosophy of the tool, briefly discuss four Turkers' reaction to a demo, and outline future work."
    },
    {
        "title": "Exploring the Role of Activity Trace Design on Evaluations of Online Worker Quality",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Impact of Crowd Work on Workers",
        "data": "April 2015",
        "authors": [
            "Jennifer Marlow",
            "Laura A. Dabbish",
            "Jodi L. Forlizzi"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702195",
        "citation": "1",
        "abstract": "Websites can record individual users' activities and display them in a variety of ways. There is a tradeoff between detail and abstraction in visualization, especially when the amount of content increases and becomes more difficult to process. We conducted an experiment on Mechanical Turk varying the quality, detail, and visual presentation of information about an individual's past work to see how these design features affected perceptions of the worker. We found that providing detail in the display through text increased processing time and led to less positive evaluations. Visually abstract displays required less processing time but decreased confidence in evaluation. This suggests that different design parameters may engender differing psychological processes that influence reactions towards an unknown person."
    },
    {
        "title": "We Are Dynamo: Overcoming Stalling and Friction in Collective Action for Crowd Workers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Impact of Crowd Work on Workers",
        "data": "April 2015",
        "authors": [
            "Niloufar Salehi",
            "Lilly C. Irani",
            "Michael S. Bernstein",
            "Ali Alkhatib",
            "Eva Ogbe",
            "Kristy Milland",
            "Clickhappier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702508",
        "citation": "174",
        "abstract": "By lowering the costs of communication, the web promises to enable distributed collectives to act around shared issues. However, many collective action efforts never succeed: while the web's affordances make it easy to gather, these same decentralizing characteristics impede any focus towards action. In this paper, we study challenges to collective action efforts through the lens of online labor by engaging with Amazon Mechanical Turk workers. Through a year of ethnographic fieldwork, we sought to understand online workers' unique barriers to collective action. We then created Dynamo, a platform to support the Mechanical Turk community in forming publics around issues and then mobilizing. We found that collective action publics tread a precariously narrow path between the twin perils of stalling and friction, balancing with each step between losing momentum and flaring into acrimony. However, specially structured labor to maintain efforts' forward motion can help such publics take action."
    },
    {
        "title": "Understanding Malicious Behavior in Crowdsourcing Platforms: The Case of Online Surveys",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: The Impact of Crowd Work on Workers",
        "data": "April 2015",
        "authors": [
            "Ujwal Gadiraju",
            "Ricardo Kawase",
            "Stefan Dietze",
            "Gianluca Demartini"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702443",
        "citation": "153",
        "abstract": "Crowdsourcing is increasingly being used as a means to tackle problems requiring human intelligence. With the ever-growing worker base that aims to complete microtasks on crowdsourcing platforms in exchange for financial gains, there is a need for stringent mechanisms to prevent exploitation of deployed tasks. Quality control mechanisms need to accommodate a diverse pool of workers, exhibiting a wide range of behavior. A pivotal step towards fraud-proof task design is understanding the behavioral patterns of microtask workers. In this paper, we analyze the prevalent malicious activity on crowdsourcing platforms and study the behavior exhibited by trustworthy and untrustworthy workers, particularly on crowdsourced surveys. Based on our analysis of the typical malicious activity, we define and identify different types of workers in the crowd, propose a method to measure malicious activity, and finally present guidelines for the efficient design of crowdsourced surveys."
    },
    {
        "title": "Session details: Social Media and Mobile Camera Privacy",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media and Mobile Camera Privacy",
        "data": "April 2015",
        "authors": [
            "Pam Briggs"
        ],
        "DOI": "https://doi.org/10.1145/3251716",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "\"I Saw Images I Didn't Even Know I Had\": Understanding User Perceptions of Cloud Storage Privacy",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media and Mobile Camera Privacy",
        "data": "April 2015",
        "authors": [
            "Jason W. Clark",
            "Peter Snyder",
            "Damon McCoy",
            "Chris Kanich"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702535",
        "citation": "34",
        "abstract": "Billions of people use cloud-based storage for personal files. While many are likely aware of the extent to which they store information in the cloud, it is unclear whether users are fully aware of what they are storing online. We recruited 30 research subjects from Craigslist to investigate how users interact with and understand the privacy issues of cloud storage. We studied this phenomenon through surveys, an interview, and custom software which lets users see and delete their photos stored in the cloud. We found that a majority of users stored private photos in the cloud that they did not intend to upload, and a large portion also chose to permanently delete some of the offending images. We believe our study highlights a mismatch between user expectation and reality. As cloud storage is plentiful and ubiquitous, effective tools for enabling risk self-assessment are necessary to protect users' privacy."
    },
    {
        "title": "Sensitive Lifelogs: A Privacy Analysis of Photos from Wearable Cameras",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media and Mobile Camera Privacy",
        "data": "April 2015",
        "authors": [
            "Roberto Hoyle",
            "Robert Templeman",
            "Denise Anthony",
            "David Crandall",
            "Apu Kapadia"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702183",
        "citation": "55",
        "abstract": "While media reports about wearable cameras have focused on the privacy concerns of bystanders, the perspectives of the `lifeloggers' themselves have not been adequately studied. We report on additional analysis of our previous in-situ lifelogging study in which 36 participants wore a camera for a week and then reviewed the images to specify privacy and sharing preferences. In this Note, we analyze the photos themselves, seeking to understand what makes a photo private, what participants said about their images, and what we can learn about privacy in this new and very different context where photos are captured automatically by one's wearable camera. We find that these devices record many moments that may not be captured by traditional (deliberate) photography, with camera owners concerned about impression management and protecting private information of both themselves and bystanders."
    },
    {
        "title": "Somebody's Watching Me?: Assessing the Effectiveness of Webcam Indicator Lights",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media and Mobile Camera Privacy",
        "data": "April 2015",
        "authors": [
            "Rebecca S. Portnoff",
            "Linda N. Lee",
            "Serge Egelman",
            "Pratyush Mishra",
            "Derek Leung",
            "David Wagner"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702164",
        "citation": "43",
        "abstract": "Most laptops and personal computers have webcams with LED indicators to notify users when they are recording. Because hackers use surreptitiously captured webcam recordings to extort users, we explored the effectiveness of these indicators under varying circumstances and how they could be improved. We observed that, on average, fewer than half of our participants (45%) noticed the existing indicator during computer-based tasks. When seated in front of the computer performing a paper-based task, only 5% noticed the indicator. We performed a followup experiment to evaluate a new indicator and observed that adding onscreen glyphs had a significant impact on both computer-based and non-computer-based tasks (93% and 59% noticed the new indicator, respectively). We discuss how our results can be integrated into current systems, as well as future ubiquitous computing systems."
    },
    {
        "title": "From Third to Surveilled Place: The Mobile in Irish Pubs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media and Mobile Camera Privacy",
        "data": "April 2015",
        "authors": [
            "Norman Makoto Su",
            "Lulu Wang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702574",
        "citation": "17",
        "abstract": "A home away from home, the pub is synonymous with good conversation. Yet, the art of conversation in pubs is changing with the ubiquity of mobile phones. We present a qualitative study spanning over three years describing experiences and rhetoric surrounding the relationship that mobiles have and should have with our conversation in the pub. We found that mobile phones are able to enhance conversation but can also cause a disruption to the informal and adhoc nature of pubs. The use of Facebook on mobile phones has also changed pubs from what Oldenburg terms a third space to a space that is potentially being surveilled. We suggest future designs should not necessarily discourage or encourage mobile use in pubs, but rather provoke us into reflecting on how intertwined modern conversation is with mobile technology in the context of the pub space."
    },
    {
        "title": "Is This Thing On?: Crowdsourcing Privacy Indicators for Ubiquitous Sensing Platforms",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media and Mobile Camera Privacy",
        "data": "April 2015",
        "authors": [
            "Serge Egelman",
            "Raghudeep Kannavara",
            "Richard Chow"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702251",
        "citation": "27",
        "abstract": "We are approaching an environment where ubiquitous computing devices will constantly accept input via audio and video channels: kiosks that determine demographic information of passersby, gesture controlled home entertainment systems and audio controlled wearable devices are just a few examples. To enforce the principle of least privilege, recent proposals have suggested technical approaches to limit third-party applications to receiving only the data they need, rather than entire audio or video streams. For users to make informed privacy decisions, applications will still need to communicate what data they are accessing and indicators will be needed to communicate this information. We performed several crowdsourcing experiments to examine how potential users might conceptualize and understand privacy indicators on ubiquitous sensing platforms."
    },
    {
        "title": "Session details: DIY Healthcare: Apps & Wearables",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: DIY Healthcare: Apps & Wearables",
        "data": "April 2015",
        "authors": [
            "David Coyle"
        ],
        "DOI": "https://doi.org/10.1145/3251717",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Blood Pressure Beyond the Clinic: Rethinking a Health Metric for Everyone",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: DIY Healthcare: Apps & Wearables",
        "data": "April 2015",
        "authors": [
            "Logan Kendall",
            "Dan Morris",
            "Desney Tan"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702276",
        "citation": "9",
        "abstract": "Blood pressure (BP) is typically captured at irregular intervals, mostly in clinic environments. This approach treats BP as a static snapshot for health classification and largely ignores its value as a continuously fluctuat-ing measure. Recognizing that consumers are increasing-ly capturing health metrics through wearable devices, we explored BP measurement in relation to everyday living through a two-week field study with 34 adults. Based on questionnaires, measurement logs, and interviews, we examined participants' perceptions and attitudes to-wards BP variability and their associations of BP with aspects of their lives. We found that participants modi-fied their use of BP devices in response to BP variabil-ity, made associations with stress, food, and daily rou-tines, and revealed challenges with the design of current BP devices for personal use. We present design recom-mendations for BP use in everyday contexts and de-scribe strategies for re-framing BP capture and reporting."
    },
    {
        "title": "Concealing or Revealing Mobile Medical Devices?: Designing for Onstage and Offstage Presentation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: DIY Healthcare: Apps & Wearables",
        "data": "April 2015",
        "authors": [
            "Aisling Ann O'Kane",
            "Yvonne Rogers",
            "Ann E. Blandford"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702453",
        "citation": "36",
        "abstract": "Adults with Type 1 Diabetes have choices regarding the technology they use to self-manage their chronic condition. They can use glucose meters, insulin pumps, smartphone apps, and other technologies to support their everyday care. However, little is known about how their social lives might influence what they adopt or how they use technologies. A multi-method study was conducted to examine contextual factors that influence their technology use. While individual differences play a large role in everyday use, social factors were also found to influence use. For example, people can hide their devices in uncertain social situations or show them off to achieve a purpose. We frame these social behaviours using Goffman's theatre metaphor of onstage and offstage behaviour, and discuss how this kind of analysis can inform the design of future mobile medical devices for self-management of chronic conditions."
    },
    {
        "title": "Understanding Individual Differences for Tailored Smoking Cessation Apps",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: DIY Healthcare: Apps & Wearables",
        "data": "April 2015",
        "authors": [
            "Jeni Paay",
            "Jesper Kjeldskov",
            "Mikael B. Skov",
            "Lars Lichon",
            "Stephan Rasmussen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702321",
        "citation": "34",
        "abstract": "Finding ways to help people quit smoking is a high priority in health behavior change research. Recent HCI studies involving technologies using specific quitting techniques such as social support and SMS messaging to help people quit have reported some success. Early studies using computer generated print material report significant success of tailored versus non-tailored material, however, there is limited understanding on what aspects of digitally delivered quitting assistance should be tailored and how. To address this, we have conducted an empirical investigation with smokers to identify perceived importance of different types of help when quitting and the potential role of technology in providing such help. We found that people are highly individual in their approach to quitting and the kind of help they regard as relevant to their situation. Our contribution is a collection of empirically derived themes for tailoring smoking cessation apps to individual quitting needs."
    },
    {
        "title": "FeedFinder: A Location-Mapping Mobile Application for Breastfeeding Women",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: DIY Healthcare: Apps & Wearables",
        "data": "April 2015",
        "authors": [
            "Madeline Balaam",
            "Rob Comber",
            "Ed Jenkins",
            "Selina Sutton",
            "Andrew Garbett"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702328",
        "citation": "89",
        "abstract": "Breastfeeding is positively encouraged across many countries as a public health endeavour. The World Health Organisation recommends breastfeeding exclusively for the first six months of an infant's life. However, women can struggle to breastfeed, and to persist with breastfeeding, for a number of reasons from technique to social acceptance. This paper reports on four phases of a design and research project, from sensitising user-engagement and user-centred design, to the development and in-the-wild deployment of a mobile phone application called FeedFinder. FeedFinder has been developed with breastfeeding women to support them in finding, reviewing and sharing public breastfeeding places with other breastfeeding women. We discuss how mobile technologies can be designed to support public health endeavours, and suggest that public health technologies are better aimed at communities and societies rather than individual."
    },
    {
        "title": "Session details: Social Embodied Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Embodied Interaction",
        "data": "April 2015",
        "authors": [
            "Gina Venolia"
        ],
        "DOI": "https://doi.org/10.1145/3251718",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Using an Interactive Avatar's Facial Expressiveness to Increase Persuasiveness and Socialness",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Embodied Interaction",
        "data": "April 2015",
        "authors": [
            "Jennifer Hyde",
            "Elizabeth J. Carter",
            "Sara Kiesler",
            "Jessica K. Hodgins"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702465",
        "citation": "18",
        "abstract": "Research indicates that the facial expressions of animated characters and agents can influence people's perceptions and interactions with these entities. We designed an experiment to examine how an interactive animated avatar's facial expressiveness influences dyadic conversations between adults and the avatar. We animated the avatar in realtime using the tracked facial motion of a confederate. To adjust facial expressiveness, we damped and exaggerated the avatar's facial motion. We found that ratings of the avatar's extroversion were positively related to its expressiveness. However, impressions of the avatar's realism and naturalness worsened with increased expressiveness. We also found that the confederate was more influential when she appeared as the damped or exaggerated avatar. Adjusting the expressiveness of interactive animated avatars may be a simple way to influence people's social judgments and willingness to collaborate with animated avatars. These results have implications for using avatar facial expressiveness to improve the effectiveness of avatars in various contexts. Adjusting the expressiveness of interactive animated avatars may be a simple way to influence people's social judgments and willingness to collaborate with animated avatars."
    },
    {
        "title": "Study on Gaze Direction Perception of Face Image Displayed on Rotatable Flat Display",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Embodied Interaction",
        "data": "April 2015",
        "authors": [
            "Ikkaku Kawaguchi",
            "Hideaki Kuzuoka",
            "Yusuke Suzuki"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702369",
        "citation": "9",
        "abstract": "A long-standing challenge of video-mediated communication systems is to correctly represent remote participant gaze direction in local environments. A telepresence robot with a movable display that shows the face of a remote participant is a promising approach for solving this issue. Researchers generally consider that display orientation is effective for local participants to properly estimate the gaze direction of remote participants. We investigate how subjects estimate gaze direction of a remote participant (\"Looker\") when his/her face is displayed on a rotatable flat display. Our experiment reveals that both the Looker's head-eye rotation in the display and display rotation affect subject estimation, but the effect of the display rotation is relatively small. Furthermore, we reveal that subjects tend to overestimate Looker gaze direction. Based on our results, we propose a design implication for a telepresence robot to reduce overestimation and properly represent the remote participant gaze direction."
    },
    {
        "title": "DynamicDuo: Co-presenting with Virtual Agents",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Embodied Interaction",
        "data": "April 2015",
        "authors": [
            "Ha Trinh",
            "Lazlo Ring",
            "Timothy Bickmore"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702584",
        "citation": "30",
        "abstract": "The quality of most professional oral presentations is often poor, owing to a number of factors, including public speaking anxiety. We present DynamicDuo, a system that uses an automated, life-sized, animated agent to help inexperienced speakers deliver their presentations in front of an audience. The design of the system was informed by an analysis of TED talks given by two human presenters to identify the most common dual-presentation formats and transition behaviors used. In a within-subjects study (N=12) comparing co-presenting with DynamicDuo against solo-presenting with conventional presentation software, we demonstrated that our system led to significant improvements in public speaking anxiety and speaking confidence for non-native English speakers. Judges who viewed videotapes of these presentations rated those with DynamicDuo significantly higher on speech quality and overall presentation quality for all presenters."
    },
    {
        "title": "Session details: Innovation in Theories & Products",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovation in Theories & Products",
        "data": "April 2015",
        "authors": [
            "Volker Wulf"
        ],
        "DOI": "https://doi.org/10.1145/3251719",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "From User-Centered to Adoption-Centered Design: A Case Study of an HCI Research Innovation Becoming a Product",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovation in Theories & Products",
        "data": "April 2015",
        "authors": [
            "Parmit K. Chilana",
            "Amy J. Ko",
            "Jacob Wobbrock"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702412",
        "citation": "38",
        "abstract": "As we increasingly strive for scientific rigor and generalizability in HCI research, should we entertain any hope that by doing good science, our discoveries will eventually be more transferrable to industry? We present an in-depth case study of how an HCI research innovation goes through the process of transitioning from a university project to a revenue-generating startup financed by venture capital. The innovation is a novel contextual help system for the Web, and we reflect on the different methods used to evaluate it and how research insights endure attempted dissemination as a commercial product. Although the extent to which any innovation succeeds commercially depends on a number of factors like market forces, we found that our HCI innovation with user-centered origins was in a unique position to gain traction with customers and garner buy-in from investors. However, since end users were not the buyers of our product, a strong user-centered focus obfuscated other critical needs of the startup and pushed out perspectives of non-user-centered stakeholders. To make the research-to-product transition, we had to focus on adoption-centered design, the process of understanding and designing for adopters and stakeholders of the product. Our case study raises questions about how we evaluate the novelty and research contributions of HCI innovations with respect to their potential for commercial impact."
    },
    {
        "title": "Creating Sustainable Cyberinfrastructures",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovation in Theories & Products",
        "data": "April 2015",
        "authors": [
            "David P. Randall",
            "E. Ilana Diamant",
            "Charlotte P. Lee"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702216",
        "citation": "9",
        "abstract": "In this paper we report the results of a qualitative research study of the GENI cyberinfrastructure: a program of four federated cyberinfrastructures. Drawing on theories of stakeholder positioning, we examine how different GENI stakeholders attempt to enlist new participants in the cyberinfrastructures of GENI, and leverage existing relationships to create sustainable infrastructure. This study contributes to our understanding of how cyberinfrastructures emerge over time through processes of stakeholder alignment, enrollment, and through synergies among stakeholder groups. We explore these issues to better understand how cyberinfrastructures can be designed to sustain over time."
    },
    {
        "title": "Standards and/as Innovation: Protocols, Creativity, and Interactive Systems Development in Ecology",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Innovation in Theories & Products",
        "data": "April 2015",
        "authors": [
            "Steven J. Jackson",
            "Sarah Barbrow"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702564",
        "citation": "13",
        "abstract": "Standards and protocols play important but under-theorized roles in HCI research and design efforts, including those dedicated to the development of new collaborative infrastructures in the sciences. Building on several years of ethnographic fieldwork, this paper examines standardization efforts attached to new forms of design and computational development in American ecology. We explore the role that standards play in large-scale research networks; how standards are enacted and enforced in complex interactive systems like science; how standards struggle and fail (and what happens when they do); and how actors work across the gaps that standards leave to produce more effective forms of practice and design. We also argue for the potentially creative role of standards, including contexts in which they function as fulcrums for change and innovation. We conclude with reflections on how HCI researchers might rethink the nature and possibilities of standards and standardization in their own work."
    },
    {
        "title": "Session details: Design and 3D Object Fabrication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design and 3D Object Fabrication",
        "data": "April 2015",
        "authors": [
            "David Kim"
        ],
        "DOI": "https://doi.org/10.1145/3251720",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Tactum: A Skin-Centric Approach to Digital Design and Fabrication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design and 3D Object Fabrication",
        "data": "April 2015",
        "authors": [
            "Madeline Gannon",
            "Tovi Grossman",
            "George Fitzmaurice"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702581",
        "citation": "41",
        "abstract": "Skin-based input has become an increasingly viable interaction model for user interfaces, however it has yet to be explored outside the domain of mobile computing. In this paper, we examine skin as an interactive input surface for gestural 3D modeling-to-fabrication systems. When used as both the input surface and base canvas for digital design, skin-input can enable non-experts users to intuitively create precise forms around highly complex physical contexts: our own bodies. In this paper, we outline design considerations when creating interfaces for such systems. We then discuss interaction techniques for three different modes of skin-centric modeling: direct, parametric, and generative. We also present Tactum, a new fabrication-aware design system that captures a user's skin-centric gestures for 3D modeling directly on the body. Lastly, we show sample artifacts generated with our system, and share a set of observations from design professionals."
    },
    {
        "title": "A Layered Fabric 3D Printer for Soft Interactive Objects",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design and 3D Object Fabrication",
        "data": "April 2015",
        "authors": [
            "Huaishu Peng",
            "Jennifer Mankoff",
            "Scott E. Hudson",
            "James McCann"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702327",
        "citation": "79",
        "abstract": "We present a new type of 3D printer that can form precise, but soft and deformable 3D objects from layers of off-the-shelf fabric. Our printer employs an approach where a sheet of fabric forms each layer of a 3D object. The printer cuts this sheet along the 2D contour of the layer using a laser cutter and then bonds it to previously printed layers using a heat sensitive adhesive. Surrounding fabric in each layer is temporarily retained to provide a removable support structure for layers printed above it. This process is repeated to build up a 3D object layer by layer. Our printer is capable of automatically feeding two separate fabric types into a single print. This allows specially cut layers of conductive fabric to be embedded in our soft prints. Using this capability we demonstrate 3D models with touch sensing capability built into a soft print in one complete printing process, and a simple LED display making use of a conductive fabric coil for wireless power reception."
    },
    {
        "title": "Platener: Low-Fidelity Fabrication of 3D Objects by Substituting 3D Print with Laser-Cut Plates",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design and 3D Object Fabrication",
        "data": "April 2015",
        "authors": [
            "Dustin Beyer",
            "Serafima Gurevich",
            "Stefanie Mueller",
            "Hsiang-Ting Chen",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702225",
        "citation": "63",
        "abstract": "This paper presents Platener, a system that allows quickly fabricating intermediate design iterations of 3D models, a process also known as low-fidelity fabrication. Platener achieves its speed-up by extracting straight and curved plates from the 3D model and substituting them with laser cut parts of the same size and thickness. Only the regions that are of relevance to the current design iteration are executed as full-detail 3D prints. Platener connects the parts it has created by automatically inserting joints. To help fast assembly it engraves instructions. Platener allows users to customize substitution results by (1) specifying fidelity-speed tradeoffs, (2) choosing whether or not to convert curved surfaces to plates bent using heat, and (3) specifying the conversion of individual plates and joints interactively. Platener is designed to best preserve the fidelity of func-tional objects, such as casings and mechanical tools, all of which contain a large percentage of straight/rectilinear elements. Compared to other low-fab systems, such as faBrickator and WirePrint, Platener better preserves the stability and functionality of such objects: the resulting assemblies have fewer parts and the parts have the same size and thickness as in the 3D model. To validate our system, we converted 2.250 3D models downloaded from a 3D model site (Thingiverse). Platener achieves a speed-up of 10 or more for 39.5% of all objects."
    },
    {
        "title": "D-Coil: A Hands-on Approach to Digital 3D Models Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design and 3D Object Fabrication",
        "data": "April 2015",
        "authors": [
            "Huaishu Peng",
            "Amit Zoran",
            "François V. Guimbretière"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702381",
        "citation": "36",
        "abstract": "We introduce D-Coil, a new digital 3D modeling approach using wax coiling to bring tangibility to the design of digital models. After defining a shape to extrude, the users follow the lead of a hand-held actuated extruder to instantiate the actual extrusion using wax. The tangibility of the wax extrusion sets the stage to create the next components until the digital model is completed. The digital model affords all digital attributes (ease of transformation, distribution, and 3D printing) while the wax artifact can be discarded or kept as a one-of-a-kind memento. We present a proof-of-concept implementation of D-Coil and showcase how this additive approach can also be extended to a subtractive process using a digitally actuated cutter. By adding a 6DOF mouse, users can also include scaling, rotation, and bending effects to create a wide variety of shapes often difficult for novices to produce in standard CAD software."
    },
    {
        "title": "Session details: Understanding & Extending Touch Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Extending Touch Interfaces",
        "data": "April 2015",
        "authors": [
            "Theophanis Tsandilas"
        ],
        "DOI": "https://doi.org/10.1145/3251721",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Performance and Ergonomics of Touch Surfaces: A Comparative Study using Biomechanical Simulation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Extending Touch Interfaces",
        "data": "April 2015",
        "authors": [
            "Myroslav Bachynskyi",
            "Gregorio Palmas",
            "Antti Oulasvirta",
            "Jürgen Steimle",
            "Tino Weinkauf"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702607",
        "citation": "57",
        "abstract": "Although different types of touch surfaces have gained extensive attention in HCI, this is the first work to directly compare them for two critical factors: performance and ergonomics. Our data come from a pointing task (N=40) carried out on five common touch surface types: public display (large, vertical, standing), tabletop (large, horizontal, seated), laptop (medium, adjustably tilted, seated), tablet (seated, in hand), and smartphone (single- and two-handed input). Ergonomics indices were calculated from biomechanical simulations of motion capture data combined with recordings of external forces. We provide an extensive dataset for researchers and report the first analyses of similarities and differences that are attributable to the different postures and movement ranges."
    },
    {
        "title": "How Much Faster is Fast Enough?: User Perception of Latency & Latency Improvements in Direct and Indirect Touch",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Extending Touch Interfaces",
        "data": "April 2015",
        "authors": [
            "Jonathan Deber",
            "Ricardo Jota",
            "Clifton Forlines",
            "Daniel Wigdor"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702300",
        "citation": "55",
        "abstract": "This paper reports on two experiments designed to further our understanding of users' perception of latency in touch- based systems. The first experiment extends previous efforts to measure latency perception by reporting on a unified study in which direct and indirect form-factors are compared for both tapping and dragging tasks. Our results show significant effects from both form-factor and task, and inform system designers as to what input latencies they should aim to achieve in a variety of system types. A follow-up experiment investigates peoples' ability to perceive small improvements to latency in direct and indirect form-factors for tapping and dragging tasks. Our results provide guidance to system designers of the relative value of making improvements in latency that reduce but do not fully eliminate lag from their systems."
    },
    {
        "title": "The Effect of Edge Targets on Touch Performance",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Extending Touch Interfaces",
        "data": "April 2015",
        "authors": [
            "Daniel Avrahami"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702439",
        "citation": "14",
        "abstract": "Edge targets, such as buttons or menus along the edge of a screen, are known to afford fast acquisition performance in desktop mousing environments. As the popularity of touch-based devices continues to grow, understanding the affordances of edge targets on touchscreen is needed. This paper describes results from two controlled experiments that examine in detail the effect of edge targets on performance in touch devices. The results show that on touch devices, a target's proximity to the edge may have a significant negative effect on reaction time. We examine the effect in detail and explore mitigating factors. We discuss potential explanations for the effect and propose implications for the design of efficient interfaces for touch devices."
    },
    {
        "title": "FlickBoard: Enabling Trackpad Interaction with Automatic Mode Switching on a Capacitive-sensing Keyboard",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Extending Touch Interfaces",
        "data": "April 2015",
        "authors": [
            "Ying-Chao Tung",
            "Ta Yang Cheng",
            "Neng-Hao Yu",
            "Chiuan Wang",
            "Mike Y. Chen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702582",
        "citation": "10",
        "abstract": "We present FlickBoard, which combines a touchpad and a keyboard into the same interaction area to reduce hand movement between a separate keyboard and touchpad. Our main contribution is automatic mode switching between typing and pointing, and the first system capable of combining a trackpad and a keyboard into an single interaction area without the need for external switches. We developed a prototype by embedding a 58x20 capacitive sensing grid into a soft keyboard cover, and used machine learning to distinguish between moving a cursor (touchpad mode) and entering text (keyboard mode). We conducted experimental studies that show automatic mode switching classification accuracies of 98% are achievable with our technology. Finally, our prototype has a thin profile and can be placed over existing keyboards."
    },
    {
        "title": "ExtensionSticker: A Proposal for a Striped Pattern Sticker to Extend Touch Interfaces and its Assessment",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Extending Touch Interfaces",
        "data": "April 2015",
        "authors": [
            "Kunihiro Kato",
            "Homei Miyashita"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702500",
        "citation": "40",
        "abstract": "In this study, we propose a striped pattern sticker called ExtensionSticker that allows a touch input to be transferred from an external source by simply attaching the sticker to a touch panel. This allows the user to input touches or continuous scrolling actions by touching a sticker printed with stripes of conductive ink, without directly touching the touch panel. This method could be applied to the sides or back of a touch panel, or even the surface upon which a device is located as a touch interface, allowing us to freely construct interfaces in shapes matching the demands of the user. This paper also reports the results of evaluation experiments conducted to assess the recognition accuracy of scroll and tap actions using the proposed method."
    },
    {
        "title": "Session details: Sharing & Collaboration @ Work",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sharing & Collaboration @ Work",
        "data": "April 2015",
        "authors": [
            "Steven Drucker"
        ],
        "DOI": "https://doi.org/10.1145/3251722",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "MUBox: Multi-User Aware Personal Cloud Storage",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sharing & Collaboration @ Work",
        "data": "April 2015",
        "authors": [
            "Michael Nebeling",
            "Matthias Geel",
            "Oleksiy Syrotkin",
            "Moira C. Norrie"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702233",
        "citation": "5",
        "abstract": "Personal cloud services such as Dropbox are used increasingly to support collaborative work, even though they typically have poor support for tracking files and users' activities and collaborators often rely on other communication channels to be notified of changes. We present a meta-cloud storage service, MUBox, that, independent of a particular cloud storage service, provides improved support for collaboration. First, users can switch to activity views that list user activities rather than files, which is an example of an increasingly available feature in popular cloud storage clients. Second, MUBox introduces multi-user aware folder views that embed information on the last changes performed by collaborators. These folder views are enhanced based on a new concept of shadow files which act as placeholders for files that have been moved or renamed. A user study (N=16) with realistic folder exploration tasks shows that activity views have a significant effect on the accuracy and confidence of users in workspace awareness tasks, while shadow files significantly improve the speed, accuracy and confidence of users in traceability tasks. We describe how existing services could implement these features as well as a new concept for voting on changes to shared folders that could improve asynchronous collaboration."
    },
    {
        "title": "DocuViz: Visualizing Collaborative Writing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sharing & Collaboration @ Work",
        "data": "April 2015",
        "authors": [
            "Dakuo Wang",
            "Judith S. Olson",
            "Jingwen Zhang",
            "Trung Nguyen",
            "Gary M. Olson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702517",
        "citation": "56",
        "abstract": "Collaborative writing is on the increase. In order to write well together, authors often need to be aware of who has done what recently. We offer a new tool, DocuViz, that displays the entire revision history of Google Docs, showing more than the one-step-at-a-time view now shown in revision history and tracking changes in Word. We introduce the tool and present cases in which the tool has the potential to be useful: To authors themselves to see recent \"seismic activity,\" indicating where in particular a co-author might want to pay attention, to instructors to see who has contributed what and which changes were made to comments from them, and to researchers interested in the new patterns of collaboration made possible by simultaneous editing capabilities."
    },
    {
        "title": "Communication through Boundary Objects in Distributed Agile Teams",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sharing & Collaboration @ Work",
        "data": "April 2015",
        "authors": [
            "Johan Kaj Blomkvist",
            "Johan Persson",
            "Johan Åberg"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702366",
        "citation": "16",
        "abstract": "Personal communication between User-Centered Design (UCD) specialists and developers is important for communicating user needs and design solutions in agile development. In distributed projects where opportunities for personal communication are limited, the design documentation is an important surrogate. This study has investigated the perceived effectiveness of boundary objects in a distributed agile team, and their role in communicating target user needs. Six in-depth interviews with UCD specialists showed that the boundary objects rarely communicate underlying needs of the users but rather focus on interaction with the system that is being developed. The used boundary objects also do not work as stand-alone deliverables; they need to be explained and elaborated. Making the boundary objects comprehensive enough to be stand-alone is seen as too time consuming and not worth the effort. For agile projects with distributed teams, this creates hand-over and follow-up problems."
    },
    {
        "title": "How to Drive a London Bus: Measuring Performance in a Mobile and Remote Workplace",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sharing & Collaboration @ Work",
        "data": "April 2015",
        "authors": [
            "Gary W. Pritchard",
            "Pam Briggs",
            "John Vines",
            "Patrick Olivier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702307",
        "citation": "15",
        "abstract": "This paper examines how London bus drivers have responded to performance monitoring via a telematics device called Drivewell. This device calculates a score based on various recordable driving-related events like abrupt braking or irregular turning actions. Our qualitative methodology incorporated semi-structured interviews and ethnographic fieldwork, in order to explore drivers' attitudes towards the system and its effect on driving behaviour and working conditions. Our findings illustrate how bus operators simultaneously accommodate and resist the demands Drivewell places upon them. Our work also demonstrates how this digital intervention acts in conjunction with other driver-related technologies, creating a unique digital ecosystem on the modern London bus. Our research contributes to HCI understandings of digital surveillance and performance monitoring in the modern workplace."
    },
    {
        "title": "Session details: Families and Their Use of Technology",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Families and Their Use of Technology",
        "data": "April 2015",
        "authors": [
            "Jennifer Marlow"
        ],
        "DOI": "https://doi.org/10.1145/3251723",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Managing Children's Online Identities: How Parents Decide what to Disclose about their Children Online",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Families and Their Use of Technology",
        "data": "April 2015",
        "authors": [
            "Tawfiq Ammari",
            "Priya Kumar",
            "Cliff Lampe",
            "Sarita Schoenebeck"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702325",
        "citation": "91",
        "abstract": "While extensive research has investigated the risks of children sharing their personal information online, little work has investigated the implications of parents sharing personal information about their children online. Drawing on 102 interviews with parents in the U.S., we investigate how parents decide what to disclose about their children on social network sites (SNSs). We find that mothers take on the responsibility of sharing content about their children more than fathers do. Fathers are more restrictive about sharing to broad and professional audiences and are concerned about sharing content that could be perceived as sexually suggestive. Both mothers and fathers work to leverage affordances of SNSs to limit oversharing. Building on prior work, we explore parental disclosure management, which describes how parents decide what to share about their children online. We also describe an emerging third shift of work that highlights the additional work parents take on to manage children's identities online. We conclude with theoretical and practical implications for designing SNSs to better support family life online."
    },
    {
        "title": "Understanding and Supporting Fathers and Fatherhood on Social Media Sites",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Families and Their Use of Technology",
        "data": "April 2015",
        "authors": [
            "Tawfiq Ammari",
            "Sarita Schoenebeck"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702205",
        "citation": "111",
        "abstract": "Fathers are taking on more childcare and household responsibilities than they used to and many non-profit and government organizations have pushed for changes in policies to support fathers. Despite this effort, little research has explored how fathers go online related to their roles as fathers. Drawing on an interview study with 37 fathers, we find that they use social media to document and archive fatherhood, learn how to be a father, and access social support. They also go online to support diverse family needs, such as single fathers' use of Reddit instead of Facebook, fathers raised by single mothers' search for role models online, and stay-at-home fathers' use of father blogs. However, fathers are constrained by privacy concerns and perceptions of judgment relating to sharing content online about their children. Drawing on theories of fatherhood, we present theoretical and design ideas for designing online spaces to better support fathers and fatherhood. We conclude with a call for a research agenda to support fathers online."
    },
    {
        "title": "Look, My Baby Is Using an iPad! An Analysis of YouTube Videos of Infants and Toddlers Using Tablets",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Families and Their Use of Technology",
        "data": "April 2015",
        "authors": [
            "Juan Pablo Hourcade",
            "Sarah L. Mascher",
            "David Wu",
            "Luiza Pantoja"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702266",
        "citation": "47",
        "abstract": "We know very little about the use of computers by children under the age of three. While few children in that age range used computers before the advent of smartphones and tablets, these devices have made computers much more accessible to infants and toddlers. In this paper, we provide a window into how these children are using tablets through an analysis of relevant YouTube videos. A majority of children aged 12 to 17 months in the videos in our dataset showed at least moderate ability to use the tablets. For children aged two, it was over 90 percent who displayed at least moderate ability. Our analysis also includes trends in interaction styles, child and device positioning, social aspects, and app genres. These findings point both to opportunities for research and starting points for design."
    },
    {
        "title": "Session details: Understanding Crowdwork in Many Domains",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Crowdwork in Many Domains",
        "data": "April 2015",
        "authors": [
            "Uichin Lee"
        ],
        "DOI": "https://doi.org/10.1145/3251724",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Apparition: Crowdsourced User Interfaces that Come to Life as You Sketch Them",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Crowdwork in Many Domains",
        "data": "April 2015",
        "authors": [
            "Walter S. Lasecki",
            "Juho Kim",
            "Nick Rafter",
            "Onkur Sen",
            "Jeffrey P. Bigham",
            "Michael S. Bernstein"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702565",
        "citation": "56",
        "abstract": "Prototyping allows designers to quickly iterate and gather feedback, but the time it takes to create even a Wizard-of-Oz prototype reduces the utility of the process. In this paper, we introduce crowdsourcing techniques and tools for prototyping interactive systems in the time it takes to describe the idea. Our Apparition system uses paid microtask crowds to make even hard-to-automate functions work immediately, allowing more fluid prototyping of interfaces that contain interactive elements and complex behaviors. As users sketch their interface and describe it aloud in natural language, crowd workers and sketch recognition algorithms translate the input into user interface elements, add animations, and provide Wizard-of-Oz functionality. We discuss how design teams can use our approach to reflect on prototypes or begin user studies within seconds, and how, over time, Apparition prototypes can become fully-implemented versions of the systems they simulate. Powering Apparition is the first self-coordinated, real-time crowdsourcing infrastructure. We anchor this infrastructure on a new, lightweight write-locking mechanism that workers can use to signal their intentions to each other."
    },
    {
        "title": "Zensors: Adaptive, Rapidly Deployable, Human-Intelligent Sensor Feeds",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Crowdwork in Many Domains",
        "data": "April 2015",
        "authors": [
            "Gierad Laput",
            "Walter S. Lasecki",
            "Jason Wiese",
            "Robert Xiao",
            "Jeffrey P. Bigham",
            "Chris Harrison"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702416",
        "citation": "64",
        "abstract": "The promise of \"smart\" homes, workplaces, schools, and other environments has long been championed. Unattractive, however, has been the cost to run wires and install sensors. More critically, raw sensor data tends not to align with the types of questions humans wish to ask, e.g., do I need to restock my pantry? Although techniques like computer vision can answer some of these questions, it requires significant effort to build and train appropriate classifiers. Even then, these systems are often brittle, with limited ability to handle new or unexpected situations, including being repositioned and environmental changes (e.g., lighting, furniture, seasons). We propose Zensors, a new sensing approach that fuses real-time human intelligence from online crowd workers with automatic approaches to provide robust, adaptive, and readily deployable intelligent sensors. With Zensors, users can go from question to live sensor feed in less than 60 seconds. Through our API, Zensors can enable a variety of rich end-user applications and moves us closer to the vision of responsive, intelligent environments."
    },
    {
        "title": "Exploring Privacy and Accuracy Trade-Offs in Crowdsourced Behavioral Video Coding",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Crowdwork in Many Domains",
        "data": "April 2015",
        "authors": [
            "Walter S. Lasecki",
            "Mitchell Gordon",
            "Winnie Leung",
            "Ellen Lim",
            "Jeffrey P. Bigham",
            "Steven P. Dow"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702605",
        "citation": "10",
        "abstract": "Coding behavioral video is an important method used by researchers to understand social phenomenon. Unfortunately, traditional hand-coding approaches can take days or weeks of time to complete. Recent work has shown that these tasks can be completed quickly by leveraging the parallelism of large online crowds, but using the crowd introduces new concerns about accuracy, reliability, privacy, and cost. To explore these issues, we conducted interviews with 12 researchers who frequently code behavioral video, to investigate common practices and challenges with video coding. We find accuracy and privacy to be the researchers' primary concerns. To explore this more concretely, we used sample videos to investigate whether crowds can accurately recognize instances of commonly coded behaviors, and show that the crowd yields accurate results. Then, we demonstrate a method for obfuscating participant identity with a video blur filter, and find, as expected, that workers' ability to identify participants decreases as blur level increases. The workers' ability to accurately and reliably code behaviors also decreases, but not as steeply as the identity test. This trade-off between coding quality and privacy protection suggests that researchers can use online crowds to code for some key behaviors in video without compromising participant identity. We conclude with a discussion of how researchers can balance privacy and accuracy on their own data using a system we introduce called Incognito."
    },
    {
        "title": "Crowdsourcing Stereotypes: Linguistic Bias in Metadata Generated via GWAP",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Crowdwork in Many Domains",
        "data": "April 2015",
        "authors": [
            "Jahna Otterbacher"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702151",
        "citation": "16",
        "abstract": "Games with a Purpose (GWAP) is a popular approach for metadata creation, enabling institutions to collect descriptions of digital artifacts on a mass scale. Creating metadata is challenging not only because one must recognize the artifact; the description must then be encoded into natural language. Language behaviors are influenced by many social factors, particularly when we are asked to describe other people. We consider labels for images of people generated via the ESP Game. While ESP has been shown to produce relevant labels, critics claim they are obvious and stereotypical. Based on theories of linguistic biases, we examine whether there are systematic differences in the ways players describe images of men versus women. Our first analysis considers images of people generally, and reveals a tendency for women to be described with subjective adjectives. A second analysis compares images depicting men and women within each of six occupational roles. Images of women receive more labels related to appearance, whereas those depicting men receive more occupation-related labels. Our work exposes the presence of gender-based stereotypes through linguistic biases, illustrates the forms in which they manifest, and raises important implications for those who design systems or train algorithms using data produced via GWAP."
    },
    {
        "title": "Session details: Eco-Green: Encouraging Energy Conservation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Eco-Green: Encouraging Energy Conservation",
        "data": "April 2015",
        "authors": [
            "Germaine Irwin"
        ],
        "DOI": "https://doi.org/10.1145/3251725",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Tiree Energy Pulse: Exploring Renewable Energy Forecasts on the Edge of the Grid",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Eco-Green: Encouraging Energy Conservation",
        "data": "April 2015",
        "authors": [
            "Will Simm",
            "Maria Angela Ferrario",
            "Adrian Friday",
            "Peter Newman",
            "Stephen Forshaw",
            "Mike Hazas",
            "Alan Dix"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702285",
        "citation": "43",
        "abstract": "In many parts of the world, the electricity supply industry makes the task of dealing with unpredictable spikes and dips in production and demand invisible to consumers, maintaining a seemingly unlimited supply. A future increase in reliance on time-variable renewable sources of electricity may lead to greater fluctuations in supply. We engaged remote islanders as equal partners in a research project that investigated through technology-mediated enquiry the topic of synchronising energy consumption with supply, and together built a prototype renewable energy forecast display. A number of participants described a change in their practices, saving high energy tasks for times when local renewable energy was expected to be available, despite having no financial incentive to do so. The main contributions of this paper are in: 1) the results of co-development sessions exploring systems supporting synchronising consumption with supply and 2) the findings arising from the deployment of the prototype."
    },
    {
        "title": "Designing Persuasive Technology to Manage Peak Electricity Demand in Ontario Homes",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Eco-Green: Encouraging Energy Conservation",
        "data": "April 2015",
        "authors": [
            "Valerie Sugarman",
            "Edward Lank"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702364",
        "citation": "13",
        "abstract": "When it comes to environmental sustainability, the time that electricity is consumed matters. For example, using an air conditioner on a hot summer afternoon as the power grid is strained necessitates the use of more polluting sources to meet demand. In this paper, we analyze end-user response to two utility-driven conservation programs in Ontario, Canada: Time-of-Use pricing and the peaksaver program. We find that time-of-use pricing encourages shifting some electricity demand, but only when it is convenient. We also find that while potentially effective at a larger scale, the peaksaver program in its current form is unattractive to participants. These results are discussed in the context of Fogg's Behavior Model for Persuasive Design, which allows us to explore the design space for improvement to these programs and ground our design implications for the design of technologies to encourage reduction of peak electricity demand."
    },
    {
        "title": "Eco-Forecasting for Domestic Electricity Use",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Eco-Green: Encouraging Energy Conservation",
        "data": "April 2015",
        "authors": [
            "Jesper Kjeldskov",
            "Mikael B. Skov",
            "Jeni Paay",
            "Dennis Lund",
            "Tue Madsen",
            "Michael Nielsen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702318",
        "citation": "21",
        "abstract": "Over the past decade we have seen an increased awareness about domestic energy consumption and a growing focus on eco-feedback displays. In this paper we explore the concept of providing forecasts in such displays as a supplement to information about past usage. Our prototype, eForecast, extends the display of past electricity usage with forecasts about expected usage, electricity price, availability of wind power, and expected demand drops and peaks. Building on previous eco-feedback display research, our approach specifically enables people to use electricity at more opportune times -- when it is cheap, green, or when there is an abundance of capacity. We evaluated eForecast in real world use in three domestic households for 22 weeks, where we explored potentials and limitations of forecasting for shifting electricity consumption. In this way, families were able to act in a more sustainable way -- without necessarily reducing the amount of electricity consumed."
    },
    {
        "title": "Beyond Eco-Feedback: Adding Online Manual and Automated Controls to Promote Workplace Sustainability",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Eco-Green: Encouraging Energy Conservation",
        "data": "April 2015",
        "authors": [
            "Ray Yun",
            "Azizan Aziz",
            "Peter Scupelli",
            "Bertrand Lasternas",
            "Chenlu Zhang",
            "Vivian Loftness"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702268",
        "citation": "18",
        "abstract": "Whereas eco-feedback has been widely studied in HCI and environmental psychology, online manual control and automated control have been rarely studied with a focus on their long-term quantitative impact and usability. To address this, an intervention was tested with eighty office workers for twenty-seven weeks. Through the long-term field test, it was found that the addition of online controls in the feedback intervention led to more energy savings than feedback only and worked better for light and phone usage than computer and monitor usage. The addition of automated control led to the greatest savings but was less effective for efficient users than inefficient ones."
    },
    {
        "title": "Understanding the Role of Thermography in Energy Auditing: Current Practices and the Potential for Automated Solutions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Eco-Green: Encouraging Energy Conservation",
        "data": "April 2015",
        "authors": [
            "Matthew Louis Mauriello",
            "Leyla Norooz",
            "Jon E. Froehlich"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702528",
        "citation": "19",
        "abstract": "The building sector accounts for 41% of primary energy consumption in the US, contributing an increasing portion of the country's carbon dioxide emissions. With recent sensor improvements and falling costs, auditors are increasingly using thermography-infrared (IR) cameras-to detect thermal defects and analyze building efficiency. Research in automated thermography has grown commensurately, aimed at reducing manual labor and improving thermal models. Though promising, we could find no prior work exploring the professional auditor's perspectives of thermography or reactions to emerging automation. To address this gap, we present results from two studies: a semi-structured interview with 10 professional energy auditors, which includes design probes of five automated thermography scenarios, and an observational case study of a residential audit. We report on common perspectives, concerns, and benefits related to thermography and summarize reactions to our automated scenarios. Our findings have implications for thermography tool designers as well as researchers working on automated solutions in robotics, computer science, and engineering."
    },
    {
        "title": "Session details: Sports Tracking & Training",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sports Tracking & Training",
        "data": "April 2015",
        "authors": [
            "Hao-Hua Chu"
        ],
        "DOI": "https://doi.org/10.1145/3251726",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Keepin' it Real: Challenges when Designing Sports-Training Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sports Tracking & Training",
        "data": "April 2015",
        "authors": [
            "Mads Møller Jensen",
            "Majken K. Rasmussen",
            "Florian \"Floyd\" Mueller",
            "Kaj Grønbæk"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702243",
        "citation": "19",
        "abstract": "Using game elements and mechanics in sports training holds great potential for increasing player enjoyment, but also introduces a risk of reducing training relevance. This paper describes a novel training installation for individual handball training, called \"The Bouncer\", and the design process behind three training games. In order to investigate how game elements can affect the training experience, we conducted a study with 10 experienced amateur handball players, eliciting responses regarding the training relevance of the games. Based on the study and our design insights, we propose three challenges that designers of interactive sports-training games need to consider: 1) Maintaining relevance when translating physical elements into digital representations. 2) Choosing an appropriate level of sensing as game input. 3) Introducing points in training exercises without reducing sport relevance. For the three challenges, we propose strategies to help future designers of training games."
    },
    {
        "title": "Flow is Not Enough: Understanding the Needs of Advanced Amateur Runners to Design Motivation Technology",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sports Tracking & Training",
        "data": "April 2015",
        "authors": [
            "Kristina Knaving",
            "Paweł Woźniak",
            "Morten Fjeld",
            "Staffan Björk"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702542",
        "citation": "50",
        "abstract": "Motivation studies on running are often focused on how to convince non-runners to run, mainly through designing for extrinsic motivations such as health concerns or external reward systems. In contrast, we conducted a structured inquiry into understanding how to design technology for those whom are already committed to running and participate in organized races. Through interviews, focus groups, ethnographic observation, questionnaires, and design-based research over the course of two years, we investigated the needs of the advanced amateur runner community. An analysis of the gathered data led to five design themes -- Festival, Competition, Practicalities, Togetherness, and Support -- to inform future runner motivation technology. While flow theory appears to be a convenient tool to understand support during a race, we observed a number of other factors that need to be considered. Through combining the themes with previous research, we conclude by presenting nine guidelines for designing technology for this domain."
    },
    {
        "title": "Jogging with a Quadcopter",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sports Tracking & Training",
        "data": "April 2015",
        "authors": [
            "Florian 'Floyd' Mueller",
            "Matthew Muirhead"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702472",
        "citation": "85",
        "abstract": "Jogging is a popular exertion activity. The abundance of jogging apps suggests to us that joggers can appreciate the opportunity for technology to support the jogging experience. We want to take this investigation a step further by exploring if, and how, robotic systems can support the jogging experience. We designed and built a flying robotic system, a quadcopter, as a jogging companion and studied its use with 13 individual joggers. By analyzing their experiences, we derived three design dimensions that describe a design space for flying robotic jogging companions: Perceived Control, Focus and Bodily Interaction. Additionally, we articulate a series of design tactics, described by these dimensions, to guide the design of future systems. With this work we hope to inspire and guide designers interested in creating robotic systems to support exertion experiences."
    },
    {
        "title": "ClimbSense: Automatic Climbing Route Recognition using Wrist-worn Inertia Measurement Units",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Sports Tracking & Training",
        "data": "April 2015",
        "authors": [
            "Felix Kosmalla",
            "Florian Daiber",
            "Antonio Krüger"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702311",
        "citation": "37",
        "abstract": "Today, sports and activity trackers are ubiquitous. Especially runners and cyclists have a variety of possibilities to record and analyze their workouts. In contrast, climbing did not find much attention in consumer electronics and human-computer interaction. If quantified data similar to cycling or running data were available for climbing, several applications would be possible, ranging from simple training diaries to virtual coaches or usage analytics for gym operators. This paper introduces a system that automatically recognizes climbed routes using wrist-worn inertia measurement units (IMUs). This is achieved by extracting features of a recorded ascent and use them as training data for the recognition system. To verify the recognition system, cross-validation methods were applied to a set of ascent recordings that were assessed during a user study with eight climbers in a local climbing gym. The evaluation resulted in a high recognition rate, thus proving that our approach is possible and operational."
    },
    {
        "title": "Session details: Feeling & Communicating Emotions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Feeling & Communicating Emotions",
        "data": "April 2015",
        "authors": [
            "Rongrong Wang"
        ],
        "DOI": "https://doi.org/10.1145/3251727",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Towards Multimodal Affective Feedback: Interaction between Visual and Haptic Modalities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Feeling & Communicating Emotions",
        "data": "April 2015",
        "authors": [
            "Akshita",
            "Harini Alagarai Sampath",
            "Bipin Indurkhya",
            "Eunhwa Lee",
            "Yudong Bae"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702288",
        "citation": "18",
        "abstract": "We explored how emotional cues presented in visual and haptic modalities interact. We constructed an affective haptic dataset, and used the emotional visual stimuli from the International Affective Picture System (IAPS). Participants were asked to rate the visual stimuli, haptic stimuli and visualhaptic stimuli. Analysis of the results indicates that the presence of haptic stimulus affects the arousal of the visual stimulus, but does not affect the valence significantly. We further explored this interaction in terms of the intensity, frequency, waveform and rhythm of the haptic stimuli. We then provide a set of guidelines on visual-haptic interaction that could be used in design of multimodal affective feedback."
    },
    {
        "title": "Emotions Mediated Through Mid-Air Haptics",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Feeling & Communicating Emotions",
        "data": "April 2015",
        "authors": [
            "Marianna Obrist",
            "Sriram Subramanian",
            "Elia Gatti",
            "Benjamin Long",
            "Thomas Carter"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702361",
        "citation": "91",
        "abstract": "Touch is a powerful vehicle for communication between humans. The way we touch (how) embraces and mediates certain emotions such as anger, joy, fear, or love. While this phenomenon is well explored for human interaction, HCI research is only starting to uncover the fine granularity of sensory stimulation and responses in relation to certain emotions. Within this paper we present the findings from a study exploring the communication of emotions through a haptic system that uses tactile stimulation in mid-air. Here, haptic descriptions for specific emotions (e.g., happy, sad, excited, afraid) were created by one group of users to then be reviewed and validated by two other groups of users. We demonstrate the non-arbitrary mapping between emotions and haptic descriptions across three groups. This points to the huge potential for mediating emotions through mid-air haptics. We discuss specific design implications based on the spatial, directional, and haptic parameters of the created haptic descriptions and illustrate their design potential for HCI based on two design ideas."
    },
    {
        "title": "In the Heat of the Moment: Subjective Interpretations of Thermal Feedback During Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Feeling & Communicating Emotions",
        "data": "April 2015",
        "authors": [
            "Graham Wilson",
            "Gavin Davidson",
            "Stephen A. Brewster"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702219",
        "citation": "34",
        "abstract": "Research has shown that thermal feedback can be an engaging and convincing means of conveying experimenter-predefined meanings, e.g., material properties or message types. However, thermal perception is subjective and its meaning in interaction can be ambiguous. Interface designers may not be sure how users could naïvely interpret thermal feedback during interaction. Little is also known about how users would choose thermal cues to convey their own meanings. The research in this paper tested subjective interpretations of thermal stimuli in three different scenarios: social media activity, a colleague's presence and the extent of use of digital content. Participants were also asked to assign their own thermal stimuli to personal experiences, to help us understand what kinds of stimuli people associate with different meanings. The results showed strong agreement among participants concerning what warmth (presence, activity, quality) and cool mean (absence, poor quality). Guidelines for the design of thermal feedback are presented to help others create effective thermal interfaces."
    },
    {
        "title": "EnviroPulse: Providing Feedback about the Expected Affective Valence of the Environment",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Feeling & Communicating Emotions",
        "data": "April 2015",
        "authors": [
            "Deltcho Valtchanov",
            "Mark Hancock"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702510",
        "citation": "6",
        "abstract": "Interacting with nature is beneficial to a person's mental-state, but it can sometimes be difficult to find environments that will induce positive affect (e.g., when planning a run). In this paper, we describe EnviroPulse-a system for auto-matically determining and communicating the expected affective valence (EAV) of environments to individuals. We describe a prototype that allows this to be used in real-time on a smartphone, but EnviroPulse could easily be incorporated into GPS systems, mapping services, or image-based systems. Our work differs from existing work in af-fective computing in that, rather than detecting a user's affect directly, we automatically determine the EAV of the environment through visual analysis. We present results that suggest our system can determine the EAV of envi-ronments. We also introduce real-time affective visual feedback of the calculated EAV of the images, and present results from an informal study suggesting that real-time visual feedback can be used for induction of affect."
    },
    {
        "title": "Session details: Critical Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Critical Design",
        "data": "April 2015",
        "authors": [
            "Giulio Jacucci"
        ],
        "DOI": "https://doi.org/10.1145/3251728",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Expanding and Refining Design and Criticality in HCI",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Critical Design",
        "data": "April 2015",
        "authors": [
            "James Pierce",
            "Phoebe Sengers",
            "Tad Hirsch",
            "Tom Jenkins",
            "William Gaver",
            "Carl DiSalvo"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702438",
        "citation": "83",
        "abstract": "The term 'critical design' is on the upswing in HCI. We analyze how discourses around 'critical design' are diverging in Design and HCI. We argue that this divergence undermines HCI's ability to learn from and appropriate the design approaches signaled by this term. Instead, we articulate two ways to broaden and deepen connections between Design and HCI: (1) develop a broader collective understanding of what these design approaches can be, without forcing them to be about 'criticality' or 'critical design,' narrowly construed; and (2) shape a variation of design criticism to better meet Design practices, terms, and ways of knowing."
    },
    {
        "title": "Immodest Proposals: Research Through Design and Knowledge",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Critical Design",
        "data": "April 2015",
        "authors": [
            "Jeffrey Bardzell",
            "Shaowen Bardzell",
            "Lone Koefoed Hansen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702400",
        "citation": "94",
        "abstract": "The paper offers theoretical support for research through design (RtD) by arguing that in order to legitimize and make use of research through design as research, HCI researchers need to explore and clarify how RtD objects might contribute to knowledge. Leveraging the tradition of aesthetics in the arts and humanities, we argue that while the intentions of the object's designer are important and while annotations are a good mechanism to articulate them, the critical reception of objects is equally foundational to RtD's broader knowledge impacts within HCI. Such a scholarly critical reception is needed precisely because of the potential inexhaustibility of design objects' meanings; their inability to be paraphrased simply and adequately. Offering a multilevel analysis of the (critical) design fiction Menstruation Machine by Sputniko!, the paper explores how design objects co-produce knowledge, by working through complex design problem spaces in non-reductive ways, proposing new connections and distinctions, and embodying design ideas and processes across time and minds."
    },
    {
        "title": "Making Multiple Uses of the Obscura 1C Digital Camera: Reflecting on the Design, Production, Packaging and Distribution of a Counterfunctional Device",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Critical Design",
        "data": "April 2015",
        "authors": [
            "James Pierce",
            "Eric Paulos"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702405",
        "citation": "43",
        "abstract": "This paper describes and explains details of the design, production and packaging of a counterfunctional device: The Obscura 1C Digital Camera. We further describe a small-scale distribution of Obscura 1C packages into everyday contexts. The paper then reflects on the various types of conceptual, imaginary and firsthand uses made of the Obscura 1C. These include its uses for everyday audiences as a unique camera and as a conceptually usable device. But we also prioritize uses particular to the HCI and design audience. These include using the Obscura 1C to articulate the concepts of inhibitive interfaces, counterfunctionality, and enabling limitations. The Obscura 1C is further used to articulate how abstract ideas can be translated into material forms, to rethink the role of packaging in user studies, and to draw attention to how discursive design objects are packaged and presented."
    },
    {
        "title": "Pause Moment Experience in SNS Communication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Critical Design",
        "data": "April 2015",
        "authors": [
            "Jae-eul Bae",
            "Youn-kyung Lim",
            "Jin-bae Bang",
            "Myung-suk Kim"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702435",
        "citation": "1",
        "abstract": "The evolution of SNS applications has focused on the increasing pace of communication. Accordingly, adopting pause moment design for the SNS domain becomes significant, considering its worth for mental well-being and diversity of experience. Nonetheless, the vision is currently controversial, as it is lacking in attempts to examine the worth of pause moment design for SNS communication. Therefore, we discussed the benefits of pause moment design as an SNS application, based on the case of Ripening Room. From observation, we have identified three benefits of pause moment design; preserving room for solitude, expanding time experience, and providing additional indirect cues for communication. Nevertheless, the benefits also imply limitations of the current design, thus require following attempts to adopt a pause moment design for the SNS domain."
    },
    {
        "title": "Session details: HMDs in Augmented & Virtual Reality",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs in Augmented & Virtual Reality",
        "data": "April 2015",
        "authors": [
            "Shahram Izadi"
        ],
        "DOI": "https://doi.org/10.1145/3251729",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Eye-Wearable Technology for Machine Maintenance: Effects of Display Position and Hands-free Operation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs in Augmented & Virtual Reality",
        "data": "April 2015",
        "authors": [
            "Xianjun Sam Zheng",
            "Cedric Foucault",
            "Patrik Matos da Silva",
            "Siddharth Dasari",
            "Tao Yang",
            "Stuart Goose"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702305",
        "citation": "63",
        "abstract": "Exciting developments in eye-wearable technology and its potential industrial applications warrant a thorough understanding of its advantages and drawbacks through empirical evidence. We conducted an experiment to investigate what characteristics of eye-wearable technology impact user performance in machine maintenance, which included a representative set of car maintenance tasks involving Locate, Manipulate, and Compare actions. Participants were asked to follow instructions displayed on one of four technologies: a peripheral eye-wearable display, a central eye-wearable display, a tablet, or a paper manual. We found a significant effect of display position: the peripheral eye-wearable display resulted in longer completion time than the central display; but no effect for hands-free operation. The technology effects were also modulated by different Tasks and Action types. We discuss the human factors implications for designing more effective eye-wearable technology, including display position, issues of monocular display, and how the physical proximity of the technology affects users' reliance level."
    },
    {
        "title": "Belt: An Unobtrusive Touch Input Device for Head-worn Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs in Augmented & Virtual Reality",
        "data": "April 2015",
        "authors": [
            "David Dobbelstein",
            "Philipp Hock",
            "Enrico Rukzio"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702450",
        "citation": "51",
        "abstract": "Belt is a novel unobtrusive input device for wearable displays that incorporates a touch surface encircling the user's hip. The wide input space is leveraged for a horizontal spatial mapping of quickly accessible information and applications. We discuss social implications and interaction capabilities for unobtrusive touch input and present our hardware implementation and a set of applications that benefit from the quick access time. In a qualitative user study with 14 participants we found out that for short interactions (2-4 seconds), most of the surface area is considered as appropriate input space, while for longer interactions (up to 10 seconds), the front areas above the trouser pockets are preferred."
    },
    {
        "title": "Content Destabilization for Head-Mounted Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs in Augmented & Virtual Reality",
        "data": "April 2015",
        "authors": [
            "Felix Lauber",
            "Sophia Cook",
            "Andreas Butz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702161",
        "citation": "3",
        "abstract": "With recent progress in display technology, visual see-through head-mounted displays are beginning to enter our everyday lives. Especially in cars they may replace head-up displays, as they can theoretically perfectly imitate them but are more flexible to use. However, prior work has shown that both screen- and vehicle-stabilized content suffer from drawbacks such as occlusion or technological limitations. As a potential alternative, we propose three concept alternatives, in which head rotation is used to manipulate the displayed content differently from both of the known stabilization techniques. In a qualitative user study, we identify the best concept proposal and then evaluate it against the established content stabilization techniques. The presented concept is perceived to be more applicable for the proposed use case and effectively reduces some of the known problems of both stabilization techniques."
    },
    {
        "title": "A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs in Augmented & Virtual Reality",
        "data": "April 2015",
        "authors": [
            "Mark McGill",
            "Daniel Boland",
            "Roderick Murray-Smith",
            "Stephen Brewster"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702382",
        "citation": "146",
        "abstract": "We identify usability challenges facing consumers adopting Virtual Reality (VR) head-mounted displays (HMDs) in a survey of 108 VR HMD users. Users reported significant issues in interacting with, and being aware of their real-world context when using a HMD. Building upon existing work on blending real and virtual environments, we performed three design studies to address these usability concerns. In a typing study, we show that augmenting VR with a view of reality significantly corrected the performance impairment of typing in VR. We then investigated how much reality should be incorporated and when, so as to preserve users' sense of presence in VR. For interaction with objects and peripherals, we found that selectively presenting reality as users engaged with it was optimal in terms of performance and users' sense of presence. Finally, we investigated how this selective, engagement-dependent approach could be applied in social environments, to support the user's awareness of the proximity and presence of others."
    },
    {
        "title": "Accuracy of Pedometry on a Head-mounted Display",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs in Augmented & Virtual Reality",
        "data": "April 2015",
        "authors": [
            "Ilias Apostolopoulos",
            "Daniel S. Coming",
            "Eelke Folmer"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702143",
        "citation": "9",
        "abstract": "The accuracy of pedometry varies depending on where an inertial sensor is located on the body. Motivated by the increasing popularity of wearable computing, this paper investigates the accuracy with which pedometry can be achieved on a head-mounted device: something previous research has not investigated. A study with 16 subjects compares the accuracy of pedometry for walking and running with an inertial sensor located at the head, pocket and hand/arm. Our study did not detect a significant difference in step counting accuracy between sensor locations, which demonstrates the feasibility of pedometry-based apps for head-mounted displays."
    },
    {
        "title": "Level-Ups: Motorized Stilts that Simulate Stair Steps in Virtual Reality",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HMDs in Augmented & Virtual Reality",
        "data": "April 2015",
        "authors": [
            "Dominik Schmidt",
            "Rob Kovacs",
            "Vikram Mehta",
            "Udayan Umapathi",
            "Sven Köhler",
            "Lung-Pan Cheng",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702253",
        "citation": "31",
        "abstract": "We present \"Level-Ups\", computer-controlled stilts that allow virtual reality users to experience walking up and down steps. Each Level-Up unit is a self-contained device worn like a boot. Its main functional element is a vertical actuation mechanism mounted to the bottom of the boot that extends vertically. Unlike traditional solutions that are integrated with locomotion devices, Level-Ups allow users to walk around freely (\"real-walking\"). We present Level-Ups in a demo environment based on a head-mounted display, optical motion capture, and integrated with two different game engines. In a user study, participants rated the realism of stepping onto objects 6.0 out of 7.0 when wearing Level-Ups compared to 3.5 without."
    },
    {
        "title": "Session details: Tangible Interaction with Phones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interaction with Phones",
        "data": "April 2015",
        "authors": [
            "Shengdong Zhao"
        ],
        "DOI": "https://doi.org/10.1145/3251730",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Acoustruments: Passive, Acoustically-Driven, Interactive Controls for Handheld Devices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interaction with Phones",
        "data": "April 2015",
        "authors": [
            "Gierad Laput",
            "Eric Brockmeyer",
            "Scott E. Hudson",
            "Chris Harrison"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702414",
        "citation": "70",
        "abstract": "We introduce Acoustruments: low-cost, passive, and power-less mechanisms, made from plastic, that can bring rich, tangible functionality to handheld devices. Through a structured exploration, we identified an expansive vocabulary of design primitives, providing building blocks for the construction of tangible interfaces utilizing smartphones' existing audio functionality. By combining design primitives, familiar physical mechanisms can all be constructed from passive elements. On top of these, we can create end-user applications with rich, tangible interactive functionalities. Our experiments show that Acoustruments can achieve 99% accuracy with minimal training, is robust to noise, and can be rapidly prototyped. Acoustruments adds a new method to the toolbox HCI practitioners and researchers can draw upon, while introducing a cheap and passive method for adding interactive controls to consumer products."
    },
    {
        "title": "HaptiCase: Back-of-Device Tactile Landmarks for Eyes-Free Absolute Indirect Touch",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interaction with Phones",
        "data": "April 2015",
        "authors": [
            "Christian Corsten",
            "Christian Cherek",
            "Thorsten Karrer",
            "Jan Borchers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702277",
        "citation": "19",
        "abstract": "Using a smartphone for touch input to control apps and games mirrored to a distant screen is difficult, as the user cannot see where she is touching while looking at the distant display. We present HaptiCase, an interaction technique that provides back-of-device tactile landmarks that the user senses with her fingers to estimate the location of her finger in relation to the touchscreen. By pinching the thumb resting above the touch- screen to a finger at the back, the finger position is transferred to the front as the thumb touches the screen. In a study, we compared touch performance of different landmark layouts with a regular landmark-free mobile device. Using a land- mark design of dots on a 3x5 grid significantly improves eyes-free tapping accuracy and allows targets to be as small as 17.5 mm---a 14% reduction in target size---to cover 99% of all touches. When users can look at the touchscreen, land- marks have no significant effect on performance. HaptiCase is low-cost, requires no electronics, and works with unmodified software."
    },
    {
        "title": "The Trial of Bendi in a Coffeehouse: Use of a Shape-Changing Device for a Tactile-Visual Phone Conversation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interaction with Phones",
        "data": "April 2015",
        "authors": [
            "Young-Woo Park",
            "Joohee Park",
            "Tek-Jin Nam"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702326",
        "citation": "32",
        "abstract": "We present Bendi, a shape-changing device for a tactile-visual phone conversation. Bendi enables users to deliver shape-changing movements (e.g., upward or downward bending, left or right tilting, and shrinking) from the user's joystick input to the other party's device in real time during phone conversations. We conducted a user study to observe how seven couples used it over three days in a coffeehouse. Our field trial of Bendi in a coffeehouse showed the private and natural uses, and integrated uses of tactile and visual expressions along with the uses of the vocabularies developed through Bendi. In addition, there were active uses even in negative and serious conversational context with its pleasant tactile feelings and movement representations. Lastly, we discuss issues for the future designs and real-world deployment of shape-changing mobile devices for daily use."
    },
    {
        "title": "SpecTrans: Versatile Material Classification for Interaction with Textureless, Specular and Transparent Surfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tangible Interaction with Phones",
        "data": "April 2015",
        "authors": [
            "Munehiko Sato",
            "Shigeo Yoshida",
            "Alex Olwal",
            "Boxin Shi",
            "Atsushi Hiyama",
            "Tomohiro Tanikawa",
            "Michitaka Hirose",
            "Ramesh Raskar"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702169",
        "citation": "21",
        "abstract": "Surface and object recognition is of significant importance in ubiquitous and wearable computing. While various techniques exist to infer context from material properties and appearance, they are typically neither designed for real-time applications nor for optically complex surfaces that may be specular, textureless, and even transparent. These materials are, however, becoming increasingly relevant in HCI for transparent displays, interactive surfaces, and ubiquitous computing. We present SpecTrans, a new sensing technology for surface classification of exotic materials, such as glass, transparent plastic, and metal. The proposed technique extracts optical features by employing laser and multi-directional, multi-spectral LED illumination that leverages the material's optical properties. The sensor hardware is small in size, and the proposed classification method requires significantly lower computational cost than conventional image-based methods, which use texture features or reflectance analysis, thereby providing real-time performance for ubiquitous computing. Our evaluation of the sensing technique for nine different transparent materials, including air, shows a promising recognition rate of 99.0%. We demonstrate a variety of possible applications using SpecTrans' capabilities."
    },
    {
        "title": "Session details: UI Impact on Performance & Decisions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UI Impact on Performance & Decisions",
        "data": "April 2015",
        "authors": [
            "Tom Gross"
        ],
        "DOI": "https://doi.org/10.1145/3251731",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Displayed Uncertainty Improves Driving Experience and Behavior: The Case of Range Anxiety in an Electric Car",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UI Impact on Performance & Decisions",
        "data": "April 2015",
        "authors": [
            "Malte F. Jung",
            "David Sirkin",
            "Turgut M. Gür",
            "Martin Steinert"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702479",
        "citation": "65",
        "abstract": "We explore the impact of the displayed precision of instrumentation estimates of range and state-of-charge on drivers' attitudes towards an all-electric vehicle (EV), on their driving experience, and driving behavior under varying conditions of resource availability. Participants (N=73) completed a 19-mile long drive through highway, rural town and mountain road conditions in an EV that displayed high vs. low remaining range, and gave estimates of that range with high and low information ambiguity. We found that an ambiguous display of range preserved drivers' feelings of trust towards the vehicle, despite encountering situations intended to induce severe range anxiety. Furthermore, compared to drivers facing an unambiguous display of range, drivers presented with an ambiguous range display reported improved driving experience, and exhibited driving behavior better adapted to road and remaining range conditions."
    },
    {
        "title": "Designing Information for Remediating Cognitive Biases in Decision-Making",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UI Impact on Performance & Decisions",
        "data": "April 2015",
        "authors": [
            "Yunfeng Zhang",
            "Rachel K.E. Bellamy",
            "Wendy A. Kellogg"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702239",
        "citation": "30",
        "abstract": "Software is playing an increasingly important role in supporting human decision-making. Previous HCI research on decision support systems (DSS) has improved the information visualization aspect of DSS information design, but has somewhat overlooked the cognitive aspect of decision-making, namely that human reasoning is heuristic and reflects systematic errors or cognitive biases. We report on an empirical study of two cognitive biases: conservatism and loss aversion. Two remediation techniques recommended by previous research were tested: the expected return method, an actuarial-inspired approach presenting objective metrics; and bootstrapping, a technique successful in improving judgment consistency. The results show that the two biases can occur simultaneously and can have a huge impact on decision-making. The results also show that the two debiasing techniques are only partly effective. These findings suggest a need for more research on debiasing, and indicate some directions for exploring debiasing techniques and building decision support systems."
    },
    {
        "title": "Quick Affective Judgments: Validation of a Method for Primed Product Comparisons",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UI Impact on Performance & Decisions",
        "data": "April 2015",
        "authors": [
            "Jussi P.P. Jokinen",
            "Johanna M. Silvennoinen",
            "Piia M.H. Perälä",
            "Pertti Saariluoma"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702422",
        "citation": "9",
        "abstract": "A method for primed product comparisons was developed, based on the methodological considerations of emotional appraisal process and affective mental contents. The method was implemented as a computer tool, which was utilised in two experiments (N = 18 for both). Ten adjectives served as primes, and five drinking glass pictures as stimuli. Participants' task was to choose a preference between two glasses, given the priming adjective. The results validate the method by providing test-retest reliability measures and showing convergence with questionnaires. Further, different evaluation times between the primes and the stimuli reveal the existence of different mental processes associated with various aspects of product experience, as predicted by appraisal theory. The results have various implications for experience research and development in HCI, as they demonstrate how the method can be used for product evaluation and the analysis of the mental processes, which users use to evaluate the products."
    },
    {
        "title": "Effects of Ad Quality & Content-Relevance on Perceived Content Quality",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UI Impact on Performance & Decisions",
        "data": "April 2015",
        "authors": [
            "Henriette Cramer"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702360",
        "citation": "22",
        "abstract": "Native advertising, ads that are highly cohesive with actual content in format and style, is a pervasive online trend. We report on a two-stage Mechanical Turk experiment exploring the effects of perceived quality of native ads on perceptions of site quality. First, a set of native ads was rated (N=98) for perceived annoyance and trust. Second, we compare four conditions of an aggregation of news headlines (N=237): 'no ads', 'low quality ads', 'high quality ads + content-relevant', 'high-quality ads + not content-relevant'. Our results indicate that native ads, which in isolation have been rated as high quality, could still have a negative effect on perceived site credibility and perceived site quality if they are too content-relevant. In addition to the effect of ad quality alone (e.g. non-annoying, trustworthy ads), there is an additional impact for ads that are too similar to content; avoiding confusion is important for quality perceptions."
    },
    {
        "title": "Session details: Player Performance & Experience in Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Player Performance & Experience in Games",
        "data": "April 2015",
        "authors": [
            "Jan Smeddinck"
        ],
        "DOI": "https://doi.org/10.1145/3251732",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "The Goal of Scoring: Exploring the Role of Game Performance in Educational Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Player Performance & Experience in Games",
        "data": "April 2015",
        "authors": [
            "Casper Harteveld",
            "Steven C. Sutherland"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702606",
        "citation": "16",
        "abstract": "In this paper the role of game performance as an assessment tool is explored and an approach is presented for designing and assessing learning-centered game scores. In recent years, attention has shifted from focusing on games for learning to games for assessment. The research question this paper tries to address is how valid games are as an assessment tool, and more specifically, how valid the use of game scores are as a measure of assessment. To explore this use, we looked at the role of game performance in a game where the goals were designed based on its learning objectives. We hypothesized that because of this design the scores could be used as a measure of learning. The results of our mixed-methods study confirmed this hypothesis. However, the scores are influenced by factors such as computer skills and age. Further analysis revealed that the design of the game and the game-based training were also of influence. These insights will help in designing better predictive game scores in the future."
    },
    {
        "title": "Moving Beyond Fun: Evaluating Serious Experience in Digital Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Player Performance & Experience in Games",
        "data": "April 2015",
        "authors": [
            "Ioanna Iacovides",
            "Anna L. Cox"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702204",
        "citation": "35",
        "abstract": "Games are normally considered to be \"fun\", though recently there is growing interest in how gameplay can promote empathy and encourage reflection through \"serious experience\". However, when looking beyond enjoyment, it is not clear how to actually evaluate serious experience. We present an evaluation of four games that were submitted to a student game design competition; the competition challenged teams to design a game that inspired curiosity around human error and blame culture within the context of healthcare. The entries were judged by a panel of six experts and subjected to a round of play testing by twelve participants. Methods included gameplay observation, questionnaires, post-play interviews and follow-up email questions. We discuss the utility of these methods, with particular emphasis on how they enabled a consideration of the immediate and longer term impact of serious experience on players."
    },
    {
        "title": "Now You Can Compete With Anyone: Balancing Players of Different Skill Levels in a First-Person Shooter Game",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Player Performance & Experience in Games",
        "data": "April 2015",
        "authors": [
            "Rodrigo Vicencio-Moreira",
            "Regan L. Mandryk",
            "Carl Gutwin"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702242",
        "citation": "44",
        "abstract": "When player skill levels differ widely in a competitive First-Person Shooter (FPS) game, enjoyment suffers: weaker players become frustrated and stronger players become less engaged. Player balancing techniques attempt to assist the weaker player and make games more competitive, but these techniques have limitations for deployment when skill levels vary substantially. We developed new player balancing schemes to deal with a range of FPS skill difference, and tested these techniques in one-on-one deathmatches using a commercial-quality FPS game developed with the UDK engine. Our results showed that the new balancing schemes are extremely effective at balancing, even for players with large skill differences. Surprisingly, the techniques that were most effective at balancing were also rated as most enjoyable by both players -- even though these schemes were the most noticeable. Our study is the first to show that player balancing can work well in realistic FPS games, providing developers with a way to increase the audience for this popular genre. In addition, our results demonstrate the idea that successful balancing is as much about the way the technique is applied as it is about the specific manipulation."
    },
    {
        "title": "All about that Base: Differing Player Experiences in Video Game Genres and the Unique Case of MOBA Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Player Performance & Experience in Games",
        "data": "April 2015",
        "authors": [
            "Daniel Johnson",
            "Lennart E. Nacke",
            "Peta Wyeth"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702447",
        "citation": "68",
        "abstract": "Video games provide unique interactive player experiences (PX) often categorised into different genres. Prior research has looked at different game genres, but rarely through a PX lens. Especially, PX in the emerging area of massive online battle arena (MOBA) games is not well understood by researchers in the field. We address this knowledge gap by presenting a PX study of different game genres, which we followed up with a second semi-structured interview study about PX in MOBA games. Among the results of our analyses are that games that are likely played with other players, such as MOBA games, stimulate less immersion and presence for players. Additionally, while challenge and frustration are significantly higher in this genre, players get a sense of satisfaction from teamwork, competition and mastery of complex gameplay interactions. Our study is the first to contribute a comprehensive insight into key motivators of MOBA players and how PX in this genre is different from other genres."
    },
    {
        "title": "Session details: Neighborhoods & Disadvantaged Communities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Neighborhoods & Disadvantaged Communities",
        "data": "April 2015",
        "authors": [
            "Katharina Reinecke"
        ],
        "DOI": "https://doi.org/10.1145/3251733",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Exploring Learning Ecologies among People Experiencing Homelessness",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Neighborhoods & Disadvantaged Communities",
        "data": "April 2015",
        "authors": [
            "Angelika Strohmayer",
            "Rob Comber",
            "Madeline Balaam"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702157",
        "citation": "16",
        "abstract": "Non-homeless youths outperform their homeless peers in school even if they live in extreme poverty. This disadvantage can have long-term consequences for engagement with and navigation of wider society. In this paper we examine how differences in achievement could be tackled outside of school through the re-envisioning of ecologies of digital education. Through interviews, design workshops, and a street visit with a total of 20 homeless young adults during a three-week engagement with a centre for people of low social stability in Bucharest, Romania, we examine the perceptions of education among street involved youth or adults. We identify the core values, aspirations, opportunities and barriers for education among these people, including survival, friendship, learning networks, and curiosity. These findings resulted in five implications for design: learning \"happens\", learning \"works\", designing for distanced learning, designing for the social politics of learning, and designing artefacts of everyday learning. These show the importance and necessity of educational reform in the field of HCI."
    },
    {
        "title": "The Promise of the Sharing Economy among Disadvantaged Communities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Neighborhoods & Disadvantaged Communities",
        "data": "April 2015",
        "authors": [
            "Tawanna R. Dillahunt",
            "Amelia R. Malone"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702189",
        "citation": "156",
        "abstract": "The digital-sharing economy presents opportunities for individuals to find temporary employment, generate extra income, increase reciprocity, enhance social interaction, and access resources not otherwise attainable. Although the sharing economy is profitable, little is known about its use among the unemployed or those struggling financially. This paper describes the results of a participatory-design based workshop to investigate the perception and feasibility of finding temporary employment and sharing spare resources using sharing-economy applications. Specifically, this study included 20 individuals seeking employment in a U.S. city suffering economic decline. We identify success factors of the digital-sharing economy to these populations, identify shortcomings and propose mitigation strategies based on prior research related to trust, social capital and theories of collective efficacy. Finally, we contribute new principles that may foster collaborative consumption within this population and identify new concepts for practical employment applications among these populations."
    },
    {
        "title": "Practice-based Design of a Neighborhood Portal: Focusing on Elderly Tenants in a City Quarter Living Lab",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Neighborhoods & Disadvantaged Communities",
        "data": "April 2015",
        "authors": [
            "Claudia Müller",
            "Dominik Hornung",
            "Theodor Hamm",
            "Volker Wulf"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702449",
        "citation": "25",
        "abstract": "This paper contributes to the current discourse on practice-based research in HCI paying particular attention to the overall temporal and situational conditions which frame an R&D project. We present a Living Lab study situated in an arbitrary neighborhood of a German city which develops ICT support to foster informal help and social interaction with a special, but not exclusive, focus on elderly tenants. We demonstrate that practice-based, long-term research in a city quarter goes beyond those challenges already described in the current Living Lab and PD literature. The long-term study's positioning in a real-world context is contoured not only by a high diversity of stakeholders and their individual interests and motivation for participation but also by their individual skill sets and learning needs. These distinct and often contradictive perspectives have to be permanently counterbalanced. Thus attention has to be focused on how related strategies and decisions impact on the design of the project as well as on the final ICT product. To enable all tenants, irrespective of age and technical skill, to participate in a long-term ICT-based community development project, we applied the format of 'experience-based PD workshops' to foster confidence in ICT usage and encourage the competency of the elderly and non-tech-savvy tenants."
    },
    {
        "title": "This Digital Life: A Neighborhood-Based Study of Adolescents' Lives Online",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Neighborhoods & Disadvantaged Communities",
        "data": "April 2015",
        "authors": [
            "Jessica A. Pater",
            "Andrew D. Miller",
            "Elizabeth D. Mynatt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702534",
        "citation": "28",
        "abstract": "In this paper, we present the results of a multi-year study of the social computing practices of 179 adolescents (Mage=12.4 years, SD=1.3; range: 10-14) living in a majority-minority lower-income urban neighborhood in the Southeast U.S. We investigate shifting social media practices using annual surveys and focus groups. We describe participants' social media use and motivations and show how that use has shifted over time. We show how participants identify social pressures and influences as well as specific behaviors including computer-mediated risky behaviors and self-harm. We discuss the implications of our findings for the CHI research community, including methodological challenges and the need for further study of computer-mediated harmful behaviors in youth populations. By demonstrating how large-scale trends are enacted on the ground, we describe participants' uses, motivations and behaviors as they deal with the increasing influence of technology in their social lives."
    },
    {
        "title": "Session details: Enhanced Security with Passwords & CAPTCHAs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Enhanced Security with Passwords & CAPTCHAs",
        "data": "April 2015",
        "authors": [
            "Serge Egelman"
        ],
        "DOI": "https://doi.org/10.1145/3251734",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Towards Making Random Passwords Memorable: Leveraging Users' Cognitive Ability Through Multiple Cues",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Enhanced Security with Passwords & CAPTCHAs",
        "data": "April 2015",
        "authors": [
            "Mahdi Nasrullah Al-Ameen",
            "Matthew Wright",
            "Shannon Scielzo"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702241",
        "citation": "25",
        "abstract": "Given the choice, users produce passwords reflecting common strategies and patterns that ease recall but offer uncertain and often weak security. System-assigned passwords provide measurable security but suffer from poor memorability. To address this usability-security tension, we argue that systems should assign random passwords but also help with memorization and recall. We investigate the feasibility of this approach with CuedR, a novel cued-recognition authentication scheme that provides users with multiple cues (visual, verbal, and spatial) and lets them choose the cues that best fit their learning process for later recognition of system-assigned keywords. In our lab study, all 37 of our participants could log in within three attempts one week after registration (mean login time: 38.0 seconds). A pilot study on using multiple CuedR passwords also showed 100% recall within three attempts. Based on our results, we suggest appropriate applications for CuedR, such as financial and e-commerce accounts."
    },
    {
        "title": "ActivPass: Your Daily Activity is Your Password",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Enhanced Security with Passwords & CAPTCHAs",
        "data": "April 2015",
        "authors": [
            "Sourav Kumar Dandapat",
            "Swadhin Pradhan",
            "Bivas Mitra",
            "Romit Roy Choudhury",
            "Niloy Ganguly"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702457",
        "citation": "12",
        "abstract": "This paper explores the feasibility of automatically extracting passwords from a user's daily activity logs, such as her Facebook activity, phone activity etc. As an example, a smartphone might ask the user: \"Today morning from whom did you receive an SMS?\" In this paper, we observe that infrequent activities (i.e., outliers) can be memorable and unpredictable. Building on this observation, we have developed an end to end system ActivPass and experimented with 70 users. With activity logs from Facebook, browsing history, call logs, and SMSs, the system achieves 95% success (authenticates legitimate users) and is compromised in 5.5% cases (authenticates impostors). While this level of security is obviously inadequate for serious authentication systems, certain practices such as password sharing can immediately be thwarted from the dynamic nature of passwords. With security improvements in the future, activity-based authentication could fill in for the inadequacies in today's password-based systems."
    },
    {
        "title": "Constructing Secure Audio CAPTCHAs by Exploiting Differences between Humans and Machines",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Enhanced Security with Passwords & CAPTCHAs",
        "data": "April 2015",
        "authors": [
            "Hendrik Meutzner",
            "Santosh Gupta",
            "Dorothea Kolossa"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702127",
        "citation": "18",
        "abstract": "To prevent abuses of Internet services, CAPTCHAs are used to distinguish humans from programs where an audio-based scheme is beneficial to support visually impaired people. Previous studies show that most audio CAPTCHAs, albeit hard to solve for humans, are lacking security strength. In this work we propose an audio CAPTCHA that is far more robust against automated attacks than it is reported for current CAPTCHA schemes. The CAPTCHA exhibits a good trade-off between human usability and security. This is achieved by exploiting the fact that the human capabilities of language understanding and speech recognition are clearly superior compared to current machines. We evaluate the CAPTCHA security by using a state-of-the-art attack and assess the intelligibility by means of a large-scale listening experiment."
    },
    {
        "title": "Easy to Draw, but Hard to Trace?: On the Observability of Grid-based (Un)lock Patterns",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Enhanced Security with Passwords & CAPTCHAs",
        "data": "April 2015",
        "authors": [
            "Emanuel von Zezschwitz",
            "Alexander De Luca",
            "Philipp Janssen",
            "Heinrich Hussmann"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702202",
        "citation": "42",
        "abstract": "We performed a systematic evaluation of the shoulder surfing susceptibility of the Android pattern (un)lock. The results of an online study (n=298) enabled us to quantify the influence of pattern length, line visibility, number of knight moves, number of overlaps and number of intersections on observation resistance. The results show that all parameters have a highly significant influence, with line visibility and pattern length being most important. We discuss implications for real-world patterns and present a linear regression model that can predict the observability of a given pattern. The model can be used to provide proactive security measurements for (un)lock patterns, in analogy to password meters."
    },
    {
        "title": "On the Effectiveness of Pattern Lock Strength Meters: Measuring the Strength of Real World Pattern Locks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Enhanced Security with Passwords & CAPTCHAs",
        "data": "April 2015",
        "authors": [
            "Youngbae Song",
            "Geumhwan Cho",
            "Seongyeol Oh",
            "Hyoungshick Kim",
            "Jun Ho Huh"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702365",
        "citation": "38",
        "abstract": "We propose an effective pattern lock strength meter to help users choose stronger pattern locks on Android devices. To evaluate the effectiveness of the proposed meter with a real world dataset (i.e., with complete ecological validity), we created an Android application called EnCloud that allows users to encrypt their Dropbox files. 101 pattern locks generated by real EnCloud users were collected and analyzed, where some portion of the users were provided with the meter support. Our statistical analysis indicates that about 10% of the pattern locks that were generated without the meter support could be compromised through just 16 guessing attempts. As for the pattern locks that were generated with the meter support, that number goes up to 48 guessing attempts, showing significant improvement in security. Our recommendation is to implement a strength meter in the next version of Android."
    },
    {
        "title": "Session details: Accessibility at Home & on The Go",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility at Home & on The Go",
        "data": "April 2015",
        "authors": [
            "Hironobu Takagi"
        ],
        "DOI": "https://doi.org/10.1145/3251735",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "RegionSpeak: Quick Comprehensive Spatial Descriptions of Complex Images for Blind Users",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility at Home & on The Go",
        "data": "April 2015",
        "authors": [
            "Yu Zhong",
            "Walter S. Lasecki",
            "Erin Brady",
            "Jeffrey P. Bigham"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702437",
        "citation": "52",
        "abstract": "Blind people often seek answers to their visual questions from remote sources, however, the commonly adopted single-image, single-response model does not always guarantee enough bandwidth between users and sources. This is especially true when questions concern large sets of information, or spatial layout, e.g., where is there to sit in this area, what tools are on this work bench, or what do the buttons on this machine do? Our RegionSpeak system addresses this problem by providing an accessible way for blind users to (i) combine visual information across multiple photographs via image stitching, em (ii) quickly collect labels from the crowd for all relevant objects contained within the resulting large visual area in parallel, and (iii) then interactively explore the spatial layout of the objects that were labeled. The regions and descriptions are displayed on an accessible touchscreen interface, which allow blind users to interactively explore their spatial layout. We demonstrate that workers from Amazon Mechanical Turk are able to quickly and accurately identify relevant regions, and that asking them to describe only one region at a time results in more comprehensive descriptions of complex images. RegionSpeak can be used to explore the spatial layout of the regions identified. It also demonstrates broad potential for helping blind users to answer difficult spatial layout questions."
    },
    {
        "title": "FingerReader: A Wearable Device to Explore Printed Text on the Go",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility at Home & on The Go",
        "data": "April 2015",
        "authors": [
            "Roy Shilkrot",
            "Jochen Huber",
            "Wong Meng Ee",
            "Pattie Maes",
            "Suranga Chandima Nanayakkara"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702421",
        "citation": "62",
        "abstract": "Accessing printed text in a mobile context is a major challenge for the blind. A preliminary study with blind people reveals numerous difficulties with existing state-of-the-art technologies including problems with alignment, focus, accuracy, mobility and efficiency. In this paper, we present a finger-worn device, FingerReader, that assists blind users with reading printed text on the go. We introduce a novel computer vision algorithm for local-sequential text scanning that enables reading single lines, blocks of text or skimming the text with complementary, multimodal feedback. This system is implemented in a small finger-worn form factor, that enables a more manageable eyes-free operation with trivial setup. We offer findings from three studies performed to determine the usability of the FingerReader."
    },
    {
        "title": "Collaborative Accessibility: How Blind and Sighted Companions Co-Create Accessible Home Spaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility at Home & on The Go",
        "data": "April 2015",
        "authors": [
            "Stacy M. Branham",
            "Shaun K. Kane"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702511",
        "citation": "93",
        "abstract": "In recent decades, great technological strides have been made toward enabling people who are blind to live independent, successful lives. However, there has been relatively little progress towards understanding the social, collaborative needs of this population, particularly in the domestic setting. We conducted semi-structured interviews in the homes of 10 pairs of close companions in which one partner was blind and one was not. We found that partners engaged in collaborative accessibility by taking active roles in co-creating an accessible environment. Due to their different visual abilities, however, partners sometimes encountered difficulties managing divergent needs and engaging in shared experiences. We describe outstanding challenges to creating accessible shared home spaces and outline new research and technology opportunities for supporting collaborative accessibility in the home."
    },
    {
        "title": "Session details: Telepresence Video, Robots, and Walls",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Telepresence Video, Robots, and Walls",
        "data": "April 2015",
        "authors": [
            "John Tang"
        ],
        "DOI": "https://doi.org/10.1145/3251736",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "ImmerseBoard: Immersive Telepresence Experience using a Digital Whiteboard",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Telepresence Video, Robots, and Walls",
        "data": "April 2015",
        "authors": [
            "Keita Higuchi",
            "Yinpeng Chen",
            "Philip A. Chou",
            "Zhengyou Zhang",
            "Zicheng Liu"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702160",
        "citation": "32",
        "abstract": "ImmerseBoard is a system for remote collaboration through a digital whiteboard that gives participants a 3D immersive experience, enabled only by an RGBD camera (Microsoft Kinect) mounted on the side of a large touch display. Using 3D processing of the depth images, life-sized rendering, and novel visualizations, ImmerseBoard emulates writing side-by-side on a physical whiteboard, or alternatively on a mirror. User studies involving three tasks show that compared to standard video conferencing with a digital whiteboard, ImmerseBoard provides participants with a quantitatively better ability to estimate their remote partners' eye gaze direction, gesture direction, intention, and level of agreement. Moreover, these quantitative capabilities translate qualitatively into a heightened sense of being together and a more enjoyable experience. ImmerseBoard's form factor is suitable for practical and easy installation in homes and offices."
    },
    {
        "title": "Accuracy of Deictic Gestures to Support Telepresence on Wall-sized Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Telepresence Video, Robots, and Walls",
        "data": "April 2015",
        "authors": [
            "Ignacio Avellino",
            "Cédric Fleury",
            "Michel Beaudouin-Lafon"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702448",
        "citation": "10",
        "abstract": "This paper presents a controlled experiment assessing the accuracy when interpreting remote users showing a shared object on a large wall-sized display, either by looking at it or by looking and pointing at it. We analyze both distance and angle errors and how they are sensitive to the relative position be- tween the remote viewer and the video feed. We show that the remote user can accurately determine the target, that eye gaze alone is more accurate than combined with the hand, and that the relative position between the viewer and the video feed has little effect on accuracy. These findings can inform the design of future telepresence systems for wall-sized displays."
    },
    {
        "title": "Can You See Me Now?: How Field of View Affects Collaboration in Robotic Telepresence",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Telepresence Video, Robots, and Walls",
        "data": "April 2015",
        "authors": [
            "Steven Johnson",
            "Irene Rae",
            "Bilge Mutlu",
            "Leila Takayama"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702526",
        "citation": "46",
        "abstract": "Robotic telepresence systems-videoconferencing systems that allow a remote user to drive around in another location-are an emerging technology for supporting geographically-distributed teams. Thus far, many of these systems rely on affordances designed for stationary systems, such as a single, narrow-view camera to provide vision for the remote user. Teleoperation has offered some solutions to this via an augmented field-of-view, but how these solutions support task outcomes in collaborative mobile telepresence tasks has yet to be understood. To investigate this, we conducted a three condition (field-of-view: narrow (45°) vs. wide-angle (180°) vs. panoramic (360°)) between-participants controlled laboratory experiment. We asked participants (N=24) to collaborate with a confederate via a robotic telepresence system while using one of these views in a redecoration task. Our results showed that wider views supported task efficiency and fewer collisions, but were perceived as more difficult to use."
    },
    {
        "title": "Session details: Experience Design for Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Experience Design for Games",
        "data": "April 2015",
        "authors": [
            "Florian \"Floyd\" Mueller"
        ],
        "DOI": "https://doi.org/10.1145/3251737",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Automatic Game Progression Design through Analysis of Solution Features",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Experience Design for Games",
        "data": "April 2015",
        "authors": [
            "Eric Butler",
            "Erik Andersen",
            "Adam M. Smith",
            "Sumit Gulwani",
            "Zoran Popović"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702330",
        "citation": "22",
        "abstract": "A long-term goal of game design research is to achieve end-to-end automation of much of the design process, one aspect of which is creating effective level progressions. A key difficulty is getting the player to practice with interesting combinations of learned skills while maintaining their engagement. Although recent work in task generation and sequencing has reduced this effort, we still lack end-to-end automation of the entire content design process. We approach this goal by incorporating ideas from intelligent tutoring systems and proposing progression strategies that seek to achieve mastery of not only base concepts but arbitrary combinations of these concepts. The input to our system is a model of what the player needs to do to complete each level, expressed as either an imperative procedure for producing solutions or a representation of features common to all solutions. The output is a progression of levels that can be adjusted by changing high-level parameters. We apply our framework to a popular math puzzle game and present results from 2,377 players showing that our automatic level progression is comparable to expert-crafted progression after a few design iterations based on a key engagement metric."
    },
    {
        "title": "Pass the Ball: Enforced Turn-Taking in Activity Tracking",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Experience Design for Games",
        "data": "April 2015",
        "authors": [
            "John Rooksby",
            "Mattias Rost",
            "Alistair Morrison",
            "Matthew Chalmers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702577",
        "citation": "29",
        "abstract": "We have developed a mobile application called Pass The Ball that enables users to track, reflect on, and discuss physical activity with others. We followed an iterative design process, trialling a first version of the app with 20 people and a second version with 31. The trials were conducted in the wild, on users' own devices. The second version of the app enforced a turn-taking system that meant only one member of a group of users could track their activity at any one time. This constrained tracking at the individual level, but more successfully led users to communicate and interact with each other. We discuss the second trial with reference to two concepts: social-relatedness and individual-competence. We discuss six key lessons from the trial, and identify two high-level design implications: attend to \"practices\" of tracking; and look within and beyond \"collaboration\" and \"competition\" in the design of activity trackers."
    },
    {
        "title": "The Data Driven Lives of Wargaming Miniatures",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Experience Design for Games",
        "data": "April 2015",
        "authors": [
            "Dimitrios Paris Darzentas",
            "Michael A. Brown",
            "Martin Flintham",
            "Steve Benford"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702377",
        "citation": "15",
        "abstract": "We present an ethnographic study of the practice of miniature wargaming in order to shed light onto the complex lives of physical things and the ways in which they acquire data footprints. We take an extended view of the practice, revealing how people invest great effort into crafting miniatures, playing with them, curating and telling stories about them, and passing them on. Throughout, we emphasise the use of both traditional and digital technologies to build rich data footprints. In discussing our findings, we adopt a \"thing-centric\" perspective that focuses on the extended lifetimes of the miniatures themselves. This enables us to identify opportunities for digital augmentation in support of capturing \"life away from the table\" and a need for HCI to focus on designing trajectories of things."
    },
    {
        "title": "Provenance for the People: An HCI Perspective on the W3C PROV Standard through an Online Game",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Experience Design for Games",
        "data": "April 2015",
        "authors": [
            "Khaled Bachour",
            "Richard Wetzel",
            "Martin Flintham",
            "Trung Dong Huynh",
            "Tom Rodden",
            "Luc Moreau"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702455",
        "citation": "8",
        "abstract": "In the information age, tools for examining the validity of data are invaluable. Provenance is one such tool, and the PROV model proposed by the World Wide Web Consortium in 2013 offers a means of expressing provenance in a machine readable format. In this paper, we examine from a user's standpoint notions of provenance, the accessibility of the PROV model, and the general attitudes towards history and the verifiability of information in modern data society. We do this through the medium of an online-game designed to explore these issues and present the findings of the study along with a discussion of some of its implications."
    },
    {
        "title": "Session details: Digital & Materials Fabrication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital & Materials Fabrication",
        "data": "April 2015",
        "authors": [
            "Stefanie Mueller"
        ],
        "DOI": "https://doi.org/10.1145/3251738",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Foundations of Materials Experience: An Approach for HCI",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital & Materials Fabrication",
        "data": "April 2015",
        "authors": [
            "Elisa Giaccardi",
            "Elvin Karana"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702337",
        "citation": "124",
        "abstract": "A growing number of HCI scholars have started to take materiality as an entry point for acquiring a deeper understanding of the possibilities and constraints of design. Steadily moving beyond a distinction between the physical and the digital, a few have also started to look at materials as part of the unfolding of social and cultural practices. Yet, to date, relatively little is known about how these practices develop within the situated experience of materials, and how this situational whole can be supported by design. By contributing to both growing materiality scholarship and emerging practice-oriented approaches in HCI, this paper articulates a framework of materials experience that discusses how materials shape ways of doing and ultimately, practice, and how this is rooted in the experience of those materials."
    },
    {
        "title": "PaperPulse: An Integrated Approach for Embedding Electronics in Paper Designs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital & Materials Fabrication",
        "data": "April 2015",
        "authors": [
            "Raf Ramakers",
            "Kashyap Todi",
            "Kris Luyten"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702487",
        "citation": "47",
        "abstract": "We present PaperPulse, a design and fabrication approach that enables designers without a technical background to produce standalone interactive paper artifacts by augmenting them with electronics. With PaperPulse, designers overlay pre-designed visual elements with widgets available in our design tool. PaperPulse provides designers with three families of widgets designed for smooth integration with paper, for an overall of 20 different interactive components. We also contribute a logic demonstration and recording approach, Pulsation, that allows for specifying functional relationships between widgets. Using the final design and the recorded Pulsation logic, PaperPulse generates layered electronic circuit designs, and code that can be deployed on a microcontroller. By following automatically generated assembly instructions, designers can seamlessly integrate the microcontroller and widgets in the final paper artifact."
    },
    {
        "title": "Data-Things: Digital Fabrication Situated within Participatory Data Translation Activities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital & Materials Fabrication",
        "data": "April 2015",
        "authors": [
            "Bettina Nissen",
            "John Bowers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702245",
        "citation": "42",
        "abstract": "This paper explores a design-led approach to digital fabrication which situates it in participatory data translation activities to demonstrate that this technology can find application beyond its use as tool for manufacture. We present two contrasting design contexts in which, respectively, data from conference twitter conversations and craft practitioners' movements are translated into interactively generated and fabricated physical artefacts. We argue that direct involvement in such digital fabrication activities can help people invest meaning into artefacts and facilitate social interaction and reflection upon their activities, while encouraging practitioners to incorporate new forms into their own work. On this basis, we reconsider digital fabrication within data translation activities as situated along an extended 'trajectory of use' in which reflective, meaningful 'data-things' can be created."
    },
    {
        "title": "Being the Machine: Reconfiguring Agency and Control in Hybrid Fabrication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital & Materials Fabrication",
        "data": "April 2015",
        "authors": [
            "Laura Devendorf",
            "Kimiko Ryokai"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702547",
        "citation": "87",
        "abstract": "This paper details the design and evaluation of Being the Machine, a portable digital fabrication system that places digital fabrication activity outside of the traditional fab lab environment. Being the Machine invites people to (re)consider materials found in their everyday and personal environment as part of the fabrication activity. We expand the design space involving hybrid (physical-digital) fabrication by describing how our system draws from art to support critical and reflective modes of making. In interaction with our system, participants distributed control between human and machine actors to support their preferred mode of making. These patterns reveal new opportunities and challenges for future hybrid fabrication systems, and suggest that designing for qualities of experience, like meditation and reflection, could support meaningful making experiences for many different kinds of makers."
    },
    {
        "title": "Session details: Tactile Notifications for Phones & Wearables",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tactile Notifications for Phones & Wearables",
        "data": "April 2015",
        "authors": [
            "Max Wilson"
        ],
        "DOI": "https://doi.org/10.1145/3251739",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "OmniVib: Towards Cross-body Spatiotemporal Vibrotactile Notifications for Mobile Phones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tactile Notifications for Phones & Wearables",
        "data": "April 2015",
        "authors": [
            "Jessalyn Alvina",
            "Shengdong Zhao",
            "Simon T. Perrault",
            "Maryam Azh",
            "Thijs Roumen",
            "Morten Fjeld"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702341",
        "citation": "32",
        "abstract": "Previous works illustrate that one's palm can reliably recognize 10 or more spatiotemporal vibrotactile patterns. However, recognition of the same patterns on other body parts is unknown. In this paper, we investigate how users perceive spatiotemporal vibrotactile patterns on the arm, palm, thigh, and waist. Results of the first two experiments indicate that precise recognition of either position or orientation is difficult across multiple body parts. Nonetheless, users were able to distinguish whether two vibration pulses were from the same location when played in quick succession. Based on this finding, we designed eight spatiotemporal vibrotactile patterns and evaluated them in two additional experiments. The results demonstrate that these patterns can be reliably recognized (>80%) across the four tested body parts, both in the lab and in a more realistic context."
    },
    {
        "title": "NotiRing: A Comparative Study of Notification Channels for Wearable Interactive Rings",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tactile Notifications for Phones & Wearables",
        "data": "April 2015",
        "authors": [
            "Thijs Roumen",
            "Simon T. Perrault",
            "Shengdong Zhao"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702350",
        "citation": "58",
        "abstract": "We conducted an empirical investigation of wearable interactive rings on the noticeability of four instantaneous notification channels (light, vibration, sound, poke) and a channel with gradually increased temperature (thermal) during five levels of physical activity (laying down, sitting, standing, walking, and running). Results showed that vibration was the most reliable and fastest channel to convey notification, followed by poke and sound which shared similar noticeability. The noticeability of these three channels was not affected by the level of physical activity. The other two channels, light and thermal, were less noticeable and were affected by the level of physical activity. Our post-experimental survey indicates that while noticeability has a significant influence on user preference, each channel has its own unique advantages that make it suitable for different notification scenarios."
    },
    {
        "title": "Skin Drag Displays: Dragging a Physical Tactor across the User's Skin Produces a Stronger Tactile Stimulus than Vibrotactile",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tactile Notifications for Phones & Wearables",
        "data": "April 2015",
        "authors": [
            "Alexandra Ion",
            "Edward Jay Wang",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702459",
        "citation": "69",
        "abstract": "We propose a new type of tactile displays that drag a physical tactor across the skin in 2D. We call this skin drag. We demonstrate how this allows us to communicate geometric shapes or characters to users. The main benefit of our approach is that it simultaneously produces two types of stimuli, i.e., (1) it moves a tactile stimulus across skin locations and (2) it stretches the user's skin. Skin drag thereby combines the essential stimuli produced by vibrotactile and skin stretch. In our study, skin drag allowed participants to recognize tactile shapes significantly better than a vibrotactile array of comparable size. We present two arm-worn prototype devices that implement our concept."
    },
    {
        "title": "Cruise Control for Pedestrians: Controlling Walking Direction using Electrical Muscle Stimulation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tactile Notifications for Phones & Wearables",
        "data": "April 2015",
        "authors": [
            "Max Pfeiffer",
            "Tim Dünte",
            "Stefan Schneegass",
            "Florian Alt",
            "Michael Rohs"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702190",
        "citation": "115",
        "abstract": "Pedestrian navigation systems require users to perceive, interpret, and react to navigation information. This can tax cognition as navigation information competes with information from the real world. We propose actuated navigation, a new kind of pedestrian navigation in which the user does not need to attend to the navigation task at all. An actuation signal is directly sent to the human motor system to influence walking direction. To achieve this goal we stimulate the sartorius muscle using electrical muscle stimulation. The rotation occurs during the swing phase of the leg and can easily be counteracted. The user therefore stays in control. We discuss the properties of actuated navigation and present a lab study on identifying basic parameters of the technique as well as an outdoor study in a park. The results show that our approach changes a user's walking direction by about 16°/m on average and that the system can successfully steer users in a park with crowded areas, distractions, obstacles, and uneven ground."
    },
    {
        "title": "Affordance++: Allowing Objects to Communicate Dynamic Use",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Tactile Notifications for Phones & Wearables",
        "data": "April 2015",
        "authors": [
            "Pedro Lopes",
            "Patrik Jonell",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702128",
        "citation": "104",
        "abstract": "We propose extending the affordance of objects by allowing them to communicate dynamic use, such as (1) motion (e.g., spray can shakes when touched), (2) multi-step processes (e.g., spray can sprays only after shaking), and (3) behaviors that change over time (e.g., empty spray can does not allow spraying anymore). Rather than enhancing objects directly, however, we implement this concept by enhancing the user. We call this affordance++. By stimulating the user's arms using electrical muscle stimulation, our prototype allows objects not only to make the user actuate them, but also perform required movements while merely approaching the object, such as not to touch objects that do not \"want\" to be touched. In our user study, affordance++ helped participants to successfully operate devices of poor natural affordance, such as a multi-functional slicer tool or a magnetic nail sweeper, and to stay away from cups filled with hot liquids."
    },
    {
        "title": "Session details: Automation and Interactive Feedback",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automation and Interactive Feedback",
        "data": "April 2015",
        "authors": [
            "Davide Spano"
        ],
        "DOI": "https://doi.org/10.1145/3251740",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "\"Automation Surprise\" in Aviation: Real-Time Solutions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automation and Interactive Feedback",
        "data": "April 2015",
        "authors": [
            "Frederic Dehais",
            "Vsevolod Peysakhovich",
            "Sébastien Scannella",
            "Jennifer Fongue",
            "Thibault Gateau"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702521",
        "citation": "37",
        "abstract": "Conflicts between the pilot and the automation, when pilots detect but do not understand them, cause \"automation surprise\" situations and jeopardize flight safety. We conducted an experiment in a 3-axis motion flight simulator with 16 pilots equipped with an eye-tracker to analyze their behavior and eye movements during the occurrence of such a situation. The results revealed that this conflict engages participant's attentional abilities resulting in excessive and inefficient visual search patterns. This experiment confirmed the crucial need to design solutions for detecting the occurrence of conflictual situations and to assist the pilots. We therefore proposed an approach to formally identify the occurrence of \"automation surprise\" conflicts based on the analysis of \"silent mode changes\" of the autopilot. A demonstrator was implemented and allowed for the automatic trigger of messages in the cockpit that explains the autopilot behavior. We implemented a real-time demonstrator that was tested as a proof-of-concept with 7 subjects facing 3 different conflicts with automation. The results shown the efficacy of this approach which could be implemented in existing cockpits."
    },
    {
        "title": "The Role of Environmental Predictability and Costs in Relying on Automation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automation and Interactive Feedback",
        "data": "April 2015",
        "authors": [
            "Steven C. Sutherland",
            "Casper Harteveld",
            "Michael E. Young"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702609",
        "citation": "7",
        "abstract": "There is a growing need to understand how automated decision aids are implemented and relied upon by users. Past research has focused on factors associated with the user and automation technology to explain reliance. The purpose of the present study was determining how the predictability of the environment affects reliance. In this paper, we present the results from an experiment using a digital game where participants had access to a free environmental cue of varying predictive validity. Some participants also had access to automated advice at varying costs. We found that participants underutilized automated advice in more predictable environments and when advice was more costly; however, when costs were low and the environment was less predictable, participants tended to overutilize automated advice. These findings provide insights for a more complete model of automation use, and offer a framework for understanding automation biases by considering how automation use compares to a model of optimality."
    },
    {
        "title": "An Architecture for Generating Interactive Feedback in Probabilistic User Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automation and Interactive Feedback",
        "data": "April 2015",
        "authors": [
            "Julia Schwarz",
            "Jennifer Mankoff",
            "Scott E. Hudson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702228",
        "citation": "8",
        "abstract": "Increasingly natural, sensed, and touch-based input is being integrated into devices. Along the way, both custom and more general solutions have been developed for dealing with the uncertainty that is associated with these forms of input. However, it is difficult to provide dynamic, flexible, and continuous feedback about uncertainty using traditional interactive infrastructure. Our contribution is a general architecture with the goal of providing support for continual feedback about uncertainty. Our architecture is based on prior work in modeling uncertainty using Monte Carlo sampling, and tracks multiple interfaces -- one for each plausible and differentiable sequence of input that the user may have intended. Importantly, it considers how the presentation of uncertainty can be organized and implemented in a general way. Our primary contribution is a method for reducing the number of alternative interfaces and fusing possible interfaces into a single interface that both communicates uncertainty and allows for disambiguation. We demonstrate the value of this result through a collection of 11 new and existing feedback techniques along with two applications demonstrating the use of the feedback architecture."
    },
    {
        "title": "IDSense: A Human Object Interaction Detection System Based on Passive UHF RFID",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automation and Interactive Feedback",
        "data": "April 2015",
        "authors": [
            "Hanchuan Li",
            "Can Ye",
            "Alanson P. Sample"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702178",
        "citation": "123",
        "abstract": "In order to enable unobtrusive human object interaction detection, we propose a minimalistic approach to instrumenting everyday objects with passive (i.e. battery-free) UHF RFID tags. By measuring the changes in the physical layer of the communication channel between the RFID tag and reader (such as RSSI, RF phase, and read rate) we are able to classify, in real time, tag/object motion events along with two types of touch events. Through a user study, we demonstrate that our real-time classification engine is able to simultaneously track 20 objects and identify four movement classes with 93% accuracy. To demonstrate how robust this general-purpose interaction mechanism is, we investigate three usage scenarios 1) interactive storytelling with toys 2) inference of daily activities in the home 3) identification of customer browsing habits in a retail setting."
    },
    {
        "title": "Session details: Art & Performance",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Art & Performance",
        "data": "April 2015",
        "authors": [
            "Thecla Schiphorst"
        ],
        "DOI": "https://doi.org/10.1145/3251741",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "What if HCI Becomes a Fashion Driven Discipline?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Art & Performance",
        "data": "April 2015",
        "authors": [
            "Yue Pan",
            "Erik Stolterman"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702544",
        "citation": "8",
        "abstract": "Recent research shows that fashion already exists in the HCI domain and influences and affects design and designers' thinking and practices throughout the design process. In this note, we draw our insights from fashion related research within HCI and interaction design, provide some observations about fashion-related design and research practices, raise questions about our field as moving forward towards fashion driven discipline."
    },
    {
        "title": "The Smartphone Project: An Augmented Dance Performance",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Art & Performance",
        "data": "April 2015",
        "authors": [
            "Leif Oppermann",
            "Clemens Putschli",
            "Constantin Brosda",
            "Oleksandr Lobunets",
            "Fabien Prioville"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702538",
        "citation": "5",
        "abstract": "The Smartphone Project (TSP) is an interactive dance-performance in a professional setting that exploits the communication channels provided by smartphone-apps as a new material in the dance-theatre domain. We present an account of the experience and its staging. Based on an initial study with 36 participants from the audience, we present results and discuss lessons learned from this project that might guide similar future work."
    },
    {
        "title": "I'd Hide You: Performing Live Broadcasting in Public",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Art & Performance",
        "data": "April 2015",
        "authors": [
            "Stuart Reeves",
            "Christian Greiffenhagen",
            "Martin Flintham",
            "Steve Benford",
            "Matt Adams",
            "Ju Row Farr",
            "Nicholas Tandavantij"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702257",
        "citation": "25",
        "abstract": "We present a study of a mixed reality game called 'I'd Hide You' that involves live video streaming from the city streets. We chart the significant challenges facing performers on the streets who must simultaneously engage in the game, stream compelling video footage featuring themselves, and interact with a remote online audience. We reveal how these street performers manage four key tensions: between their body and camera; between the demands of online audiences and what takes place on-the-street; between what appears 'frontstage' on camera versus what happens 'backstage'; and balancing being a player of the game with being a performer. By reflecting on how they achieve this, we are able to draw out wider lessons for future interfaces aimed at supporting people broadcasting video of themselves to online audiences while engaged in games, sports and other demanding real-world activities."
    },
    {
        "title": "Making the Invisible Visible: Design to Support the Documentation of Participatory Arts Experiences",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Art & Performance",
        "data": "April 2015",
        "authors": [
            "Jonathan Hook",
            "Rachel Clarke",
            "John McCarthy",
            "Kate Anderson",
            "Jane Dudman",
            "Peter Wright"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702187",
        "citation": "17",
        "abstract": "We explore how digital technology might support the documentation of experiences of participatory arts engagement. During a fourteen session workshop series, we worked with artists, project managers, support workers and participants to explore the integration of digital media capture and presentation technologies into participatory arts workshops, and the implications that this would have for the experiences and practices of key stakeholders involved. We contribute insight into the social and practical challenges faced when using digital technology to create documentation of participatory arts. Our findings highlight the importance of situating documentation, sense making and re-telling of experiences in sensitive contexts such as participatory arts within the practices of skilled interpreters that are mindful of the complexities involved."
    },
    {
        "title": "Trap it!: A Playful Human-Biology Interaction for a Museum Installation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Art & Performance",
        "data": "April 2015",
        "authors": [
            "Seung Ah Lee",
            "Engin Bumbacher",
            "Alice M. Chung",
            "Nate Cira",
            "Byron Walker",
            "Ji Young Park",
            "Barry Starr",
            "Paulo Blikstein",
            "Ingmar H. Riedel-Kruse"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702220",
        "citation": "41",
        "abstract": "We developed Trap it!, a human-biology interaction (HBI) medium encompassing a touchscreen interface, microscopy, and light projection. Users can interact with living cells by drawing on a touchscreen displaying the microscope view of the cells. These drawings are projected onto the microscopy field as light patterns, prompting observable movement in phototactic responses. The system design enables stable and robust HBI and a wide variety of programmed activities (art, games, and experiments). We investigated its affordances as an exhibit in a science museum in both facilitated and unfacilitated contexts. Overall, it had a low barrier of entry and fostered rich communication among visitors. Visitors were particularly excited upon realizing that the interaction involved real organisms, an understanding that was facilitated by the eyepiece on the physical system. With the results from user study, we provide our observations, insights and guidelines for designing HBI as a permanent museum exhibit."
    },
    {
        "title": "Session details: Bridging People & Beliefs with Social Media",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging People & Beliefs with Social Media",
        "data": "April 2015",
        "authors": [
            "N. Sadat Shami"
        ],
        "DOI": "https://doi.org/10.1145/3251742",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Modeling Ideology and Predicting Policy Change with Social Media: Case of Same-Sex Marriage",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging People & Beliefs with Social Media",
        "data": "April 2015",
        "authors": [
            "Amy X. Zhang",
            "Scott Counts"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702193",
        "citation": "13",
        "abstract": "Social media has emerged as a prominent platform where people can express their feelings about social and political issues of our time. We study the many voices discussing an issue within a constituency and how they reflect ideology and may signal the outcome of important policy decisions. Focusing on the issue of same-sex marriage legalization, we examine almost 2 million public Twitter posts related to same-sex marriage in the U.S. states over the course of 4 years starting from 2011. Among other findings, we find evidence of moral culture wars between ideologies and show that constituencies that express higher levels of emotion and have fewer actively engaged participants often precede legalization efforts that fail. From our measures, we build statistical models to predict the outcome of potential policy changes, with our best model achieving 87% accuracy. We also achieve accuracies of 70%, comparable to public opinion surveys, many months before a policy decision. We discuss how these analyses can augment traditional political science techniques as well as assist activists and policy analysts in understanding discussions on important issues at a population scale."
    },
    {
        "title": "\"Is it Weird to Still Be a Virgin\": Anonymous, Locally Targeted Questions on Facebook Confession Boards",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging People & Beliefs with Social Media",
        "data": "April 2015",
        "authors": [
            "Jeremy Birnholtz",
            "Nicholas Aaron Ross Merola",
            "Arindam Paul"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702410",
        "citation": "40",
        "abstract": "People have long sought answers to questions online, typically using either anonymous or pseudonymous forums or social network platforms that primarily use real names. Systems that allow anonymous communication afford freedom to explore identity and discuss taboo topics, but can result in negative disinhibited behavior such as cyberbullying. Identifiable communication systems allows one to reach a known audience and avoid negative disinhibition, but can constrain behavior with concerns about privacy and reputation. One persistent design issue is understanding how to leverage the benefits of anonymity without suffering its drawbacks. This paper presents a case study analysis of question asking on Facebook confession boards (FCBs), a tool popular on some college campuses. FCBs present a unique configuration in which members of an offline community (e.g., a university) anonymously submit content to a moderator who posts it to a Facebook page where others in the community can view it and respond. Response is via identifiable Facebook comments and likes. Our results show users asking about taboo and stigmatized topics with local others, and receiving relevant responses with little cyberbullying or negativity."
    },
    {
        "title": "Social Media Dynamics of Global Co-presence During the 2014 FIFA World Cup",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging People & Beliefs with Social Media",
        "data": "April 2015",
        "authors": [
            "Jae Won Kim",
            "Dongwoo Kim",
            "Brian Keegan",
            "Joon Hee Kim",
            "Suin Kim",
            "Alice Oh"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702317",
        "citation": "12",
        "abstract": "Sporting championships and other media events can induce very strong feelings of co-presence that can change communication patterns within large communities. Live tweeting reactions to media events provide high-resolution data with time-stamps to understand these behavioral dynamics. We employ a computational focus group method to identify a population of 790,744 international Twitter users, and we track their behavior before, during, and after the 2014 FIFA World Cup. We pick, in particular, a set of Twitter users who specified the teams that they are supporting, such that we can identify communities of fans of the teams, as well as the entire community of World Cup fans. The structure, dynamics, and content of communication of these communities of users are analyzed to compare behavior outside of the matches to behavior during the event and to examine behavioral responses across languages. Specifically, the temporal patterns of the tweeting volume, topics, retweet- ing, and mentioning behaviors are analyzed. We find there are similarities in the responses to media events, characteristic changes in activity patterns of users, and substantial differences in linguistic features. These findings have implications for designing more resilient socio-technical systems during crises and developing better models of complex social behavior."
    },
    {
        "title": "Bridges into the Unknown: Personalizing Connections to Little-known Countries",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging People & Beliefs with Social Media",
        "data": "April 2015",
        "authors": [
            "Yelena Mejova",
            "Javier Borge-Holthoefer",
            "Ingmar Weber"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702152",
        "citation": "3",
        "abstract": "How are you related to Malawi? Do recent events on the Comoros effect you in any subtle way? Who in your extended social network is in Croatia? We seldom ask ourselves these questions, yet a \"long tail\" of content beyond our everyday knowledge is waiting to be explored. In this work we propose a recommendation task of creating interest in little-known content by building personalized \"bridges\" to users. We consider an example task of interesting users in little-known countries, and propose a system which aggregates a user's Twitter profile, network, and tweets to create an interest model, which is then matched to a library of knowledge about the countries. We perform a user study of 69 participants and conduct 11 in-depth interviews in order to evaluate the efficacy of the proposed approach and gather qualitative insight into the effect of multi-faceted use of Twitter on the perception of the bridges. We find the increase in interest concerning little-known content to greatly depend on the pre-existing disposition to it. Additionally, we discover a set of vital properties good bridges must possess, including recency, novelty, emotiveness, and a proper selection of language. Using the proposed approach we aim to harvest the \"invisible connections\" to make explicit the idea of a \"small world\" where even a faraway country is more closely connected to you than you might have imagined."
    },
    {
        "title": "Session details: Quantified Self for Humans & Pets",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Quantified Self for Humans & Pets",
        "data": "April 2015",
        "authors": [
            "Rodrigo de Oliveira"
        ],
        "DOI": "https://doi.org/10.1145/3251743",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Change of Heart: Emotion Tracking to Promote Behavior Change",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Quantified Self for Humans & Pets",
        "data": "April 2015",
        "authors": [
            "Victoria Hollis",
            "Artie Konrad",
            "Steve Whittaker"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702196",
        "citation": "32",
        "abstract": "Preventable behaviors contribute to many life threatening health problems. Behavior-change technologies have been deployed to modify these, but such systems typically draw on traditional behavioral theories that overlook affect. We examine the importance of emotion tracking for behavior change. First, we conducted interviews to explore how emotions influence unwanted behaviors. Next, we deployed a system intervention, in which 35 participants logged information for a self-selected, unwanted behavior (e.g., smoking or overeating) over 21 days. 16 participants engaged in standard behavior tracking using a Fact-Focused system to record objective information about goals. 19 participants used an Emotion-Focused system to record emotional consequences of behaviors. Emotion-Focused logging promoted more successful behavior change and analysis of logfiles revealed mechanisms for success: greater engagement of negative affect for unsuccessful days and increased insight were key to motivating change. We present design implications to improve behavior-change technologies with emotion tracking."
    },
    {
        "title": "Beyond Self-Tracking and Reminders: Designing Smartphone Apps That Support Habit Formation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Quantified Self for Humans & Pets",
        "data": "April 2015",
        "authors": [
            "Katarzyna Stawarz",
            "Anna L. Cox",
            "Ann Blandford"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702230",
        "citation": "138",
        "abstract": "Habit formation is an important part of behavior change interventions: to ensure an intervention has long-term effects, the new behavior has to turn into a habit and become automatic. Smartphone apps could help with this process by supporting habit formation. To better understand how, we conducted a 4-week study exploring the influence of different types of cues and positive reinforcement on habit formation and reviewed the functionality of 115 habit formation apps. We discovered that relying on reminders supported repetition but hindered habit development, while the use of event-based cues led to increased automaticity; positive reinforcement was ineffective. The functionality review revealed that existing apps focus on self-tracking and reminders, and do not support event-based cues. We argue that apps, and technology-based interventions in general, have the potential to provide real habit support, and present design guidelines for interventions that could support habit formation through contextual cues and implementation intentions."
    },
    {
        "title": "Problematising Upstream Technology through Speculative Design: The Case of Quantified Cats and Dogs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Quantified Self for Humans & Pets",
        "data": "April 2015",
        "authors": [
            "Shaun Lawson",
            "Ben Kirman",
            "Conor Linehan",
            "Tom Feltwell",
            "Lisa Hopkins"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702260",
        "citation": "70",
        "abstract": "There is growing interest in technology that quantifies aspects of our lives. This paper draws on critical practice and speculative design to explore, question and problematise the ultimate consequences of such technology using the quantification of companion animals (pets) as a case study. We apply the concept of \"moving upstream\" to study such technology and use a qualitative research approach in which both pet owners, and animal behavioural experts, were presented with, and asked to discuss, speculative designs for pet quantification applications, the design of which were extrapolated from contemporary trends. Our findings indicate a strong desire among pet owners for technology that has little scientific justification, whilst our experts caution that the use of technology to augment human-animal communication has the potential to disimprove animal welfare, undermine human-animal bonds, and create human-human conflicts. Our discussion informs wider debates regarding quantification technology."
    },
    {
        "title": "Re-Centering Multispecies Practices: A Canine Interface for Cancer Detection Dogs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Quantified Self for Humans & Pets",
        "data": "April 2015",
        "authors": [
            "Clara Mancini",
            "Rob Harris",
            "Brendan Aengenheister",
            "Claire Guest"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702562",
        "citation": "38",
        "abstract": "We report on participatory design research where interaction designers, and canine behavioral specialists, together with their cancer detection dogs, teamed up to better support the dogs' life-saving work. We discuss interspecies communication challenges in cancer detection training, requiring the dogs to use human signaling conventions that perturb their detection work. We describe our effort to develop a technology that could resolve those challenges, and how in the process our design focus gradually shifted from a human-centered to a canine-centered interaction model. The resulting interface, based on honest signaling, re-centers cancer detection practices on the dogs themselves, enabling them to better express their potential as cancer detection workers; it also provides a model for re-thinking human-computer interactions."
    },
    {
        "title": "Session details: Visualizing Statistics & Graphs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Statistics & Graphs",
        "data": "April 2015",
        "authors": [
            "Benjamin Bach"
        ],
        "DOI": "https://doi.org/10.1145/3251744",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "(s|qu)eries: Visual Regular Expressions for Querying and Exploring Event Sequences",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Statistics & Graphs",
        "data": "April 2015",
        "authors": [
            "Emanuel Zgraggen",
            "Steven M. Drucker",
            "Danyel Fisher",
            "Robert DeLine"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702262",
        "citation": "34",
        "abstract": "Many different domains collect event sequence data and rely on finding and analyzing patterns within it to gain meaningful insights. Current systems that support such queries either provide limited expressiveness, hinder exploratory workflows or present interaction and visualization models which do not scale well to large and multi-faceted data sets. In this paper we present (s|qu)eries (pronounced \"Squeries\"), a visual query interface for creating queries on sequences (series) of data, based on regular expressions. (s|qu)eries is a touch-based system that exposes the full expressive power of regular expressions in an approachable way and interleaves query specification with result visualizations. Being able to visually investigate the results of different query-parts supports debugging and encourages iterative query-building as well as exploratory work-flows. We validate our design and implementation through a set of informal interviews with data scientists that analyze event sequences on a daily basis."
    },
    {
        "title": "Statsplorer: Guiding Novices in Statistical Analysis",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Statistics & Graphs",
        "data": "April 2015",
        "authors": [
            "Chat Wacharamanotham",
            "Krishna Subramanian",
            "Sarah Theres Völkel",
            "Jan Borchers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702347",
        "citation": "23",
        "abstract": "Each step of statistical analysis requires researchers to make decisions based on both statistical knowledge and the knowledge of their own data. For novice analysts, this is cognitively demanding and can lead to mistakes and misinterpretations of the results. We present Statsplorer, a software that helps novices learn and perform inferential statistical tests. It lets the user kick-start data analysis from their research questions. Statsplorer automatically tests necessary statistical assumptions and uses visualizations to guide the user in both selecting statistical tests and interpreting the results. We compared Statsplorer with a statistics lecture and investigated how Statsplorer prepares novices for learning statistics in an AB/BA crossover experiment. The results indicates that using Statsplorer prior to the lecture leads to significantly better test scores in understanding statistical assumptions and choosing appropriate statistical tests. Statsplorer is open-source and is available online at: http://hci.rwth-aachen.de/statsplorer."
    },
    {
        "title": "Investigating the Direct Manipulation of Ranking Tables for Time Navigation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Statistics & Graphs",
        "data": "April 2015",
        "authors": [
            "Romain Vuillemot",
            "Charles Perin"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702237",
        "citation": "16",
        "abstract": "We introduce a novel time navigation technique to update ranking tables by direct manipulation. The technique allows users to drag a table's cells to change the time period, while a line chart overlays on top of the table to provide an overview of the changes. The line chart is also a visual hint to control the pace at which data are updated. We explore the design and usability of this technique for table variations in size, time spans and data variability. We report the results of a usability study, using academic citation rankings and economic complexity datasets, and discuss design implications coming with real-world scenarios such as missing data and affordance."
    },
    {
        "title": "Dynamic Opacity Optimization for Scatter Plots",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Statistics & Graphs",
        "data": "April 2015",
        "authors": [
            "Justin Matejka",
            "Fraser Anderson",
            "George Fitzmaurice"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702585",
        "citation": "25",
        "abstract": "Scatterplots are an effective and commonly used technique to show the relationship between two variables. However, as the number of data points increases, the chart suffers from \"over-plotting\" which obscures data points and makes the underlying distribution of the data difficult to discern. Reducing the opacity of the data points is an effective way to address over-plotting, however, setting the individual point opacity is a manual task performed by the chart designer. We present a user-driven model of opacity scaling for scatter plots built from crowd-sourced responses to opacity scaling tasks using several synthetic data distributions, and then test our model on a collection of real-world data sets."
    },
    {
        "title": "Evaluating How Level of Detail of Visual History Affects Process Memory",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualizing Statistics & Graphs",
        "data": "April 2015",
        "authors": [
            "Eric D. Ragan",
            "John R. Goodall",
            "Albert Tung"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702376",
        "citation": "10",
        "abstract": "Visual history tools provide visual representations of the workflow during data analysis tasks. While there is an established need for reviewing analytic processes, and many visual history tools provide visualizations to do so, it is not well known how helpful the tools actually are for process recall. Through a controlled experiment, we evaluated how the presence of a visual history aid and varying levels of visual detail affect process memory. Participants conducted an analysis task using a visual text-document analysis tool. We evaluated their memories of the process both immediately after the analysis and then again one week later. Results showed that even visual history views with reduced data-resolution were effective for aiding process memory. Further, even without inclusion of any data in the visual history aids, the visual cues alone from the final workspace were enough to improve memory of the main themes of analyses."
    },
    {
        "title": "Session details: Understanding Everyday Use of Mobile Phones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Everyday Use of Mobile Phones",
        "data": "April 2015",
        "authors": [
            "Matt Jones"
        ],
        "DOI": "https://doi.org/10.1145/3251745",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Demand in My Pocket: Mobile Devices and the Data Connectivity Marshalled in Support of Everyday Practice",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Everyday Use of Mobile Phones",
        "data": "April 2015",
        "authors": [
            "Carolynne Lord",
            "Mike Hazas",
            "Adrian K. Clear",
            "Oliver Bates",
            "Rosalind Whittam",
            "Janine Morley",
            "Adrian Friday"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702162",
        "citation": "29",
        "abstract": "This paper empirically explores the role that mobile devices have come to play in everyday practice, and how this links to demand for network connectivity and online services. After a preliminary device-logging period, thirteen participants were interviewed about how they use their iPhones or iPads. Our findings build a picture of how, through use of such devices, a variety of daily practices have come to depend upon a working data connection, which sometimes surges, but is at least always a trickle. This aims to inform the sustainable design of applications, services and infrastructures for smartphones and tablets. By focusing our analysis in this way, we highlight a little-explored challenge for sustainable HCI and discuss ideas for (re)designing around the principle of 'light-weight' data 'needs'."
    },
    {
        "title": "An In-Situ Study of Mobile App & Mobile Search Interactions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Everyday Use of Mobile Phones",
        "data": "April 2015",
        "authors": [
            "Juan Pablo Carrascal",
            "Karen Church"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702486",
        "citation": "67",
        "abstract": "When trying to satisfy an information need, smartphone users frequently transition from mobile search engines to mobile apps and vice versa. However, little is known about the nature of these transitions nor how mobile search and mobile apps interact. We report on a 2-week, mixed-method study involving 18 Android users, where we collected real-world mobile search and mobile app usage data alongside subjective insights on why certain interactions between apps and mobile search occur. Our results show that when people engage with mobile search they tend to interact with more mobile apps and for longer durations. We found that certain categories of apps are used more intensely alongside mobile search. Furthermore we found differences in app usage before and after mobile search and show how mobile app interactions can both prompt mobile search and enable users to take action. We conclude with a discussion on what these patterns mean for mobile search and how we might design mobile search experiences that take these app interactions into account."
    },
    {
        "title": "The Composition and Use of Modern Mobile Phonebooks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Everyday Use of Mobile Phones",
        "data": "April 2015",
        "authors": [
            "Frank R. Bentley",
            "Ying-Yu Chen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702182",
        "citation": "18",
        "abstract": "Over the past decade, the mobile phonebook has evolved from a relatively short list of people that one calls and texts to a many-hundred person list of aggregated contacts from around the web. This is happening at a time when an increasing number of mobile applications are relying on the mobile phonebook to create one's social network in their services. Through a large-scale study of the phonebooks of 200 diverse participants, containing 65,940 contacts, we set out to understand today's mobile contact lists. Our participants reported that they did not recognize the names of 29% of their contacts and we found that the most frequently contacted five contacts represent greater than 80% of all calls and text messages with phonebook contacts. We conclude with implications for the design of mobile applications that rely on phonebook data."
    },
    {
        "title": "Session details: GUI Size, Resolution & Layout",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: GUI Size, Resolution & Layout",
        "data": "April 2015",
        "authors": [
            "Enrico Rukzio"
        ],
        "DOI": "https://doi.org/10.1145/3251746",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Effects of Display Size and Resolution on User Behavior and Insight Acquisition in Visual Exploration",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: GUI Size, Resolution & Layout",
        "data": "April 2015",
        "authors": [
            "Khairi Reda",
            "Andrew E. Johnson",
            "Michael E. Papka",
            "Jason Leigh"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702406",
        "citation": "42",
        "abstract": "Large high-resolution displays are becoming increasingly common in research settings, providing data scientists with visual interfaces for the analysis of large datasets. Numerous studies have demonstrated unique perceptual and cognitive benefits afforded by these displays in visual analytics and information visualization tasks. However, the effects of these displays on knowledge discovery in exploratory visual analysis are still poorly understood. We present the results of a small-scale study to better understand how display size and resolution affect insight. Analyzing participants' verbal statements, we find preliminary evidence that larger displays with more pixels can significantly increase the number of discoveries reported during visual exploration, while yielding broader, more integrative insights. Furthermore, we find important differences in how participants performed the same visual exploration task using displays of varying sizes. We tie these results to extant work and propose explanations by considering the cognitive and interaction costs associated with visual exploration."
    },
    {
        "title": "Subjective and Objective Effects of Tablet's Pixel Density",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: GUI Size, Resolution & Layout",
        "data": "April 2015",
        "authors": [
            "Lars Lischke",
            "Sven Mayer",
            "Katrin Wolf",
            "Alireza Sahami Shirazi",
            "Niels Henze"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702390",
        "citation": "1",
        "abstract": "Pixel densities are increasing rapidly. We can observe this trend in particular for mobile devices like smartphones and tablets. Previous work revealed an effect of pixel density on subjective feedback and objective performance only for low resolution cathode ray tube screens. It is unclear if this effect persists for the four times higher pixel densities of current mobile devices. Therefore, we conducted a study to compare four pixel densities with 359, 180, 120, and 90 pixels per inch. While participants performed three tasks involving images, text and videos on a tablet, we measured perceived effort, perceived visual quality, task completion time, error rate, and body pose. Our results show that the effect of the pixel density highly depends on the content. We found that only for text, the four pixel densities have clearly different perceived media qualities. Pixel density seems to have a smaller effect on perceived media quality for images and videos and we found no effect on objective measures. Results show that text should be displayed in high resolution, while this is less important for images and videos."
    },
    {
        "title": "Push-Edge and Slide-Edge: Scrolling by Pushing Against the Viewport Edge",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: GUI Size, Resolution & Layout",
        "data": "April 2015",
        "authors": [
            "Sylvain Malacria",
            "Jonathan Aceituno",
            "Philip Quinn",
            "Géry Casiez",
            "Andy Cockburn",
            "Nicolas Roussel"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702132",
        "citation": "7",
        "abstract": "Edge-scrolling allows users to scroll a viewport while simultaneously dragging near or beyond a window's edge. Common implementations rely on rate control, mapping the distance between the pointer and the edge of the viewport to the scrolling velocity. While ubiquitous in operating systems, edge-scrolling has received little attention, even though previous works suggest that (1) rate control may be suboptimal for isotonic pointing devices like mice and trackpads and (2) space beyond the window's edge might be scarce, limiting scrolling control. To address these problems, we developed Push-edge scrolling (and Slide-edge scrolling, its inertial variant), two novel position-based techniques that allow scrolling by \"pushing\" against the viewport edge. A controlled experiment shows that our techniques reduce overshoots and offer performance improvements by up to 13% over traditional edge-scrolling."
    },
    {
        "title": "Investigating Visual Feedforward for Target Expansion Techniques",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: GUI Size, Resolution & Layout",
        "data": "April 2015",
        "authors": [
            "Maxime Guillon",
            "François Leitner",
            "Laurence Nigay"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702375",
        "citation": "11",
        "abstract": "Target expansion techniques facilitate the pointing task by enlarging the effective sizes of targets. When the target expansion is applied to both the motor and visual spaces, the visual feedforward mechanism is key: Indeed it provides a visual aid to the user on the effective expanded targets prior to the execution or completion of the pointing task, enabling the user to take full advantage of the target expansion technique. Focusing on feedforward mechanisms, we introduce a design space that allows us to describe, classify and design target expansion techniques. To do so we first introduce and characterize the concept of atomic feedforward mechanism along three design axes. We then describe a target expansion technique as a combination of atomic feedforward mechanisms using a matrix-based notation. We provide an analytical exploration of the design space by classifying existing techniques and by designing six new techniques. We also provide a first experimental exploration of the design space in the context of distant pointing. The experimental protocol includes an innovative target layout for handling non-centroidal target expansion. The results show that feedforward dynamicity increases movement time and decreases subjective usability, while explicit expansion observability efficiently supports error prevention for distant pointing."
    },
    {
        "title": "GACA: Group-Aware Command-based Arrangement of Graphic Elements",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: GUI Size, Resolution & Layout",
        "data": "April 2015",
        "authors": [
            "Pengfei Xu",
            "Hongbo Fu",
            "Chiew-Lan Tai",
            "Takeo Igarashi"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702198",
        "citation": "15",
        "abstract": "Many graphic applications rely on command-based arrangement tools to achieve precise layouts. Traditional tools are designed to operate on a single group of elements that are distributed consistently with the arrangement axis implied by a command. This often demands a process with repeated element selections and arrangement commands to achieve 2D layouts involving multiple rows and/or columns of well aligned and/or distributed elements. Our work aims to reduce the numbers of selection operation and command invocation, since such reductions are particularly beneficial to professional designers who design lots of layouts. Our key idea is that an issued arrangement command is in fact very informative, instructing how to automatically decompose a 2D layout into multiple 1D groups, each of which is compatible with the command. We present a parameter-free, command-driven grouping approach so that users can easily predict our grouping results. We also design a simple user interface with pushpins to enable explicit control of grouping and arrangement. Our user study confirms the intuitiveness of our technique and its performance improvement over traditional command-based arrangement tools."
    },
    {
        "title": "Session details: Kids Social, Emotional & Special Needs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Social, Emotional & Special Needs",
        "data": "April 2015",
        "authors": [
            "Konstantinos Kazakos"
        ],
        "DOI": "https://doi.org/10.1145/3251747",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Designing Social and Emotional Skills Training: The Challenges and Opportunities for Technology Support",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Social, Emotional & Special Needs",
        "data": "April 2015",
        "authors": [
            "Petr Slovák",
            "Ran Gilad-Bachrach",
            "Geraldine Fitzpatrick"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702385",
        "citation": "21",
        "abstract": "Social and emotional skills are crucial for all aspects of our everyday life. However, understanding how digital technology can facilitate the development and learning of such skills is yet an under-researched area in HCI. To start addressing this gap, this paper reports on a series of interviews and design workshops with the leading researchers and developers of 'Social and Emotional Learning' (SEL) curricula. SEL is a subfield of educational psychology with a long history of teaching such skills, and a range of evidence based curricula that are widely deployed in primary and secondary schools. We identify the shared challenges across existing curricula that digital technology might help address: the support for out-of-session learning, scaffolding for parental engagement, and feedback for the curricula developers. We argue how this presents an opportunity for mutually beneficial collaborations, with the potential for significant real-world impact of novel HCI systems, and can inform HCI work on supporting social and emotional skills development in other domains."
    },
    {
        "title": "Designing Autism Research for Maximum Impact",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Social, Emotional & Special Needs",
        "data": "April 2015",
        "authors": [
            "Elizabeth J. Carter",
            "Jennifer Hyde"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702471",
        "citation": "7",
        "abstract": "In recent decades, rates of autism spectrum disorder (ASD) have risen dramatically, and research into assistive technologies for this population has similarly escalated. For technology to be adopted, technologists need to communicate with practitioners across fields and match methodological and evaluation standards. We provide a set of recommendations for researchers to bridge the gap between fields and maximize the impact of their research, including instructions on how to identify and describe research participants and how to avoid research confounds and challenges specific to this population. We also advocate that researchers in ASD maintain a nimble, adaptable approach when performing experiments."
    },
    {
        "title": "Networked Empowerment on Facebook Groups for Parents of Children with Special Needs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Social, Emotional & Special Needs",
        "data": "April 2015",
        "authors": [
            "Tawfiq Ammari",
            "Sarita Schoenebeck"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702324",
        "citation": "67",
        "abstract": "Theories of empowerment explain how people gain personal and political control to take action to improve their lives. However, empowerment theories were developed prior to the Internet and fail to account for the speed and scale that people can find one another online. One domain where empowerment is critical is caring for children with special needs, in which parents are required to navigate a complex maze of services and processes to access care for their child. We conducted 43 interviews with parents of children with special needs to investigate whether using social media sites helps them to perform this caregiving work. Critically, parents are able to do this through almost real-time access to other parents on Facebook. This work introduces the concept of networked empowerment, that describes how parents find other parents, access resources, and explore new ways for promoting health advocacy among caregivers at a local and national level. We conclude with design implications for facilitating faster and better access to information and support for caregivers."
    },
    {
        "title": "Toward 3D-Printed Movable Tactile Pictures for Children with Visual Impairments",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Social, Emotional & Special Needs",
        "data": "April 2015",
        "authors": [
            "Jeeeun Kim",
            "Tom Yeh"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702144",
        "citation": "46",
        "abstract": "Many children's books contain movable pictures with elements that can be physically opened, closed, pushed, pulled, spun, flipped, or swung. But these tangible, interactive reading experiences are inaccessible to children with visual impairments. This paper presents a set of 3D-printable models designed as building blocks for creating movable tactile pictures that can be touched, moved, and understood by children with visual impairments. Examples of these models are canvases, connectors, hinges, spinners, sliders, lifts, walls, and cutouts. They can be used to compose movable tactile pictures to convey a range of spatial concepts, such as in/out, up/down, and high/low. The design and development of these models were informed by three formative studies including 1) a survey on popular moving mechanisms in children's books and 3D-printed parts to implement them, 2) two workshops on the process creating movable tactile pictures by hand (e.g., Lego, Play-Doh), and 3) creation of wood-based prototypes and an informal testing on sighted preschoolers. Also, we propose a design language based on XML and CSS for specifying the content and structure of a movable tactile picture. Given a specification, our system can generate a 3D-printable model. We evaluate our approach by 1) transcribing six children's books, and 2) conducting six interviews on domain experts including four teachers for the visually impaired, one blind adult, two publishers at the National Braille Press, a renowned tactile artist, and a librarian."
    },
    {
        "title": "Multimodal Analysis in Participatory Design with Children: A Primary School Case Study",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Social, Emotional & Special Needs",
        "data": "April 2015",
        "authors": [
            "Jan Derboven",
            "Maarten Van Mechelen",
            "Karin Slegers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702475",
        "citation": "10",
        "abstract": "We describe a multimodal method for the analysis of co-design outcomes in participatory design (PD) with children. The multimodal approach we take allows researchers to treat both verbal (notes, writings) and tangible material out-comes as complementary ways of communicating design ideas. We argue that an integrated approach in which both PD outcomes are compared and contrasted can result in a richer analysis, in which underlying values can be identified more clearly. To illustrate the method, we describe a PD process with primary school children."
    },
    {
        "title": "The Fun and the Serious in an Educational Game: The Monkey Tales Case",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Kids Social, Emotional & Special Needs",
        "data": "April 2015",
        "authors": [
            "Jan Derboven",
            "Bieke Zaman",
            "Jorick Vissers",
            "David Geerts",
            "Dirk De Grooff"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702519",
        "citation": "1",
        "abstract": "We describe a study of Monkey Tales, an educational game targeted at primary school children. Starting from the assumption that all meaning is socially constructed, we focus our attention on the way an educational game, and its balance between fun and serious aspects, is constructed in public texts (game manufacturer's communication and game reviews) and in individual use (the way players and their parents talk about the game). Through an analysis of public texts and individual use, we show how the balance between the fun and the serious in Monkey Tales is constructed in different ways."
    },
    {
        "title": "Session details: HCI for Civic Engagement",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for Civic Engagement",
        "data": "April 2015",
        "authors": [
            "John Vines"
        ],
        "DOI": "https://doi.org/10.1145/3251748",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "HCI, Civic Engagement & Trust",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for Civic Engagement",
        "data": "April 2015",
        "authors": [
            "Mike Harding",
            "Bran Knowles",
            "Nigel Davies",
            "Mark Rouncefield"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702255",
        "citation": "95",
        "abstract": "There is a widespread belief that pervasive technologies will encourage and facilitate partnerships between citizens and civic authorities, enabling individuals to play a greater role in civic planning, service delivery and infrastructure management. However, at present sustained use and perceived value of civic engagement technologies remains low because the design space is poorly understood by system developers who focus almost exclusively on empowering citizens rather than adopting an informed, inclusive approach that addresses the needs of both citizens and civic authorities, and helps establish trusted relationships between these different stakeholders. We report on an extensive study of civic engagement in the domain of public infrastructure maintenance and provide insights into the civic management processes to support future design of trusted civic engagement interactions."
    },
    {
        "title": "Factful: Engaging Taxpayers in the Public Discussion of a Government Budget",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for Civic Engagement",
        "data": "April 2015",
        "authors": [
            "Juho Kim",
            "Eun-Young Ko",
            "Jonghyuk Jung",
            "Chang Won Lee",
            "Nam Wook Kim",
            "Jihee Kim"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702352",
        "citation": "16",
        "abstract": "While a government budget determines how taxpayers' money is allocated to various programs and stakeholders that compete for limited resources, the extensiveness and complexity of the budget and its process hinder taxpayers from understanding the budget information and participating in the public discussion. To engage taxpayers in the public discussion around budgetary issues, we leverage news articles containing budgetary information for design opportunities. We present Factful, a web-based annotative article reading interface that enhances the article with fact-checking support and contextual budgetary information by processing open government data. In our lab study, participants using Factful discussed more critically with more fact-based supporting statements. They built a rich context surrounding the relevant budget facts beyond what was presented in the article. Factful presents a simple yet powerful model for supporting fact-oriented budgetary discussions online by leveraging open government data."
    },
    {
        "title": "Contesting the City: Enacting the Political Through Digitally Supported Urban Walks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for Civic Engagement",
        "data": "April 2015",
        "authors": [
            "Clara Crivellaro",
            "Rob Comber",
            "Martyn Dade-Robertson",
            "Simon J. Bowen",
            "Peter C. Wright",
            "Patrick Olivier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702176",
        "citation": "46",
        "abstract": "We present a method for the situated discovery and articulation of issues at the intersection between the politics of place making and city planning. We describe the construction and use of designed tools, such as historical political archives; counterfactual maps; and cards to invite situated dialogue between the social and institutional practices and mechanisms that produce our cities. Grounded in an account of the political as vernacular and embodied, our analysis advance understandings on the politics of design, and on the complex interrelationship between places and political spaces. We outline how HCI can adopt methods and develop sensitivities to support democratic practices and publics envisioning their urban futures."
    },
    {
        "title": "Data-in-Place: Thinking through the Relations Between Data and Community",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI for Civic Engagement",
        "data": "April 2015",
        "authors": [
            "Alex S. Taylor",
            "Siân Lindley",
            "Tim Regan",
            "David Sweeney",
            "Vasillis Vlachokyriakos",
            "Lillie Grainger",
            "Jessica Lingel"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702558",
        "citation": "114",
        "abstract": "We present findings from a year-long engagement with a street and its community. The work explores how the production and use of data is bound up with place, both in terms of physical and social geography. We detail three strands of the project. First, we consider how residents have sought to curate existing data about the street in the form of an archive with physical and digital components. Second, we report endeavours to capture data about the street's environment, especially of vehicle traffic. Third, we draw on the possibilities afforded by technologies for polling opinion. We reflect on how these engagements have: materialised distinctive relations between the community and their data; surfaced flows and contours of data, and spatial, temporal and social boundaries; and enacted a multiplicity of 'small worlds'. We consider how such a conceptualisation of data-in-place is relevant to the design of technology."
    },
    {
        "title": "Session details: Security Feedback & Warnings",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security Feedback & Warnings",
        "data": "April 2015",
        "authors": [
            "Alexander De Luca"
        ],
        "DOI": "https://doi.org/10.1145/3251749",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Scaling the Security Wall: Developing a Security Behavior Intentions Scale (SeBIS)",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security Feedback & Warnings",
        "data": "April 2015",
        "authors": [
            "Serge Egelman",
            "Eyal Peer"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702249",
        "citation": "149",
        "abstract": "Despite the plethora of security advice and online education materials offered to end-users, there exists no standard measurement tool for end-user security behaviors. We present the creation of such a tool. We surveyed the most common computer security advice that experts offer to end-users in order to construct a set of Likert scale questions to probe the extent to which respondents claim to follow this advice. Using these questions, we iteratively surveyed a pool of 3,619 computer users to refine our question set such that each question was applicable to a large percentage of the population, exhibited adequate variance between respondents, and had high reliability (i.e., desirable psychometric properties). After performing both exploratory and confirmatory factor analysis, we identified a 16-item scale consisting of four sub-scales that measures attitudes towards choosing passwords, device securement, staying up-to-date, and proactive awareness."
    },
    {
        "title": "How Polymorphic Warnings Reduce Habituation in the Brain: Insights from an fMRI Study",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security Feedback & Warnings",
        "data": "April 2015",
        "authors": [
            "Bonnie Brinton Anderson",
            "C. Brock Kirwan",
            "Jeffrey L. Jenkins",
            "David Eargle",
            "Seth Howard",
            "Anthony Vance"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702322",
        "citation": "59",
        "abstract": "Research on security warnings consistently points to habituation as a key reason why users ignore security warnings. However, because habituation as a mental state is difficult to observe, previous research has examined habituation indirectly by observing its influence on security behaviors. This study addresses this gap by using functional magnetic resonance imaging (fMRI) to open the \"black box\" of the brain to observe habituation as it develops in response to security warnings. Our results show a dramatic drop in the visual processing centers of the brain after only the second exposure to a warning, with further decreases with subsequent exposures. To combat the problem of habituation, we designed a polymorphic warning that changes its appearance. We show in two separate experiments using fMRI and mouse cursor tracking that our polymorphic warning is substantially more resistant to habituation than conventional warnings. Together, our neurophysiological findings illustrate the considerable influence of human biology on users' habituation to security warnings."
    },
    {
        "title": "Improving SSL Warnings: Comprehension and Adherence",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security Feedback & Warnings",
        "data": "April 2015",
        "authors": [
            "Adrienne Porter Felt",
            "Alex Ainslie",
            "Robert W. Reeder",
            "Sunny Consolvo",
            "Somas Thyagaraja",
            "Alan Bettes",
            "Helen Harris",
            "Jeff Grimes"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702442",
        "citation": "101",
        "abstract": "Browsers warn users when the privacy of an SSL/TLS connection might be at risk. An ideal SSL warning would empower users to make informed decisions and, failing that, guide confused users to safety. Unfortunately, users struggle to understand and often disregard real SSL warnings. We report on the task of designing a new SSL warning, with the goal of improving comprehension and adherence. We designed a new SSL warning based on recommendations from warning literature and tested our proposal with microsurveys and a field experiment. We ultimately failed at our goal of a well-understood warning. However, nearly 30% more total users chose to remain safe after seeing our warning. We attribute this success to opinionated design, which promotes safety with visual cues. Subsequently, our proposal was released as the new Google Chrome SSL warning. We raise questions about warning comprehension advice and recommend that other warning designers use opinionated design."
    },
    {
        "title": "A Spoonful of Sugar?: The Impact of Guidance and Feedback on Password-Creation Behavior",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security Feedback & Warnings",
        "data": "April 2015",
        "authors": [
            "Richard Shay",
            "Lujo Bauer",
            "Nicolas Christin",
            "Lorrie Faith Cranor",
            "Alain Forget",
            "Saranga Komanduri",
            "Michelle L. Mazurek",
            "William Melicher",
            "Sean M. Segreti",
            "Blase Ur"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702586",
        "citation": "38",
        "abstract": "Users often struggle to create passwords under strict requirements. To make this process easier, some providers present real-time feedback during password creation, indicating which requirements are not yet met. Other providers guide users through a multi-step password-creation process. Our 6,435-participant online study examines how feedback and guidance affect password security and usability. We find that real-time password-creation feedback can help users create strong passwords with fewer errors. We also find that although guiding participants through a three-step password-creation process can make creation easier, it may result in weaker passwords. Our results suggest that service providers should present password requirements with feedback to increase usability. However, the presentation of feedback and guidance must be carefully considered, since identical requirements can have different security and usability effects depending on presentation."
    },
    {
        "title": "Session details: Wellness & Wearables",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Wellness & Wearables",
        "data": "April 2015",
        "authors": [
            "Marianna Obrist"
        ],
        "DOI": "https://doi.org/10.1145/3251750",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Snot, Sweat, Pain, Mud, and Snow: Performance and Experience in the Use of Sports Watches",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Wellness & Wearables",
        "data": "April 2015",
        "authors": [
            "Jakob Tholander",
            "Stina Nylander"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702482",
        "citation": "83",
        "abstract": "We have conducted interviews with ten elite and recreational athletes to understand their experiences and engagement with endurance sport and personal and wearable sports technology. The athletes emphasized the experiential aspects of doing sports and the notion of feeling was repeatedly used to talk about their activities. Technology played both an instrumental role in measuring performance and feeding bio-data back to them, and an experiential role in supporting and enhancing the sport experience. To guide further interaction design research in the sports domain, we suggest two interrelated ways of looking at sports performances and experiences, firstly through the notion of a measured sense of performance, and secondly as a lived-sense of performance."
    },
    {
        "title": "Contextual Influences on the Use and Non-Use of Digital Technology While Exercising at the Gym",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Wellness & Wearables",
        "data": "April 2015",
        "authors": [
            "Misha Patel",
            "Aisling Ann O'Kane"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702384",
        "citation": "29",
        "abstract": "The use of wearable technology will become significantly more prevalent in the coming years, with major companies releasing devices such as the Samsung Gear Fit. With sensors, such as pedometers and heart rate monitors, embedded in these devices it is possible to use them for fitness purposes. However, little is known about how wearable adopters actually use wearable and existing technologies during exercise. In an exploratory situated study of technology use and non-use in the context of the gym, fitness informatics adopters showed varied practices related to distraction, appropriating technology into their routines, and information needs. We discuss this variance in relation to individual differences and the impact of the physical nature of the gym. Although further research might show other influencing factors such as the social context, we make a case for the use of situated studies to uncover tensions that lead to use and non-use of technology that arise in the different unfolding situations of using wearables in everyday life, including at the gym, which is a surprisingly complex context."
    },
    {
        "title": "TastyBeats: Designing Palatable Representations of Physical Activity",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Wellness & Wearables",
        "data": "April 2015",
        "authors": [
            "Rohit Ashok Khot",
            "Jeewon Lee",
            "Deepti Aggarwal",
            "Larissa Hjorth",
            "Florian 'Floyd' Mueller"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702197",
        "citation": "58",
        "abstract": "In this paper, we introduce palatable representations that besides improving the understanding of physical activity through abstract visualization also provide an appetizing drink to celebrate the experience of being physically active. By designing such palatable representations, our aim is to offer novel opportunities for reflection on one's physical activities. We present TastyBeats, a fountain-based interactive system that creates a fluidic spectacle of mixing sport drinks based on heart rate data of physical activity, which the user can later consume to replenish the loss of body fluids due to the physical activity. We articulate our experiences in designing the system as well as learning gained through field deployments of the system in participants' homes for a period of two weeks. We found that our system increased participants' awareness of physical activity and facilitated a shared social experience, while the prepared drink was treated as a hedonic reward that motivated participants to exercise more. Ultimately, with this work, we aim to inspire and guide design thinking on palatable representations, which we believe opens up new interaction possibilities to support physical activity experience."
    },
    {
        "title": "As Light as your Footsteps: Altering Walking Sounds to Change Perceived Body Weight, Emotional State and Gait",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Wellness & Wearables",
        "data": "April 2015",
        "authors": [
            "Ana Tajadura-Jiménez",
            "Maria Basia",
            "Ophelia Deroy",
            "Merle Fairhurst",
            "Nicolai Marquardt",
            "Nadia Bianchi-Berthouze"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702374",
        "citation": "102",
        "abstract": "An ever more sedentary lifestyle is a serious problem in our society. Enhancing people's exercise adherence through technology remains an important research challenge. We propose a novel approach for a system supporting walking that draws from basic findings in neuroscience research. Our shoe-based prototype senses a person's footsteps and alters in real-time the frequency spectra of the sound they produce while walking. The resulting sounds are consistent with those produced by either a lighter or heavier body. Our user study showed that modified walking sounds change one's own perceived body weight and lead to a related gait pattern. In particular, augmenting the high frequencies of the sound leads to the perception of having a thinner body and enhances the motivation for physical activity inducing a more dynamic swing and a shorter heel strike. We here discuss the opportunities and the questions our findings open."
    },
    {
        "title": "Session details: Task Interruption & Resumption",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task Interruption & Resumption",
        "data": "April 2015",
        "authors": [
            "Martin Halvey"
        ],
        "DOI": "https://doi.org/10.1145/3251751",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "SwitchBack: Using Focus and Saccade Tracking to Guide Users' Attention for Mobile Task Resumption",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task Interruption & Resumption",
        "data": "April 2015",
        "authors": [
            "Alexander Mariakakis",
            "Mayank Goel",
            "Md Tanvir Islam Aumi",
            "Shwetak N. Patel",
            "Jacob O. Wobbrock"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702539",
        "citation": "35",
        "abstract": "Smartphones and tablets are often used in dynamic environments that force users to break focus and attend to their surroundings, creating a form of \"situational impairment.\" Current mobile devices have no ability to sense when users divert or restore their attention, let alone provide support for resuming tasks. We therefore introduce SwitchBack, a system that allows mobile device users to resume tasks more efficiently. SwitchBack is built upon Focus and Saccade Tracking (FAST), which uses the front-facing camera to determine when the user is looking and how their eyes are moving across the screen. In a controlled study, we found that FAST can identify how many lines the user has read in a body of text within a mean absolute percent error of just 3.9%. We then tested SwitchBack in a dual focus-of-attention task, finding that SwitchBack improved average reading speed by 7.7% in the presence of distractions."
    },
    {
        "title": "EyeBookmark: Assisting Recovery from Interruption during Reading",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task Interruption & Resumption",
        "data": "April 2015",
        "authors": [
            "Jaemin Jo",
            "Bohyoung Kim",
            "Jinwook Seo"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702340",
        "citation": "15",
        "abstract": "In this paper, we present gaze-based bookmarking, EyeBookmark, to mitigate the deleterious effect of interruption during reading. The key idea of EyeBookmark is to provide a visual cue to help people decide where to resume reading. We design four highlighting methods and conduct a controlled user study with a proof-of-concept design to verify the usefulness of EyeBookmark. The user study demonstrates not only that participants preferred our highlighting methods but also that such highlighting methods significantly reduced the time taken to resume reading after interruption regardless of the difficulty of text."
    },
    {
        "title": "The Effects of Chronic Multitasking on Analytical Writing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task Interruption & Resumption",
        "data": "April 2015",
        "authors": [
            "Danielle M. Lottridge",
            "Christine Rosakranse",
            "Catherine S. Oh",
            "Sean J. Westwood",
            "Katherine A. Baldoni",
            "Abrey S. Mann",
            "Clifford I. Nass"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702367",
        "citation": "11",
        "abstract": "Chronic multitaskers perform worse on core multitasking skills: memory management, cognitive filtering and task switching, likely due to their inability to filter irrelevant stimuli [17]. Our experiment examines effects of chronic multitasking with task-relevant and irrelevant distractors on analytical writing quality. We found a general switch cost and, when controlling for that cost, effects of chronic multitasking habits: heavy multitaskers write worse essays in the irrelevant condition and better essays in the relevant condition. Our study changes multitasking research paradigms in two fundamental ways: it studied a realistic writing scenario including access to both irrelevant and relevant distractors. We found that the effect of chronic multitasking is complex; heavy multitaskers are seduced by unrelated distractors but able to integrate multiple sources of relevant information."
    },
    {
        "title": "What Makes Interruptions Disruptive?: A Process-Model Account of the Effects of the Problem State Bottleneck on Task Interruption and Resumption",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task Interruption & Resumption",
        "data": "April 2015",
        "authors": [
            "Jelmer P. Borst",
            "Niels A. Taatgen",
            "Hedderik van Rijn"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702156",
        "citation": "68",
        "abstract": "In this paper we present a computational cognitive model of task interruption and resumption, focusing on the effects of the problem state bottleneck. Previous studies have shown that the disruptiveness of interruptions is for an important part determined by three factors: interruption duration, interrupting-task complexity, and moment of interruption. However, an integrated theory of these effects is still missing. Based on previous research into multitasking, we propose a first step towards such a theory in the form of a process model that attributes these effects to problem state requirements of both the interrupted and the interrupting task. Subsequently, we tested two predictions of this model in two experiments. The experiments confirmed that problem state requirements are an important predictor for the disruptiveness of interruptions. This suggests that interfaces should be designed to a) interrupt users at low-problem state moments and b) maintain the problem state for the user when interrupted."
    },
    {
        "title": "Interruptibility of Software Developers and its Prediction Using Psycho-Physiological Sensors",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Task Interruption & Resumption",
        "data": "April 2015",
        "authors": [
            "Manuela Züger",
            "Thomas Fritz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702593",
        "citation": "53",
        "abstract": "Interruptions of knowledge workers are common and can cause a high cost if they happen at inopportune moments. With recent advances in psycho-physiological sensors and their link to cognitive and emotional states, we are interested whether such sensors might be used to measure interruptibility of a knowledge worker. In a lab and a field study with a total of twenty software developers, we examined the use of psycho-physiological sensors in a real-world context. The results show that a Naive Bayes classifier based on psycho-physiological features can be used to automatically assess states of a knowledge worker's interruptibility with high accuracy in the lab as well as in the field. Our results demonstrate the potential of these sensors to avoid expensive interruptions in a real-world context. Based on brief interviews, we further discuss the usage of such an interruptibility measure and interruption support for software developers."
    },
    {
        "title": "Session details: Using Random Body Parts for Input",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using Random Body Parts for Input",
        "data": "April 2015",
        "authors": [
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/3251752",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "iSkin: Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using Random Body Parts for Input",
        "data": "April 2015",
        "authors": [
            "Martin Weigel",
            "Tong Lu",
            "Gilles Bailly",
            "Antti Oulasvirta",
            "Carmel Majidi",
            "Jürgen Steimle"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702391",
        "citation": "265",
        "abstract": "We propose iSkin, a novel class of skin-worn sensors for touch input on the body. iSkin is a very thin sensor overlay, made of biocompatible materials, and is flexible and stretchable. It can be produced in different shapes and sizes to suit various locations of the body such as the finger, forearm, or ear. Integrating capacitive and resistive touch sensing, the sensor is capable of detecting touch input with two levels of pressure, even when stretched by 30% or when bent with a radius of 0.5cm. Furthermore, iSkin supports single or multiple touch areas of custom shape and arrangement, as well as more complex widgets, such as sliders and click wheels. Recognizing the social importance of skin, we show visual design patterns to customize functional touch sensors and allow for a visually aesthetic appearance. Taken together, these contributions enable new types of on-body devices. This includes finger-worn devices, extensions to conventional wearable devices, and touch input stickers, all fostering direct, quick, and discreet input for mobile computing."
    },
    {
        "title": "Cyclops: Wearable and Single-Piece Full-Body Gesture Input Devices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using Random Body Parts for Input",
        "data": "April 2015",
        "authors": [
            "Liwei Chan",
            "Chi-Hao Hsieh",
            "Yi-Ling Chen",
            "Shuo Yang",
            "Da-Yuan Huang",
            "Rong-Hao Liang",
            "Bing-Yu Chen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702464",
        "citation": "30",
        "abstract": "This paper presents Cyclops, a single-piece wearable device that sees its user's whole body postures through an ego-centric view of the user that is obtained through a fisheye lens at the center of the user's body, allowing it to see only the user's limbs and interpret body postures effectively. Unlike currently available body gesture input systems that depend on external cameras or distributed motion sensors across the user's body, Cyclops is a single-piece wearable device that is worn as a pendant or a badge. The main idea proposed in this paper is the observation of limbs from a central location of the body. Owing to the ego-centric view, Cyclops turns posture recognition into a highly controllable computer vision problem. This paper demonstrates a proof-of-concept device, and an algorithm for recognizing static and moving bodily gestures based on motion history images (MHI) and a random decision forest (RDF). Four example applications of interactive bodily workout, a mobile racing game that involves hands and feet, a full-body virtual reality system, and interaction with a tangible toy are presented. The experiment on the bodily workout demonstrates that, from a database of 20 body workout gestures that were collected from 20 participants, Cyclops achieved a recognition rate of 79% using MHI and simple template matching, which increased to 92% with the more advanced machine learning approach of RDF."
    },
    {
        "title": "Bodyprint: Biometric User Identification on Mobile Devices Using the Capacitive Touchscreen to Scan Body Parts",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using Random Body Parts for Input",
        "data": "April 2015",
        "authors": [
            "Christian Holz",
            "Senaka Buthpitiya",
            "Marius Knaust"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702518",
        "citation": "95",
        "abstract": "Recent mobile phones integrate fingerprint scanners to authenticate users biometrically and replace passwords, making authentication more convenient for users. However, due to their cost, capacitive fingerprint scanners have been limited to top-of-the-line phones, a result of the required resolution and quality of the sensor. We present Bodyprint, a biometric authentication system that detects users' biometric features using the same type of capacitive sensing, but uses the touchscreen as the image sensor instead. While the input resolution of a touchscreen is ~6 dpi, the surface area is larger, allowing the touch sensor to scan users' body parts, such as ears, fingers, fists, and palms by pressing them against the display. Bodyprint compensates for the low input resolution with an increased false rejection rate, but does not compromise on authentication precision: In our evaluation with 12 participants, Bodyprint classified body parts with 99.98% accuracy and identifies users with 99.52% accuracy with a retry likelihood of 26.82% to prevent false positives, thereby bringing reliable biometric user authentication to a vast number of commodity devices."
    },
    {
        "title": "NailO: Fingernails as an Input Surface",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using Random Body Parts for Input",
        "data": "April 2015",
        "authors": [
            "Hsin-Liu (Cindy) Kao",
            "Artem Dementyev",
            "Joseph A. Paradiso",
            "Chris Schmandt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702572",
        "citation": "97",
        "abstract": "We present NailO, a nail-mounted gestural input surface. Using capacitive sensing on printed electrodes, the interface can distinguish on-nail finger swipe gestures with high accuracy (>92%). NailO works in real-time: we miniaturized the system to fit on the fingernail, while wirelessly transmitting the sensor data to a mobile phone or PC. NailO allows one-handed and always-available input, while being unobtrusive and discrete. Inspired by commercial nail stickers, the device blends into the user's body, is customizable, fashionable and even removable. We show example applications of using the device as a remote controller when hands are busy and using the system to increase the input space of mobile phones."
    },
    {
        "title": "Exploring Subtle Foot Plantar-based Gestures with Sock-placed Pressure Sensors",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using Random Body Parts for Input",
        "data": "April 2015",
        "authors": [
            "Koumei Fukahori",
            "Daisuke Sakamoto",
            "Takeo Igarashi"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702308",
        "citation": "41",
        "abstract": "We propose subtle foot-based gestures named foot plantar-based (FPB) gestures that are used with sock-placed pressure sensors. In this system, the user can control a computing device by changing his or her foot plantar distributions, e.g., pressing the floor with his/her toe. Because such foot movement is subtle, it is suitable for use especially in a public space such as a crowded train. In this study, we first conduct a guessability study to design a user-defined gesture set for interaction with a computing device. Then, we implement a gesture recognizer with a machine learning technique. To avoid unexpected gesture activations, we also collect foot plantar pressure patterns made during daily activities such as walking, as negative training data. Additionally, we evaluate the unobservability of FPB gestures by using crowdsourcing. Finally, we conclude with several applications to further illustrate the utility of FPB gestures."
    },
    {
        "title": "Session details: Brain & Physiological Data use for HCI",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Brain & Physiological Data use for HCI",
        "data": "April 2015",
        "authors": [
            "Jacob Robert"
        ],
        "DOI": "https://doi.org/10.1145/3251753",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Classification Accuracy from the Perspective of the User: Real-Time Interaction with Physiological Computing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Brain & Physiological Data use for HCI",
        "data": "April 2015",
        "authors": [
            "Stephen H. Fairclough",
            "Alexander J. Karran",
            "Kiel Gilleade"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702454",
        "citation": "15",
        "abstract": "The accurate classification of psychophysiological data is an important determinant of the quality when interacting with a physiological computing system. Previous research has focused on classification accuracy of psychophysiological data in purely mathematical terms but little is known about how accuracy metrics relate to users' perceptions of accuracy during real-time interaction. A group of 14 participants watched a series of movie trailers and were asked to subjectively indicate their level of interest in a binary high/low fashion. Psychophysiological data (EEG, ECG and SCL) were used to create a binary classification of interest via a Support Vector Machine (SVM) algorithm. After a period of training, participants received real-time feedback from the classification algorithm and perceptions of accuracy were assessed. The purpose of the study was to compare mathematical classification accuracy with the perceived accuracy of the system as experienced by the users. Results indicated that perceived accuracy was subject to a number of psychological biases resulting from expectations, entrainment and development of trust. The F1 score was generally a significant predictor of perceived accuracy."
    },
    {
        "title": "Examining the Reliability of Using fNIRS in Realistic HCI Settings for Spatial and Verbal Tasks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Brain & Physiological Data use for HCI",
        "data": "April 2015",
        "authors": [
            "Horia A. Maior",
            "Matthew Pike",
            "Sarah Sharples",
            "Max L. Wilson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702315",
        "citation": "16",
        "abstract": "Recent efforts have shown that functional near-infrared spectroscopy (fNIRS) has potential value for brain sensing in HCI user studies. Research has shown that, although large head movement significantly affects fNIRS data, typical keyboard use, mouse movement, and non-task-related verbalisations do not affect measurements during Verbal tasks. This work aims to examine the Reliability of fNIRS, by 1) confirming these prior findings, and 2) significantly extending our understanding of how artefacts affect recordings during Spatial tasks, since much of user interfaces and interaction is inherently spatial. Our results show that artefacts have a significantly different impact during Verbal and Spatial tasks. We contribute clearer insights into using fNIRS as a tool within HCI user studies."
    },
    {
        "title": "Session details: Software Engineering Tools",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Software Engineering Tools",
        "data": "April 2015",
        "authors": [
            "Feng Tian"
        ],
        "DOI": "https://doi.org/10.1145/3251754",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "StructJumper: A Tool to Help Blind Programmers Navigate and Understand the Structure of Code",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Software Engineering Tools",
        "data": "April 2015",
        "authors": [
            "Catherine M. Baker",
            "Lauren R. Milne",
            "Richard E. Ladner"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702589",
        "citation": "56",
        "abstract": "It can be difficult for a blind developer to understand and navigate through a large amount of code quickly, as they are unable to skim as easily as their sighted counterparts. To help blind developers overcome this problem, we present StructJumper, an Eclipse plugin that creates a hierarchical tree based on the nesting structure of a Java class. The programmer can use the TreeView to get an overview of the code structure of the class (including all the methods and control flow statements) and can quickly switch between the TreeView and the Text Editor to get an idea of where they are within the nested structure. To evaluate StructJumper, we had seven blind programmers complete three tasks with and without our tool. We found that the users thought they would use StructJumper and there was a trend that they were faster completing the tasks with StructJumper."
    },
    {
        "title": "An Interactive System for Data Structure Development",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Software Engineering Tools",
        "data": "April 2015",
        "authors": [
            "Jibin Ou",
            "Martin Vechev",
            "Otmar Hilliges"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702319",
        "citation": "5",
        "abstract": "Data structure algorithms are of fundamental importance in teaching and software development, yet are difficult to understand. We propose a new approach for understanding, debugging and developing heap manipulating data structures. The key technical idea of our work is to combine deep parametric abstraction techniques emerging from the area of static analysis with interactive abstraction manipulation. Our approach bridges program analysis with HCI and enables new capabilities not possible before: i) online automatic visualization of the data structure in a way which captures its essential operation, thus enabling powerful local reasoning, and ii) fine grained pen and touch gestures allowing for interactive control of the abstraction -- at any point the developer can pause the program, graphically interact with the data, and continue program execution. These features address some of the most pressing challenges in developing data structures. We implemented our approach in a Java-based system called FluiEdt and evaluated it with $27$ developers. The results indicate that FluiEdt is more effective in helping developers find data structure errors than existing state of the art IDEs (e.g. Eclipse) or pure visualization based approaches."
    },
    {
        "title": "Polymorphic Blocks: Formalism-Inspired UI for Structured Connectors",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Software Engineering Tools",
        "data": "April 2015",
        "authors": [
            "Sorin Lerner",
            "Stephen R. Foster",
            "William G. Griswold"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702302",
        "citation": "13",
        "abstract": "We present a novel block-based UI called Polymorphic Blocks, in which a connector's shape visually represents the structure of the data being passed through the connector. We use Polymorphic Blocks to add visual type information to block-based programming environments like Blockly or Scratch. We also use Polymorphic Blocks to represent logical proofs. In this context, if we erase all symbols, our UI becomes a puzzle game, where solving the puzzle amounts to building a proof. We show through a user study that our Logical Puzzle Game is faster, more fun, and more engaging than an equivalent pen-and-paper interface."
    },
    {
        "title": "Session details: HCI at Home",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI at Home",
        "data": "April 2015",
        "authors": [
            "David Geerts"
        ],
        "DOI": "https://doi.org/10.1145/3251755",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Investigating Genres and Perspectives in HCI Research on the Home",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI at Home",
        "data": "April 2015",
        "authors": [
            "Audrey Desjardins",
            "Ron Wakkary",
            "William Odom"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702540",
        "citation": "81",
        "abstract": "The home and domestic experiences have been studied from multiple points of view and disciplines, with an array of methodologies in the past twenty-five years in HCI. Given the attention to the home and the volume of research, what further areas of research might there be? Based on a critical analysis of 121 works on the topic, we present seven genres of domestic technology research in HCI: social routines in the home, ongoing domestic practices, the home as a testing ground, smart homes, contested values of a home, the home as a site for interpretation, and speculative visions of the home. We articulate dominant research perspectives in HCI, and we offer two complementary perspectives about how to investigate the domestic experience in future research: the material perspective and the first person perspective."
    },
    {
        "title": "Building Change: Constructive Design of Smart Domestic Environments for Goal Achievement",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI at Home",
        "data": "April 2015",
        "authors": [
            "Ryan Brotman",
            "Winslow Burleson",
            "Jodi Forlizzi",
            "William Heywood",
            "Jisoo Lee"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702602",
        "citation": "8",
        "abstract": "This paper presents the constructive design research (CDR) of smart domestic environments comprised of smart home infrastructure, smart domestic artifacts and digital services. CDR is an approach that focuses on imagining futures and learning through the making and testing of prototypes to construct new knowledge about how people engage with the world. While the body of research on smart domestic environments includes a wealth of human-centered research, the use of CDR is marginal. Our work demonstrates how such a process engages residents in activities to imagine why people might value smart domestic environments and how they might want to interact with them. Through goal setting activities, paper prototyping, and field-testing of resident designed technology probes, we present use cases, design principles and experiential insights. After sharing these findings, we introduce the emergence of smart domestic environments as possessing persuasive, personified and artful qualities."
    },
    {
        "title": "uCap: An Internet Data Management Tool For The Home",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI at Home",
        "data": "April 2015",
        "authors": [
            "Marshini Chetty",
            "Hyojoon Kim",
            "Srikanth Sundaresan",
            "Sam Burnett",
            "Nick Feamster",
            "W. Keith Edwards"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702218",
        "citation": "17",
        "abstract": "Internet Service Providers (ISPs) have introduced \"data caps\", or quotas on the amount of data that a customer can download during a billing cycle. Under this model, Internet users who reach a data cap can be subject to degraded performance, extra fees, or even temporary interruption of Internet service. For this reason, users need better visibility into and control over their Internet usage to help them understand what uses up data and control how these quotas are reached. In this paper, we present the design and implementation of a tool, called uCap, to help home users manage Internet data. We conducted a field trial of uCap in 21 home networks in three countries and performed an in-depth qualitative study of ten of these homes. We present the results of the evaluation and implications for the design of future Internet data management tools."
    },
    {
        "title": "Mediating Attention for Second Screen Companion Content",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: HCI at Home",
        "data": "April 2015",
        "authors": [
            "Timothy Neate",
            "Matt Jones",
            "Michael Evans"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702278",
        "citation": "27",
        "abstract": "There is increasing interest in providing content to users on secondary devices while they watch TV. This material, termed companion content, can be anything from textual information, to interactive quiz games. It can be delivered throughout a broadcast and often directly relates to specific scenes in a show. This new scenario has exposed a challenging design space for creators of both the content and the enabling technology. A key question when introducing content on a secondary device is how much it detracts from, or enhances, the show the user is currently engaged with. To examine this, we investigated methods for mediating attention from the TV and onto a secondary device. By examining a typical use case we have been able to gain new insights into how best to design additional stimuli to alert users to companion content from both a broadcasting, and an HCI perspective."
    },
    {
        "title": "Session details: Voting & Volunteerism",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Voting & Volunteerism",
        "data": "April 2015",
        "authors": [
            "Andres Monroy-Hernandez"
        ],
        "DOI": "https://doi.org/10.1145/3251756",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Social Media Effectiveness for Public Engagement: Example of Small Nonprofits",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Voting & Volunteerism",
        "data": "April 2015",
        "authors": [
            "Youyang Hou",
            "Cliff Lampe"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702557",
        "citation": "36",
        "abstract": "Social media sites are increasingly adopted by small nonprofit organizations (NPOs) to help them meet their public engagement goals. However, several characteristics of small organizations make it hard for them to effectively use social media sites. We present findings from interviews with 26 small NPOs' social media professionals on how they use multiple social media sites to support public engagement. Small NPOs use multiple social media sites to engage with different stakeholders toward various ends. However, these NPOs are not using social media to its full potential with regard to community-building and action mobilization. Several challenges in small NPOs, such as ineffective measurement of social media performance, deficient organizational resources, and lack of control over work, lead to strong tensions between social media engagement strategies and outcomes. Drawing on these findings, we present several practical implications for the design of successful public engagement social media tools."
    },
    {
        "title": "Exploring Barriers to the Adoption of Mobile Technologies for Volunteer Data Collection Campaigns",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Voting & Volunteerism",
        "data": "April 2015",
        "authors": [
            "Sunyoung Kim",
            "Jennifer Mankoff",
            "Eric Paulos"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702378",
        "citation": "11",
        "abstract": "Volunteer campaigns for data collection make it possible for non-profit organizations to extend their ability to monitor and respond to critical environmental and societal issues. Yet mobile data collection technologies that have the potential to lower the costs and increase the accuracy of volunteer-collected data are not commonly used in these campaigns. In this paper we conduct a series of studies that reveal the complex issues affecting technology adoption in this domain. First, we surveyed and interviewed existing volunteering campaigns to map out current technology usage within volunteer campaigns. Next, we provided two organizations with a customizable tool for data collection (Sensr) and studied its use and non-use across six real volunteer-driven campaigns over six months. Our study explored success and failure across the first few phases of the campaign lifecycle (campaign creation, initial deployment, and adoption). Our results highlight the impact of resource constraints, cognitive factors, the depth of volunteer engagement, and stakeholders' perspective on technology as important factors contributing to the adoption and usage of mobile data collection technologies. We use these findings to argue for specific design features to accelerate the adoption and use of such tools in volunteer data collection campaigns."
    },
    {
        "title": "\"Everyone Is Talking about It!\": A Distributed Approach to Urban Voting Technology and Visualisations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Voting & Volunteerism",
        "data": "April 2015",
        "authors": [
            "Lisa Koeman",
            "Vaiva Kalnikaité",
            "Yvonne Rogers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702263",
        "citation": "69",
        "abstract": "The deployment of technology interventions, such as public displays and mobile apps, in community settings has been found to engage people in sharing and comparing their opinions. Our research is concerned with how to extend this to community-wide participation by devising and deploying multiple voting devices and visualisations. We present an in-the-wild study where a number of shopkeepers along a street participated by placing a novel voting device in their shops to collect locals' opinions. Results were displayed outside the shops, on the pavement. This distributed set-up was found to promote public debate on local issues, particularly around the perceived divide between people on either end of the street. We outline our design process and describe the impact of distributing voting devices and situated visualisations in a local community. \\"
    },
    {
        "title": "Design Challenges in Supporting Distributed Knowledge: An Examination of Organizing Elections",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Voting & Volunteerism",
        "data": "April 2015",
        "authors": [
            "Nina Boulus-Rødje",
            "Pernille Bjorn"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702458",
        "citation": "6",
        "abstract": "This paper identifies the design challenges for creating collaborative technologies supporting the practices of organizing elections. We ethnographically investigate the distributed nature of knowledge as enacted between heterogeneous groups over the course of three elections in Denmark. We 1) identify fundamental characteristics of elections, 2) provide a comprehensive account of the distributed nature of knowledge in organizing and executing elections, and 3) point to new challenging areas for human-computer interaction (HCI) design supporting distributed collaborative knowledge practices. We found that organizational pattern of elections complicates the embodiment of nomadic knowledge, which is crucial for managing the effective organization of an election. Thus, one of the relevant design challenges is finding out how to support the timely distribution of large amounts of information, while still ensuring it is appropriately divided and delivered to various groups participating in planning and executing elections."
    },
    {
        "title": "Session details: Socio-Political Interactions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Socio-Political Interactions",
        "data": "April 2015",
        "authors": [
            "Liang Gou"
        ],
        "DOI": "https://doi.org/10.1145/3251757",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "The Politics of Measurement and Action",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Socio-Political Interactions",
        "data": "April 2015",
        "authors": [
            "Kathleen H. Pine",
            "Max Liboiron"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702298",
        "citation": "88",
        "abstract": "Contemporary decisions about the management of populations, public services, security, and the environment are increasingly made through knowledge gleaned from \"big data\" and its attendant infrastructures and algorithms. Though often described as \"raw,\" this data is produced by techniques of measurement that are imbued with judgments and values that dictate what is counted and what is not, what is considered the best unit of measurement, and how different things are grouped together and \"made\" into a measureable entity. In this paper, we analyze these politics of measurement and how they relate to action through two case studies involving high stake public health measurements where experts intentionally leverage measurement to change definitions of harm and health. That is, they use measurement for activism. The case studies offer a framework for thinking about of how the politics of measurement are present in user interfaces. It is usually assumed that the human element has been scrubbed from the database and that significant political and subjective interventions come from the analysis or use of data after the fact. Instead, we argue that human-computer interactions start before the data reaches the computer because various measurement interfaces are the invisible premise of data and databases, and these measurements are political."
    },
    {
        "title": "Beyond Participatory Production: Digitally Supporting Grassroots Documentary",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Socio-Political Interactions",
        "data": "April 2015",
        "authors": [
            "David Philip Green",
            "Simon J. Bowen",
            "Christopher Newell",
            "Guy Schofield",
            "Tom Bartindale",
            "Clara Crivellaro",
            "Alia Sheikh",
            "Peter Wright",
            "Patrick Olivier"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702203",
        "citation": "17",
        "abstract": "We conducted a study to explore the values and qualities of 'grassroots documentaries', framed around the production of two parallel documentary films with a London-based opera company. A team of professional filmmakers produced one film and the other was an exploratory form of grassroots documentary. We studied the different production activities through observations, interviews and a reflective workshop at the end of the study and evaluated the resulting films. Our analysis reveals critical insights that could inform the next generation of technological systems to support user-generated video content (UGVC) production, particularly in collaborative contexts such as grassroots communities."
    },
    {
        "title": "Designing Political Deliberation Environments to Support Interactions in the Public Sphere",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Socio-Political Interactions",
        "data": "April 2015",
        "authors": [
            "Bryan Semaan",
            "Heather Faucett",
            "Scott P. Robertson",
            "Misa Maruyama",
            "Sara Douglas"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702403",
        "citation": "47",
        "abstract": "Little is known about the challenges and successes people face when piecing together multiple social media to interact in the online public sphere when: seeking information, disseminating information, and engaging in political discussions. We interviewed 29 US citizens and conducted 17 talk-out-loud sessions with people who were using one or more social media technologies, such as Facebook and Twitter, to interact in the online public sphere. We identified a number of challenges and workarounds related to public sphere interactions, and used our findings to formulate requirements for new political environments that support the interactions in the public sphere. Through evolving requirements generation, we developed a new political deliberation technology, dubbed Poli, which is an integrated social media environment with the potential to enable more effective interactions in the public sphere. We discuss several remaining questions and limitations to our tool that will drive future work."
    },
    {
        "title": "Debating Poverty Porn on Twitter: Social Media as a Place for Everyday Socio-Political Talk",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Socio-Political Interactions",
        "data": "April 2015",
        "authors": [
            "Phil Brooker",
            "John Vines",
            "Selina Sutton",
            "Julie Barnett",
            "Tom Feltwell",
            "Shaun Lawson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702291",
        "citation": "29",
        "abstract": "This paper presents an empirical investigation of how people appropriated Twitter for socio-political talk in response to a television (TV) portrayal of people supported by state welfare and benefits. Our findings reveal how online discussion during, and in-between, TV broadcasts was characterised by distinctly different qualities, topics and user behaviours. These findings offer design opportunities for social media services to (i) support more balanced real-time commentaries of politically-charged media, (ii) actively promote discussion to continue after, and between, programming; and (iii) incorporate different motivations and attitudes towards socio-political concerns, as well as different practices of communicating those concerns. We contribute to the developing HCI literature on how social media intersects with political and civic engagement and specifically highlight the ways in which Twitter interacts with other forms of media as a site of everyday socio-political talk and debate."
    },
    {
        "title": "Session details: Understanding Health through Online Behavior",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Health through Online Behavior",
        "data": "April 2015",
        "authors": [
            "Mary Czerwinski"
        ],
        "DOI": "https://doi.org/10.1145/3251758",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Recognizing Depression from Twitter Activity",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Health through Online Behavior",
        "data": "April 2015",
        "authors": [
            "Sho Tsugawa",
            "Yusuke Kikuchi",
            "Fumio Kishino",
            "Kosuke Nakajima",
            "Yuichi Itoh",
            "Hiroyuki Ohsaki"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702280",
        "citation": "167",
        "abstract": "In this paper, we extensively evaluate the effectiveness of using a user's social media activities for estimating degree of depression. As ground truth data, we use the results of a web-based questionnaire for measuring degree of depression of Twitter users. We extract several features from the activity histories of Twitter users. By leveraging these features, we construct models for estimating the presence of active depression. Through experiments, we show that (1) features obtained from user activities can be used to predict depression of users with an accuracy of 69%, (2) topics of tweets estimated with a topic model are useful features, (3) approximately two months of observation data are necessary for recognizing depression, and longer observation periods do not contribute to improving the accuracy of estimation for current depression; sometimes, longer periods worsen the accuracy."
    },
    {
        "title": "You Tweet What You Eat: Studying Food Consumption Through Twitter",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Health through Online Behavior",
        "data": "April 2015",
        "authors": [
            "Sofiane Abbar",
            "Yelena Mejova",
            "Ingmar Weber"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702153",
        "citation": "137",
        "abstract": "Food is an integral part of our lives, cultures, and well-being, and is of major interest to public health. The collection of daily nutritional data involves keeping detailed diaries or periodic surveys and is limited in scope and reach. Alternatively, social media is infamous for allowing its users to update the world on the minutiae of their daily lives, including their eating habits. In this work we examine the potential of Twitter to provide insight into US-wide dietary choices by linking the tweeted dining experiences of 210K users to their interests, demographics, and social networks. We validate our approach by relating the caloric values of the foods mentioned in the tweets to the state-wide obesity rates, achieving a Pearson correlation of 0.77 across the 50 US states and the District of Columbia. We then build a model to predict county-wide obesity and diabetes statistics based on a combination of demographic variables and food names mentioned on Twitter. Our results show significant improvement over previous CHI research (Culotta 2014). We further link this data to societal and economic factors, such as education and income, illustrating that areas with higher education levels tweet about food that is significantly less caloric. Finally, we address the somewhat controversial issue of the social nature of obesity (Christakis & Fowler 2007) by inducing two social networks using mentions and reciprocal following relationships."
    },
    {
        "title": "Rethinking the Mobile Food Journal: Exploring Opportunities for Lightweight Photo-Based Capture",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Health through Online Behavior",
        "data": "April 2015",
        "authors": [
            "Felicia Cordeiro",
            "Elizabeth Bales",
            "Erin Cherry",
            "James Fogarty"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702154",
        "citation": "131",
        "abstract": "Food choices are among the most frequent and important health decisions in everyday life, but remain notoriously difficult to capture. This work examines opportunities for lightweight photo-based capture in mobile food journals. We first report on a survey of 257 people, examining how they define healthy eating, their experiences and challenges with existing food journaling methods, and their ability to interpret nutritional information that can be captured in a food journal. We then report on interviews and a field study with 27 participants using a lightweight, photo-based food journal for between 4 to 8 weeks. We discuss mismatches between motivations and current designs, challenges of current approaches to food journaling, and opportunities for photos as an alternative to the pervasive but often inappropriate emphasis on quantitative tracking in mobile food journals."
    },
    {
        "title": "Collective Sensemaking in Online Health Forums",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Health through Online Behavior",
        "data": "April 2015",
        "authors": [
            "Lena Mamykina",
            "Drashko Nakikj",
            "Noemie Elhadad"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702566",
        "citation": "62",
        "abstract": "Online health communities collect vast amounts of information and opinions in regards to health and wellness management. However, these opinions are usually stored within lengthy and loosely structured discussion threads; synthesizing information in these threads can be challenging. In this mixed-methods study, grounded in the theoretical perspective of collective sensemaking, we examined patterns of communication within an online diabetes community TuDiabetes. The results of the study suggest that members of TuDiabetes often construct shared meaning through deep discussions, back and forth negotiation of perspectives, and resolution of conflicts in opinions. However, unlike participants of other sensemaking communities, members of TuDiabetes often value multiplicity of opinions rather than consensus. We use study results to draw implications for the design of computing platforms for facilitating collective sensemaking that promote construction of shared knowledge yet embrace diversity of opinions."
    },
    {
        "title": "Session details: Natural User Interfaces for InfoVis",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Natural User Interfaces for InfoVis",
        "data": "April 2015",
        "authors": [
            "Bongshin Lee"
        ],
        "DOI": "https://doi.org/10.1145/3251759",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Opportunities and Challenges for Data Physicalization",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Natural User Interfaces for InfoVis",
        "data": "April 2015",
        "authors": [
            "Yvonne Jansen",
            "Pierre Dragicevic",
            "Petra Isenberg",
            "Jason Alexander",
            "Abhijit Karnik",
            "Johan Kildal",
            "Sriram Subramanian",
            "Kasper Hornbæk"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702180",
        "citation": "270",
        "abstract": "Physical representations of data have existed for thousands of years. Yet it is now that advances in digital fabrication, actuated tangible interfaces, and shape-changing displays are spurring an emerging area of research that we call Data Physicalization. It aims to help people explore, understand, and communicate data using computer-supported physical data representations. We call these representations physicalizations, analogously to visualizations -- their purely visual counterpart. In this article, we go beyond the focused research questions addressed so far by delineating the research area, synthesizing its open challenges and laying out a research agenda."
    },
    {
        "title": "Exploring Interactions with Physically Dynamic Bar Charts",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Natural User Interfaces for InfoVis",
        "data": "April 2015",
        "authors": [
            "Faisal Taher",
            "John Hardy",
            "Abhijit Karnik",
            "Christian Weichel",
            "Yvonne Jansen",
            "Kasper Hornbæk",
            "Jason Alexander"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702604",
        "citation": "96",
        "abstract": "Visualizations such as bar charts help users reason about data, but are mostly screen-based, rarely physical, and almost never physical and dynamic. This paper investigates the role of physically dynamic bar charts and evaluates new interactions for exploring and working with datasets rendered in dynamic physical form. To facilitate our exploration we constructed a 10x10 interactive bar chart and designed interactions that supported fundamental visualisation tasks, specifically; annotation, filtering, organization, and navigation. The interactions were evaluated in a user study with 17 participants. Our findings identify the preferred methods of working with the data for each task i.e. directly tapping rows to hide bars, highlight the strengths and limitations of working with physical data, and discuss the challenges of integrating the proposed interactions together into a larger data exploration system. In general, physical interactions were intuitive, informative, and enjoyable, paving the way for new explorations in physical data visualizations."
    },
    {
        "title": "Evaluating the Memorability of Physical Visualizations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Natural User Interfaces for InfoVis",
        "data": "April 2015",
        "authors": [
            "Simon Stusak",
            "Jeannette Schwarz",
            "Andreas Butz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702248",
        "citation": "31",
        "abstract": "Physical Visualizations are currently mostly used in casual contexts, e.g., as artistic data sculptures. However, their measurable benefits for traditional information visualization are largely unexplored. As a step in this direction, we compared the memorability of physical visualizations to that of digital visualizations. We conducted a user study with 40 participants in which we measured the recall of three types of information immediately after exploration and with a delay of two weeks. The results show that the physical visualization led to significantly less information decay within this time span. Our results build on known effects from cognitive psychology and provide a first indicator for measurable benefits of physical visualizations regarding memorability."
    },
    {
        "title": "Personality as a Predictor of User Strategy: How Locus of Control Affects Search Strategies on Tree Visualizations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Natural User Interfaces for InfoVis",
        "data": "April 2015",
        "authors": [
            "Alvitta Ottley",
            "Huahai Yang",
            "Remco Chang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702590",
        "citation": "34",
        "abstract": "Individual differences matter. While this has been the theme for many recent works in the Visualization and HCI communities, the mystery of how to develop personalized visualizations remains. This is largely because very little is known about how users actually use visualizations to solve problems and even less is known about how individual differences affect these problem-solving strategies. In this paper, we provide evidence that strategies are indeed influenced by individual differences. We demonstrate how the personality trait locus of control impacts strategies on hierarchical visualizations, and we introduce design recommendations for personalized visualizations."
    },
    {
        "title": "SketchSliders: Sketching Widgets for Visual Exploration on Wall Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Natural User Interfaces for InfoVis",
        "data": "April 2015",
        "authors": [
            "Theophanis Tsandilas",
            "Anastasia Bezerianos",
            "Thibaut Jacob"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702129",
        "citation": "20",
        "abstract": "We introduce a mobile sketching interface for exploring multi-dimensional datasets on wall displays. We demonstrate the idea of SketchSliders, range sliders that users can freely sketch on a mobile surface to customize their exploration. A small combination of sketches and gestures allows the creation of complex interactive sliders, such as circular sliders for periodic data, slider branches for detailed interaction, and fisheye transformation sliders. We augment sliders with a suite of tools, such as markers, slider cursors, and approximate views of data distributions. Our designs are inspired by a design study with three visualization experts and validated through a user study with six experts using our system. Our findings indicate that our sketching interface accommodates a wide range of exploration strategies, helping users customize as well as focus their visual explorations."
    },
    {
        "title": "Session details: UX Methods 4",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UX Methods 4",
        "data": "April 2015",
        "authors": [
            "Benjamin Hanrahan"
        ],
        "DOI": "https://doi.org/10.1145/3251760",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Two-Level Personas for Nested Design Spaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UX Methods 4",
        "data": "April 2015",
        "authors": [
            "Anke Dittmar",
            "Maximilian Hensch"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702168",
        "citation": "12",
        "abstract": "The persona approach is often treated as a single user-centered design method, but there are variations and adaptations for different design contexts which go beyond local customization. The paper discusses a set of dimensions and success criteria for describing the different persona uses, presenting a new framework. It then specifically investigates personas in the context of end-user development. Professional designers need to consider the design space for potential end-user tools. In addition they need to understand that their users are often designers themselves (they are designer-users), requiring that they also consider the design spaces of their users. Two-level personas are introduced to make professional designers more aware of such nested design spaces. A two-level persona consists of one first-level persona and a set of second-level personas to additionally represent complex designer-user relationships. The effectiveness of the approach is investigated in an exploratory empirical study. The results suggest that two-level personas add value when designing end-user design tools."
    },
    {
        "title": "The Work of Mad Men that Makes the Methods of Math Men Work: Practically Occasioned Segment Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UX Methods 4",
        "data": "April 2015",
        "authors": [
            "Michael F. Clarke"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702493",
        "citation": "12",
        "abstract": "This study concerns the practical methods used to design segmentation models for digital advertising. I illuminate some of the collaborative activities workers rely on to create these web analytics based groupings. This work remains overlooked as the popularity of automation and statistical methods for segmenting customers continues to grow. I explain some of the ways the advertising customer is present as a background expectancy while workers make segment composition decisions. This approach is meant to complement established evaluative, technical, and statistical methods used to create segments and personas in design and marketing. This may inspire similar approaches to designing for specific groups of people while working with large data sets. Incorporating these customer-orienting practices in design and advertising processes could lead to novel approaches for both segment targeting and customer relationship management (CRM) software."
    },
    {
        "title": "Flow of Competence in UX Design Practice",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UX Methods 4",
        "data": "April 2015",
        "authors": [
            "Colin M. Gray",
            "Austin L. Toombs",
            "Shad Gross"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702579",
        "citation": "41",
        "abstract": "UX and design culture are beginning to dominate corporate priorities, but despite the current hype there is often a disconnect between the organizational efficiencies desired by executives and the knowledge of how UX can or should address these issues. This exploratory study addresses this space by reframing the concept of competence in UX to include the flow of competence between individual designers and the companies in which they work. Our reframing resulted in a preliminary schema based on interviews conducted with six design practitioners, which allows this flow to be traced in a performative way on the part of individuals and groups over time. We then trace this flow of individual and organizational competence through three case studies of UX adoption. Opportunities for use of this preliminary schema as a generative, rhetorical tool for HCI researchers to further interrogate UX adoption are considered, including accounting for factors that affect adoption."
    },
    {
        "title": "Usees",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: UX Methods 4",
        "data": "April 2015",
        "authors": [
            "Eric P.S. Baumer"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702147",
        "citation": "34",
        "abstract": "HCI has developed a powerful vocabulary for thinking about, and methods for engaging with, users. Similarly, recent work has advanced complementary understanding of technology non-use. However, other spaces of interaction with technology may occur that sit uncomfortably between these two poles. This paper presents two case studies highlighting individuals who neither are clearly users of a system nor are clearly non-users. Based on these cases, the paper develops the concept of usee to help account for such situations that lie between existing analytic categories."
    },
    {
        "title": "Session details: Augmented & Virtual Reality in the Real World",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmented & Virtual Reality in the Real World",
        "data": "April 2015",
        "authors": [
            "Morten Fjeld"
        ],
        "DOI": "https://doi.org/10.1145/3251761",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Substitutional Reality: Using the Physical Environment to Design Virtual Reality Experiences",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmented & Virtual Reality in the Real World",
        "data": "April 2015",
        "authors": [
            "Adalberto L. Simeone",
            "Eduardo Velloso",
            "Hans Gellersen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702389",
        "citation": "226",
        "abstract": "Experiencing Virtual Reality in domestic and other uncontrolled settings is challenging due to the presence of physical objects and furniture that are not usually defined in the Virtual Environment. To address this challenge, we explore the concept of Substitutional Reality in the context of Virtual Reality: a class of Virtual Environments where every physical object surrounding a user is paired, with some degree of discrepancy, to a virtual counterpart. We present a model of potential substitutions and validate it in two user studies. In the first study we investigated factors that affect participants' suspension of disbelief and ease of use. We systematically altered the virtual representation of a physical object and recorded responses from 20 participants. The second study investigated users' levels of engagement as the physical proxy for a virtual object varied. From the results, we derive a set of guidelines for the design of future Substitutional Reality experiences."
    },
    {
        "title": "The Semantic Paintbrush: Interactive 3D Mapping and Recognition in Large Outdoor Spaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmented & Virtual Reality in the Real World",
        "data": "April 2015",
        "authors": [
            "Ondrej Miksik",
            "Vibhav Vineet",
            "Morten Lidegaard",
            "Ram Prasaath",
            "Matthias Nießner",
            "Stuart Golodetz",
            "Stephen L. Hicks",
            "Patrick Pérez",
            "Shahram Izadi",
            "Philip H.S. Torr"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702222",
        "citation": "34",
        "abstract": "We present an augmented reality system for large scale 3D reconstruction and recognition in outdoor scenes. Unlike existing prior work, which tries to reconstruct scenes using active depth cameras, we use a purely passive stereo setup, allowing for outdoor use and extended sensing range. Our system not only produces a map of the 3D environment in real-time, it also allows the user to draw (or 'paint') with a laser pointer directly onto the reconstruction to segment the model into objects. Given these examples our system then learns to segment other parts of the 3D map during online acquisition. Unlike typical object recognition systems, ours therefore very much places the user 'in the loop' to segment particular objects of interest, rather than learning from predefined databases. The laser pointer additionally helps to 'clean up' the stereo reconstruction and final 3D map, interactively. Using our system, within minutes, a user can capture a full 3D map, segment it into objects of interest, and refine parts of the model during capture. We provide full technical details of our system to aid replication, as well as quantitative evaluation of system components. We demonstrate the possibility of using our system for helping the visually impaired navigate through spaces. Beyond this use, our system can be used for playing large-scale augmented reality games, shared online to augment streetview data, and used for more detailed car and person navigation."
    },
    {
        "title": "User-Defined Game Input for Smart Glasses in Public Space",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmented & Virtual Reality in the Real World",
        "data": "April 2015",
        "authors": [
            "Ying-Chao Tung",
            "Chun-Yen Hsu",
            "Han-Yu Wang",
            "Silvia Chyou",
            "Jhe-Wei Lin",
            "Pei-Jung Wu",
            "Andries Valstar",
            "Mike Y. Chen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702214",
        "citation": "67",
        "abstract": "Smart glasses, such as Google Glass, provide always-available displays not offered by console and mobile gaming devices, and could potentially offer a pervasive gaming experience. However, research on input for games on smart glasses has been constrained by the available sensors to date. To help inform design directions, this paper explores user-defined game input for smart glasses beyond the capabilities of current sensors, and focuses on the interaction in public settings. We conducted a user-defined input study with 24 participants, each performing 17 common game control tasks using 3 classes of interaction and 2 form factors of smart glasses, for a total of 2448 trials. Results show that users significantly preferred non-touch and non-handheld interaction over using handheld input devices, such as in-air gestures. Also, for touch input without handheld devices, users preferred interacting with their palms over wearable devices (51% vs 20%). In addition, users preferred interactions that are less noticeable due to concerns with social acceptance, and preferred in-air gestures in front of the torso rather than in front of the face (63% vs 37%)."
    },
    {
        "title": "Retargeting Technical Documentation to Augmented Reality",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Augmented & Virtual Reality in the Real World",
        "data": "April 2015",
        "authors": [
            "Peter Mohr",
            "Bernhard Kerbl",
            "Michael Donoser",
            "Dieter Schmalstieg",
            "Denis Kalkofen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702490",
        "citation": "38",
        "abstract": "We present a system which automatically transfers printed technical documentation, such as handbooks, to three-dimensional Augmented Reality. Our system identifies the most frequent forms of instructions found in printed documentation, such as image sequences, explosion diagrams, textual annotations and arrows indicating motion. The analysis of the printed documentation works automatically, with minimal user input. The system only requires the documentation itself and a CAD model or 3D scan of the object described in the documentation. The output is a fully interactive Augmented Reality application, presenting the information from the printed documentation in 3D, registered to the real object."
    },
    {
        "title": "Session details: Gesture Elicitation & Recognition",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gesture Elicitation & Recognition",
        "data": "April 2015",
        "authors": [
            "Niels Henze"
        ],
        "DOI": "https://doi.org/10.1145/3251762",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Soft-Constraints to Reduce Legacy and Performance Bias to Elicit Whole-body Gestures with Low Arm Fatigue",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gesture Elicitation & Recognition",
        "data": "April 2015",
        "authors": [
            "Jaime Ruiz",
            "Daniel Vogel"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702583",
        "citation": "43",
        "abstract": "Participant biases can influence proposed gestures in elicitation studies. There is a legacy bias from previous experience with, or even knowledge of, existing input devices, interfaces, and technologies. There is also a performance bias, where the artificial study setting does not encourage consideration of long-term aspects such as fatigue. These biases make it especially difficult to uncover gestures appropriate for whole-body gestural input. We propose using soft constraints to correct for legacy and performance biases by penalizing physical movements. We use wrist weights as a soft constraint to elicit whole-body gestures with low arm fatigue. We show soft constraints encourage a wider range of gestures using subtler arm movements or alternate body parts and lower consumed endurance for arm movements."
    },
    {
        "title": "Unistroke Gesture Recognition Through Polyline Approximation and Alignment",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gesture Elicitation & Recognition",
        "data": "April 2015",
        "authors": [
            "Vittorio Fuccella",
            "Gennaro Costagliola"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702505",
        "citation": "13",
        "abstract": "We present a novel gesture recognizer suitable for fast prototyping of gesture-based applications. The recognizer uses a nearest neighbor approach, and requires a small number of samples for each class. The similarity between two gestures is calculated through a three steps procedure: firstly, each gesture is approximated to a polyline, in order to extract its main movements; then, the two polylines are aligned to obtain an equal number of segments from both of them; lastly, the distance is found by summing the contribution of each pair of segments. We tested the recognizer on two different datasets and found that it performs more accurately than a state-of-art method."
    },
    {
        "title": "Gesture On: Enabling Always-On Touch Gestures for Fast Mobile Access from the Device Standby Mode",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gesture Elicitation & Recognition",
        "data": "April 2015",
        "authors": [
            "Hao Lu",
            "Yang Li"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702610",
        "citation": "18",
        "abstract": "A significant percentage of mobile interaction involves short-period usages that originate from the standby mode-users wake up a device by pressing the power button, unlock the device by authenticating themselves, and then search for a target app or functionality on the device. These additional steps preceding a target task imposes significant overhead on users for each mobile device access. To address the issue, we developed Gesture On, a system that enables gesture shortcuts in the standby mode by which a user can draw a gesture on the touchscreen before the screen is turned on. Based on the gesture, our system directly brings up a target item onto the screen that bypasses all these additional steps in a mobile access. This paper examines several challenges in realizing Gesture On, including robustly rejecting accidental touches when the device is in standby, battery consumption incurred for continuous sensing and gesture-based user authentication methods for automatically device unlocking. Our analyses based on a set of user data indicated that Gesture On demonstrates a feasible approach for leveraging the standby mode for fast access to mobile content."
    },
    {
        "title": "Optimizing Touchscreen Keyboards for Gesture Typing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gesture Elicitation & Recognition",
        "data": "April 2015",
        "authors": [
            "Brian A. Smith",
            "Xiaojun Bi",
            "Shumin Zhai"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702357",
        "citation": "34",
        "abstract": "Despite its growing popularity, gesture typing suffers from a major problem not present in touch typing: gesture ambiguity on the Qwerty keyboard. By applying rigorous mathematical optimization methods, this paper systematically investigates the optimization space related to the accuracy, speed, and Qwerty similarity of a gesture typing keyboard. Our investigation shows that optimizing the layout for gesture clarity (a metric measuring how unique word gestures are on a keyboard) drastically improves the accuracy of gesture typing. Moreover, if we also accommodate gesture speed, or both gesture speed and Qwerty similarity, we can still reduce error rates by 52% and 37% over Qwerty, respectively. In addition to investigating the optimization space, this work contributes a set of optimized layouts such as GK-D and GK-T that can immediately benefit mobile device users."
    },
    {
        "title": "Design and Evaluation of a Self-Correcting Gesture Interface based on Error Potentials from EEG",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gesture Elicitation & Recognition",
        "data": "April 2015",
        "authors": [
            "Felix Putze",
            "Christoph Amma",
            "Tanja Schultz"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702184",
        "citation": "8",
        "abstract": "Any user interface which automatically interprets the user's input using natural modalities like gestures makes mistakes. System behavior depending on such mistakes will confuse the user and lead to an erroneous interaction flow. The automatic detection of error potentials in electroencephalographic data recorded from a user allows the system to detect such states of confusion and automatically bring the interaction back on track. In this work, we describe the design of such a self-correcting gesture interface, implement different strategies to deal with detected errors, use a simulation approach to analyze performance and costs of those strategies and execute a user study to evaluate user satisfaction. We show that self-correction significantly improves gesture recognition accuracy at lower costs and with higher acceptance than manual correction."
    },
    {
        "title": "Session details: Programming Environments",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming Environments",
        "data": "April 2015",
        "authors": [
            "Joonhwan Lee"
        ],
        "DOI": "https://doi.org/10.1145/3251763",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Constructing Conceptual Knowledge Artefacts: Activity Patterns in the Ontology Authoring Process",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming Environments",
        "data": "April 2015",
        "authors": [
            "Markel Vigo",
            "Caroline Jay",
            "Robert Stevens"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702495",
        "citation": "8",
        "abstract": "Ontologies are complex knowledge representation artefacts used widely across biomedical, media and industrial domains. They are used for defining terminologies and providing metadata, especially for linked open data, and as such their use is rapidly increasing, but so far development tools have not benefited from empirical research into the ontology authoring process. This paper presents the results of a study that identifies common activity patterns through analysis of eye-tracking data and the event logs of the popular authoring tool, Protégé. Informed by the activity patterns discovered, we propose design guidelines for bulk editing, efficient reasoning and increased situational awareness. Methodological implications go beyond the remit of knowledge artefacts: we establish a method for studying the usability of software designed for highly specialised complex domains."
    },
    {
        "title": "Helping Users Bootstrap Ontologies: An Empirical Investigation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming Environments",
        "data": "April 2015",
        "authors": [
            "Yuhao Zhang",
            "Tania Tudorache",
            "Matthew Horridge",
            "Mark A. Musen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702433",
        "citation": "2",
        "abstract": "An ontology is a machine processable artifact that captures knowledge about some domain of interest. Ontologies are used in various domains including healthcare, science, and commerce. In this paper we examine the ontology bootstrapping problem. Specifically, we look at an approach that uses both competency questions and knowledge source reuse via recommendations to address the \"cold start problem\" that is, the task of creating an ontology from scratch. We describe this approach, an implementation of it, and we present an evaluation in the form of a controlled user study. We find that the approach leads users into creating significantly more detailed initial ontologies that have a greater domain coverage than ontologies produced without this support. Furthermore, in spite of a more involved workflow, the usability and user satisfaction of the bootstrapping approach is as good as a state-of-the-art ontology editor with no additional support."
    },
    {
        "title": "A Spreadsheet Model for Handling Streaming Data",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming Environments",
        "data": "April 2015",
        "authors": [
            "Kerry Shih-Ping Chang",
            "Brad A. Myers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702587",
        "citation": "6",
        "abstract": "We present a spreadsheet model for working with streaming data. Our prototype tool presents techniques to let the user stream data from web services and web input elements to a spreadsheet without preprogramming those sources into the tool. Spreadsheet cells record metadata about where and when the data came from, allowing the user to view and manipulate streaming data using temporal information. Starting and pausing a data stream in the spreadsheet can be controlled programmatically using values computed by spreadsheet cells, making the spreadsheet program highly dynamic and interactive. We demonstrate the range of our design with a series of examples highlighting its ability to create different kinds of applications that process real-time data from the web using simple spreadsheet formulas."
    },
    {
        "title": "TextAlive: Integrated Design Environment for Kinetic Typography",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming Environments",
        "data": "April 2015",
        "authors": [
            "Jun Kato",
            "Tomoyasu Nakano",
            "Masataka Goto"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702140",
        "citation": "25",
        "abstract": "This paper presents TextAlive, a graphical tool that allows interactive editing of kinetic typography videos in which lyrics or transcripts are animated in synchrony with the corresponding music or speech. While existing systems have allowed the designer and casual user to create animations, most of them do not take into account synchronization with audio signals. They allow predefined motions to be applied to objects and parameters to be tweaked, but it is usually impossible to extend the predefined set of motion algorithms within these systems. We therefore propose an integrated design environment featuring (1) GUIs that designers can use to create and edit animations synchronized with audio signals, (2) integrated tools that programmers can use to implement animation algorithms, and (3) a framework for bridging the interfaces for designers and programmers. A preliminary user study with designers, programmers, and casual users demonstrated its capability in authoring various kinetic typography videos."
    },
    {
        "title": "Power, Empowerment and Open Source Usability",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Programming Environments",
        "data": "April 2015",
        "authors": [
            "Mikko Rajanen",
            "Netta Iivari"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702441",
        "citation": "15",
        "abstract": "Open source software (OSS) projects are often seen as participatory and egalitarian settings where people collaboratively develop software to serve their needs as well as the needs of others. In this paper, however, we argue that power and politics also characterize OSS development, and that this has serious implications for OSS usability. The existing Human-Computer Interaction (HCI) research on OSS usability has already shown that power and politics play a role; this study offers a theoretical treatment of the matter. A theoretical framework on power and empowerment is utilized in analyzing empirical data on OSS usability as well as the existing body of knowledge on the topic. With the help of this framework, HCI research can address the aspects of power and empowerment in OSS usability in a more systematic and comprehensive manner."
    },
    {
        "title": "Session details: Digital Collections, Practice & Legacy",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital Collections, Practice & Legacy",
        "data": "April 2015",
        "authors": [
            "Will Odom"
        ],
        "DOI": "https://doi.org/10.1145/3251764",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Digital Collections and Digital Collecting Practices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital Collections, Practice & Legacy",
        "data": "April 2015",
        "authors": [
            "Rebecca D. Watkins",
            "Abigail Sellen",
            "Siân E. Lindley"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702380",
        "citation": "29",
        "abstract": "Reference is increasingly made to 'digital collections', yet this term encompasses accumulated digital objects of varying form, purpose and value. We review social science literature on material collections and draw from in-depth interviews with 20 people in the UK in order to offer a clearer understanding of what constitutes a digital collection and what does not. We develop a taxonomy that presents three distinct types of digital collection and demonstrate ways in which the affordances of digital environments may facilitate or impede meaningful practices of acquisition, curation and exhibition in each case. Through doing so, we present a framework for design in support of collecting practices and the development of more meaningful and valued digital collections."
    },
    {
        "title": "Medium, Access, and Obsolescence: What Kinds of Objects are Lasting Objects?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital Collections, Practice & Legacy",
        "data": "April 2015",
        "authors": [
            "Jane Gruning",
            "Julia Bullard",
            "Melissa Ocepek"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702238",
        "citation": "4",
        "abstract": "This paper presents findings from a field study of records managers that provides context for understanding how people see objects on varying media as long-lasting objects (or not). Part of the mandate of the profession of records management is long-term preservation of digital and paper records. At the site of the fieldwork for this study, research participants' tasks primarily consisted of examining individual case files to determine if the files should be kept or destroyed under the relevant rules set by higher-level management according to legal requirements. Close observation of work practices showed that application of records management rules varied depending on the medium of the records, despite the policy that records on varying media are equal in importance. The results of the study suggest that the perceived accessibility and obsolescence of digital objects deserve more attention in the exploration of the place of digital objects in human lives over the long-term."
    },
    {
        "title": "Things That Make Us Reminisce: Everyday Memory Cues as Opportunities for Interaction Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital Collections, Practice & Legacy",
        "data": "April 2015",
        "authors": [
            "Doménique van Gennip",
            "Elise van den Hoven",
            "Panos Markopoulos"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702460",
        "citation": "38",
        "abstract": "Interactive devices can support personal remembering to benefit well-being. These designs require insight into what brings the past to mind, and how people relate to such cues. Prior work focused on mementos in the home; instead, this paper presents a diary and interview study of involuntary memory cueing in everyday life. Data was collected from fifteen adult individuals, using sentence completion diaries, combined with debriefing interviews. Qualitative analysis of the data showed that these participants were relying on everyday physical objects like food items for cueing memories during everyday life, locations and (repeated) activities, while digital items and photos were shown to be less frequent stimulants. Meaningful relations to memory cues can be partially explained from a memory cueing perspective. We discuss how design for remembering can benefit from our insights, through careful trade-offs in timing, exposure to cues, and supporting a process of personal attachment with items invoking memories."
    },
    {
        "title": "Curatorial Agents: How Systems Shape Our Understanding of Personal and Familial Digital Information",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Digital Collections, Practice & Legacy",
        "data": "April 2015",
        "authors": [
            "Rebecca Gulotta",
            "Alex Sciuto",
            "Aisling Kelliher",
            "Jodi Forlizzi"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702297",
        "citation": "34",
        "abstract": "As people increasingly turn to digital channels to share, store, and reflect on their lives and experiences, the processes by which they manage the diverse collection of information generated over the course of their lives are changing. These processes, once a matter of hands-on curation and personal meaning making, are now deeply rooted in interactions with digital systems. In this work, we drew from prior research from personalization, memory, and information management to create four interactive, provocative systems. Through sessions with 12 adults from Pittsburgh, PA we used a combination of these systems and interviews to examine how systems might play a role in the near and long term resurfacing of personal and familial digital information. Findings point to an opportunity to create systems that can openly mediate the curation and transmission of digital content, and ways to draw meaning from the differences between how systems and people recall and represent their experiences."
    },
    {
        "title": "Session details: Multilingual Communication",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multilingual Communication",
        "data": "April 2015",
        "authors": [
            "Hao-Chuan Wang"
        ],
        "DOI": "https://doi.org/10.1145/3251765",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Improving Multilingual Collaboration by Displaying How Non-native Speakers Use Automated Transcripts and Bilingual Dictionaries",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multilingual Communication",
        "data": "April 2015",
        "authors": [
            "Ge Gao",
            "Naomi Yamashita",
            "Ari M.J. Hautasaari",
            "Susan R. Fussell"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702498",
        "citation": "20",
        "abstract": "Conversational grounding, or establishing mutual knowledge that messages have been understood as intended, can be difficult to achieve when some conversational participants are using a non-native language. These difficulties in grounding can be challenging for native speakers to detect. In this paper, we examine the value of signaling potential grounding problems to native speakers (NS) by displaying how non-native speakers (NNS) use automated transcripts and bilingual dictionaries. We conducted a laboratory experiment in which NS and NNS of English collaborated via audio conferencing on a map navigation task. Triads of one NS guider, one NS follower, and one NNS follower performed the task using one of three awareness displays: (a) a no awareness display that showed only the automated transcripts, (b) a general awareness display that showed whether each follower was reading the automated transcripts and/or translating a word; or (c) a detailed awareness display that showed which line of the transcripts a follower was reading and/or which words he/she was translating. NS guiders and NNS followers collaborated most successfully with the detailed awareness display, while NS guiders and NS followers performed equally across conditions. Our findings suggest several ways to improve systems to support multilingual collaboration."
    },
    {
        "title": "Effect of Machine Translation in Interlingual Conversation: Lessons from a Formative Study",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multilingual Communication",
        "data": "April 2015",
        "authors": [
            "Kotaro Hara",
            "Shamsi T. Iqbal"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702407",
        "citation": "10",
        "abstract": "Language barrier is the primary challenge for effective cross-lingual conversations. Spoken language translation (SLT) is perceived as a cost-effective alternative to less affordable human interpreters, but little research has studied how people interact with such technology. Using a prototype translator application, we performed a formative evaluation to elicit how people interact with the technology and adapt their conversation style. We conducted two sets of studies with a total of 23 pairs (46 participants). Participants worked on storytelling tasks to simulate natural conversations with 3 different interface settings. Our findings show that collocutors naturally adapt their style of speech production and comprehension to compensate for inadequacies in SLT. We conclude the paper with design guidelines that emerged from the analysis."
    },
    {
        "title": "Supporting the Modern Polyglot: A Comparison of Multilingual Search Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multilingual Communication",
        "data": "April 2015",
        "authors": [
            "Ben Steichen",
            "Luanne Freund"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702541",
        "citation": "16",
        "abstract": "The unrelenting rise in online user diversification has generated tremendous new challenges for search system providers. Among these, the need to address multiple user language abilities and preferences is paramount. The majority of research on multilingual search has so far focused on improving retrieval and translation techniques in cross-language information retrieval. However, less research has focused on the human-computer interaction aspects of multilingual search, particularly in terms of multilingual result display interfaces. To address this research gap, this paper presents a comparison of 5 different search interface designs for multilingual search. We analyze and evaluate these interfaces through a crowd-based experiment involving 885 participants. Our results show that the common approach of interleaving multilingual results is in fact the least preferred, whereas single-page displays with clear language separation are most preferred. In addition, we show that user proficiency and search content type play an important role in user preferences, and that different interfaces elicit different user behaviors."
    },
    {
        "title": "New Interaction Tools for Preserving an Old Language",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multilingual Communication",
        "data": "April 2015",
        "authors": [
            "Beryl Plimmer",
            "Liang He",
            "Tariq Zaman",
            "Kasun Karunanayaka",
            "Alvin W. Yeo",
            "Garen Jengan",
            "Rachel Blagojevic",
            "Ellen Yi-Luen Do"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702339",
        "citation": "14",
        "abstract": "The Penan people of Malaysian Borneo were traditionally nomads of the rainforest. They would leave messages in the jungle for each other by shaping natural objects into language tokens and arranging these symbols in specific ways -- much like words in a sentence. With settlement, the language is being lost as it is not being used by the younger generation. We report here, a tangible system designed to help the Penan preserve their unique object writing language. The key features of the system are that: its tangibles are made of real objects; it works in the wild; and new tangibles can be fabricated and added to the system by the users. Our evaluations show that the system is engaging and encourages intergenerational knowledge transfer and thus has the potential to help preserve this language."
    },
    {
        "title": "Session details: Empowering Users",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empowering Users",
        "data": "April 2015",
        "authors": [
            "Maarten Thissen"
        ],
        "DOI": "https://doi.org/10.1145/3251766",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Mixed-Initiative Approaches to Global Editing in Slideware",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empowering Users",
        "data": "April 2015",
        "authors": [
            "Darren Edge",
            "Sumit Gulwani",
            "Natasa Milic-Frayling",
            "Mohammad Raza",
            "Reza Adhitya Saputra",
            "Chao Wang",
            "Koji Yatani"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702551",
        "citation": "7",
        "abstract": "Good alignment and repetition of objects across presentation slides can facilitate visual processing and contribute to audience understanding. However, creating and maintaining such consistency during slide design is difficult. To solve this problem, we present two complementary tools: (1) StyleSnap, which increases the alignment and repetition of objects by adaptively clustering object edge positions and allowing parallel editing of all objects snapped to the same spatial extent; and (2) FlashFormat, which infers the least-general generalization of editing examples and applies it throughout the selected range. In user studies of repetitive styling task performance, StyleSnap and FlashFormat were 4-5 times and 2-3 times faster respectively than conventional editing. Both use a mixed-initiative approach to improve the consistency of slide decks and generalize to any situations involving direct editing across disjoint visual spaces."
    },
    {
        "title": "\"For Telling\" the Present: Using the Delphi Method to Understand Personal Information Management Practices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Empowering Users",
        "data": "April 2015",
        "authors": [
            "William Jones",
            "Robert Capra",
            "Anne Diekema",
            "Jaime Teevan",
            "Manuel Pérez-Quiñones",
            "Jesse David Dinneen",
            "Bradley Hemminger"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702523",
        "citation": "35",
        "abstract": "Researchers have been studying personal information management (PIM) for many years, but little exists by way of practical advice for how individuals should manage their own information. We employed the Delphi Method to engage PIM researchers with expertise in a variety of relevant areas in a five-round extended dialog about PIM practices. Participants identified key everyday choices of PIM, suggested alternatives, and identified pros and cons of each alternative. Our contributions include: 1) a set of 36 PIM practices, along with pros, cons, and recommendations for or against each practice, 2) directions of future research and development including \"near-future\" improvements in tool support and 3) a detailed description of how we applied the Delphi Method to study PIM and how it might be used more widely in HCI research as a complement to more established methods of inquiry."
    },
    {
        "title": "Session details: Accessibility for Vision Impaired Users",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility for Vision Impaired Users",
        "data": "April 2015",
        "authors": [
            "Xiaojuan Ma"
        ],
        "DOI": "https://doi.org/10.1145/3251767",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Privacy Concerns and Behaviors of People with Visual Impairments",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility for Vision Impaired Users",
        "data": "April 2015",
        "authors": [
            "Tousif Ahmed",
            "Roberto Hoyle",
            "Kay Connelly",
            "David Crandall",
            "Apu Kapadia"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702334",
        "citation": "82",
        "abstract": "Various technologies have been developed to help make the world more accessible to visually impaired people, and recent advances in low-cost wearable and mobile computing are likely to drive even moreadvances. However, the unique privacy and security needs of visually impaired people remain largely unaddressed. We conducted an exploratory user study with 14 visually impaired participants to understand the techniques they currently use for protecting privacy, their remaining privacy concerns,and how new technologies may be able to help. The interviews explored privacy not only in the physical world (e.g., bystanders overhearing private conversations) and the online world (e.g., determining if a URL is legitimate), but also in the interface between the two (e.g. bystanders `shoulder-surfing' data from screens). The study revealed serious concerns that are not adequately solved by current technology, and suggested new directions for improving the privacy of this significant fraction of the population."
    },
    {
        "title": "Participatory Design of Therapeutic Video Games for Young People with Neurological Vision Impairment",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility for Vision Impaired Users",
        "data": "April 2015",
        "authors": [
            "Jonathan Waddington",
            "Conor Linehan",
            "Kathrin Gerling",
            "Kieran Hicks",
            "Timothy L. Hodgson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702261",
        "citation": "33",
        "abstract": "Neurological Vision Impairment (NVI) detrimentally impacts upon quality of life, as daily activities such as reading and crossing the road often become significantly impaired. Therapy strategies for NVI based on visual scanning of on-screen stimuli have recently been demonstrated as effective at improving functional vision. However, these strategies are repetitive, monotonous and unsuitable for use with children and young adults. This project explores the design of a game-based therapy programme that aims to support participant engagement and adherence. We first outline requirements for this software, before reporting on the iterative design process undertaken in collaboration with young people, therapists and teachers at a centre for vision impairment. Our work provides insights into the participatory design of games in collaboration with young people with special needs, and reflects upon the tension of balancing game challenge, therapy goals, and accessibility. Furthermore, it highlights the potential of games to empower special populations by providing a medium through which to communicate the subjective experience of specific impairments."
    },
    {
        "title": "ColourID: Improving Colour Identification for People with Impaired Colour Vision",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Accessibility for Vision Impaired Users",
        "data": "April 2015",
        "authors": [
            "David R. Flatla",
            "Alan R. Andrade",
            "Ross D. Teviotdale",
            "Dylan L. Knowles",
            "Craig Stewart"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702578",
        "citation": "23",
        "abstract": "Being able to identify colours is a fundamental human activity; colour identification helps us work, get dressed, prepare food, and keep safe. But for the 5% of the world with impaired colour vision (ICV), colour identification is often a challenge, resulting in frustration and confusion with sometimes dangerous consequences. Colour namer tools have been proposed as a solution, however these are often slow to use and imprecise. To address these shortcomings, we developed three new colour identification techniques (ColourNames, ColourMeters, ColourPopper) using a new colour name dictionary based on the largest colour naming experiment to date. We compared our techniques to colour namers using participants with ICV in desktop and mobile conditions, and found that ColourNames and ColourPopper resulted in ~99% colour identification accuracy (10% higher than the colour namer), ColourMeters and ColourPopper were three times faster, and ColourPopper had lower perceived effort and was ranked significantly higher. With the benefits provided by our new colour identification techniques, people with ICV are one step closer to seeing the world like everyone else."
    },
    {
        "title": "Session details: Interactive & Multi-Surface Maps",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive & Multi-Surface Maps",
        "data": "April 2015",
        "authors": [
            "Brent Hecht"
        ],
        "DOI": "https://doi.org/10.1145/3251768",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "TerraGuide: Design and Evaluation of a Multi-Surface Environment for Terrain Visibility Analysis",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive & Multi-Surface Maps",
        "data": "April 2015",
        "authors": [
            "Matthew Oskamp",
            "Christophe Bortolaso",
            "Robin Harrap",
            "T.C. Nicholas Graham"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702480",
        "citation": "4",
        "abstract": "Terrain visibility analysis is a challenging task that is currently supported by complex digital tools with cumbersome interfaces. In this paper, we present TerraGuide, a novel multi-surface environment for exploratory terrain analysis. TerraGuide provides three tightly coupled displays including a real-time viewshed, a 3D panoramic view, and a helicopter view controlled by an optically tracked tablet. A user study compared these techniques and identified users' strategies in solving a complex terrain analysis problem. Users overwhelmingly adopted a bi-manual use of the tabletop viewshed and tablet-based helicopter techniques. This paper gives insight into how multi-surface environments can be designed to allow complementary use of and fluid switching between techniques."
    },
    {
        "title": "Lightweight Relief Shearing for Enhanced Terrain Perception on Interactive Maps",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive & Multi-Surface Maps",
        "data": "April 2015",
        "authors": [
            "Wesley Willett",
            "Bernhard Jenny",
            "Tobias Isenberg",
            "Pierre Dragicevic"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702172",
        "citation": "30",
        "abstract": "We explore interactive relief shearing, a set of non-intrusive, direct manipulation interactions that expose depth and shape information in terrain maps using ephemeral animations. Reading and interpreting topography and relief on terrain maps is an important aspect of map use, but extracting depth information from 2D maps is notoriously difficult. Modern mapping software attempts to alleviate this limitation by presenting digital terrain using 3D views. However, 3D views introduce occlusion, complicate distance estimations, and typically require more complex interactions. In contrast, our approach reveals depth information via shearing animations on 2D maps, and can be paired with existing interactions such as pan and zoom. We examine explicit, integrated, and hybrid interactions for triggering relief shearing and present a version that uses device tilt to control depth effects. Our evaluation shows that these interactive techniques improve depth perception when compared to standard 2D and perspective views."
    },
    {
        "title": "An Evaluation of Interactive Map Comparison Techniques",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive & Multi-Surface Maps",
        "data": "April 2015",
        "authors": [
            "María-Jesús Lobo",
            "Emmanuel Pietriga",
            "Caroline Appert"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702130",
        "citation": "35",
        "abstract": "Geovisualization applications typically organize data into layers. These layers hold different types of geographical features, describe different characteristics of the same features, or represent those features at different points in time. Layers can be composited in various ways, most often employing a juxtaposition or superimposition strategy, to produce maps that users can explore interactively. From an HCI perspective, one of the main challenges is to design interactive compositions that optimize the legibility of the resulting map and that ease layer comparison. We characterize five representative techniques, and empirically evaluate them using a set of real-world maps in which we purposefully introduce six types of differences amenable to inter-layer visual comparison. We discuss the merits of these techniques in terms of visual interference, user attention and scanning strategy. Our results can help inform the design of map-based visualizations for supporting geo-analysis tasks in many application areas."
    },
    {
        "title": "Ethermap: Real-time Collaborative Map Editing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interactive & Multi-Surface Maps",
        "data": "April 2015",
        "authors": [
            "Thore Fechner",
            "Dennis Wilhelm",
            "Christian Kray"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702536",
        "citation": "18",
        "abstract": "Real-time synchronization is increasingly available in web-based environments for editing textual data, and this has changed how groups of people collaborate. We present a novel approach for real-time collaborative editing of geo-data. We introduce Ethermap, an open source web-application that implements this approach and enables multiple users to map data concurrently. It supports synchronous and collaborative mapping in several ways: it visually highlights mapping activities, it allows for fine-grained reviewing of all changes, and it enhances text-based communication with cross-modal references to geo-objects. We report on key results from a multi-tiered evaluation of Ethermap based on a user-study and on expert interviews. The concept of real-time collaborative editing was received favorably by users and experts. Participants of the study learned to use Ethermap quickly, and successfully completed a collaborative mapping task. Experts and users agreed that, given the right scenario (e.g., disaster mapping, teaching, planning), the approach could benefit the process of working on geo-data collaboratively."
    },
    {
        "title": "Session details: Robot Personalities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Robot Personalities",
        "data": "April 2015",
        "authors": [
            "Malte Jung"
        ],
        "DOI": "https://doi.org/10.1145/3251769",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Too Much Humanness for Human-Robot Interaction: Exposure to Highly Humanlike Robots Elicits Aversive Responding in Observers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Robot Personalities",
        "data": "April 2015",
        "authors": [
            "Megan Strait",
            "Lara Vujovic",
            "Victoria Floerke",
            "Matthias Scheutz",
            "Heather Urry"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702415",
        "citation": "36",
        "abstract": "People tend to anthropomorphize agents that look and/or act human, and further, they tend to evaluate such agents more positively. This, in turn, has motivated the development of robotic agents that are humanlike in appearance and/or behavior. Yet, some agents -- often those with highly humanlike appearances -- have been found to elicit the opposite, wherein they are evaluated more negatively than their less humanlike counterparts. These trends are captured by Masahiro Mori's uncanny valley hypothesis, which describes a (uncanny) valley in emotional responding - a switch from affinity to dislike - elicited by agents that are ``too humanlike'. However, while the valley phenomenon has been repeatedly observed via subjective measures, it remains unknown as to whether such evaluations reflect a potential impact to a person's behavior (i.e., aversion). We attempt to address this gap in the literature via a novel experimental paradigm employing both traditional subjective ratings, as well as measures of peoples' behavioral and phsyiological responding. The results show that not only do people rate highly humanlike robots as uncanny, but moreover, they exhibit greater avoidance of such encounters than encounters with less humanlike and human agents. Thus, the findings not only support Mori's hypothesis, but further, they indicate the valley should be taken as a serious consideration for peoples' interactions with humanlike agents."
    },
    {
        "title": "Look Like Me: Matching Robot Personality via Gaze to Increase Motivation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Robot Personalities",
        "data": "April 2015",
        "authors": [
            "Sean Andrist",
            "Bilge Mutlu",
            "Adriana Tapus"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702592",
        "citation": "88",
        "abstract": "Socially assistive robots are envisioned to provide social and cognitive assistance where they will seek to motivate and engage people in therapeutic activities. Due to their physicality, robots serve as a powerful technology for motivating people. Prior work has shown that effective motivation requires adaption to user needs and characteristics, but how robots might successfully achieve such adaptation is still unknown. In this paper, we present work on matching a robot's personality-expressed via its gaze behavior-to that of its users. We confirmed in an online study with 22 participants that the robot's gaze behavior can successfully express either an extroverted or introverted personality. In a laboratory study with 40 participants, we demonstrate the positive effect of personality matching on a user's motivation to engage in a repetitive task. These results have important implications for the design of adaptive robot behaviors in assistive human-robot interaction."
    },
    {
        "title": "The Social Impact of a Robot Co-Worker in Industrial Settings",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Robot Personalities",
        "data": "April 2015",
        "authors": [
            "Allison Sauppé",
            "Bilge Mutlu"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702181",
        "citation": "112",
        "abstract": "Across history and cultures, robots have been envisioned as assistants working alongside people. Following this vision, an emerging family of products-collaborative manufacturing robots-is enabling human and robot workers to work side by side as collaborators in manufacturing tasks. Their introduction presents an opportunity to better understand people's interactions with and perceptions of a robot \"co-worker\" in a real-world setting to guide the design of these products. In this paper, we present findings from an ethnographic field study at three manufacturing sites and a Grounded Theory analysis of observations and interviews. Our results show that, even in this safety-critical manufacturing setting, workers relate to the robot as a social entity and rely on cues to understand the robot's actions, which we observed to be critical for workers to feel safe when near the robot. These findings contribute to our understanding of interactions with robotic products in real-world settings and offer important design implications."
    },
    {
        "title": "Robots, Pancakes, and Computer Games: Designing Serious Games for Robot Imitation Learning",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Robot Personalities",
        "data": "April 2015",
        "authors": [
            "Benjamin Walther-Franks",
            "Jan Smeddinck",
            "Peter Szmidt",
            "Andrei Haidu",
            "Michael Beetz",
            "Rainer Malaka"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702552",
        "citation": "6",
        "abstract": "Autonomous manipulation robots can be valuable aids as interactive agents in the home, yet it has proven extremely difficult to program their behavior. Imitation learning uses data on human demonstrations to build behavioral models for robots. In order to cover a wide range of action strategies, data from many individuals is needed. Acquiring such large amounts of data can be a challenge. Tools for data capturing in this domain must thus implement a good user experience. We propose to use human computation games in order to gather data on human manual behavior. We demonstrate the idea with a strategy game that is operated via a natural user interface. A comparison between using the game for action execution and demonstrating actions in a virtual environment shows that people interact longer and have a better experience when playing the game."
    },
    {
        "title": "Session details: Mid-Air Gestures and Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mid-Air Gestures and Interaction",
        "data": "April 2015",
        "authors": [
            "Yang Li"
        ],
        "DOI": "https://doi.org/10.1145/3251770",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Accurate, Robust, and Flexible Real-time Hand Tracking",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mid-Air Gestures and Interaction",
        "data": "April 2015",
        "authors": [
            "NONE"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702179",
        "citation": "298",
        "abstract": "We present a new real-time hand tracking system based on a single depth camera. The system can accurately reconstruct complex hand poses across a variety of subjects. It also allows for robust tracking, rapidly recovering from any temporary failures. Most uniquely, our tracker is highly flexible, dramatically improving upon previous approaches which have focused on front-facing close-range scenarios. This flexibility opens up new possibilities for human-computer interaction with examples including tracking at distances from tens of centimeters through to several meters (for controlling the TV at a distance), supporting tracking using a moving depth camera (for mobile scenarios), and arbitrary camera placements (for VR headsets). These features are achieved through a new pipeline that combines a multi-layered discriminative reinitialization strategy for per-frame pose estimation, followed by a generative model-fitting stage. We provide extensive technical details and a detailed qualitative and quantitative analysis."
    },
    {
        "title": "Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mid-Air Gestures and Interaction",
        "data": "April 2015",
        "authors": [
            "Srinath Sridhar",
            "Anna Maria Feit",
            "Christian Theobalt",
            "Antti Oulasvirta"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702136",
        "citation": "80",
        "abstract": "This paper investigates an emerging input method enabled by progress in hand tracking: input by free motion of fingers. The method is expressive, potentially fast, and usable across many settings as it does not insist on physical contact or visual feedback. Our goal is to inform the design of high-performance input methods by providing detailed analysis of the performance and anatomical characteristics of finger motion. We conducted an experiment using a commercially available sensor to report on the speed, accuracy, individuation, movement ranges, and individual differences of each finger. Findings show differences of up to 50% in movement times and provide indices quantifying the individuation of single fingers. We apply our findings to text entry by computational optimization of multi-finger gestures in mid-air. To this end, we define a novel objective function that considers performance, anatomical factors, and learnability. First investigations of one optimization case show entry rates of 22 words per minute (WPM). We conclude with a critical discussion of the limitations posed by human factors and performance characteristics of existing markerless hand trackers."
    },
    {
        "title": "Myopoint: Pointing and Clicking Using Forearm Mounted Electromyography and Inertial Motion Sensors",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mid-Air Gestures and Interaction",
        "data": "April 2015",
        "authors": [
            "Faizan Haque",
            "Mathieu Nancel",
            "Daniel Vogel"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702133",
        "citation": "68",
        "abstract": "We describe a mid-air, barehand pointing and clicking interaction technique using electromyographic (EMG) and inertial measurement unit (IMU) input from a consumer armband device. The technique uses enhanced pointer feedback to convey state, a custom pointer acceleration function tuned for angular inertial motion, and correction and filtering techniques to minimize side-effects when combining EMG and IMU input. By replicating a previous large display study using a motion capture pointing technique, we show the EMG and IMU technique is only 430 to 790 ms slower and has acceptable error rates for targets greater than 48 mm. Our work demonstrates that consumer-level EMG and IMU sensing is practical for distant pointing and clicking on large displays."
    },
    {
        "title": "Joint Estimation of 3D Hand Position and Gestures from Monocular Video for Mobile Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mid-Air Gestures and Interaction",
        "data": "April 2015",
        "authors": [
            "Jie Song",
            "Fabrizio Pece",
            "Gábor Sörös",
            "Marion Koelle",
            "Otmar Hilliges"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702601",
        "citation": "14",
        "abstract": "We present a machine learning technique to recognize gestures and estimate metric depth of hands for 3D interaction, relying only on monocular RGB video input. We aim to enable spatial interaction with small, body-worn devices where rich 3D input is desired but the usage of conventional depth sensors is prohibitive due to their power consumption and size. We propose a hybrid classification-regression approach to learn and predict a mapping of RGB colors to absolute, metric depth in real time. We also classify distinct hand gestures, allowing for a variety of 3D interactions. We demonstrate our technique with three mobile interaction scenarios and evaluate the method quantitatively and qualitatively."
    },
    {
        "title": "zSense: Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mid-Air Gestures and Interaction",
        "data": "April 2015",
        "authors": [
            "Anusha Withana",
            "Roshan Peiris",
            "Nipuna Samarasekara",
            "Suranga Nanayakkara"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702371",
        "citation": "43",
        "abstract": "In this paper we present zSense, which provides greater input expressivity for spatially limited devices such as smart wearables through a shallow depth gesture recognition system using non-focused infrared sensors. To achieve this, we introduce a novel Non-linear Spatial Sampling (NSS) technique that significantly cuts down the number of required infrared sensors and emitters. These can be arranged in many different configurations; for example, number of sensor emitter units can be as minimal as one sensor and two emitters. We implemented different configurations of zSense on smart wearables such as smartwatches, smartglasses and smart rings. These configurations naturally fit into the flat or curved surfaces of such devices, providing a wide scope of zSense enabled application scenarios. Our evaluations reported over 94.8% gesture recognition accuracy across all configurations."
    },
    {
        "title": "Session details: MOOCS & e-Learning",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: MOOCS & e-Learning",
        "data": "April 2015",
        "authors": [
            "Juho Kim"
        ],
        "DOI": "https://doi.org/10.1145/3251771",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Providing Adaptive Support in an Interactive Simulation for Learning: An Experimental Evaluation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: MOOCS & e-Learning",
        "data": "April 2015",
        "authors": [
            "Samad Kardan",
            "Cristina Conati"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702424",
        "citation": "25",
        "abstract": "Recent rise of Massive Open Online Courses (MOOCs) with unlimited participants, makes employing learning tools such as interactive simulations all but inevitable. Interactive simulations give students the opportunity to experiment with concrete examples and develop better understanding of concepts they have learned. However, some students do not learn well from this relatively unstructured form of interaction, suggesting the provision of adaptive support as a way to address this issue. This paper presents a formal evaluation of providing support to facilitate open exploration. We describe the process of designing an intervention delivery mechanism for adding adaptive support to an exploratory interactive simulation. The experimental evaluation of the adaptive version of the simulation indicates that the adaptive support provided to students significantly improved their learning performance. Quantitative and qualitative evaluations of users' acceptance of the system are generally positive but pinpoint areas for improvement."
    },
    {
        "title": "Interactive Cloud Experimentation for Biology: An Online Education Case Study",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: MOOCS & e-Learning",
        "data": "April 2015",
        "authors": [
            "NONE"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702354",
        "citation": "23",
        "abstract": "Interacting with biological systems via experiments is important for academia, industry, and education, but access barriers exist due to training, costs, safety, logistics, and spatial separation. High-throughput equipment combined with web streaming could enable interactive biology experiments online, but no such platform currently exists. We present a cloud experimentation architecture (paralleling cloud computation), which is optimized for a class of domain-specific equipments (biotic processing units - BPU) to share and execute many experiments in parallel remotely and interactively at all time. We implemented an instance of this architecture that enables chemotactic experiments with a slime mold Physarum Polycephelum. A user study in the blended teaching and research setting of a graduate-level biophysics class demonstrated that this platform lowers the access barrier for non-biologists, enables discovery, and facilitates learning analytics. This architecture is flexible for integration with various biological specimens and equipments to facilitate scalable interactive online education, collaborations, research, and citizen science."
    },
    {
        "title": "Mining Memories: Designing a Platform to Support Social Media Based Writing",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: MOOCS & e-Learning",
        "data": "April 2015",
        "authors": [
            "John Sadauskas",
            "Daragh Byrne",
            "Robert K. Atkinson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702383",
        "citation": "7",
        "abstract": "Many teens struggle with school writing and particularly in identifying personally relevant topics, which motivate writing improvement. However, a wealth of potential topics is available through their social media data. We explore the design of Sparkfolio, a prewriting support tool that aims to help students successfully prepare meaningful writing topics from their own social media content. This web-delivered tool was evaluated with 46 teen users in the context of their high school English class. Findings demonstrate that the use of social media can enhance the quality of written outcomes, as Sparkfolio users had significantly greater gains than a control group."
    },
    {
        "title": "Wait-Learning: Leveraging Wait Time for Second Language Education",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: MOOCS & e-Learning",
        "data": "April 2015",
        "authors": [
            "Carrie J. Cai",
            "Philip J. Guo",
            "James R. Glass",
            "Robert C. Miller"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702267",
        "citation": "28",
        "abstract": "Competing priorities in daily life make it difficult for those with a casual interest in learning to set aside time for regular practice. In this paper, we explore wait-learning: leveraging brief moments of waiting during a person's existing conversations for second language vocabulary practice, even if the conversation happens in the native language. We present an augmented version of instant messaging, WaitChatter, that supports the notion of wait-learning by displaying contextually relevant foreign language vocabulary and micro-quizzes just-in-time while the user awaits a response from her conversant. Through a two week field study of WaitChatter with 20 people, we found that users were able to learn 57 new words on average during casual instant messaging. Furthermore, we found that users were most receptive to learning opportunities immediately after sending a chat message, and that this timing may be critical given user tendency to multi-task during waiting periods."
    },
    {
        "title": "Session details: Understanding Gamers",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Gamers",
        "data": "April 2015",
        "authors": [
            "Toni-Jan Keith Monserrat"
        ],
        "DOI": "https://doi.org/10.1145/3251772",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Masters of Control: Behavioral Patterns of Simultaneous Unit Group Manipulation in StarCraft 2",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Gamers",
        "data": "April 2015",
        "authors": [
            "Eddie Q. Yan",
            "Jeff Huang",
            "Gifford K. Cheung"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702429",
        "citation": "10",
        "abstract": "Most user interfaces require the user to focus on one element at a time, but StarCraft 2 is a game where players often control more than a hundred units simultaneously. The game interface provides an optional mechanism called \"control groups\" that allows players to select multiple units and assign them to a group in order to quickly recall previous selections of units. From an analysis of over 3,000 replays, we show that the usage of control groups is a key differentiator of individual players as well as players of different skill levels---novice users rarely use control groups while experts nearly always do. But players also behave differently in how they use their control groups, especially in time-pressured situations. While certain control group behaviors are common across all skill levels, expert players appear to be better at remaining composed and sustaining control group use in battle. We also qualitatively analyze discussions on web forums from players about how they use control groups to provide context about how such a simple interface mechanic has produced numerous ways of optimizing unit control."
    },
    {
        "title": "Cooperative Game Play with Avatars and Agents: Differences in Brain Activity and the Experience of Play",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Gamers",
        "data": "April 2015",
        "authors": [
            "Daniel Johnson",
            "Peta Wyeth",
            "Madison Clark",
            "Christopher Watling"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702468",
        "citation": "16",
        "abstract": "The current study sought to identify the impact of whether teammates in a cooperative videogame were controlled by other humans (avatars) or by the game (agents). The impact on player experience was explored through both subjective questionnaire measures and brain wave activity measurement (electroencephalography). Play with human teammates was associated with a greater sense of relatedness, but less competence and flow than play with other computer-controlled teammates. In terms of brain activity, play with human teammates was associated with greater activity in the alpha, theta and beta power bands than play with computer-controlled teammates. Overall, the results suggest that play with human teammates involves greater cognitive activity in terms of 'mentalising' than play with computer-controlled teammates. Additionally, the associations between subjective measures of player experience and brain activity are described. Limitations of the current study are identified and key directions for future research are discussed."
    },
    {
        "title": "Examining Game World Topology Personalization",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Gamers",
        "data": "April 2015",
        "authors": [
            "Sauvik Das",
            "Alexander Zook",
            "Mark O. Riedl"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702473",
        "citation": "3",
        "abstract": "We present an exploratory analysis of the effects of game world topologies on self-reported player experience in Computer Role Playing Games (CRPGs). We find that (a) players are more engaged in game worlds that better match their self-reported preferences; and (b) player preferences for game topology can be predicted based on their in-game behavior. We further describe how in-game behavioral features that correlate to preferences can be used to control procedural content generation algorithms."
    },
    {
        "title": "The Use of Games as Extrinisic Motivation in Education",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Gamers",
        "data": "April 2015",
        "authors": [
            "Chris Preist",
            "Robert Jones"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702282",
        "citation": "4",
        "abstract": "This paper presents results of a controlled trial using a clash-of-clans style game as an extrinsic motivator to encourage revision in 15-16 year olds preparing for a maths exam. The trial demonstrates a statistically significant improvement in performance among those using the game. We discuss differences between our work and a previous trial that showed no performance improvement from an extrinsically linked educational game, and present hypotheses as to why the game structure we used may be effective within our chosen deployment environment."
    },
    {
        "title": "Exploring Cyberbullying and Other Toxic Behavior in Team Competition Online Games",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding Gamers",
        "data": "April 2015",
        "authors": [
            "Haewoon Kwak",
            "Jeremy Blackburn",
            "Seungyeop Han"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702529",
        "citation": "114",
        "abstract": "In this work we explore cyberbullying and other toxic behavior in team competition online games. Using a dataset of over 10 million player reports on 1.46 million toxic players along with corresponding crowdsourced decisions, we test several hypotheses drawn from theories explaining toxic behavior. Besides providing large-scale, empirical based understanding of toxic behavior, our work can be used as a basis for building systems to detect, prevent, and counter-act toxic behavior."
    },
    {
        "title": "Session details: Bridging Communities",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging Communities",
        "data": "April 2015",
        "authors": [
            "Edward Cutrell"
        ],
        "DOI": "https://doi.org/10.1145/3251773",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Computer-Enabled Project Spaces: Connecting with Palestinian Refugees across Camp Boundaries",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging Communities",
        "data": "April 2015",
        "authors": [
            "George Yerousis",
            "Konstantin Aal",
            "Thomas von Rekowski",
            "David W. Randall",
            "Markus Rohde",
            "Volker Wulf"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702283",
        "citation": "47",
        "abstract": "Come_IN computer clubs are an established approach to support inter-cultural and inter-generational learning in German neighborhoods. We explore the adaptation of the come_IN concept to the Palestinian context as a means to bridge the social and economic divide that has plagued West Bank society for a period of more than six decades. Social exclusion, political conflicts and prolonged military occupation have kept the refugee camps in a perpetual state of marginalization. In this paper we report on our work in Al Amari-- a Palestinian refugee camp adjacent to the city of Ramallah. We examine how the computer club enables the emergence of social ties among residents of the camp and university students acting as tutors. Even though the ties are small-scale and informal, they have the potential to generate new and wider opportunities for exchange that may eventually support more social integration between the camp's marginalized population and the wider Palestinian population."
    },
    {
        "title": "Transnationalism, Indigenous Knowledge and Technology: Insights from the Kenyan Diaspora",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging Communities",
        "data": "April 2015",
        "authors": [
            "Kagonya Awori",
            "Frank Vetere",
            "Wally Smith"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702488",
        "citation": "21",
        "abstract": "Our paper investigates how current digital technologies are sufficient, or insufficient, in supporting Kenyan transnationals in practising indigenous knowledge. We first outline a view of indigenous knowledge, and then apply it to a study of diaspora Kenyans living in Australia. The findings are framed as nine techniques for sustaining displaced practising of indigenous knowledge. These appropriations suggest directions for technology innovation, providing design considerations for technologies that translate, formulate and support indigenous knowledge in transnational contexts."
    },
    {
        "title": "Collective Intelligence in Computer-Mediated Collaboration Emerges in Different Contexts and Cultures",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging Communities",
        "data": "April 2015",
        "authors": [
            "David Engel",
            "Anita Williams Woolley",
            "Ishani Aggarwal",
            "Christopher F. Chabris",
            "Masamichi Takahashi",
            "Keiichi Nemoto",
            "Carolin Kaiser",
            "Young Ji Kim",
            "Thomas W. Malone"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702259",
        "citation": "37",
        "abstract": "Collective intelligence (CI) is a property of groups that emerges from the coordination and collaboration of members and predicts group performance on a wide range of tasks. Previous studies of CI have been conducted with lab-based groups in the USA. We introduce a new standardized online battery to measure CI and demonstrate consistent emergence of a CI factor across three different studies despite broad differences in (a) communication media (face-to-face vs online), (b) group contexts (short-term ad hoc groups vs long-term groups) and (c) cultural settings (US, Germany, and Japan). In two of the studies, we also show that CI is correlated with a group's performance on more complex tasks. Consequently, the CI metric provides a generalizable performance measure for groups that is robust to broad changes in media, context, and culture, making it useful for testing the effects of general-purpose collaboration technologies intended to improve group performance."
    },
    {
        "title": "Google+ Communities as Plazas and Topic Boards",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Bridging Communities",
        "data": "April 2015",
        "authors": [
            "Michael J. Brzozowski",
            "Phil Adams",
            "Ed H. Chi"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702600",
        "citation": "8",
        "abstract": "Researchers have recently been focusing on understanding online communities in social networks that offer easy access to new audiences. How do online communities function within these social networks? In this work, we conducted a mixed-method study of public Google+ Communities and found two major types evident in both how users talk about them and how they appear to use them: plazas to meet new people, and topic boards to discuss common interests. This reflects two common motivations users cite in describing Communities: \"meeting like minded people\" and \"finding great content\". We characterize these two types of Communities within Google+ using mixed methods including surveys, interviews, and quantitative analytics, and expose differences in user behaviors between them."
    },
    {
        "title": "Session details: Gender & Technology",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gender & Technology",
        "data": "April 2015",
        "authors": [
            "Antonella De Angeli"
        ],
        "DOI": "https://doi.org/10.1145/3251774",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Gender and Tenure Diversity in GitHub Teams",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gender & Technology",
        "data": "April 2015",
        "authors": [
            "Bogdan Vasilescu",
            "Daryl Posnett",
            "Baishakhi Ray",
            "Mark G.J. van den Brand",
            "Alexander Serebrenik",
            "Premkumar Devanbu",
            "Vladimir Filkov"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702549",
        "citation": "203",
        "abstract": "Software development is usually a collaborative venture. Open Source Software (OSS) projects are no exception; indeed, by design, the OSS approach can accommodate teams that are more open, geographically distributed, and dynamic than commercial teams. This, we find, leads to OSS teams that are quite diverse. Team diversity, predominantly in offline groups, is known to correlate with team output, mostly with positive effects. How about in OSS? Using GitHub, the largest publicly available collection of OSS projects, we studied how gender and tenure diversity relate to team productivity and turnover. Using regression modeling of GitHub data and the results of a survey, we show that both gender and tenure diversity are positive and significant predictors of productivity, together explaining a sizable fraction of the data variability. These results can inform decision making on all levels, leading to better outcomes in recruiting and performance."
    },
    {
        "title": "Offline Strangers, Online Friends: Bridging Classroom Gender Segregation with WhatsApp",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gender & Technology",
        "data": "April 2015",
        "authors": [
            "Preeti Mudliar",
            "Nimmi Rangaswamy"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702533",
        "citation": "15",
        "abstract": "Mobile Instant Messaging (MIM) apps such as WhatsApp are heralding new communication behaviors amongst students in peri-urban India. From an ethnographic study of a co-ed engineering college, we describe and analyze the role of WhatsApp in both engendering and balancing the ripples caused by cross gender communication. Through in-depth interviews and immersive participant observations in both physical as well as digital spaces, we show how WhatsApp emerges as the backbone of student interactions in a gender segregated academic environment. In analyzing social conditions and identifying structural features of WhatsApp that led to its bottoms up appropriation, our study presents possibilities for educators and designers aiming to create technology enabled collaborative spaces between people otherwise hemmed in by social norms from reaching out to one another."
    },
    {
        "title": "Online Inspiration and Exploration for Identity Reinvention",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gender & Technology",
        "data": "April 2015",
        "authors": [
            "Oliver L. Haimson",
            "Anne E. Bowser",
            "Edward F. Melcer",
            "Elizabeth F. Churchill"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702270",
        "citation": "33",
        "abstract": "Self-representation online can be difficult for those who are in life transitions that involve exploring new identity facets and changes in personal style. Many desire to tailor their online representations for different audiences. Social media site profiles and sharing settings offer varying levels of anonymity, privacy, and thus safety, but these settings are often opaque and poorly understood. To understand the complex relationship between identity, personal style and online self-representation, we examine how people explore and experiment with new styles in public and in private online settings during gender transition. We present the results of interviews with transgender people who have recently reinvented their personal style, or are planning to do so in the near future. We find that people explore new styles in online settings to craft possible or ideal future selves. When involving others, people engage intimate and unknown others, but often avoid weak ties. Our results indicate that to account for changing identities, social media sites must be designed to support finding inspiration and advice from strangers and style experimentation with close friends."
    },
    {
        "title": "Unequal Representation and Gender Stereotypes in Image Search Results for Occupations",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gender & Technology",
        "data": "April 2015",
        "authors": [
            "Matthew Kay",
            "Cynthia Matuszek",
            "Sean A. Munson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702520",
        "citation": "225",
        "abstract": "Information environments have the power to affect people's perceptions and behaviors. In this paper, we present the results of studies in which we characterize the gender bias present in image search results for a variety of occupations. We experimentally evaluate the effects of bias in image search results on the images people choose to represent those careers and on people's perceptions of the prevalence of men and women in each occupation. We find evidence for both stereotype exaggeration and systematic underrepresentation of women in search results. We also find that people rate search results higher when they are consistent with stereotypes for a career, and shifting the representation of gender in image search results can shift people's perceptions about real-world distributions. We also discuss tensions between desires for high-quality results and broader societal goals for equality of representation in this space."
    },
    {
        "title": "Session details: Coping & Wellbeing Through HCI",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Coping & Wellbeing Through HCI",
        "data": "April 2015",
        "authors": [
            "Jina Huh"
        ],
        "DOI": "https://doi.org/10.1145/3251775",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Finding the Adaptive Sweet Spot: Balancing Compliance and Achievement in Automated Stress Reduction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Coping & Wellbeing Through HCI",
        "data": "April 2015",
        "authors": [
            "Artie Konrad",
            "Victoria Bellotti",
            "Nicole Crenshaw",
            "Simon Tucker",
            "Les Nelson",
            "Honglu Du",
            "Peter Pirolli",
            "Steve Whittaker"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702512",
        "citation": "45",
        "abstract": "Automated coaching systems offer a convenient, cost-effective way to reduce stress, which can be a serious health issue. However, one concern with such systems is compliance; users fail to achieve daily stress reduction goals because goals are too easy or too difficult. To address this, we built DStress (Design for Stress), a theoretically grounded system that sets adaptive goals in three coaching dimensions: Exercise, Meditation and Accessibility. DStress modifies goal-difficulty based on the individual's immediately previous performance. In a 28-day deployment with 65 users, DStress reduced scores on one direct measure of stress almost in half, significantly more than two other non-adaptive coaching strategies. However, on a second direct stress measure, no improvement was found. There were also no improvements on other indirect stress measures. Analysis of 2842 user-generated reports suggests our findings were the result of DStress balancing compliance against the degree of challenge of the goals it would set."
    },
    {
        "title": "SoberDiary: A Phone-based Support System for Assisting Recovery from Alcohol Dependence",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Coping & Wellbeing Through HCI",
        "data": "April 2015",
        "authors": [
            "Chuang-wen You",
            "Kuo-Cheng Wang",
            "Ming-Chyi Huang",
            "Yen-Chang Chen",
            "Cheng-Lin Lin",
            "Po-Shiun Ho",
            "Hao-Chuan Wang",
            "Polly Huang",
            "Hao-Hua Chu"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702289",
        "citation": "23",
        "abstract": "Alcohol dependence is a chronic disorder associated with severe harm in multiple areas, and relapsing is easy, despite treatment. This study proposes SoberDiary, a phone-based support system that enables alcohol-dependent patients to self-monitor and -manage their own alcohol behavior, and remain sober in their daily lives. We tested SoberDiary in a real-life 12-week user study involving 27 clinical patients. The quantitative and qualitative results revealed that SoberDiary helped patients self-monitor and -manage their alcohol-use behavior, and reduced their total alcohol consumption as well as the number of heavy drinking days. Compared with patients who received standard treatment alone, this study demonstrated SoberDiary successfully complemented current alcohol treatment in reducing patients' alcoholic cravings and dropout rate over 3-month study period. Follow-up interviews further revealed the sophisticated use practices and value of SoberDiary."
    },
    {
        "title": "Solutionism, the Game: Design Fictions for Positive Aging",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Coping & Wellbeing Through HCI",
        "data": "April 2015",
        "authors": [
            "Mark Blythe",
            "Jamie Steane",
            "Jenny Roe",
            "Caroline Oliver"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702491",
        "citation": "48",
        "abstract": "This paper reports a qualitative study of thriving older people and illustrates the findings with design fiction. Design research has been criticized as \"solutionist\" i.e. solving problems that don't exist or providing \"quick fixes\" for complex social, political and environmental problems. We respond to this critique by presenting a \"solutionist\" board game used to generate design concepts. Players are given data cards and technology dice, they move around the board by pitching concepts that would support positive aging. We argue that framing concept design as a solutionist game explicitly foregrounds play, irony and the limitations of technological intervention. Three of the game concepts are presented as design fictions in the form of advertisements for products and services that do not exist. The paper argues that design fiction can help create a space for design beyond solutionism."
    },
    {
        "title": "Design Considerations for Patient Portal Adoption by Low-Income, Older Adults",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Coping & Wellbeing Through HCI",
        "data": "April 2015",
        "authors": [
            "Celine Latulipe",
            "Amy Gatto",
            "Ha T. Nguyen",
            "David P. Miller",
            "Sara A. Quandt",
            "Alain G. Bertoni",
            "Alden Smith",
            "Thomas A. Arcury"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702392",
        "citation": "39",
        "abstract": "This paper describes the results of an interview study investigating facilitators and barriers to adoption of patient portals among low-income, older adults in rural and urban populations in the southeastern USA. We describe attitudes of this population of older adults and their current level of technology use and patient portal use. From qualitative analysis of 36 patient interviews and 16 caregiver interviews within these communities, we derive themes related to benefits of portals, barriers to use, concerns and desired features. Based on our initial findings, we present a set of considerations for designing the patient portal user experience, aimed at helping healthcare clinics to meet U.S. federally-mandated `meaningful use' requirements."
    },
    {
        "title": "Session details: Interacting with Floors & Situated Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with Floors & Situated Displays",
        "data": "April 2015",
        "authors": [
            "Diego Martinez Plasencia"
        ],
        "DOI": "https://doi.org/10.1145/3251776",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "BaseLase: An Interactive Focus+Context Laser Floor",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with Floors & Situated Displays",
        "data": "April 2015",
        "authors": [
            "Jörg Müller",
            "Dieter Eberle",
            "Constantin Schmidt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702246",
        "citation": "13",
        "abstract": "We present BaseLase, an interactive laser projected focus + context floor display. In order to provide a transportable system that works in areas where there are no ceilings, we provide an integrated unit (1.3m height) that stands on the floor. One unsolved challenge for laser projectors is to cover large projection areas while providing high resolution at the same time. Our focus + context laser projector solves this problem. BaseLase can cover a large context area in low resolution, while providing three movable high-resolution focus spots. We provide a convex mirror design that enables the laser to reach a large area (75m2) with low resolution while decreasing the beam divergence compared to spherical or parabolic mirrors. This hyperboloidal mirror shape approximately equalizes the point size on the floor independent from the projected location. We propose to add a number of planar mirrors on pan-tilt units to create dynamic zones of high resolution that can adjust to the user behavior. We provide example applications for BaseLase and report on user experience in preliminary trials."
    },
    {
        "title": "Ergonomic Interaction for Touch Floors",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with Floors & Situated Displays",
        "data": "April 2015",
        "authors": [
            "Dominik Schmidt",
            "Johannes Frohnhofen",
            "Sven Knebel",
            "Florian Meinel",
            "Mariya Perchyk",
            "Julian Risch",
            "Jonathan Striebel",
            "Julia Wachtel",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702254",
        "citation": "5",
        "abstract": "The main appeal of touch floors is that they are the only direct touch form factor that scales to arbitrary size, therefore allowing direct touch to scale to very large numbers of display objects. In this paper, however, we argue that the price for this benefit is bad physical ergonomics: prolonged standing, especially in combination with looking down, quickly causes fatigue and repetitive strain. We propose addressing this issue by allowing users to operate touch floors in any pose they like, including sitting and lying. To allow users to transition between poses seamlessly, we present a simple pose-aware view manager that supports users by adjusting the entire view to the new pose. We support the main assumption behind the work with a simple study that shows that several poses are indeed more ergonomic for touch floor interaction than standing. We ground the design of our view manager by analyzing, which screen regions users can see and touch in each of the respective poses."
    },
    {
        "title": "Display Blindness?: Looking Again at the Visibility of Situated Displays using Eye-tracking",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with Floors & Situated Displays",
        "data": "April 2015",
        "authors": [
            "Nicholas S. Dalton",
            "Emily Collins",
            "Paul Marshall"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702150",
        "citation": "52",
        "abstract": "Observational studies of situated displays have suggested that they are rarely looked at, and when they are it is typically only for a short period of time. Using a mobile eye tracker during a realistic shopping task in a shopping center, we show that people look at displays more than would be predicted from these observational studies, but still only short glances and often from quite far away. We characterize the patterns of eye-movements that precede looking at a display and discuss some of the design implications for the design of situated display technologies that are deployed in public space."
    },
    {
        "title": "Detecting User Intention at Public Displays from Foot Positions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with Floors & Situated Displays",
        "data": "April 2015",
        "authors": [
            "Bernd Huber",
            "Joong Ho Lee",
            "Ji-Hyung Park"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702148",
        "citation": "4",
        "abstract": "Foot positions are features of how humans express their intentions during conversations. This inspired us to investigate the usage of foot expressions during interactions with computers. We conducted an observational study to determine how foot positions correlate with the intentions of users at public displays. Using our findings, we performed a case study to demonstrate the usefulness of adapting content according to the intentions detected based on foot positions. Our results are valuable for researchers designing context-aware public displays."
    },
    {
        "title": "Session details: Multi-Device Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multi-Device Interaction",
        "data": "April 2015",
        "authors": [
            "Michael Nebeling"
        ],
        "DOI": "https://doi.org/10.1145/3251777",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "A Diary Study on Combining Multiple Information Devices in Everyday Activities and Tasks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multi-Device Interaction",
        "data": "April 2015",
        "authors": [
            "Tero Jokela",
            "Jarno Ojala",
            "Thomas Olsson"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702211",
        "citation": "102",
        "abstract": "As people possess increasing numbers of information devices, situations where several devices are combined and used together have become more common. We present a user study on people's current practices in combining multiple information devices in their everyday lives, ranging from pragmatic tasks to leisure activities. Based on diaries and interviews of 14 participants, we characterize the usage practices of the most common devices, including smartphones, computers, tablets, and home media centers. We analyze 123 real-life multi-device use cases and identify the main usage patterns, including Sequential Use, Resource Lending, Related Parallel Use, and Unrelated Parallel Use. We discuss the practical challenges of using several information devices together. Finally, we identify three levels of decisions that determine which devices are used in a particular situation, including acquiring, making available, and selecting the devices for use."
    },
    {
        "title": "Spatially-aware or Spatially-agnostic?: Elicitation and Evaluation of User-Defined Cross-Device Interactions",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multi-Device Interaction",
        "data": "April 2015",
        "authors": [
            "Roman Rädle",
            "Hans-Christian Jetter",
            "Mario Schreiner",
            "Zhihao Lu",
            "Harald Reiterer",
            "Yvonne Rogers"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702287",
        "citation": "50",
        "abstract": "Cross-device interaction between multiple mobile devices is a popular field of research in HCI. However, the appropriate design of this interaction is still an open question, with competing approaches such as spatially-aware vs. spatially-agnostic techniques. In this paper, we present the results of a two-phase user study that explores this design space: In phase 1, we elicited gestures for typical mobile cross-device tasks from 4 focus groups (N=17). The results show that 71% of the elicited gestures were spatially-aware and that participants strongly associated cross-device tasks with interacting and thinking in space. In phase 2, we implemented one spatially-agnostic and two spatially-aware techniques from phase 1 and compared them in a controlled experiment (N=12). The results indicate that spatially-aware techniques are preferred by users and can decrease mental demand, effort, and frustration, but only when they are designed with great care. We conclude with a summary of findings to inform the design of future cross-device interactions."
    },
    {
        "title": "Weave: Scripting Cross-Device Wearable Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multi-Device Interaction",
        "data": "April 2015",
        "authors": [
            "Pei-Yu (Peggy) Chi",
            "Yang Li"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702451",
        "citation": "58",
        "abstract": "We present Weave, a framework for developers to create cross-device wearable interaction by scripting. Weave provides a set of high-level APIs, based on JavaScript, for developers to easily distribute UI output and combine sensing events and user input across mobile and wearable devices. Weave allows developers to focus on their target interaction behaviors and manipulate devices regarding their capabilities and affordances, rather than low-level specifications. Weave also contributes an integrated authoring environment for developers to program and test cross-device behaviors, and when ready, deploy these behaviors to its runtime environment on users' ad-hoc network of devices. An evaluation of Weave with 12 participants on a range of tasks revealed that Weave significantly reduced the effort of developers for creating and iterating on cross-device interaction."
    },
    {
        "title": "MultiFi: Multi Fidelity Interaction with Displays On and Around the Body",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multi-Device Interaction",
        "data": "April 2015",
        "authors": [
            "Jens Grubert",
            "Matthias Heinisch",
            "Aaron Quigley",
            "Dieter Schmalstieg"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702331",
        "citation": "77",
        "abstract": "Display devices on and around the body such as smartwatches, head-mounted displays or tablets enable users to interact on the go. However, diverging input and output fidelities of these devices can lead to interaction seams that can inhibit efficient mobile interaction, when users employ multiple devices at once. We present MultiFi, an interactive system that combines the strengths of multiple displays and overcomes the seams of mobile interaction with widgets distributed over multiple devices. A comparative user study indicates that combined head-mounted display and smartwatch interfaces can outperform interaction with single wearable devices."
    },
    {
        "title": "Session details: Speech & Auditory Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Speech & Auditory Interfaces",
        "data": "April 2015",
        "authors": [
            "Cosmin Munteanu"
        ],
        "DOI": "https://doi.org/10.1145/3251778",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Form Follows Sound: Designing Interactions from Sonic Memories",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Speech & Auditory Interfaces",
        "data": "April 2015",
        "authors": [
            "Baptiste Caramiaux",
            "Alessandro Altavilla",
            "Scott G. Pobiner",
            "Atau Tanaka"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702515",
        "citation": "23",
        "abstract": "Sonic interaction is the continuous relationship between user actions and sound, mediated by some technology. Because interaction with sound may be task oriented or experience-based it is important to understand the nature of action-sound relationships in order to design rich sonic interactions. We propose a participatory approach to sonic interaction design that first considers the affordances of sounds in order to imagine embodied interaction, and based on this, generates interaction models for interaction designers wishing to work with sound. We describe a series of workshops, called Form Follows Sound, where participants ideate imagined sonic interactions, and then realize working interactive sound prototypes. We introduce the Sonic Incident technique, as a way to recall memorable sound experiences. We identified three interaction models for sonic interaction design: conducting; manipulating; substituting. These three interaction models offer interaction designers and developers a framework on which they can build richer sonic interactions."
    },
    {
        "title": "Repurposing Conversation: Experiments with the Continuous Speech Stream",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Speech & Auditory Interfaces",
        "data": "April 2015",
        "authors": [
            "Donald McMillan",
            "Antoine Loriette",
            "Barry Brown"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702532",
        "citation": "14",
        "abstract": "Voice interaction with mobile devices has been focused on hands-free interaction or situations where visual interfaces are not applicable. In this paper we explore a subtler means of interaction -- speech recognition from continual, in the background, audio recording of conversations. We call this the 'continuous speech stream' and explore how it could be repurposed as user input. We analyse ten days of recorded audio from our participants, alongside corresponding interviews, to explore how systems might make use of extracts from this stream. Rather than containing directly actionable items, our data suggests that the continuous speech stream is a rich resource for identifying users' next actions, along with the interests and dispositions of those being recorded. Through design workshops we explored new interactions using the speech stream, and describe concepts for individual, shared and distributed use."
    },
    {
        "title": "The CADENCE Corpus: A New Resource for Inclusive Voice Interface Design",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Speech & Auditory Interfaces",
        "data": "April 2015",
        "authors": [
            "Maria K. Wolters",
            "Jonathan Kilgour",
            "Sarah E. MacPherson",
            "Myroslava Dzikovska",
            "Johanna D. Moore"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702372",
        "citation": "3",
        "abstract": "Papers on voice interfaces for people with cognitive impairment or demenita only provide small snapshots of actual interactions, if at all. This is a major obstacle to the development of better interfaces. Transcripts of interactions between users and systems contain rich evidence of typical language patterns, indicate how users conceptualise their computer interlocutor, and highlight key design issues. In this paper, we introduce the CADENCE corpus and outline how it can be used to stimulate replicable research on inclusive voice interfaces. The CADENCE corpus is first data set of its kind to include rich data from people with cognitive impairment and free for research use. The corpus consists of transcribed spoken interactions between older people with and without cognitive impairment and a simulated Intelligent Cognitive Assistant and includes comprehensive data on users' cognitive abilities."
    },
    {
        "title": "Empirical Evidence for a Diminished Sense of Agency in Speech Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Speech & Auditory Interfaces",
        "data": "April 2015",
        "authors": [
            "Hannah Limerick",
            "James W. Moore",
            "David Coyle"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702379",
        "citation": "36",
        "abstract": "While the technology underlying speech interfaces has improved in recent years, our understanding of the human side of speech interactions remains limited. This paper provides new insight on one important human aspect of speech interactions: the sense of agency - defined as the experience of controlling one's own actions and their outcomes. Two experiments are described. In each case a voice command is compared with keyboard input. Agency is measured using an implicit metric: intentional binding. In both experiments we find that participants' sense of agency is significantly reduced for voice commands as compared to keyboard input. This finding presents a fundamental challenge for the design of effective speech interfaces. We reflect on this finding and, based on current theory in HCI and cognitive neuroscience, offer possible explanations for the reduced sense of agency observed in speech interfaces."
    },
    {
        "title": "To Beep or Not to Beep?: Comparing Abstract versus Language-Based Multimodal Driver Displays",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Speech & Auditory Interfaces",
        "data": "April 2015",
        "authors": [
            "Ioannis Politis",
            "Stephen Brewster",
            "Frank Pollick"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702167",
        "citation": "33",
        "abstract": "Multimodal displays are increasingly being utilized as driver warnings. Abstract warnings, without any semantic association to the signified event, and language-based warnings are examples of such displays. This paper presents a first comparison between these two types, across all combinations of audio, visual and tactile modalities. Speech, text and Speech Tactons (a novel form of tactile warnings synchronous to speech) were compared to abstract pulses in two experiments. Results showed that recognition times of warning urgency during a non-critical driving situation were shorter for abstract warnings, highly urgent warnings and warnings including visual feedback. Response times during a critical situation were shorter for warnings including audio. We therefore suggest abstract visual feedback when informing drivers during a non-critical situation and audio in a highly critical one. Language-based warnings during a critical situation performed equally well as abstract ones, so they are suggested as less annoying vehicle alerts."
    },
    {
        "title": "Session details: Email & Social Media at Work",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Email & Social Media at Work",
        "data": "April 2015",
        "authors": [
            "Pernille Bjorn"
        ],
        "DOI": "https://doi.org/10.1145/3251779",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Lost in Email: Pulling Users Down a Path of Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Email & Social Media at Work",
        "data": "April 2015",
        "authors": [
            "Benjamin V. Hanrahan",
            "Manuel A. Pérez-Quiñones"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702351",
        "citation": "7",
        "abstract": "In this paper we describe a study exploring why users spend more time in email than originally intended, which we call getting lost in email. To study this phenomenon, we implemented an IMAP logger that also dispatched diary entries to collect data for twenty participants over a two week period. Most participants reported getting lost in email during both short and long sessions. Our analysis suggests two primary factors in getting lost: the number of emails awaiting a reply and whether or not the session caused an interruption. We conclude that much of the problem around getting lost in email is in managing the tension between promptly responding to messages while limiting engagement with email."
    },
    {
        "title": "Balancing Boundaries: Using Multiple Devices to Manage Work-Life Balance",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Email & Social Media at Work",
        "data": "April 2015",
        "authors": [
            "Rowanne Fleck",
            "Anna L. Cox",
            "Rosalyn A.V. Robison"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702386",
        "citation": "22",
        "abstract": "Information and communication technologies (ICTs) continue to give us increased flexibility about when and where we choose to work and the freedom to deal with home tasks whilst at work. However more use of ICT for work during non-work time has been linked with negative outcomes including lower work and life satisfaction and increased stress. Previous work has suggested that in order to reduce some of these negative effects, people should adopt technology use strategies that aid separation of their home and work lives. In this paper we report the results of a questionnaire study investigating work-life balance boundary behaviours and technology use. We find that people use multiple devices as a way of creating boundaries between home and work, and the extent to which they do this relates to their boundary behaviour style. These findings have particular relevance given the increasing trend for Bring Your Own Device (BYOD) policies."
    },
    {
        "title": "Working 9-5?: Professional Differences in Email and Boundary Management Practices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Email & Social Media at Work",
        "data": "April 2015",
        "authors": [
            "Marta E. Cecchinato",
            "Anna L. Cox",
            "Jon Bird"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702537",
        "citation": "32",
        "abstract": "Technology not only brings benefits such as flexible working practices but can also have negative stressful consequences such as increasing email overload and the blurring of work-home boundaries. We report on an exploratory study that extends the current understanding of email usage by investigating how different professions at a university manage work and personal emails using different devices and how this impacts their work-home boundary management. Our findings lead us to identify two user groups: those with permeable boundaries (primarily academics) and those who have more rigid ones (primarily professional services employees) and that there are differences in when, where and how they manage their work and personal emails. In particular we find that some participants use micro-boundary strategies to manage transitions between work and personal life. Based on these novel findings we propose improvements of email software design to facilitate effective email, work-home boundary management, and support micro-boundary practices."
    },
    {
        "title": "Inferring Employee Engagement from Social Media",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Email & Social Media at Work",
        "data": "April 2015",
        "authors": [
            "N. Sadat Shami",
            "Michael Muller",
            "Aditya Pal",
            "Mikhil Masli",
            "Werner Geyer"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702445",
        "citation": "25",
        "abstract": "Employees increasingly are expressing ideas and feelings through enterprise social media. Recent work in CHI and CSCW has applied linguistic analysis towards understanding employee experiences. In this paper, we apply dictionary based linguistic analysis to measure 'Employee Engagement'. Employee engagement is a measure of employee willingness to apply discretionary effort towards organizational goals, and plays an important role in organizational outcomes such as financial or operational results. Organizations typically use surveys to measure engagement. This paper describes an approach to model employee engagement based on word choice in social media. This method can potentially complement surveys, thus providing more real-time insights into engagement and allowing organizations to address engagement issues faster. Our results predicting engagement scores on a survey by combining demographics with social media text demonstrate that social media text has significant predictive power compared to demographic data alone. We also find that engagement may be a state than a stable trait since social media posts closer to the administration of the survey had the most predictive power. We further identify the minimum number of social media posts required per employee for the best prediction."
    },
    {
        "title": "Mailing Lists: Why Are They Still Here, What's Wrong With Them, and How Can We Fix Them?",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Email & Social Media at Work",
        "data": "April 2015",
        "authors": [
            "Amy X. Zhang",
            "Mark S. Ackerman",
            "David R. Karger"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702194",
        "citation": "17",
        "abstract": "Mailing lists have existed since the early days of email and are still widely used today, even as more sophisticated online forums and social media websites proliferate. The simplicity of mailing lists can be seen as a reason for their endurance, a source of dissatisfaction, and an opportunity for improvement. Using a mixed-method approach, we studied two community mailing lists in depth with interviews and surveys, and surveyed a broader spectrum of 28 lists. We report how members of the different communities use their lists and their goals and desires for them. We explore why members prefer mailing lists to other group communication tools. But we also identify several tensions around mailing list usage that appear to contribute to dissatisfaction with them. We conclude with design implications, discussing ways to alleviate these tensions while preserving mailing lists' appeal."
    },
    {
        "title": "Session details: Understanding & Protecting Kids Tech Use",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Protecting Kids Tech Use",
        "data": "April 2015",
        "authors": [
            "Svetlana Yarosh"
        ],
        "DOI": "https://doi.org/10.1145/3251780",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Regulating Access to Adult Content (with Privacy Preservation)",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Protecting Kids Tech Use",
        "data": "April 2015",
        "authors": [
            "Karen Renaud",
            "Joseph Maguire"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702456",
        "citation": "6",
        "abstract": "In the physical world we have well-established mechanisms for keeping children out of adult-only areas. In the virtual world this is generally replaced by self declaration. Some service providers resort to using heavy-weight identification mechanisms, judging adulthood as a side effect thereof. Collection of identification data arguably constitutes an unwarranted privacy invasion in this context, if carried out merely to perform adulthood estimation. This paper presents a mechanism that exploits the adult's more extensive exposure to public media, relying on the likelihood that they will be able to recall details if cued by a carefully chosen picture. We conducted an online study to gauge the viability of this scheme. With our prototype we were able to predict that the user was a child 99% of the time. Unfortunately the scheme also misclassified too many adults. We discuss our results and suggest directions for future research."
    },
    {
        "title": "Resilience Mitigates the Negative Effects of Adolescent Internet Addiction and Online Risk Exposure",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Protecting Kids Tech Use",
        "data": "April 2015",
        "authors": [
            "Pamela Wisniewski",
            "Haiyan Jia",
            "Na Wang",
            "Saijing Zheng",
            "Heng Xu",
            "Mary Beth Rosson",
            "John M. Carroll"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702240",
        "citation": "65",
        "abstract": "We cannot fully protect adolescents from experiencing online risks; however, we can aim to better understand how online risk experiences impact teens, factors that contribute to or prevent teens from exposure to risk, as well as factors that can protect teens from psychological harm in spite of online risk exposure. Through a web-based survey study of 75 adolescents in the US, we develop and empirically validate a theoretical model of adolescent resilience in the presence of online risks. We show evidence that resilience is a key factor in protecting teens from experiencing online risks, even when teens exhibit high levels of Internet addiction. Resilience also neutralizes the negative psychological effects associated with Internet addiction and online risk exposure. Therefore, we emphasize the importance of design solutions that foster teen resilience and strength building, as opposed to solutions targeted toward parents that often focus on restriction and risk prevention."
    },
    {
        "title": "Generation Like: Comparative Characteristics in Instagram",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Protecting Kids Tech Use",
        "data": "April 2015",
        "authors": [
            "Jin Yea Jang",
            "Kyungsik Han",
            "Patrick C. Shih",
            "Dongwon Lee"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702555",
        "citation": "64",
        "abstract": "The emergence of social media has had a significant impact on how people communicate and socialize. Teens use social media to make and maintain social connections with friends and build their reputation. However, the way of analyzing the characteristics of teens in social media has mostly relied on ethnographic accounts or quantitative analyses with small datasets. This paper shows the possibility of detecting age information in user profiles by using a combination of textual and facial recognition methods and presents a comparative study of 27K teens and adults in Instagram. Our analysis highlights that (1) teens tend to post fewer photos but highly engage in adding more tags to their own photos and receiving more Likes and comments about their photos from others, and (2) to post more selfies and express themselves more than adults, showing a higher sense of self-representation. We demonstrate the application of our novel method that shows clear trends of age differences as well as substantiates previous insights in social media."
    },
    {
        "title": "Investigating High School Students' Perceptions of Digital Badges in Afterschool Learning",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding & Protecting Kids Tech Use",
        "data": "April 2015",
        "authors": [
            "Katie Davis",
            "Eve Klein"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702413",
        "citation": "10",
        "abstract": "This paper investigates high school students' perceptions of the opportunities and challenges of using digital badges to recognize and reward the skills and achievements they acquire in an afterschool science education program. Focus groups and usability tests were conducted with 10 students during the design of a badge system prototype for use in the program. We found that students recognized opportunities for personal empowerment in their use of badges, but also expressed concerns about sharing badges in various online contexts. The findings provide new insight into the values and goals that learners bring to discussions of digital badges in education. These insights hold relevance for designers of education-based badge systems as well as educators seeking to introduce badges into their practice."
    },
    {
        "title": "Session details: Social Media & Citizen Science",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media & Citizen Science",
        "data": "April 2015",
        "authors": [
            "Elena Glassman"
        ],
        "DOI": "https://doi.org/10.1145/3251781",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Piggyback Prototyping: Using Existing, Large-Scale Social Computing Systems to Prototype New Ones",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media & Citizen Science",
        "data": "April 2015",
        "authors": [
            "Catherine Grevet",
            "Eric Gilbert"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702395",
        "citation": "34",
        "abstract": "We propose a technique we call piggyback prototyping, a prototyping mechanism for designing new social computing systems on top of existing ones. Traditional HCI prototyping techniques do not translate well to large social computing systems. To address this gap, we describe a 6-stage process for prototyping new social computing systems using existing online systems, such as Twitter or Facebook. This allows researchers to focus on what people do on their system rather than how to attract people to it. We illustrate this technique with an instantiation on Twitter to pair people who are different from each other in airports. Even though there were many missed meetings, 53% of survey respondents would be interested in being matched again, and eight people even met in person. Through piggyback prototyping, we gained insight into the future design of this system. We conclude the paper with considerations for privacy, consent, volume of users, and evaluation metrics."
    },
    {
        "title": "Situated Social Media Use: A Methodological Approach to Locating Social Media Practices and Trajectories",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media & Citizen Science",
        "data": "April 2015",
        "authors": [
            "Thomas Hillman",
            "Alexandra Weilenmann"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702531",
        "citation": "6",
        "abstract": "In this paper we draw upon a number of explorations of social media activities, trying to capture and understand them as located, situated practices. This methodological endeavor spans over analyzing patterns in big data feeds (here Instagram) as well as small-scale video-based ethnographic studies of user activities. A situated social media perspective involves examining how social media production and consumption are intertwined. Drawing upon our studies of social media use in cultural institutions we show how visitors orient to their social media presence while attending to physical space during a visit, and how editing and sharing processes are formed by the trajectory through a space. We discuss the application and relevance of this approach for understanding social media and social photography in situ."
    },
    {
        "title": "Break It Down: A Comparison of Macro- and Microtasks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media & Citizen Science",
        "data": "April 2015",
        "authors": [
            "Justin Cheng",
            "Jaime Teevan",
            "Shamsi T. Iqbal",
            "Michael S. Bernstein"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702146",
        "citation": "79",
        "abstract": "A large, seemingly overwhelming task can sometimes be transformed into a set of smaller, more manageable microtasks that can each be accomplished independently. For example, it may be hard to subjectively rank a large set of photographs, but easy to sort them in spare moments by making many pairwise comparisons. In crowdsourcing systems, microtasking enables unskilled workers with limited commitment to work together to complete tasks they would not be able to do individually. We explore the costs and benefits of decomposing macrotasks into microtasks for three task categories: arithmetic, sorting, and transcription. We find that breaking these tasks into microtasks results in longer overall task completion times, but higher quality outcomes and a better experience that may be more resilient to interruptions. These results suggest that microtasks can help people complete high quality work in interruption-driven environments."
    },
    {
        "title": "DIYbio Things: Open Source Biology Tools as Platforms for Hybrid Knowledge Production and Scientific Participation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media & Citizen Science",
        "data": "April 2015",
        "authors": [
            "Stacey Kuznetsov",
            "Carrie Doonan",
            "Nathan Wilson",
            "Swarna Mohan",
            "Scott E. Hudson",
            "Eric Paulos"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702235",
        "citation": "28",
        "abstract": "DIYbio (Do It Yourself Biology) is a growing movement of scientists, hobbyists, artists, and tinkerers who practice biology outside of professional settings. In this paper, we present our work with several open source DIYbio tools, including OpenPCR and Pearl Blue Transilluminator, which can be used to test DNA samples for specific sequences. We frame these platforms as things that gather heterogeneous materials and concerns, and enable new forms of knowledge transfer. Working with these hybrid systems in professional and DIY settings, we conducted a workshop where non-biologists tested food products for genetic modifications. Our findings suggest new design directions at the intersection of biology, technology, and DIY: i) DIYbio platforms as rich tools for hybrid knowledge production; and ii) open source biology as a site for public engagement with science."
    },
    {
        "title": "Designing for Citizen Data Analysis: A Cross-Sectional Case Study of a Multi-Domain Citizen Science Platform",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media & Citizen Science",
        "data": "April 2015",
        "authors": [
            "Ramine Tinati",
            "Max Van Kleek",
            "Elena Simperl",
            "Markus Luczak-Rösch",
            "Robert Simpson",
            "Nigel Shadbolt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702420",
        "citation": "57",
        "abstract": "Designing an effective and sustainable citizen science (CS)project requires consideration of a great number of factors. This makes the overall process unpredictable, even when a sound, user-centred design approach is followed by an experienced team of UX designers. Moreover, when such systems are deployed, the complexity of the resulting interactions challenges any attempt to generalisation from retrospective analysis. In this paper, we present a case study of the largest single platform of citizen driven data analysis projects to date, the Zooniverse. By eliciting, through structured reflection, experiences of core members of its design team, our grounded analysis yielded four sets of themes, focusing on Task Specificity, Community Development, Task Design and Public Relations and Engagement, supported by two-to-four specific design claims each. For each, we propose a set of design claims (DCs), drawing comparisons to the literature on crowdsourcing and online communities to contextualise our findings."
    },
    {
        "title": "Is This How We (All) Do It?: Butler Lies and Ambiguity Through a Broader Lens",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social Media & Citizen Science",
        "data": "April 2015",
        "authors": [
            "Megan French",
            "Madeline E. Smith",
            "Jeremy Birnholtz",
            "Jeff T. Hancock"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702368",
        "citation": "0",
        "abstract": "The ubiquity of mobile devices has resulted in more opportunities to interact with more people than ever before. Given a finite capacity for interaction with others, people commonly manage their availability by limiting others' access to them. Prior work has demonstrated the importance of doing so in a relationally sensitive way and identified the butler lie, in which deception is used to manage availability, as a common linguistic strategy. Two key limitations of existing exploratory work, however, are limited samples of primarily students and a focus on media properties in understanding ambiguity that enables butler lies to be plausible. This paper aims to address these issues via a broad field study of deception and butler lies using a novel message-sampling method employed via a custom mobile app. Results show clear evidence of butler lies occurring in a broader population, with some gender differences; and urge adoption of a multi-level framework for understanding ambiguity that also includes private information and infrastructure-level attributes of interaction media."
    },
    {
        "title": "Session details: Disasters & Humanitarian Events",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disasters & Humanitarian Events",
        "data": "April 2015",
        "authors": [
            "Tawanna Dillahunt"
        ],
        "DOI": "https://doi.org/10.1145/3251782",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "CrowdMonitor: Mobile Crowd Sensing for Assessing Physical and Digital Activities of Citizens during Emergencies",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disasters & Humanitarian Events",
        "data": "April 2015",
        "authors": [
            "Thomas Ludwig",
            "Christian Reuter",
            "Tim Siebigteroth",
            "Volkmar Pipek"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702265",
        "citation": "61",
        "abstract": "Emergencies such as the 2013 Central European flood or the 2013 typhoon Haiyan in Philippines have shown how citizens can organize themselves and coordinate private relief activities. These activities can be found in (physical) groups of affected people, but also within (digital) social media communities. There is an evident need, however, for a clearer picture of what exactly is going on to be available for use by the official emergency services: to enlist them, to keep them safe, to support their efforts and to avoid needless duplications or conflicts. Aligning emergency services and volunteer activities is, then, crucial. In this paper we present a mobile crowd sensing based concept, which was designed as well as implemented as the application CrowdMonitor and facilitates the detection of physical and digital activities and the assignment of specific tasks to citizens. Finally we outline the findings of its evaluation."
    },
    {
        "title": "XHELP: Design of a Cross-Platform Social-Media Application to Support Volunteer Moderators in Disasters",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disasters & Humanitarian Events",
        "data": "April 2015",
        "authors": [
            "Christian Reuter",
            "Thomas Ludwig",
            "Marc-André Kaufhold",
            "Volkmar Pipek"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702171",
        "citation": "44",
        "abstract": "Recent disasters have shown an increase in the significance of social media for both affected citizens and volunteers alike in the coordination of information and organization of relief activities, often independently of and in addition to the official emergency response. Existing research mainly focuses on the way in which individual platforms are used by volunteers in response to disasters. This paper examines the use of social media during the European Floods of 2013 and proposes a novel cross-social-media application for volunteers. Besides comprehensive analysis of volunteer communities, interviews were conducted with \"digital volunteers\" such as Facebook moderators of disaster-related groups. Based on the challenges identified, we designed and implemented the cross-social-media application \"XHELP\", which allows information to be both, acquired and distributed cross-media and cross-channel. The evaluation with 20 users leads to further design requirements for applications aiming to support volunteer moderators during disasters."
    },
    {
        "title": "Building a Birds Eye View: Collaborative Work in Disaster Response",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disasters & Humanitarian Events",
        "data": "April 2015",
        "authors": [
            "Joel E. Fischer",
            "Stuart Reeves",
            "Tom Rodden",
            "Steve Reece",
            "Sarvapali D. Ramchurn",
            "David Jones"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702313",
        "citation": "19",
        "abstract": "Command and control environments ranging from transport control rooms to disaster response have long been of interest to HCI and CSCW as rich sites of interactive technology use embedded in work practice. Drawing on our engagement with disaster response teams, including ethnography of their training work, we unpack the ways in which situational uncertainty is managed while a shared operational 'picture' is constituted through various practices around tabletop work. Our analysis reveals how this picture is collaboratively assembled as a socially shared object and displayed by drawing on digital and physical resources. Accordingly, we provide a range of principles implicated by our study that guide the design of systems augmenting and enriching disaster response work practices. In turn, we propose the Augmented Bird Table to illustrate how our principles can be implemented to support tabletop work."
    },
    {
        "title": "Success & Scale in a Data-Producing Organization: The Socio-Technical Evolution of OpenStreetMap in Response to Humanitarian Events",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disasters & Humanitarian Events",
        "data": "April 2015",
        "authors": [
            "Leysia Palen",
            "Robert Soden",
            "T. Jennings Anderson",
            "Mario Barrenechea"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702294",
        "citation": "49",
        "abstract": "OpenStreetMap (OSM) is a volunteer-driven, globally distributed organization whose members work to create a common digital map of the world. OSM embraces ideals of open data, and to that end innovates both socially and technically to develop practices and processes for coordinated operation. This paper provides a brief history of OSM and then, through quantitative and qualitative examination of the OSM database and other sites of articulation work, examines organizational growth through the lens of two catastrophes that spurred enormous humanitarian relief responses-the 2010 Haiti Earthquake and the 2013 Typhoon Yolanda. The temporally- and geographically- constrained events scope analysis for what is a rapidly maturing, whole-planet operation. The first disaster identified how OSM could support other organizations responding to the event. However, to achieve this, OSM has had to refine mechanisms of collaboration around map creation, which were tested again in Typhoon Yolanda. The transformation of work between these two events yields insights into the organizational development of large, data-producing online organizations."
    },
    {
        "title": "Session details: Home Physiotherapy & Rehabilitation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home Physiotherapy & Rehabilitation",
        "data": "April 2015",
        "authors": [
            "Yi-Ping Hung"
        ],
        "DOI": "https://doi.org/10.1145/3251783",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Physio@Home: Exploring Visual Guidance and Feedback Techniques for Physiotherapy Exercises",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home Physiotherapy & Rehabilitation",
        "data": "April 2015",
        "authors": [
            "Richard Tang",
            "Xing-Dong Yang",
            "Scott Bateman",
            "Joaquim Jorge",
            "Anthony Tang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702401",
        "citation": "73",
        "abstract": "Physiotherapy patients exercising at home alone are at risk of re-injury since they do not have corrective guidance from a therapist. To explore solutions to this problem, we designed Physio@Home, a prototype that guides people through prerecorded physiotherapy exercises using real-time visual guides and multi-camera views. Our design addresses several aspects of corrective guidance, including: plane and range of movement, joint positions and angles, and extent of movement. We evaluated our design, com-paring how closely people could follow exercise movements under various feedback conditions. Participants were most accurate when using our visual guide and multi-views. We provide suggestions for exercise guidance systems drawn from qualitative findings on visual feedback complexity."
    },
    {
        "title": "Lessons Learnt from Deploying an End-User Development Platform for Physical Rehabilitation",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home Physiotherapy & Rehabilitation",
        "data": "April 2015",
        "authors": [
            "Daniel Tetteroo",
            "Paul Vreugdenhil",
            "Ivor Grisel",
            "Marc Michielsen",
            "Els Kuppens",
            "Diana Vanmulken",
            "Panos Markopoulos"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702504",
        "citation": "23",
        "abstract": "Clinical researchers in rehabilitation technology have often called for exercise customization to address patient specific needs. Where such customization transcends simple parameter setting, the need for End-User Development (EUD) arises. EUD in this field can potentially tap on the expertise of highly skilled workers, but presents serious challenges regarding acceptance by end users and the feasibility of embedding EUD in their professional practice. This paper describes the deployment and adoption process of TagTrainer, a physical rehabilitation technology that supports EUD. TagTrainer was deployed in four rehabilitation clinics and was used by 24 rehabilitation therapists. We analyze how they engaged in EUD activities and we discuss decisions that we took in the design and deployment of TagTrainer. Based on these case studies, we present guidelines for the deployment of EUD systems."
    },
    {
        "title": "Exergames for Physiotherapy and Rehabilitation: A Medium-term Situated Study of Motivational Aspects and Impact on Functional Reach",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home Physiotherapy & Rehabilitation",
        "data": "April 2015",
        "authors": [
            "Jan David Smeddinck",
            "Marc Herrlich",
            "Rainer Malaka"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702598",
        "citation": "43",
        "abstract": "Exergames are increasingly considered as an exercise instruction modality in health applications. Studies are typically conducted in non-situated contexts and capture short-term effects. We present first results from a medium-scale study conducted over the course of 5 weeks and integrated into a normal rehabilitation program. The study features three groups, comparing manually adjustable exergames with the identical games in adaptive versions and manual physiotherapy interventions without games. The results indicate that the exergames and traditional therapy are comparable regarding measures of competence and enjoyment, while exergames led to significantly higher scores for autonomy, presence, and in a functional reach test. With traditional therapy, scores for tension-pressure and effort-importance were significantly higher. The initial results of the broader study presented in this paper deliver insights regarding motivational aspects of exergames and traditional therapy and point out which motivational aspects could be strengthened in future implementations."
    },
    {
        "title": "Resilience Ex Machina: Learning a Complex Medical Device for Haemodialysis Self-Treatment",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home Physiotherapy & Rehabilitation",
        "data": "April 2015",
        "authors": [
            "Paul James Noble"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702348",
        "citation": "2",
        "abstract": "Resilience, the ability to bounce back or manage sufficiently despite ongoing adversity, has received considerable interest from several domains over the last two decades. A concept that is easily and widely applicable, it has evolved a variety of nuanced interpretations. Recent work in the systems theory and resilience engineering domains has moved towards some sharper definitions. This paper discusses and develops these definitions, and by contrasting with robustness, applies them as an approach for HCI evaluation. Ethnographic data from a hospital training environment is used to examine how patients learn to operate home haemodialysis devices, and how patients' safety is managed and maintained. This paper concludes that to improve recovery of adverse situations within the home, there is a necessity for design to support the acquirement of resilient reaction as a skill, in hand with temporal management. These ideas are developed in conjunction with the consideration of how technology can support, or nudge, the expression of resilient behaviours."
    },
    {
        "title": "Understanding Design Tradeoffs for Health Technologies: A Mixed-Methods Approach",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Home Physiotherapy & Rehabilitation",
        "data": "April 2015",
        "authors": [
            "Katie O'Leary",
            "Jordan Eschler",
            "Logan Kendall",
            "Lisa M. Vizer",
            "James D. Ralston",
            "Wanda Pratt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702576",
        "citation": "5",
        "abstract": "We introduce a mixed-methods approach for determining how people weigh tradeoffs in values related to health and technologies for health self-management. Our approach combines interviews with Q-methodology, a method from psychology uniquely suited to quantifying opinions. We derive the framework for structured data collection and analysis for the Q-methodology from theories of self-management of chronic illness and technology adoption. To illustrate the power of this new approach, we used it in a field study of nine older adults with type 2 diabetes, and nine mothers of children with asthma. Our mixed-methods approach provides three key advantages for health design science in HCI: (1) it provides a structured health sciences theoretical framework to guide data collection and analysis; (2) it enhances the coding of unstructured data with statistical patterns of polarizing and consensus views; and (3) it empowers participants to actively weigh competing values that are most personally significant to them."
    },
    {
        "title": "Session details: Interaction Techniques for Tables & Walls",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction Techniques for Tables & Walls",
        "data": "April 2015",
        "authors": [
            "Tom Bartindale"
        ],
        "DOI": "https://doi.org/10.1145/3251784",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "G-raff: An Elevating Tangible Block for Spatial Tabletop Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction Techniques for Tables & Walls",
        "data": "April 2015",
        "authors": [
            "Chang-Min Kim",
            "Tek-Jin Nam"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702444",
        "citation": "5",
        "abstract": "We present an elevating tangible block, G-raff that supports spatial interaction in a tabletop computing environment. The elevating head part of G-raff moves according to the given height and angle data. We adopted two rollable metal tape structures to create large movements with a small volume block. On the head part, a smartphone can be mounted either horizontally or vertically. G-raff becomes a device that can connect a mobile device with a tabletop computer, thus a new spatial representation and control interaction is made. This paper introduces the design details, key features and applications of G-raff. We report on the results of a preliminary user study and discuss future work to improve the elevating device. This work contributes to maximizing the availability of augmented reality space above the tabletop display."
    },
    {
        "title": "Modeling Distant Pointing for Compensating Systematic Displacements",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction Techniques for Tables & Walls",
        "data": "April 2015",
        "authors": [
            "Sven Mayer",
            "Katrin Wolf",
            "Stefan Schneegass",
            "Niels Henze"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702332",
        "citation": "31",
        "abstract": "Distant pointing at objects and persons is a highly expressive gesture that is widely used in human communication. Pointing is also used to control a range of interactive systems. For determining where a user is pointing at, different ray casting methods have been proposed. In this paper we assess how accurately humans point over distance and how to improve it. Participants pointed at projected targets from 2m and 3m while standing and sitting. Testing three common ray casting methods, we found that even with the most accurate one the average error is 61.3cm. We found that all tested ray casting methods are affected by systematic displacements. Therefore, we trained a polynomial to compensate this displacement. We show that using a user-, pose-, and distant-independent quartic polynomial can reduce the average error by 37.3%"
    },
    {
        "title": "Is Moving Improving?: Some Effects of Locomotion in Wall-Display Interaction",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction Techniques for Tables & Walls",
        "data": "April 2015",
        "authors": [
            "Mikkel R. Jakobsen",
            "Kasper Hornbæk"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702312",
        "citation": "23",
        "abstract": "Physical movement plays an important role in interaction with wall-displays. Earlier work on its effect on performance has been inconclusive, however, because movement has not been experimentally controlled. In a first experiment, we controlled participants' ability to physically move in front of a 3-meter wide 24-megapixel wall-display. Participants performed a classification task involving navigation using a zoom-and-pan interface. Results suggest that the ability to move does not increase performance, and that a majority of participants used virtual navigation (i.e., zooming and panning) and little or no physical navigation (i.e., moving their bodies). To isolate the effects of physical and virtual navigation, a second experiment compared conditions where participants could navigate using either only physical movement or only virtual navigation. The second experiment showed that physical movement does benefit performance. The results from the experiments suggest that moving may not be improving performance, depending on the use of virtual navigation."
    },
    {
        "title": "Gaze+RST: Integrating Gaze and Multitouch for Remote Rotate-Scale-Translate Tasks",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction Techniques for Tables & Walls",
        "data": "April 2015",
        "authors": [
            "Jayson Turner",
            "Jason Alexander",
            "Andreas Bulling",
            "Hans Gellersen"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702355",
        "citation": "45",
        "abstract": "Our work investigates the use of gaze and multitouch to fluidly perform rotate-scale-translate (RST) tasks on large displays. The work specifically aims to understand if gaze can provide benefit in such a task, how task complexity affects performance, and how gaze and multitouch can be combined to create an integral input structure suited to the task of RST. We present four techniques that individually strike a different balance between gaze-based and touch-based translation while maintaining concurrent rotation and scaling operations. A 16 participant empirical evaluation revealed that three of our four techniques present viable options for this scenario, and that larger distances and rotation/scaling operations can significantly affect a gaze-based translation configuration. Furthermore we uncover new insights regarding multimodal integrality, finding that gaze and touch can be combined into configurations that pertain to integral or separable input structures."
    },
    {
        "title": "Designing for Exploratory Search on Touch Devices",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction Techniques for Tables & Walls",
        "data": "April 2015",
        "authors": [
            "Khalil Klouche",
            "Tuukka Ruotsalo",
            "Diogo Cabral",
            "Salvatore Andolina",
            "Andrea Bellucci",
            "Giulio Jacucci"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702489",
        "citation": "42",
        "abstract": "Exploratory search confront users with challenges in expressing search intents as the current search interfaces require investigating result listings to identify search directions, iterative typing, and reformulating queries. We present the design of Exploration Wall, a touch-based search user interface that allows incremental exploration and sense-making of large information spaces by combining entity search, flexible use of result entities as query parameters, and spatial configuration of search streams that are visualized for interaction. Entities can be flexibly reused to modify and create new search streams, and manipulated to inspect their relationships with other entities. Data comprising of task-based experiments comparing Exploration Wall with conventional search user interface indicate that Exploration Wall achieves significantly improved recall for exploratory search tasks while preserving precision. Subjective feedback supports our design choices and indicates improved user satisfaction and engagement. Our findings can help to design user interfaces that can effectively support exploratory search on touch devices."
    },
    {
        "title": "Session details: Interacting with GUIs",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with GUIs",
        "data": "April 2015",
        "authors": [
            "David Flatla"
        ],
        "DOI": "https://doi.org/10.1145/3251785",
        "citation": "0",
        "abstract": "No abstract available."
    },
    {
        "title": "Clutching Is Not (Necessarily) the Enemy",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with GUIs",
        "data": "April 2015",
        "authors": [
            "Mathieu Nancel",
            "Daniel Vogel",
            "Edward Lank"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702134",
        "citation": "19",
        "abstract": "Clutching is usually assumed to be triggered by a lack of physical space and detrimental to pointing performance. We conduct a controlled experiment using a laptop trackpad where the effect of clutching on pointing performance is dissociated from the effects of control-to-display transfer functions. Participants performed a series of target acquisition tasks using typical cursor acceleration functions with and without clutching. All pointing tasks were feasible without clutching, but clutch-less movements were harder to perform, caused more errors, required more preparation time, and were not faster than clutch-enabled movements."
    },
    {
        "title": "Visual Grouping in Menu Interfaces",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with GUIs",
        "data": "April 2015",
        "authors": [
            "Duncan P. Brumby",
            "Susan Zhuang"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702177",
        "citation": "5",
        "abstract": "Menu interfaces often arrange options into semantic groups. This semantic structure is then usually conveyed to the user by supplementary visual grouping cues. We investigate whether these visual grouping cues actually help users locate items in menus faster, and whether there is potential for these powerful grouping cues to impede search when used inappropriately. Thirty-six participants performed known-item searches of word menus. These menus differed along three dimensions: (1) whether visual grouping cues were used, (2) whether items were semantically organized, and (3) the number of items belonging to each semantic group. Results show that the usefulness of visual grouping entirely depends on the underlying semantic structure of the menu. When menus were semantically organized, having visual grouping cues delineate the boundaries between large semantic groups resulted in the fastest search times. But when semantically unrelated items were visually grouped together, participants took far longer to locate targets. Menu designers should therefore take great care to avoid visually grouping semantically unrelated items as this has the potential to hinder menu interactions."
    },
    {
        "title": "Color Portraits: From Color Picking to Interacting with Color",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with GUIs",
        "data": "April 2015",
        "authors": [
            "Ghita Jalal",
            "Nolwenn Maudet",
            "Wendy E. Mackay"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702173",
        "citation": "30",
        "abstract": "Although ubiquitous, color pickers have remained largely unchanged for 25 years. Based on contextual interviews with artists and designers, we created the Color Portraits design space to characterize five key color manipulation activities: sampling and tweaking individual colors, manipulating color relationships, combining colors with other elements, revisiting previous color choices, and revealing a design process through color. We found similar color manipulation requirements with scientists and engineers. We designed novel color interaction tools inspired by the design space, and used them as probes to identify specific design requirements, including: interactive palettes for sampling colors and exploring relationships; color composites for blending and decomposing colors with other elements; interactive histories to enable reuse of previous color choices; and providing color as a way to reveal underlying processes. We argue that color tools should allow users to interact with colors, not just pick or sample them."
    },
    {
        "title": "The Emergence of Interactive Behavior: A Model of Rational Menu Search",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with GUIs",
        "data": "April 2015",
        "authors": [
            "Xiuli Chen",
            "Gilles Bailly",
            "Duncan P. Brumby",
            "Antti Oulasvirta",
            "Andrew Howes"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702483",
        "citation": "33",
        "abstract": "One reason that human interaction with technology is difficult to understand is because the way in which people perform interactive tasks is highly adaptive. One such interactive task is menu search. In the current article we test the hypothesis that menu search is rationally adapted to (1) the ecological structure of interaction, (2) cognitive and perceptual limits, and (3) the goal to maximise the trade-off between speed and accuracy. Unlike in previous models, no assumptions are made about the strategies available to or adopted by users, rather the menu search problem is specified as a reinforcement learning problem and behaviour emerges by finding the optimal Markov Decision Process (MDP). The model is tested against existing empirical findings concerning the effect of menu organisation and menu length. The model predicts the effect of these variables on task completion time and eye movements. The discussion considers the pros and cons of the modelling approach relative to other well-known mod- elling approaches."
    },
    {
        "title": "Selective Undo Support for Painting Applications",
        "conferenceTitle": "CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with GUIs",
        "data": "April 2015",
        "authors": [
            "Brad A. Myers",
            "Ashley Lai",
            "Tam Minh Le",
            "YoungSeok Yoon",
            "Andrew Faulring",
            "Joel Brandt"
        ],
        "DOI": "https://doi.org/10.1145/2702123.2702543",
        "citation": "21",
        "abstract": "Today's widely deployed painting applications use a linear undo model that allows users to backtrack previous operations in reverse chronological order. This undo model is not useful if the user has performed desired operations after undesired ones. Selective undo, in contrast, allows users to select specific operations in the past and only undo those, while keeping the remaining operations intact. Although selective undo has been widely explored in the context of text editing and object-oriented drawing, we explore selective undo for painting (bitmap) editing, which has received less attention and introduces many interesting user interface design challenges. Our system, called Aquamarine, explores the script model for selective undo, where selectively undone operations are skipped in the history, rather than the more explored inverse model, which puts an inverse of the selected operations at the end of the history. We discuss the design implications and show through two informal user studies that selective undo is usable and desirable"
    }
]