import sys
import json
import nltk
import gensim
import string
# 데이터 전처리
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
# Word2Vec
from gensim.models import Word2Vec
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
# 시각화
import numpy as np
import matplotlib.pyplot as plt
# t-SNE
from sklearn.manifold import TSNE
import base64
from io import BytesIO
# PaCMAP
import pacmap
# DBSCAN
from sklearn.cluster import DBSCAN


# 처음 실행시 설치 필요
# nltk.download('punkt')
# nltk.download('stopwords')

def preprocess_text(text):
    # 소문자 변환
    lower_text = text.lower()
    # NLTK 토큰화
    tokenized_text = word_tokenize(lower_text)
    # 불용어 제거
    stop_words = set(stopwords.words('english'))
    filtered_text = [word for word in tokenized_text if word not in stop_words and word not in string.punctuation]
    return filtered_text


# def tSNE_visualize(model, top_n=50):
#     # 상위 N개의 단어 추출
#     words = model.wv.index_to_key[:top_n]
#     word_vectors = [model.wv[word] for word in words]

#     # t-SNE 모델 생성 및 단어 벡터 변환
#     tsne = TSNE(n_components=2, random_state=0)
#     word_vectors = np.array(word_vectors)  # NumPy 배열로 변환
#     word_vectors_2d = tsne.fit_transform(word_vectors)

#     # 시각화
#     plt.figure(figsize=(12, 8))
#     for i, word in enumerate(words):
#         plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1])
#         plt.annotate(word, xy=(word_vectors_2d[i, 0], word_vectors_2d[i, 1]), xytext=(5, 2),
#                      textcoords='offset points', ha='right', va='bottom')

#     # t-SNE 시각화에 대한 base64 인코딩된 PNG 이미지를 생성
#     img = BytesIO()
#     plt.savefig(img, format='png')
#     img.seek(0)
#     plot_data = base64.b64encode(img.getvalue()).decode()
#     plt.close()
#     return plot_data

def tSNE_visualize(model, top_n=50):
    # 상위 N개의 단어와 해당 벡터 추출
    # model.wv.index_to_key : 빈도 수에따라 정렬된 모델의 단어 리스트
    words = model.wv.index_to_key[:top_n]   
     # model.wv[word] : 주어진 `word`에 해당하는 임베딩 벡터 반환
    word_vectors = np.array([model.wv[word] for word in words])    

    # t-SNE 모델 적용하여 2차원 벡터 생성
    tsne = TSNE(n_components=2, random_state=0)
    word_vectors_2d = tsne.fit_transform(word_vectors)

    # DBSCAN 클러스터링 수행
    clustering = DBSCAN(eps=0.5, min_samples=2).fit(word_vectors_2d)
    
    # 시각화
    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(word_vectors_2d[:, 0], word_vectors_2d[:, 1], c=clustering.labels_)
    legend1 = plt.legend(*scatter.legend_elements(), title="Clusters")
    plt.gca().add_artist(legend1)

    for i, word in enumerate(words):
        plt.annotate(word, xy=(word_vectors_2d[i, 0], word_vectors_2d[i, 1]), xytext=(5, 2),
                     textcoords='offset points', ha='right', va='bottom')
    
    plt.show()

def tSNE_visualize_doc2vec(model, labels=None, top_n=50):
    # 문서 벡터 추출
    doc_ids = list(range(min(top_n, len(model.dv))))
    doc_vectors = np.array([model.dv[i] for i in doc_ids])

    # t-SNE 모델 적용하여 2차원 벡터 생성
    tsne = TSNE(n_components=2, random_state=0, perplexity=40)
    doc_vectors_2d = tsne.fit_transform(doc_vectors)

    # 시각화
    plt.figure(figsize=(12, 8))
    for i, doc_id in enumerate(doc_ids):
        plt.scatter(doc_vectors_2d[i, 0], doc_vectors_2d[i, 1])
        plt.annotate(labels[i] if labels else f'Doc {doc_id}', xy=(doc_vectors_2d[i, 0], doc_vectors_2d[i, 1]),
                     xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')
    
    plt.show()

def tSNE_visualize_doc2vec_DBSCAN(model, labels=None, top_n=50):
    # 문서 벡터 추출
    doc_ids = list(range(min(top_n, len(model.dv))))
    doc_vectors = np.array([model.dv[i] for i in doc_ids])

    # t-SNE 모델 적용하여 2차원 벡터 생성
    tsne = TSNE(n_components=2, random_state=0, perplexity=20)
    doc_vectors_2d = tsne.fit_transform(doc_vectors)

    # DBSCAN 클러스터링 수행
    clustering = DBSCAN(eps=0.5, min_samples=2).fit(doc_vectors_2d)

    # 시각화
    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(doc_vectors_2d[:, 0], doc_vectors_2d[:, 1], c=clustering.labels_)
    legend1 = plt.legend(*scatter.legend_elements(), title="Clusters")
    plt.gca().add_artist(legend1)

    for i, doc_id in enumerate(doc_ids):
        plt.annotate(labels[i] if labels else f'Doc {doc_id}', xy=(doc_vectors_2d[i, 0], doc_vectors_2d[i, 1]),
                     xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')
    
    plt.show()


def PaCMAP_visualize(model, top_n=50):
    # 상위 N개의 단어와 해당 벡터 추출
    words = model.wv.index_to_key[:top_n]
    word_vectors = np.array([model.wv[word] for word in words])

    # PaCMAP 적용하여 2차원 벡터 생성
    embedding = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0)
    word_vectors_2d = embedding.fit_transform(word_vectors, init="pca")

    # 시각화
    plt.figure(figsize=(12, 8))
    for i, word in enumerate(words):
        plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1])
        plt.annotate(word, xy=(word_vectors_2d[i, 0], word_vectors_2d[i, 1]), xytext=(5, 2),
                     textcoords='offset points', ha='right', va='bottom')
    
    plt.show()

def PaCMAP_visualize_doc2Vec(model, labels=None, top_n=50):
    doc_ids = list(range(min(top_n, len(model.dv))))
    doc_vectors = np.array([model.dv[i] for i in doc_ids])

    # PaCMAP 적용하여 2차원 벡터 생성
    embedding = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0)
    doc_vectors_2d = embedding.fit_transform(doc_vectors, init="pca")

    # 시각화
    plt.figure(figsize=(12, 8))
    for i, doc_id in enumerate(doc_ids):
        plt.scatter(doc_vectors_2d[i, 0], doc_vectors_2d[i, 1])
        plt.annotate(labels[i] if labels else f'Doc {doc_id}', xy=(doc_vectors_2d[i, 0], doc_vectors_2d[i, 1]), 
                     xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')
    
    plt.show()
    
###################################
######### create model ############
###################################
    
def calculate_Word2Vec(input_data):
    tokenized_data = []

    # 모든 논문 abstract을 하나의 데이터 세트로 결합
    for abstract in input_data:
        sentences = sent_tokenize(abstract)
        for sentence in sentences:
            tokenized_data.append(preprocess_text(sentence))

    # 모든 데이터에 대한 하나의 Word2Vec 모델 학습
    model = Word2Vec(tokenized_data, vector_size=100, window=5, min_count=1, workers=4)

    return model


def calculate_Doc2Vec(input_data):
    tagged_data = []

    # 모든 논문 abstract를 TaggedDocument로 변환
    for i, abstract in enumerate(input_data):
        tokens = preprocess_text(abstract)
        tagged_data.append(TaggedDocument(words=tokens, tags=[str(i)]))
        
    # Doc2Vec 모델 초기화 및 학습
    model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=40)
    model.build_vocab(tagged_data)
    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)

    return model

    
def main():
    # 입력 데이터를 JSON 형식으로 받음
    # input_data = json.loads(sys.stdin.read())

    # algorithm 검색 결과
    input_data1 = [
  'Although speech is a potentially rich information source, a major barrier to exploiting speech archives is the lack of useful tools for efficiently accessing lengthy speech recordings. This paper develops and evaluates techniques for temporal compression - reducing the time people take to listen to a recording while still extracting critical information. We first describe an exploratory study that identifies novel excision techniques that remove unimportant words or utterances from the recording. We then develop a new method for evaluating how well temporal compression supports users in forming a general understanding of a recording. Applying this method, we demonstrate that excision techniques are generally more effective than standard compression techniques that simply speed up the entire recording.',
  'To understand how and why individuals make use of emerging information assimilation services on the Web as part of their daily routine, we combined video recordings of online activity with targeted interviews of eleven experienced web users. From these observations, we describe their choice of systems, the goals they are trying to achieve, their information diets, the basic process they use for assimilating information, and the impact of user interface speed.',
  "Hierarchical menus are now ubiquitous. The performance of the menu depends on many factors: structure, layout, colors and so on. There has been extensive research on novel menus, but there has been little work on improving the performance by optimizing the menu's structure. This paper proposes an algorithm based on the genetic algorithm (GA) for optimizing the performance of menus. The algorithm aims to minimize the average selection time of menu items by considering movement and decision time. We show results on a static hierarchical menu of a cellular phone where a small screen and limited input device are assumed. Our work makes several contributions: a novel mathematical optimization model for hierarchical menus; novel optimization method based on the genetic algorithm (GA).",
  'We designed an algorithm to build a speed-call list adaptively based on mobile phone call logs. Call logs provide the time-dependent calling patterns of mobile phone users, and therefore a speed-call list based on them will be more successful in recommending a desired number than a speed-call list based on recent calls only. This paper presents the design process of our algorithm for an adaptive speed-call list, its verification result with recorded call logs, and in-situ evaluation results of the algorithm using an Experience Sampling Method (ESM) system.',
  'Automated detection of excessive visual search (ES) experienced by a user during software use presents the potential for substantial improvement in the efficiency of supervised usability analysis. This paper presents an objective evaluation of several methods for the automated segmentation and classification of ES intervals from an eye movement recording, a technique that can be utilized to aid in the identification of usability problems during software usability testing. Techniques considered for automated segmentation of the eye movement recording into unique intervals include mouse/keyboard events and eye movement scanpaths. ES is identified by a number of eye movement metrics, including: fixation count, saccade amplitude, convex hull area, scanpath inflections, scanpath length, and scanpath duration. The ES intervals identified by each algorithm are compared to those produced by manual classification to verify the accuracy, precision, and performance of each algorithm. The results indicate that automated classification can be successfully employed to substantially reduce the amount of recorded data reviewed by HCI experts during usability testing, with relatively little loss in accuracy.',
  'The time and labor demanded by a typical laboratory-based keyboard evaluation are limiting resources for algorithmic adjustment and optimization. We propose Remulation, a complementary method for evaluating touchscreen keyboard correction and recognition algorithms. It replicates prior user study data through real-time, on-device simulation. We have developed Octopus, a Remulation-based evaluation tool that enables keyboard developers to efficiently measure and inspect the impact of algorithmic changes without conducting resource-intensive user studies. It can also be used to evaluate third-party keyboards in a "black box" fashion, without access to their algorithms or source code. Octopus can evaluate both touch keyboards and word-gesture keyboards. Two empirical examples show that Remulation can efficiently and effectively measure many aspects of touch screen keyboards at both macro and micro levels. Additionally, we contribute two new metrics to measure keyboard accuracy at the word level: the Ratio of Error Reduction (RER) and the Word Score.',
  'Interruptions can have a significant impact on users working to complete a task. When people are collaborating, either with other users or with systems, coordinating interruptions is an important factor in maintaining efficiency and preventing information overload. Computer systems can observe user behavior, model it, and use this to optimize the interruptions to minimize disruption. However, current techniques often require long training periods that make them unsuitable for online collaborative environments where new users frequently participate.',
  "Our daily digital life is full of algorithmically selected content such as social media feeds, recommendations and personalized search results. These algorithms have great power to shape users' experiences, yet users are often unaware of their presence. Whether it is useful to give users insight into these algorithms' existence or functionality and how such insight might affect their experience are open questions. To address them, we conducted a user study with 40 Facebook users to examine their perceptions of the Facebook News Feed curation algorithm. Surprisingly, more than half of the participants (62.5%) were not aware of the News Feed curation algorithm's existence at all. Initial reactions for these previously unaware participants were surprise and anger. We developed a system, FeedVis, to reveal the difference between the algorithmically curated and an unadulterated News Feed to users, and used it to study how users perceive this difference. Participants were most upset when close friends and family were not shown in their feeds. We also found participants often attributed missing stories to their friends' decisions to exclude them rather than to Facebook News Feed algorithm. By the end of the study, however, participants were mostly satisfied with the content on their feeds. Following up with participants two to six months after the study, we found that for most, satisfaction levels remained similar before and after becoming aware of the algorithm's presence, however, algorithmic awareness led to more active engagement with Facebook and bolstered overall feelings of control on the site.",
  "People are becoming increasingly reliant on online socio-technical systems that employ algorithmic curation to organize, select and present information. We wanted to understand how individuals make sense of the influence of algorithms, and how awareness of algorithmic curation may impact their interaction with these systems. We investigated user understanding of algorithmic curation in Facebook's News Feed, by analyzing open-ended responses to a survey question about whether respondents believe their News Feeds show them every post their Facebook Friends create. Responses included a wide range of beliefs and causal inferences, with different potential consequences for user behavior in the system. Because user behavior is both input for algorithms and constrained by them, these patterns of belief may have tangible consequences for the system as a whole.",
  "Recent research has developed analytics that threaten online self-presentation and privacy by automatically generating profiles of individuals' most personal traits-their personality, values, motivations, and so on. But we know little about people's reactions to personal traits profiles of themselves, or what influences their decisions to share such profiles. We present an early qualitative study of people's reactions to a working hyper-personal analytics system. The system lets them see their personality and values profile derived from their own social media text. Our results reveal a paradox. Participants found their personal traits profiles creepily accurate and did not like sharing them in many situations. However, they felt pressured by the social risks of not sharing and showed signs of learned helplessness, leading them to share despite their misgivings. Further, they felt unqualified to significantly modify their profile contents due to a surprising trust in the 'expert' algorithm. We explore design implications for hyper-personal analytics systems that consider the needs and preferences of the people being profiled, suggesting ways to enhance the control they feel and the benefits they reap.",
  'We present a novel approach that integrates algorithmic recommender techniques with interactive faceted filtering methods. We refer to this approach as blended recommending. It allows users to interact with a set of filter facets representing criteria that can serve as input for different recommendation methods including both collaborative and content-based filtering. Users can select filter criteria from these facets and weight them to express their preferences and to exert control over the hybrid recommendation process. In contrast to hard Boolean filtering, the method aggregates the weighted criteria and calculates a ranked list of recommendations that is visualized and immediately updated when users change the filter settings. Based on this approach, we implemented an interactive movie recommender, MyMovieMixer. In a user study, we compared the system with a conventional faceted filtering system that served as a baseline to obtain insights into user interaction behavior and to assess recommendation quality for our system. The results indicate, among other findings, a higher level of perceived user control, more detailed preference settings, and better suitability when the search goal is vague.',
  'Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.',
  'The rising prevalence of algorithmic interfaces, such as curated feeds in online news, raises new questions for designers, scholars, and critics of media. This work focuses on how transparent design of algorithmic interfaces can promote awareness and foster trust. A two-stage process of how transparency affects trust was hypothesized drawing on theories of information processing and procedural justice. In an online field experiment, three levels of system transparency were tested in the high-stakes context of peer assessment. Individuals whose expectations were violated (by receiving a lower grade than expected) trusted the system less, unless the grading algorithm was made more transparent through explanation. However, providing too much information eroded this trust. Attitudes of individuals whose expectations were met did not vary with transparency. Results are discussed in terms of a dual process model of attitude change and the depth of justification of perceived inconsistency. Designing for trust requires balanced interface transparency - not too little and not too much.',
  'Many algorithms have been created to automatically detect community structures in social networks. These algorithms have been studied from the perspective of optimisation extensively. However, which community finding algorithm most closely matches the human notion of communities? In this paper, we conduct a user study to address this question. In our experiment, users collected their own Facebook network and manually annotated it, indicating their social communities. Given this annotation, we run state-of-the-art community finding algorithms on the network and use Normalised Mutual Information (NMI) to compare annotated communities with automatically detected ones. Our results show that the Infomap algorithm has the greatest similarity to user defined communities, with Girvan-Newman and Louvain algorithms also performing well.',
  'The digital design space, unlimited by its virtual freedom, differs from traditional craft, which is bounded by a fixed set of given materials. We study how to introduce parametric design tools to craftspersons. Our hypothesis is that the arrangement of parametric design in modular representation, in the form of a catalog, can assist makers unfamiliar with this practice. We evaluate this assumption in the realm of bag design, through a Honeycomb Smocking Pattern Catalog and custom Computer-Aided Smocking (CAS) design software. We describe the technical work and designs made with our tools, present a user study that validates our assumptions, and conclude with ideas for future work developing additional tools to bridge computational design and craft.',
  'Much research has shown that social media platforms have substantial population biases. However, very little is known about how these population biases affect the many algorithms that rely on social media data. Focusing on the case study of geolocation inference algorithms and their performance across the urban-rural spectrum, we establish that these algorithms exhibit significantly worse performance for underrepresented populations (i.e. rural users). We further establish that this finding is robust across both text- and network-based algorithm designs. However, we also show that some of this bias can be attributed to the design of algorithms themselves rather than population biases in the underlying data sources. For instance, in some cases, algorithms perform badly for rural users even when we substantially overcorrect for population biases by training exclusively on rural data. We discuss the implications of our findings for the design and study of social media-based algorithms.',
  "As algorithmically-driven content curation has become an increasingly common feature of social media platforms, user resistance to algorithmic change has become more frequent and visible. These incidents of user backlash point to larger issues such as inaccurate understandings of how algorithmic systems work as well as mismatches between designer and user intent. Using a content analysis of 102,827 tweets from #RIPTwitter, a recent hashtag-based backlash to rumors about introducing algorithmic curation to Twitter's timeline, this study addresses the nature of user resistance in the form of the complaints being expressed, folk theories of the algorithmic system espoused by users, and how these folk theories potentially frame user reactions. We find that resistance to algorithmic change largely revolves around expectation violation, with folk theories acting as frames for reactions such that more detailed folk theories are expressed through more specific reactions to algorithmic change.",
  "Algorithms are increasingly being incorporated into diverse services that orchestrate multiple stakeholders' needs and interests. How can we design these algorithmic services to make decisions that are not only efficient, but also fair and motivating? We take a human-centered approach to identify and address challenges in building human-centered algorithmic services. We are in the process of building an allocation algorithm for 412 Food Rescue, an organization that matches food donations with non-profit organizations. As part of this ongoing project, we conducted interviews with multiple stakeholders in the service-organization staff, donors, volunteers, recipient non-profits and their clients, and everyday citizens-in order to understand how the allocation algorithm, interfaces, and surrounding work practices should be designed. The findings suggest that we need to understand and account for varying fairness notions held by stakeholders; consider people, contexts, and interfaces for algorithms to work fairly in the real world; and preserve meaningfulness and social interaction in automation in order to build fair and motivating algorithmic services.",
  "Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making.",
  'The promise AI’s proponents have made for decades is one in which our needs are predicted, anticipated, and met - often before we even realize it. Instead, algorithmic systems, particularly AIs trained on large datasets and deployed to massive scales, seem to keep making the wrong decisions, causing harm and rewarding absurd outcomes. Attempts to make sense of why AIs make wrong calls in the moment explain the instances of errors, but how the environment surrounding these systems precipitate those instances remains murky. This paper draws from anthropological work on bureaucracies, states, and power, translating these ideas into a theory describing the structural tendency for powerful algorithmic systems to cause tremendous harm. I show how administrative models and projections of the world create marginalization, just as algorithmic models cause representational and allocative harm. This paper concludes with a recommendation to avoid the absurdity algorithmic systems produce by denying them power.',
  "Recently, Artificial Intelligence (AI) has been used to enable efficient decision-making in managerial and organizational contexts, ranging from employment to dismissal. However, to avoid employees’ antipathy toward AI, it is important to understand what aspects of AI employees like and/or dislike. In this paper, we aim to identify how employees perceive current human resource (HR) teams and future algorithmic management. Specifically, we explored what factors negatively influence employees’ perceptions of AI making work performance evaluations. Through in-depth interviews with 21 workers, we found that 1) employees feel six types of burdens (i.e., emotional, mental, bias, manipulation, privacy, and social) toward AI's introduction to human resource management (HRM), and that 2) these burdens could be mitigated by incorporating transparency, interpretability, and human intervention to algorithmic decision-making. Based on our findings, we present design efforts to alleviate employees’ burdens. To leverage AI for HRM in fair and trustworthy ways, we call for the HCI community to design human-AI collaboration systems with various HR stakeholders.",
  'There is a growing concern that e-commerce platforms are amplifying vaccine-misinformation. To investigate, we conduct two-sets of algorithmic audits for vaccine misinformation on the search and recommendation algorithms of Amazon—world’s leading e-retailer. First, we systematically audit search-results belonging to vaccine-related search-queries without logging into the platform—unpersonalized audits. We find 10.47% of search-results promote misinformative health products. We also observe ranking-bias, with Amazon ranking misinformative search-results higher than debunking search-results. Next, we analyze the effects of personalization due to account-history, where history is built progressively by performing various real-world user-actions, such as clicking a product. We find evidence of filter-bubble effect in Amazon’s recommendations; accounts performing actions on misinformative products are presented with more misinformation compared to accounts performing actions on neutral and debunking products. Interestingly, once user clicks on a misinformative product, homepage recommendations become more contaminated compared to when user shows an intention to buy that product.',
  'The relationships that constitute the global industrial food system tend towards two dominant values that are creating unsustainable social and environmental inequalities. The first is a human-centered perspective on food that privileges humans over all other species. The second is a view of food as a commodity to be traded for maximum economic value, rewarding a small number of shareholders. We present work that explores the unique algorithmic affordances of blockchain to create new types of value exchange and governance in the food system. We describe a project that used roleplay with urban agricultural communities to co-design blockchain-based food futures and explore the conditions for creating a thriving multispecies food commons. We discuss how the project helped rethink algorithmic food justice by reconfiguring more-than-human values and reconfiguring food as more-than-human commons. We also discuss some of the challenges and tensions arising from these explorations.',
  'Across the United States, a growing number of school districts are turning to matching algorithms to assign students to public schools. The designers of these algorithms aimed to promote values such as transparency, equity, and community in the process. However, school districts have encountered practical challenges in their deployment. In fact, San Francisco Unified School District voted to stop using and completely redesign their student assignment algorithm because it was frustrating for families and it was not promoting educational equity in practice. We analyze this system using a Value Sensitive Design approach and find that one reason values are not met in practice is that the system relies on modeling assumptions about families’ priorities, constraints, and goals that clash with the real world. These assumptions overlook the complex barriers to ideal participation that many families face, particularly because of socioeconomic inequalities. We argue that direct, ongoing engagement with stakeholders is central to aligning algorithmic values with real world conditions. In doing so we must broaden how we evaluate algorithms while recognizing the limitations of purely algorithmic solutions in addressing complex socio-political problems.',
  'More visualization systems are simplifying the data analysis process by automatically suggesting relevant visualizations. However, little work has been done to understand if users trust these automated recommendations. In this paper, we present the results of a crowd-sourced study exploring preferences and perceived quality of recommendations that have been positioned as either human-curated or algorithmically generated. We observe that while participants initially prefer human recommenders, their actions suggest an indifference for recommendation source when evaluating visualization recommendations. The relevance of presented information (e.g., the presence of certain data fields) was the most critical factor, followed by a belief in the recommender’s ability to create accurate visualizations. Our findings suggest a general indifference towards the provenance of recommendations, and point to idiosyncratic definitions of visualization quality and trustworthiness that may not be captured by simple measures. We suggest that recommendation systems should be tailored to the information-foraging strategies of specific users.',
  'Prior research has studied the detrimental impact of algorithmic management on gig workers and strategies that workers devise in response. However, little work has investigated alternative platform designs to promote worker well-being, particularly from workers’ own perspectives. We use a participatory design approach wherein workers explore their algorithmic imaginaries to co-design interventions that center their lived experiences, preferences, and well-being in algorithmic management. Our interview and participatory design sessions highlight how various design dimensions of algorithmic management, including information asymmetries and unfair, manipulative incentives, hurt worker well-being. Workers generate designs to address these issues while considering competing interests of the platforms, customers, and themselves, such as information translucency, incentives co-configured by workers and platforms, worker-centered data-driven insights for well-being, and collective driver data sharing. Our work offers a case study that responds to a call for designing worker-centered digital work and contributes to emerging literature on algorithmic work.',
  "Enterprises have recently adopted AI to human resource management (HRM) to evaluate employees’ work performance evaluation. However, in such an HRM context where multiple stakeholders are complexly intertwined with different incentives, it is problematic to design AI reflecting one stakeholder group's needs (e.g., enterprises, HR managers). Our research aims to investigate what tensions surrounding AI in HRM exist among stakeholders and explore design solutions to balance the tensions. By conducting stakeholder-centered participatory workshops with diverse stakeholders (including employees, employers/HR teams, and AI/business experts), we identified five major tensions: 1) divergent perspectives on fairness, 2) the accuracy of AI, 3) the transparency of the algorithm and its decision process, 4) the interpretability of algorithmic decisions, and 5) the trade-off between productivity and inhumanity. We present stakeholder-centered design ideas for solutions to mitigate these tensions and further discuss how to promote harmony among various stakeholders at the workplace.",
  'AI-based decision support tools (ADS) are increasingly used to augment human decision-making in high-stakes, social contexts. As public sector agencies begin to adopt ADS, it is critical that we understand workers’ experiences with these systems in practice. In this paper, we present findings from a series of interviews and contextual inquiries at a child welfare agency, to understand how they currently make AI-assisted child maltreatment screening decisions. Overall, we observe how workers’ reliance upon the ADS is guided by (1) their knowledge of rich, contextual information beyond what the AI model captures, (2) their beliefs about the ADS’s capabilities and limitations relative to their own, (3) organizational pressures and incentives around the use of the ADS, and (4) awareness of misalignments between algorithmic predictions and their own decision-making objectives. Drawing upon these findings, we discuss design implications towards supporting more effective human-AI decision-making.',
  'Machine learning tools have been deployed in various contexts to support human decision-making, in the hope that human-algorithm collaboration can improve decision quality. However, the question of whether such collaborations reduce or exacerbate biases in decision-making remains underexplored. In this work, we conducted a mixed-methods study, analyzing child welfare call screen workers’ decision-making over a span of four years, and interviewing them on how they incorporate algorithmic predictions into their decision-making process. Our data analysis shows that, compared to the algorithm alone, workers reduced the disparity in screen-in rate between Black and white children from 20% to 9%. Our qualitative data show that workers achieved this by making holistic risk assessments and adjusting for the algorithm’s limitations. Our analyses also show more nuanced results about how human-algorithm collaboration affects prediction accuracy, and how to measure these effects. These results shed light on potential mechanisms for improving human-algorithm collaboration in high-risk decision-making contexts.',
  'Designing solution plans before writing code is critical for successful algorithmic problem-solving. Novices, however, often plan on-the-fly during implementation, resulting in unsuccessful problem-solving due to lack of mental organization of the solution. Research shows that subgoal learning helps learners develop more complete solution plans by enhancing their understanding of the high-level solution structure. However, expert-created materials such as subgoal labels are necessary to provide learning benefits from subgoal learning, which are a scarce resource in self-learning due to limited availability and high cost. We propose a learnersourcing workflow that collects high-quality subgoal labels from learners by helping them improve their label quality. We implemented the workflow into AlgoSolve, a prototype interface that supports subgoal learning for algorithmic problems. A between-subjects study with 63 problem-solving novices revealed that AlgoSolve helped learners create higher-quality labels and more complete solution plans, compared to a baseline method known to be effective in subgoal learning.',
  'Reflecting on stress-related data is critical in addressing one’s mental health. Personal Informatics (PI) systems augmented by algorithms and sensors have become popular ways to help users collect and reflect on data about stress. While prediction algorithms in the PI systems are mainly for diagnostic purposes, few studies examine how the explainability of algorithmic prediction can support user-driven self-insight. To this end, we developed MindScope, an algorithm-assisted stress management system that determines user stress levels and explains how the stress level was computed based on the user’s everyday activities captured by a smartphone. In a 25-day field study conducted with 36 college students, the prediction and explanation supported self-reflection, a process to re-establish preconceptions about stress by identifying stress patterns and recalling past stress levels and patterns that led to coping planning. We discuss the implications of exploiting prediction algorithms that facilitate user-driven retrospection in PI systems.',
  'If you were significantly impacted by an algorithmic decision, how would you want the decision to be reviewed? In this study, we explore perceptions of review processes for algorithmic decisions that differ across three dimensions: the reviewer, how the review is conducted, and how long the review takes. Using a choice-based conjoint analysis we find that people prefer review processes that provide for human review, the ability to participate in the review process, and a timely outcome. Using a survey, we find that people also see human review that provides for participation to be the fairest review process. Our qualitative analysis indicates that the fairest review process provides the greatest likelihood of a favourable outcome, an opportunity for the decision subject and their situation to be fully and accurately understood, human involvement, and dignity. These findings have implications for the design of contestation procedures and also the design of algorithmic decision-making processes.',
  'In the media, in policy-making, but also in research articles, algorithmic decision-making (ADM) systems are referred to as algorithms, artificial intelligence, and computer programs, amongst other terms. We hypothesize that such terminological differences can affect people’s perceptions of properties of ADM systems, people’s evaluations of systems in application contexts, and the replicability of research as findings may be influenced by terminological differences. In two studies (N = 397, N = 622), we show that terminology does indeed affect laypeople’s perceptions of system properties (e.g., perceived complexity) and evaluations of systems (e.g., trust). Our findings highlight the need to be mindful when choosing terms to describe ADM systems, because terminology can have unintended consequences, and may impact the robustness and replicability of HCI research. Additionally, our findings indicate that terminology can be used strategically (e.g., in communication about ADM systems) to influence people’s perceptions and evaluations of these systems.',
  'YouTube is a space where people with disabilities can reach a wider online audience to present what it is like to have disabilities. Thus, it is imperative to understand how content creators with disabilities strategically interact with algorithms to draw viewers around the world. However, considering that the algorithm carries the risk of making less inclusive decisions for users with disabilities, whether the current algorithmic experiences (AXs) on video platforms is inclusive for creators with disabilities is an open question. To address that, we conducted semi-structured interviews with eight YouTubers with disabilities. We found that they aimed to inform the public of diverse representations of disabilities, which led them to work with algorithms by strategically portraying disability identities. However, they were disappointed that the way the algorithms work did not sufficiently support their goals. Based on findings, we suggest implications for designing inclusive AXs that could embrace creators’ subtle needs.',
  'Recent work in HCI suggests that users can be powerful in surfacing harmful algorithmic behaviors that formal auditing approaches fail to detect. However, it is not well understood how users are often able to be so effective, nor how we might support more effective user-driven auditing. To investigate, we conducted a series of think-aloud interviews, diary studies, and workshops, exploring how users find and make sense of harmful behaviors in algorithmic systems, both individually and collectively. Based on our findings, we present a process model capturing the dynamics of and influences on users’ search and sensemaking behaviors. We find that 1) users’ search strategies and interpretations are heavily guided by their personal experiences with and exposures to societal bias; and 2) collective sensemaking amongst multiple users is invaluable in user-driven algorithm audits. We offer directions for the design of future methods and tools that can better support user-driven auditing.',
  'Inappropriate design and deployment of machine learning (ML) systems lead to negative downstream social and ethical impacts – described here as social and ethical risks – for users, society, and the environment. Despite the growing need to regulate ML systems, current processes for assessing and mitigating risks are disjointed and inconsistent. We interviewed 30 industry practitioners on their current social and ethical risk management practices and collected their first reactions on adapting safety engineering frameworks into their practice – namely, System Theoretic Process Analysis (STPA) and Failure Mode and Effects Analysis (FMEA). Our findings suggest STPA/FMEA can provide an appropriate structure for social and ethical risk assessment and mitigation processes. However, we also find nontrivial challenges in integrating such frameworks in the fast-paced culture of the ML industry. We call on the CHI community to strengthen existing frameworks and assess their efficacy, ensuring that ML systems are safer for all people.',
  'Recent research claims that information cues and system attributes of algorithmic decision-making processes affect decision subjects’ fairness perceptions. However, little is still known about how these factors interact. This paper presents a user study (N = 267) investigating the individual and combined effects of explanations, human oversight, and contestability on informational and procedural fairness perceptions for high- and low-stakes decisions in a loan approval scenario. We find that explanations and contestability contribute to informational and procedural fairness perceptions, respectively, but we find no evidence for an effect of human oversight. Our results further show that both informational and procedural fairness perceptions contribute positively to overall fairness perceptions but we do not find an interaction effect between them. A qualitative analysis exposes tensions between information overload and understanding, human involvement and timely decision-making, and accounting for personal circumstances while maintaining procedural consistency. Our results have important design implications for algorithmic decision-making processes that meet decision subjects’ standards of justice.',
  'The use of algorithms for decision-making in higher education is steadily growing, promising cost-savings to institutions and personalized service for students but also raising ethical challenges around surveillance, fairness, and interpretation of data. To address the lack of systematic understanding of how these algorithms are currently designed, we reviewed an extensive corpus of papers proposing algorithms for decision-making in higher education. We categorized them based on input data, computational method, and target outcome, and then investigated the interrelations of these factors with the application of human-centered lenses: theoretical, participatory, or speculative design. We found that the models are trending towards deep learning, and increased use of student personal data and protected attributes, with the target scope expanding towards automated decisions. However, despite the associated decrease in interpretability and explainability, current development predominantly fails to incorporate human-centered lenses. We discuss the challenges with these trends and advocate for a human-centered approach.',
  'We are witnessing an emergence in Passive Sensing enabled AI (PSAI) to provide dynamic insights for performance and wellbeing of information workers. Hybrid work paradigms have simultaneously created new opportunities for PSAI, but have also fostered anxieties of misuse and privacy intrusions within a power asymmetry. At this juncture, it is unclear if those who are sensed can find these systems acceptable. We conducted scenario-based interviews of 28 information workers to highlight their perspectives as data subjects in PSAI. We unpack their expectations using the Contextual Integrity framework of privacy and information gathering. Participants described appropriateness of PSAI based on its impact on job consequences, work-life boundaries, and preservation of flexibility. They perceived that PSAI inferences could be shared with selected stakeholders if they could negotiate the algorithmic inferences. Our findings help envision worker-centric approaches to implementing PSAI as an empowering tool in the future of work.',
  'Artificial intelligence (AI) systems can cause harm to people. This research examines how individuals react to such harm through the lens of blame. Building upon research suggesting that people blame AI systems, we investigated how several factors influence people’s reactive attitudes towards machines, designers, and users. The results of three studies (N = 1,153) indicate differences in how blame is attributed to these actors. Whether AI systems were explainable did not impact blame directed at them, their developers, and their users. Considerations about fairness and harmfulness increased blame towards designers and users but had little to no effect on judgments of AI systems. Instead, what determined people’s reactive attitudes towards machines was whether people thought blaming them would be a suitable response to algorithmic harm. We discuss implications, such as how future decisions about including AI systems in the social and moral spheres will shape laypeople’s reactions to AI-caused harm.',
  'Algorithmic systems have infiltrated many aspects of our society, mundane to high-stakes, and can lead to algorithmic harms known as representational and allocative. In this paper, we consider what stigma theory illuminates about mechanisms leading to algorithmic harms in algorithmic assemblages. We apply the four stigma elements (i.e., labeling, stereotyping, separation, status loss/discrimination) outlined in sociological stigma theories to algorithmic assemblages in two contexts : 1) "risk prediction" algorithms in higher education, and 2) suicidal expression and ideation detection on social media. We contribute the novel theoretical conceptualization of algorithmic stigmatization as a sociotechnical mechanism that leads to a unique kind of algorithmic harm: algorithmic stigma. Theorizing algorithmic stigmatization aids in identifying theoretically-driven points of intervention to mitigate and/or repair algorithmic stigma. While prior theorizations reveal how stigma governs socially and spatially, this work illustrates how stigma governs sociotechnically.', 
  'Recent years have seen growing interest among both researchers and practitioners in user-engaged approaches to algorithm auditing, which directly engage users in detecting problematic behaviors in algorithmic systems. However, we know little about industry practitioners’ current practices and challenges around user-engaged auditing, nor what opportunities exist for them to better leverage such approaches in practice. To investigate, we conducted a series of interviews and iterative co-design activities with practitioners who employ user-engaged auditing approaches in their work. Our findings reveal several challenges practitioners face in appropriately recruiting and incentivizing user auditors, scaffolding user audits, and deriving actionable insights from user-engaged audit reports. Furthermore, practitioners shared organizational obstacles to user-engaged auditing, surfacing a complex relationship between practitioners and user auditors. Based on these findings, we discuss opportunities for future HCI research to help realize the potential (and mitigate risks) of user-engaged auditing in industry practice.',
  'Homelessness presents a long-standing problem worldwide. Like other welfare services, homeless services have gained increased traction in Machine Learning (ML) research. Unhoused persons are vulnerable and using their data in the ML pipeline raises serious concerns about the unintended harms and consequences of prioritizing different ML values. To address this, we conducted a critical analysis of 40 research papers identified through a systematic literature review in ML homelessness service provision research. We found that the values of novelty, performance, and identifying limitations were uplifted in these papers, whereas (in)efficiency, (low/high) cost, fast, (violated) privacy, and (homeless condition) reproducibility valuescollapse. Consequently, unhoused persons were lost (i.e., humans were deprioritized) at multi-level ML abstraction of predictors, categories, and algorithms. Our findings illuminate potential pathways forward at the intersection of data science, HCI and STS by situating humans at the center to support this vulnerable community.',       
  'The consumption of music is increasingly reliant on the personalisation, recommendation, and automated curation features of music streaming services. Using algorithm experience (AX) as a lens, we investigated the user experience of the algorithmic recommendation and automated curation features of several popular music streaming services. We conducted interviews and participant-observation with 15 daily users of music streaming services, followed by a design workshop. We found that despite the utility of increasingly algorithmic personalisation, listeners experienced these algorithmic and recommendation features as impersonal in determining their background listening, music discovery, and playlist curation. While listener desire for more control over recommendation settings is not new, we offer a number of novel insights about music listening to nuance this understanding, particularly through the notion of vibe.',
  'Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.',
  'Social media platforms are a place where people look for information and social support for mental health, resulting in both positive and negative effects on users. TikTok has gained notoriety for an abundance of mental health content and discourse. We present findings from a semi-structured interview study with 16 participants about mental health content and participants’ perceptions of community on TikTok. We find that TikTok’s community structure is permeable, allowing for self-discovery and understanding not found in traditional online communities. However, participants are wary of mental health information due to conflicts between a creator’s vulnerability and credibility. Our interviews suggest that the “For You Page" is a runaway train that encourages diverse community and content engagement but also displays harmful content that participants feel they cannot escape. We propose design implications to support better mental health, as well as implications for social computing research on community in algorithmic landscapes.',
  'Personalized recommender systems suffuse modern life, shaping what media we read and what products we consume. Algorithms powering such systems tend to consist of supervised-learning-based heuristics, such as latent factor models with a variety of heuristically chosen prediction targets. Meanwhile, theoretical treatments of recommendation frequently address the decision-theoretic nature of the problem, including the need to balance exploration and exploitation, via the multi-armed bandits (MABs) framework. However, MAB-based approaches rely heavily on assumptions about human preferences. These preference assumptions are seldom tested using human subject studies, partly due to the lack of publicly available toolkits to conduct such studies. In this work, we conduct a study with crowdworkers in a comics recommendation MABs setting. Each arm represents a comic category, and users provide feedback after each recommendation. We check the validity of core MABs assumptions—that human preferences (reward distributions) are fixed over time—and find that they do not hold. This finding suggests that any MAB algorithm used for recommender systems should account for human preference dynamics. While answering these questions, we provide a flexible experimental framework for understanding human preference dynamics and testing MABs algorithms with human users. The code for our experimental framework and the collected data can be found at https://github.com/HumainLab/human-bandit-evaluation.',        
  'This work explores how users navigate the opaque and ever-changing algorithmic processes that dictate visibility on Instagram through the lens of Attachment Theory. We conducted thematic analysis on 1,100 posts and comments on r/Instagram to understand how users engage in collective sensemaking with regards to Instagram’s algorithms, user-perceived punishments, and strategies to counteract algorithmic precarity. We found that the unpredictability in how Instagram rewards or punishes a user can lead to distress, hypervigilance, and a need to appease “the algorithm’’. We therefore frame these findings through Attachment Theory, drawing upon the metaphor of Instagram as an unreliable paternalistic figure that inconsistently rewards users [74]. User experiences are then contextualized through the lens of anxious, avoidant, disorganized, and secure attachment. We conclude by making suggestions for fostering secure attachment towards the Instagram algorithm, by suggesting potential strategies to help users successfully cope with uncertainty.',
  'In many creator economy platforms, algorithms significantly impact creators’ practices and decisions about their creative expression and monetization. Emerging research suggests that the opacity of the algorithm and platform policies often distract creators from their creative endeavors. To study how algorithmic platforms can be more ‘creator-friendly,’ we conducted a mixed-methods study: interviews (N=14) and a participatory design workshop (N=12) with YouTube creators. Through the interviews, we found how creators’ folk theories of the curation algorithm impact their work strategies — whether they choose to work with or against the algorithm — and the associated challenges in the process. In the workshop, creators explored solution ideas to overcome the aforementioned challenges, such as fostering diverse and creative expressions, achieving success as a creator, and motivating creators to continue their job. Based on these findings, we discuss design opportunities for how algorithmic platforms can support and motivate creators to sustain their creative work.',
  'Recent years have witnessed an interesting phenomenon in which users come together to interrogate potentially harmful algorithmic behaviors they encounter in their everyday lives. Researchers have started to develop theoretical and empirical understandings of these user-driven audits, with a hope to harness the power of users in detecting harmful machine behaviors. However, little is known about users’ participation and their division of labor in these audits, which are essential to support these collective efforts in the future. Through collecting and analyzing 17,984 tweets from four recent cases of user-driven audits, we shed light on patterns of users’ participation and engagement, especially with the top contributors in each case. We also identified the various roles users’ generated content played in these audits, including hypothesizing, data collection, amplification, contextualization, and escalation. We discuss implications for designing tools to support user-driven audits and users who labor to raise awareness of algorithm bias.',
  'Emerging methods for participatory algorithm design have proposed collecting and aggregating individual stakeholders’ preferences to create algorithmic systems that account for those stakeholders’ values. Drawing on two years of research across two public school districts in the United States, we study how families and school districts use students’ preferences for schools to meet their goals in the context of algorithmic student assignment systems. We find that the design of the preference language, i.e. the structure in which participants must express their needs and goals to the decision-maker, shapes the opportunities for meaningful participation. We define three properties of preference languages – expressiveness, cost, and collectivism – and discuss how these factors shape who is able to participate, and the extent to which they are able to effectively communicate their needs to the decision-maker. Reflecting on these findings, we offer implications and paths forward for researchers and practitioners who are considering applying a preference-based model for participation in algorithmic decision making.',
  'Multiplayer digital games can use aim assistance to help people with different levels of aiming ability to play together.',
  'Despite the proliferation of research on how people engage with and experience algorithmic systems, the materiality and physicality of these experiences is often overlooked. We tend to forget about bodies. The Embodying the Algorithm1 project worked with artists to explore the experience of translating algorithmically produced performance instructions through human bodies. As performers interpreted the rules of engagement produced by GPT-3, they struggled with the lack of consideration the rules showed for the limits of the human body. Performers made sense of their experience through personification, reflexivity, and interpretation, which gave rise to three modes of relating with the algorithm – agonistic, perfunctory, and agreeable. We demonstrate that collaboration with algorithmic systems is ultimately impossible as people can only relate to algorithmic systems (a one-way relation) due to the material limitations of algorithmic systems for reciprocity, understanding, and consideration for the human body.',
  'Algorithm aversion occurs when humans are reluctant to use algorithms despite their superior performance. Studies show that giving users outcome control by providing agency over how models’ predictions are incorporated into decision-making mitigates algorithm aversion. We study whether algorithm aversion is mitigated by process control, wherein users can decide what input factors and algorithms to use in model training. We conduct a replication study of outcome control, and test novel process control study conditions on Amazon Mechanical Turk (MTurk) and Prolific. Our results partly confirm prior findings on the mitigating effects of outcome control, while also forefronting reproducibility challenges. We find that process control in the form of choosing the training algorithm mitigates algorithm aversion, but changing inputs does not. Furthermore, giving users both outcome and process control does not reduce algorithm aversion more than outcome or process control alone. This study contributes to design considerations around mitigating algorithm aversion.',     
  'Machine learning (ML) recourse techniques are increasingly used in high-stakes domains, providing end users with actions to alter ML predictions, but they assume ML developers understand what input variables can be changed. However, a recourse plan’s actionability is subjective and unlikely to match developers’ expectations completely. We present GAM Coach, a novel open-source system that adapts integer linear programming to generate customizable counterfactual explanations for Generalized Additive Models (GAMs), and leverages interactive visualizations to enable end users to iteratively generate recourse plans meeting their needs. A quantitative user study with 41 participants shows our tool is usable and useful, and users prefer personalized recourse plans over generic plans. Through a log analysis, we explore how users discover satisfactory recourse plans, and provide empirical evidence that transparency can lead to more opportunities for everyday users to discover counterintuitive patterns in ML models. GAM Coach is available at: https://poloclub.github.io/gam-coach/.',
  'Risk assessment algorithms are being adopted by public sector agencies to make high-stakes decisions about human lives. Algorithms model “risk” based on individual client characteristics to identify clients most in need. However, this understanding of risk is primarily based on easily quantifiable risk factors that present an incomplete and biased perspective of clients. We conducted a computational narrative analysis of child-welfare casenotes and draw attention to deeper systemic risk factors that are hard to quantify but directly impact families and street-level decision-making. We found that beyond individual risk factors, the system itself poses a significant amount of risk where parents are over-surveilled by caseworkers and lack agency in decision-making processes. We also problematize the notion of risk as a static construct by highlighting the temporality and mediating effects of different risk, protective, systemic, and procedural factors. Finally, we draw caution against using casenotes in NLP-based systems by unpacking their limitations and biases embedded within them.',
  'No abstract available.',
  'Mobile eye tracking traditionally requires gaze to be coded manually. We introduce an open-source Python package (GazeClassify) that algorithmically annotates mobile eye tracking data for the study of human interactions. Instead of manually identifying objects and identifying if gaze is directed towards an area of interest, computer vision algorithms are used for the identification and segmentation of human bodies. To validate the algorithm, mobile eye tracking data from short combat sport sequences were analyzed. The performance of the algorithm was compared against three manual raters. The algorithm performed with substantial reliability in comparison to the manual raters when it came to annotating which area of interest gaze was closest to. However, the algorithm was more conservative than the manual raters for classifying if gaze was directed towards an object of interest. The algorithmic approach represents a viable and promising means for automating gaze classification for mobile eye tracking.',
  'Eye-tracking is a key sensing technology for upcoming retinal projection augmented reality (AR) glasses. State-of-the-art eye-tracking sensor technologies rely on video oculography (VOG) and 3D model based gaze estimation algorithms, which infer gaze from observations of the projected pupil over time. The convergence time of these algorithms relies heavily on the pupil ellipse fitting accuracy. In this work, we investigate the effects of pupil ellipse contour noise and pupil center noise on the convergence time of a state-of-the-art eye-tracking approach and show that the convergence time relies heavily on a sub-pixel accurate pupil ellipse fitting and can reach tens of seconds for inaccurately fitted ellipses.'
]
    
    # wine 검색 결과
    input_data2 = [
'This paper reviews how empirical research on User Experience (UX) is conducted. It integrates products, dimensions of experience, and methodologies across a systematically selected sample of 51 publications from 2005-2009, reporting a total of 66 empirical studies. Results show a shift in the products and use contexts that are studied, from work towards leisure, from controlled tasks towards open use situations, and from desktop computing towards consumer products and art. Context of use and anticipated use, often named key factors of UX, are rarely researched. Emotions, enjoyment and aesthetics are the most frequently assessed dimensions. The methodologies used are mostly qualitative, and known from traditional usability studies, though constructive methods with unclear validity are being developed and used. Many studies use self-developed questionnaires without providing items or statistical validations. We discuss underexplored research questions and potential improvements of UX research.',
'The digital codification and measurement of food preparation has made strong contributions to HCI food research, whether through ingredient manipulation, workflow management, or recipe interaction. But prior work has shown that technical developments that emphasize precise gourmet practices tend to overlook the importance of cultural knowledge. Drawing on an integrative autobiographical design approach, we describe an open-source hardware toolkit that we developed to examine the process of integrating precision techniques with ritual cooking practices across three recipes: flour skin, rice wine, and doufu. Our work points to the importance of understanding precision as a cultural process with roots in personal and familial experience. We end with a reflection on the particular knowledge-forms that come from cultivating cultural relationships to fabrication processes and their implications for reading digital fabrication processes as meaningfully relational.'
]
    # uncetainty 검색 결과
    input_data3 = [
  'Ambiguity is usually considered anathema in Human Computer Interaction. We argue, in contrast, that it is a resource for design that can be used to encourage close personal engagement with systems. We illustrate this with examples from contemporary arts and design practice, and distinguish three broad classes of ambiguity according to where uncertainty is located in the interpretative relationship linking person and artefact. Ambiguity of information finds its source in the artefact itself, ambiguity of context in the sociocultural discourses that are used to interpret it, and ambiguity of relationship in the interpretative and evaluative stance of the individual. For each of these categories, we describe tactics for emphasising ambiguity that may help designers and other practitioners understand and craft its use.',
  "This paper presents the design, implementation and validation of an enhanced mobile phone messaging system (DeDe), allowing the sender to define the context in which the message will be delivered to the recipient. A field trial among a socially tight group of teenagers showed that the DeDe feature was incorporated as part of the participants' existing messaging culture. 11,4% of their total messaging output made use of the DeDe feature. The most frequently used context parameters were location (based on network cell-ID) and time. Novel message practices emerged, as compared to 'normal' messaging, both in terms of timing of message sending, as well as creating content that specifically exploited the DeDe feature. Some use barriers were recognized, the most important being the sender's uncertainty of delivery success. Implications for design are discussed.",
  'Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues.',
  'We describe a particle filtering approach to inferring finger movements on capacitive sensing arrays. This technique allows the efficient combination of human movement models with accurate sensing models, and gives high-fidelity results with low-resolution sensor grids and tracks finger height. Our model provides uncertainty estimates, which can be linked to the interaction to provide appropriately smoothed responses as sensing perfomance degrades; system autonomy is increased as estimates of user behaviour become less certain. We demonstrate the particle filter approach with a map browser running with a very small sensor board, where finger position uncertainty is linked to autonomy handover.',
  'This study investigates user ideas about the role and value of tags in social media. An analysis of 45 interviews with heavy Web users reveals that user perceptions of tags differ from common assumptions held by researchers and designers of social tagging systems. Among beliefs held by participants were that tags were query suggestions or links to other pages, sites, or advertisements - although most identified tags as categories or keywords - and that tags were generated automatically by the computer system. Several participants believed that tags were intended for not only other users but also systems such as search engines. Our findings indicate that Web users, including those who are taggers themselves, experience a high level of uncertainty and confusion about the nature, purpose and value of tags.',
  'We present a finger-tracking system for touch-based interaction which can track 3D finger angle in addition to position, using low-resolution conventional capacitive sensors, therefore compensating for the inaccuracy due to pose variation in conventional touch systems. Probabilistic inference about the pose of the finger is carried out in real-time using a particle filter; this results in an efficient and robust pose estimator which also gives appropriate uncertainty estimates. We show empirically that tracking the full pose of the finger results in greater accuracy in pointing tasks with small targets than competitive techniques. Our model can detect and cope with different finger sizes and the use of either fingers or thumbs, bringing a significant potential for improvement in one-handed interaction with touch devices. In addition to the gain in accuracy we also give examples of how this technique could open up the space of novel interactions.',
  "The quantity of email people receive each day can be overwhelming. Previous research suggests that when handling email, individuals prioritize certain messages for attention over others. Since people generally make this decision about which message to read before opening the email, the question largely unanswered in the email literature is: what surface features of an email draw attention to it? In this research, we examined how top-level cues about an email's content influence attention to email. We describe results from a think-aloud study examining people's stated rationale for prioritizing certain emails over others. Based on these results and theory on curiosity, we conducted an experiment examining how message importance, subject line specificity, workload and personal utility influence attention to email. Results suggest that uncertainty about message content at the inbox level increases the likelihood of attention to a message. The influence of uncertainty diminishes, however, in the face of enhanced task and personal utility cues and increased demand, suggesting that curiosity operates in an intrinsic way in the email context. Our results have implications for intelligent email system design, email client interfaces, and reducing email strain.",
  'We often use datasets that reflect samples, but many visualization tools treat data as full populations. Uncertain visualizations are good at representing data distributions emerging from samples, but are more limited in allowing users to carry out decision tasks. This is because tasks that are simple on a traditional chart (e.g. "compare two bars") become a complex probabilistic task on a chart with uncertainty. We present guidelines for creating visual annotations for solving tasks with uncertainty, and an implementation that addresses five core tasks on a bar chart. A preliminary user study shows promising results: that users have a justified confidence in their answers with our system.',
  "Social media use is widespread, but many people worry about overuse. This paper explores how and why people take breaks from social media. Using a mixed methods approach, we pair data from users who tweeted about giving up Twitter for Lent with an interview study of social media users. We find that 64% of users who proclaim that they are giving up Twitter for Lent successfully do so. Among those who fail, 31% acknowledge their failure; the other 69 simply return. We observe hedging patterns (e.g. 'I thought about giving up Twitter for Lent but'?) that surfaced uncertainty about social media behavior. Interview participants were concerned about the tradeoffs of spending time on social media versus doing other things and of spending time on social media rather than in 'real life.'We discuss gaps in related theory that might help reduce users' anxieties and open design problems related to designing systems and services that can help users manage their own social media use.",
  'This work reports on the design and evaluation of culturally appropriate technology for older adults. Our design context was Cognitive Testing on a Computer (C-TOC): a self-administered computerized test under development, intended to screen older adults for cognitive impairments. Using theory triangulation of cultural attitudes toward uncertainty, we designed two interfaces (one minimal and one rich) for one C-TOC subtest and hypothesized they would be culturally appropriate for older adult Caucasians and East Asians respectively. We ran an experiment with 36 participants to investigate cultural differences in performance, preference and anxiety. We found that Caucasians preferred the interface with minimal elements (i.e. those essential for the primary task) or had no preference. By contrast, East Asians preferred the rich interface augmented with security and learning support and felt less anxious with it than the minimal.',
  'Users often struggle to enter text accurately on touchscreen keyboards. To address this, we present a flexible decoder for touchscreen text entry that combines probabilistic touch models with a language model. We investigate two different touch models. The first touch model is based on a Gaussian Process regression approach and implicitly models the inherent uncertainty of the touching process. The second touch model allows users to explicitly control the uncertainty via touch pressure. Using the first model we show that the character error rate can be reduced by up to 7% over a baseline method, and by up to 1.3% over a leading commercial keyboard. Using the second model we demonstrate that providing users with control over input certainty reduces the amount of text users have to correct manually and increases the text entry rate.',
  'Many HCI and ubiquitous computing systems are characterized by two important properties: their output is uncertain-it has an associated accuracy that researchers attempt to optimize-and this uncertainty is user-facing-it directly affects the quality of the user experience. Novel classifiers are typically evaluated using measures like the F1 score-but given an F-score of (e.g.) 0.85, how do we know whether this performance is good enough? Is this level of uncertainty actually tolerable to users of the intended application-and do people weight precision and recall equally? We set out to develop a survey instrument that can systematically answer such questions. We introduce a new measure, acceptability of accuracy, and show how to predict it based on measures of classifier accuracy. Out tool allows us to systematically select an objective function to optimize during classifier evaluation, but can also offer new insights into how to design feedback for user-facing classification systems (e.g., by combining a seemingly-low-performing classifier with appropriate feedback to make a highly usable system). It also reveals potential issues with the ubiquitous F1-measure as applied to user-facing systems.',
  'Increasingly natural, sensed, and touch-based input is being integrated into devices. Along the way, both custom and more general solutions have been developed for dealing with the uncertainty that is associated with these forms of input. However, it is difficult to provide dynamic, flexible, and continuous feedback about uncertainty using traditional interactive infrastructure. Our contribution is a general architecture with the goal of providing support for continual feedback about uncertainty. Our architecture is based on prior work in modeling uncertainty using Monte Carlo sampling, and tracks multiple interfaces -- one for each plausible and differentiable sequence of input that the user may have intended. Importantly, it considers how the presentation of uncertainty can be organized and implemented in a general way. Our primary contribution is a method for reducing the number of alternative interfaces and fusing possible interfaces into a single interface that both communicates uncertainty and allows for disambiguation. We demonstrate the value of this result through a collection of 11 new and existing feedback techniques along with two applications demonstrating the use of the feedback architecture.',
  "Command and control environments ranging from transport control rooms to disaster response have long been of interest to HCI and CSCW as rich sites of interactive technology use embedded in work practice. Drawing on our engagement with disaster response teams, including ethnography of their training work, we unpack the ways in which situational uncertainty is managed while a shared operational 'picture' is constituted through various practices around tabletop work. Our analysis reveals how this picture is collaboratively assembled as a socially shared object and displayed by drawing on digital and physical resources. Accordingly, we provide a range of principles implicated by our study that guide the design of systems augmenting and enriching disaster response work practices. In turn, we propose the Augmented Bird Table to illustrate how our principles can be implemented to support tabletop work.",
  'Rumors are regular features of crisis events due to the extreme uncertainty and lack of information that often characterizes these settings. Despite recent research that explores rumoring during crisis events on social media platforms, limited work has focused explicitly on how individuals and groups express uncertainty. Here we develop and apply a flexible typology for types of expressed uncertainty. By applying our framework across six rumors from two crisis events we demonstrate the role of uncertainty in the collective sensemaking process that occurs during crisis events.',
  "The increase in the availability of personal genomic data to lay consumers using online services poses a challenge to HCI researchers: such data are complex and sensitive, involve multiple dimensions of uncertainty, and can have substantial implications for individuals' well-being. Personal genomic data are also unique because unlike other personal data, which constantly change, genomic data are largely stable during a person's lifetime; it is their interpretation and implications that change over time as new medical research exposes relationships between genes and health. In this paper, we present a novel tool for self exploration of personal genomic data. To evaluate the usability and utility of the tool, we conducted the first study of a genome interpretation tool to date, in which users used their own personal genomic data. We conclude by offering design implications for the development of interactive personal genomic reports.",
  'We examine how financial assurance structures and the clearly defined financial transaction at the core of monetized network hospitality reduce uncertainty for Airbnb hosts and guests. We apply the principles of social exchange and intrinsic and extrinsic motivation to a qualitative study of Airbnb hosts to 1) describe activities that are facilitated by the peer-to-peer exchange platform and 2) how the assurance of the initial financial exchange facilitates additional social exchanges between hosts and guests. The study illustrates that the financial benefits of hosting do not necessarily crowd out intrinsic motivations for hosting but instead strengthen them and even act as a gateway to further social exchange and interpersonal interaction. We describe the assurance structures in networked peer-to-peer exchange, and explain how such assurances can reconcile contention between extrinsic and intrinsic motivations. We conclude with implications for design and future research.',
  "This paper contributes to the growing literature on peer-to-peer (P2P) applications through an ethnographic study of auto-rickshaw drivers in Bengaluru, India. We describe how the adoption of a P2P application, Ola, which connects passengers to rickshaws, changes drivers work practices. Ola is part of the 'peer services' phenomenon which enable new types of ad-hoc trade in labour, skills and goods. Auto-rickshaw drivers present an interesting case because prior to Ola few had used Smartphones or the Internet. Furthermore, as financially vulnerable workers in the informal sector, concerns about driver welfare become prominent. Whilst technologies may promise to improve livelihoods, they do not necessarily deliver [57]. We describe how Ola does little to change the uncertainty which characterizes an auto drivers' day. This leads us to consider how a more equitable and inclusive system might be designed.",
  'Users often rely on realtime predictions in everyday contexts like riding the bus, but may not grasp that such predictions are subject to uncertainty. Existing uncertainty visualizations may not align with user needs or how they naturally reason about probability. We present a novel mobile interface design and visualization of uncertainty for transit predictions on mobile phones based on discrete outcomes. To develop it, we identified domain specific design requirements for visualizing uncertainty in transit prediction through: 1) a literature review, 2) a large survey of users of a popular realtime transit application, and 3) an iterative design process. We present several candidate visualizations of uncertainty for realtime transit predictions in a mobile context, and we propose a novel discrete representation of continuous outcomes designed for small screens, quantile dotplots. In a controlled experiment we find that quantile dotplots reduce the variance of probabilistic estimates by ~1.15 times compared to density plots and facilitate more confident estimation by end-users in the context of realtime transit prediction scenarios.',
  'We propose using eye tracking to support interface use with decreased reliance on visual guidance. While the design of most graphical user interfaces take visual guidance during manual input for granted, eye tracking allows distinguishing between the cases when the manual input is conducted with or without guidance. We conceptualize the latter cases as input with uncertainty that require separate handling. We describe the design space of input handling by utilizing input resources available to the system, possible actions the system can realize and various feedback techniques for informing the user. We demonstrate the particular action mechanisms and feedback techniques through three applications we developed for touch interaction on a large screen. We conducted a two stage study of positional accuracy during target acquisition with varying visual guidance, to determine the selection range around a touch point due to positional uncertainty. We also conducted a qualitative evaluation of example applications with participants to identify perceived utility and hand eye coordination challenges while using interfaces with decreased visual guidance.',
  "RFID tags can be used to add inexpensive, wireless, batteryless sensing to objects. However, quickly and accurately estimating the state of an RFID tag is difficult. In this work, we show how to achieve low-latency manipulation and movement sensing with off-the-shelf RFID tags and readers. Our approach couples a probabilistic filtering layer with a monte-carlo-sampling-based interaction layer, preserving uncertainty in tag reads until they can be resolved in the context of interactions. This allows designers' code to reason about inputs at a high level. We demonstrate the effectiveness of our approach with a number of interactive objects, along with a library of components that can be combined to make new designs.",
  '"Remind me to get milk later this afternoon." In communications and planning, people often express uncertainty about time using imprecise temporal expressions (ITEs). Unfortunately, modern virtual assistants often lack system support to capture the intents behind these expressions. This can result in unnatural interactions and undesirable interruptions (e.g., having a work reminder delivered at 12pm when out at lunch, because the user said "this afternoon"). In this paper we explore existing practices, expectations, and preferences surrounding the use of ITEs. Our mixed methods approach employs surveys, interviews, and an analysis of a large corpus of written communications. We find that people frequently use a diverse set of ITEs in both communication and planning. These uses reflect a variety of motivations, such as conveying uncertainty or task priority. In addition, we find that people have a variety of expectations about time input and management when interacting with virtual assistants. We conclude with design implications for future virtual assistants.',
  "We often base our decisions on uncertain data - for instance, when consulting the weather forecast before deciding what to wear. Due to their uncertainty, such forecasts can differ by provider. To make an informed decision, many people compare several forecasts, which is a time-consuming and cumbersome task. To facilitate comparison, we identified three aggregation mechanisms for forecasts: manual comparison and two mechanisms of computational aggregation. In a survey, we compared the mechanisms using different representations. We then developed a weather application to evaluate the most promising candidates in a real-world study. Our results show that aggregation increases users' confidence in uncertain data, independent of the type of representation. Further, we find that for daily events, users prefer to use computationally aggregated forecasts. However, for high-stakes events, they prefer manual comparison. We discuss how our findings inform the design of improved interfaces for comparison of uncertain data, including non-weather purposes.",
  'An important problem for HCI researchers is to estimate the parameter values of a cognitive model from behavioral data. This is a difficult problem, because of the substantial complexity and variety in human behavioral strategies. We report an investigation into a new approach using approximate Bayesian computation (ABC) to condition model parameters to data and prior knowledge. As the case study we examine menu interaction, where we have click time data only to infer a cognitive model that implements a search behaviour with parameters such as fixation duration and recall probability. Our results demonstrate that ABC (i) improves estimates of model parameter values, (ii) enables meaningful comparisons between model variants, and (iii) supports fitting models to individual users. ABC provides ample opportunities for theoretical HCI research by allowing principled inference of model parameter values and their uncertainty.',
  "This paper reports on two years of ethnographic observation of the science and politics of flood risk in Colorado, as well as design research that examines citizen interaction with expert knowledge about flooding in the region. We argue that the 100-year floodplain standard that inform maps produced by the USA Federal Emergency Management Agency (FEMA)'s National Floodplain Insurance Program (NFIP) represent a problematic form of discursive closure of scientific understanding of flood hazard. We show that in order to meet the requirements of the NFIP, this standard acts as a closure that conveys a certainty that the underlying science does not warrant and foreshortens dialogue on disaster risk and public understanding of flood hazard. Engaging with literature in science and technology studies and human-centered computing, we investigate design opportunities for resisting closure and supporting public formation through encounters with the uncertainty and complexities of risk information.",
  'Uncertainty plays an important and complex role in data analysis, where the goal is to find pertinent patterns, build robust models, and support decision making. While these endeavours are often associated with professional data scientists, many domain experts engage in such activities with varying skill levels. To understand how these domain experts (or "data workers") analyse uncertain data we conducted a qualitative user study with 12 participants from a variety of domains. In this paper, we describe their various coping strategies to understand, minmise, exploit or even ignore this uncertainty. The choice of the coping strategy is influenced by accepted domain practices, but appears to depend on the types and sources of uncertainty and whether participants have access to support tools. Based on these findings, we propose a new process model of how data workers analyse various types of uncertain data and conclude with design considerations for uncertainty-aware data analytics.',
  'Recently, diseases like H1N1 influenza, Ebola, and Zika virus have created severe crises, requiring public resources and personal behavior adaptation. Crisis Informatics literature examines interconnections of people, organizations, and IT during crisis events. However, how people use technology to cope with disease crises (outbreaks, epidemics, and pandemics) remains understudied. We investigate how individuals used social media in response to the outbreak of Zika, focusing on travel-related decisions. We found that extreme uncertainty and ambiguity characterized the Zika virus crisis. To cope, people turned to social media for information gathering and social learning geared towards personal risk assessment and modifying decisions when dealing with partial and conflicting information about Zika. In particular, individuals sought local information and used socially informed logical reasoning to deduce the risk at a specific locale. We conclude with implications for designing information systems to support individual risk assessment and decision-making when faced with uncertainty and ambiguity during public health crises.',
  "We present the results of a design case study focusing on supporting the daily transportation of elderly in Germany. We conceptualized, developed and studied the appropriation of a transportation information system intended to ease switching between different transportation modes. Based on a literature review and a context study with 21 interviews we explored routinized transport mode usage and barriers when switching between modes. Iteratively, we co-designed a transport platform accessible via a website, a mobile app, and an iTV app. We further looked at the appropriation of the platform into the daily lives of 19 persons. Studying the appropriation highlighted different factors that facilitate the adoption of alternative transport options. The factors included reducing uncertainty, complementing transport information with context information (e.g. weather) and providing informational access based on the user's preferences as well as fitting in with the situational needs (activity related).",
  'While the growth of financial technologies (FinTech) is making the flow of money faster, easier, and more secure, such technologies are often unable to serve many countries due to the global political environment. Despite its severe impact, this issue has remained understudied in the HCI literature. We address this gap by presenting our findings from a three-month-long ethnography with the Iranian community in Toronto, Canada. We present their struggles in transferring money to and from their home country - a process that entails financial loss, fear, uncertainty, and privacy breaches. We also outline the informal workarounds that allow this community to circumvent these challenges, along with the associated hassles. This paper contributes to broadening the scope of FinTech in the HCI literature by connecting it with the politics surrounding transnational transactions. We discuss the design implications of our findings and their contribution to the broader interests of HCI in mobilities and social justice.',
  'Design research is important for understanding and interrogating how emerging technologies shape human experience. However, design research with Machine Learning (ML) is relatively underdeveloped. Crucially, designers have not found a grasp on ML uncertainty as a design opportunity rather than an obstacle. The technical literature points to data and model uncertainties as two main properties of ML. Through post-phenomenology, we position uncertainty as one defining material attribute of ML processes which mediate human experience. To understand ML uncertainty as a design material, we investigate four design research case studies involving ML. We derive three provocative concepts: thingly uncertainty: ML-driven artefacts have uncertain, variable relations to their environments; pattern leakage: ML uncertainty can lead to patterns shaping the world they are meant to represent; and futures creep: ML technologies texture human relations to time with uncertainty. Finally, we outline design research trajectories and sketch a post-phenomenological approach to human-ML relations.',
  'Polycystic Ovary Syndrome (PCOS) is a condition that causes hormonal imbalance and infertility in women and people with female reproductive organs. PCOS causes different symptoms for different people, with no singular or universal cure. Being a stigmatized and enigmatic condition, it is challenging to discover, diagnose, and manage PCOS. This work aims to inform the design of inclusive health technologies through an understanding of people’s lived experiences and challenges with PCOS. We conducted semi-structured interviews with 10 women diagnosed with PCOS and analyzed a PCOS-specific subreddit forum. We report people’s support-seeking, sense-making, and self-experimentation practices, and find uncertainty and stigma to be key in shaping their unique experiences of the condition. We further identify potential avenues for designing technology to support their diverse needs, such as personalized and contextual tracking, accelerated self-discovery, and co-management, contributing to a growing body of HCI literature on stigmatized topics in women’s health and well-being.',
  'Two-dimensional canvases are the core components of many digital productivity and creativity tools, with “artboards” containing objects rather than pixels. Unfortunately, the contents of artboards remain largely inaccessible to blind users relying on screen-readers, but the precise problems are not well understood. This study sought to understand how blind screen-reader users interact with artboards. Specifically, we conducted contextual interviews, observations, and task-based usability studies with 15 blind participants to understand their experiences of artboards found in Microsoft PowerPoint, Apple Keynote, and Google Slides. Participants expressed that the inaccessibility of these artboards contributes to significant educational and professional barriers. We found that the key problems faced were: (1) high cognitive loads from a lack of feedback about artboard contents and object state; (2) difficulty determining relationships among artboard objects; and (3) constant uncertainty about whether object manipulations were successful. We offer design remedies that improve feedback for object state, relationships, and manipulations.',
  'Motion correlation interfaces are those that present targets moving in different patterns, which the user can select by matching their motion. In this paper, we re-formulate the task of target selection as a probabilistic inference problem. We demonstrate that previous interaction techniques can be modelled using a Bayesian approach and that how modelling the selection task as transmission of information can help us make explicit the assumptions behind similarity measures. We propose ways of incorporating uncertainty into the decision-making process and demonstrate how the concept of entropy can illuminate the measurement of the quality of a design. We apply these techniques in a case study and suggest guidelines for future work.',
  'Message deletion in mobile messaging apps allows people to “unsay” things they have said. This paper explores how and why people use (or do not use) this feature within remediation strategies after a communication error is identified. We present findings from a multi-stage survey designed to explore people’s general experiences of the message deletion feature (N = 401), peoples’ experiences of using this feature during the remediation of an error (N = 70), and receivers’ perceptions around recent message deletions (N = 68). While people are typically aware of the deletion feature, it is infrequently used. When used, it is primarily done so to improve conversations by reducing confusion between conversation partners. We found people being aware of message deletions creating information-gaps which can provoke curiosity in recipients, causing them to develop narratives to help address the uncertainty. We found concerns amongst senders that these narratives would be of a negative nature, having an undesirable impact on how others perceive them. We use our findings to suggest ways in which mobile messaging apps could improve conversational experiences around erroneous and regrettable messages.',
  'Co-designing with children in an online environment is increasingly important due to external factors, such as the COVID-19 pandemic, and the diversification and inclusion of youth participants. Many prior studies about co-design with youth focus on co-located or asynchronous online sessions. However, conducting synchronous online co-design sessions adds layers of complexity and uncertainty to collaboration. This paper introduces a model explicating factors to consider when co-designing with children synchronously in an online space. We examined ten consecutive intergenerational participatory design sessions online where children (ages 7-11) and adults designed new technologies. Along with highlighting unexpected moments and interactions, we use theories of improvisation to guide our understanding of dynamic situations that are out of the control of researchers. This work contributes to improving theoretical understanding of improvisation as a method of inquiry for co-designing with youth, and offers practical suggestions for suitable online co-design techniques and implementation.',
  'Ranging from subtle to overt, unintentional to systemic, navigating racism is additional everyday work for many people. Yet the needs of people who experience racism have been overlooked as a fertile ground for better technology. Through a series of workshops we call Foundational Fiction, we engaged BIPOC (Black, Indigenous, People of Color) in participatory design to identify qualities of technology that can support people coping before, during, and after a racist interaction. Participants developed storyboards for digital tools that offer advice, predict consequences, identify racist remarks and intervene, educate both targets and perpetrators about interpersonal and systemic racism, and more. In the paper we present our workshop method utilizing interactive fiction, participants’ design concepts, prevalent themes (reducing uncertainty and offering comfort), and we provide critical analysis of the complexity of technology in these contexts. This work identifies specific opportunities for exploring anti-racist social tools.',
  'Uncertainty is widely acknowledged as an engaging gameplay element but rarely used in exergames. In this research, we explore the role of uncertainty in exergames and introduce three uncertain elements (false-attacks, misses, and critical hits) to an exergame. We conducted a study under two conditions (uncertain and certain), with two display types (virtual reality and large display) and across young and middle-aged adults to measure their effect on game performance, experience, and exertion. Results show that (1) our designed uncertain elements are instrumental in increasing exertion levels; (2) when playing a motion-based first-person perspective exergame, virtual reality can improve performance, while maintaining the same motion sickness level as a large display; and (3) exergames for middle-aged adults should be designed with age-related declines in mind, similar to designing for elderly adults. We also framed two design guidelines for exergames that have similar features to the game used in this research.',
  'In recent work, design researchers have sought to ensure that people with disabilities are engaged as competent and valued contributors to co-design. Yet, little is known about how to achieve this with adults with severe intellectual disabilities. Navigating design in the context of complex care practices is challenging, charged with uncertainty, and requires sustained effort of methodological and affective adjustments. To establish a respectful co-design relationship and enrich participation, we turn to Active Support (AS), an evidence-based strategy for engaging adults with severe intellectual disabilities. We present a reflective account of long-term field work that utilized the four aspects of AS, a) every moment has potential; b) graded assistance; c) little and often; d) maximizing choice and control. We discuss how these principles contribute to deepening HCI methods by ensuring interactional turns for adults with severe disabilities, revealing their unique competences, thereby shaping design direction and providing design insight.',
  "Designing technologies that support the mutual cybersecurity and autonomy of older adults facing cognitive challenges requires close collaboration of partners. As part of research to design a Safety Setting application for older adults with memory loss or mild cognitive impairment (MCI), we use a scenario-based participatory design. Our study builds on previous findings that couples’ approach to memory loss was characterized by a desire for flexibility and choice, and an embrace of role uncertainty. We find that couples don't want a system that fundamentally alters their relationship and are looking to maximize self-surveillance competence and minimize loss of autonomy for their partners. All desire Safety Settings to maintain their mutual safety rather than designating one partner as the target of oversight. Couples are open to more rigorous surveillance if they have control over what types of activities trigger various levels of oversight.",
  'During a global pandemic such as COVID-19, laypeople bear a large burden of responsibility for assessing risks associated with COVID-19 and taking action to manage risks in their everyday lives, yet epidemic-related information is characterized by uncertainty and ambiguity. People perceive risks based on partial, changing information. We draw on crisis informatics research to examine the multiple types of risk people perceive in relation to the COVID-19 pandemic, the information sources that inform perceptions of COVID-19 risks, and the challenges that people have in getting the information they need to understand risks, using qualitative interviews with individuals across the United States. Participants describe multiple pandemic-related threats, including illness, secondary health conditions, economic, socio-behavioral, and institutional risks. We further uncover how people draw on multiple information sources from technological infrastructures, people, and spaces to inform the types of their risk perceptions, uncovering deep challenges to acquiring needed risk information.',
  'In this paper we present Immersive Speculative Enactments (ISEs), a novel concept that extends conventional Speculative Enactments to Virtual Reality. Through ISEs, participants are immersed in a speculative world depicted by the designers and can engage with it in its truest envisioned form. We explore this concept via four scenarios with increasing technological uncertainty: a glimpse in the daily life of the parent of a newborn baby; a Mixed Reality experience supporting hybrid classrooms; two wearable devices that present a pet’s emotional state and needs; and an enactment on the effect of communication delay across interplanetary distances. We discuss the concept of ISEs and contrast them to other forms of speculation, provide guidelines on how to design them, as well as reflecting on the challenges, limitations, and potential associated with the role of ISEs in the HCI discourse.',
  'HCI is increasingly concerned with health information quality and spread of misinformation on social media. Despite many major platforms having been adopted across the world, the situated evaluation and sharing of health information is underexplored across diverse health systems and cultural and political contexts. Drawing on semi-structured interviews, we study the navigation of health information on social media in urban and rural South India, backdropped by plural knowledges around health and the specific politics and sociality of health and social media in this setting. We use Ivan Illich’s concept of tools for conviviality [49] to distinguish between how people creatively use tools versus how tools manage and impose values on people—participants aimed to use health information towards care beyond institutionalized healthcare, but insidious misinformation and information-sharing practices served to commodify, spark uncertainty in, and discipline caring behavior. We use our findings to expand understandings of the use of health information on social media and how positionality shapes how people are affected by and respond to misinformation. We also draw attention to the structural aspects of health misinformation in the Indian context and how the design of social media platforms might play a role in addressing it.',
  'During crises like COVID-19, individuals are inundated with conflicting and time-sensitive information that drives a need for rapid assessment of the trustworthiness and reliability of information sources and platforms. This parallels evolutions in information infrastructures, ranging from social media to government data platforms. Distinct from current literature, which presumes a static relationship between the presence or absence of trust and people’s behaviors, our mixed-methods research focuses on situated trust, or trust that is shaped by people’s information-seeking and assessment practices through emerging information platforms (e.g., social media, crowdsourced systems, COVID data platforms). Our findings characterize the shifts in trustee (what/who people trust) from information on social media to the social media platform(s), how distrust manifests skepticism in issues of data discrepancy, the insufficient presentation of uncertainty, and how this trust and distrust shift over time. We highlight the deep challenges in existing information infrastructures that influence trust and distrust formation.',
  'Digital calendars and other technologies for social event planning leave little space to communicate uncertainty regarding time, place or the ability to attend an event. However, narratives of certainty can be detrimental and lead to the marginalisation of those who find it hard to cope with rigid and strictly paced schedules, such as people with health conditions or caring responsibilities. In this paper, we explore uncertainty as the starting point and leading principle behind digital scheduling tools. We present Haze, a speculative tool and user interface, designed to gain insights on participants’ perceptions of uncertainty-based scheduling scenarios. We report on two qualitative studies (total of 21 participants), which indicate that a change in perspective towards uncertainty can challenge moral assumptions around certainty, increase temporal empathy, and indeed support those who are particularly affected by uncertainty. These findings help shift and expand the repertoire of temporality and discuss moral and social responsibilities for design and HCI.',
  'Sustainable Development Goal 4 promotes inclusive and equitable quality education and lifelong learning opportunities for all. However, regions with ongoing socio-political conflict suffer disruption to education and learning. We situate our work in Kashmir, India, affected by socio-political conflict for more than three decades. We did multiple field visits and conducted 21 semi-structured interviews with parents, teachers, students, and members of a non-government organization that runs Community Learning Centers in Kashmir. Our findings present the barriers in education caused by disruption and the role of community learning centers in overcoming the barriers within these contextual constraints. Further, we discuss engaging researchers and policymakers to leverage human infrastructure, embedding uncertainty into the design, infrastructuring trust, and content usability to develop solutions to make education more accessible. Despite significant research in HCI and Education, research in this particular context is under-explored, and our work contributes to filling this gap.',
  'Reducing uncertainty around the nature of racist interactions is one of the key motivations driving individual behaviors for coping with those incidents. However, there are few appropriate technologies to support BIPOC (Black, Indigenous, People of Color) in engaging in social uncertainty reduction around this vulnerable, sensitive topic. This paper reports on an exploratory design study investigating how social technology might facilitate uncertainty reduction through three “provotypes” - provocative prototypes of user-generated speculative design concepts. U.S.-based participants engaged with the provotypes through an interactive fiction to explore their usefulness in the context of a racist microaggression. Results showed that engaging the provotypes through interactive fiction facilitated complex and productive interactions and critiques. This work contributes a novel method for conducting exploratory design, remote user studies using interactive fiction as well as priorities, tensions, and further information what role, if any, technology might play in managing racist interactions.',
  'Gesture elicitation studies are commonly used for designing novel gesture-based interfaces. There is a rich methodology literature on metrics and analysis methods that helps researchers understand and characterize data arising from such studies. However, deriving concrete gesture vocabularies from this data, which is often the ultimate goal, remains largely based on heuristics and ad hoc methods. In this paper, we treat the problem of deriving a gesture vocabulary from gesture elicitation data as a computational optimization problem. We show how to formalize it as an optimal assignment problem and discuss how to express objective functions and custom design constraints through integer programs. In addition, we introduce a set of tools for assessing the uncertainty of optimization outcomes due to random sampling, and for supporting researchers’ decisions on when to stop collecting data from a gesture elicitation study. We evaluate our methods on a large number of simulated studies.',
  'There are myriad ways to analyse a dataset. But which one to trust? In the face of such uncertainty, analysts may adopt multiverse analysis: running all reasonable analyses on the dataset. Yet this is cognitively and technically difficult with existing tools—how does one specify and execute all combinations of reasonable analyses of a dataset?—and often requires discarding existing workflows. We present multiverse, a tool for implementing multiverse analyses in R with expressive syntax supporting existing computational notebook workflows. multiverse supports building up a multiverse through local changes to a single analysis and optimises execution by pruning redundant computations. We evaluate how multiverse supports programming multiverse analyses using (a) principles of cognitive ergonomics to compare with two existing multiverse tools; and (b) case studies based on semi-structured interviews with researchers who have successfully implemented an end-to-end analysis using multiverse. We identify design tradeoffs (e.g. increased flexibility versus learnability), and suggest future directions for multiverse tool design.',
  'Information communication and visualization practices reflect two centuries of developments of conventions and best practices which may not be reflective of global audiences’ methods for conveying information. Contrasting between rural traditional visual culture and contemporary HCI and data-visualization, we argue that an understanding of traditional practices for information visualization is required for building rich data-narratives and making data-driven systems more accessible and culturally situated. Our ten-month ethnographic study investigates how rural Bangladeshi communities construct narratives through visual media. 1 Our observation, interviews, and FGDs (n=54) expose how participants convey risk management, decision-making, and monetary management practices to their peers. We find that villagers used a rich network of polysemic symbols and abstractions to manifest subjectivity, factuality, consequence, situatedness, and uncertainty; varied visual attributes for constructing narratives; and emphasized material relations among components in visuals. These findings inform the design of future systems for decision support in a culturally situated manner.',
  'Data visualizations are vital to scientific communication on critical issues such as public health, climate change, and socioeconomic policy. They are often designed not just to inform, but to persuade people to make consequential decisions (e.g., to get vaccinated). Are such visualizations persuasive, especially when audiences have beliefs and attitudes that the data contradict? In this paper we examine the impact of existing attitudes (e.g., positive or negative attitudes toward COVID-19 vaccination) on changes in beliefs about statistical correlations when viewing scatterplot visualizations with different representations of statistical uncertainty. We find that strong prior attitudes are associated with smaller belief changes when presented with data that contradicts existing views, and that visual uncertainty representations may amplify this effect. Finally, even when participants’ beliefs about correlations shifted their attitudes remained unchanged, highlighting the need for further research on whether data visualizations can drive longer-term changes in views and behavior.',
  'Dying is a universal experience that entails uncertainty, loss, and termination. Often, people face death unprepared and miss out on opportunities to shape their final stage of life as well as their afterlife. To better understand how thanato-technology can support the dying and the bereaved, we performed a scoping review on the current state-of-art in Human Computer Interaction. Following the PRISMA-ScR procedure, we gathered and analyzed 107 relevant papers. We categorized theoretical and conceptual contributions into three overarching themes: digital remains, remembrance, and coping. We further highlight 18 practices, such as curation, honoring and letting go. We show that technology can help to capture the identity of the deceased, to validate the life lived, and to come to terms with death. However, available approaches focus more on the bereaved than on the dying. In addition, potentially important aspects of dying (e.g., balancing involvement and autonomy, spiritual meaning-making) remain largely unexplored.',
  'Scientists often use meta-analysis to characterize the impact of an intervention on some outcome of interest across a body of literature. However, threats to the utility and validity of meta-analytic estimates arise when scientists average over potentially important variations in context like different research designs. Uncertainty about quality and commensurability of evidence casts doubt on results from meta-analysis, yet existing software tools for meta-analysis do not provide an explicit software representation of these concerns. We present MetaExplorer, a prototype system for meta-analysis that we developed using iterative design with meta-analysis experts to provide a guided process for eliciting assessments of uncertainty and reasoning about how to incorporate them during statistical inference. Our qualitative evaluation of MetaExplorer with experienced meta-analysts shows that imposing a structured workflow both elevates the perceived importance of epistemic concerns and presents opportunities for tools to engage users in dialogue around goals and standards for evidence aggregation.',
  'Visualization supports exploratory data analysis (EDA), but EDA frequently presents spurious charts, which can mislead people into drawing unwarranted conclusions. We investigate interventions to prevent false discovery from visualized data. We evaluate whether eliciting analyst beliefs helps guard against the over-interpretation of noisy visualizations. In two experiments, we exposed participants to both spurious and ‘true’ scatterplots, and assessed their ability to infer data-generating models that underlie those samples. Participants who underwent prior belief elicitation made 21% more correct inferences along with 12% fewer false discoveries. This benefit was observed across a variety of sample characteristics, suggesting broad utility to the intervention. However, additional interventions to highlight counterevidence and sample uncertainty did not provide significant advantage. Our findings suggest that lightweight, belief-driven interactions can yield a reliable, if moderate, reduction in false discovery. This work also suggests future directions to improve visual inference and reduce bias.',
  'This work explores how users navigate the opaque and ever-changing algorithmic processes that dictate visibility on Instagram through the lens of Attachment Theory. We conducted thematic analysis on 1,100 posts and comments on r/Instagram to understand how users engage in collective sensemaking with regards to Instagram’s algorithms, user-perceived punishments, and strategies to counteract algorithmic precarity. We found that the unpredictability in how Instagram rewards or punishes a user can lead to distress, hypervigilance, and a need to appease “the algorithm’’. We therefore frame these findings through Attachment Theory, drawing upon the metaphor of Instagram as an unreliable paternalistic figure that inconsistently rewards users [74]. User experiences are then contextualized through the lens of anxious, avoidant, disorganized, and secure attachment. We conclude by making suggestions for fostering secure attachment towards the Instagram algorithm, by suggesting potential strategies to help users successfully cope with uncertainty.',
  'Misconceptions about digital security and privacy topics in the general public frequently lead to insecure behavior. However, little is known about the prevalence and extent of such misconceptions in a global context. In this work, we present the results of the first large-scale survey of a global population on misconceptions: We conducted an online survey with n = 12, 351 participants in 12 countries on four continents. By investigating influencing factors of misconceptions around eight common security and privacy topics (including E2EE, Wi-Fi, VPN, and malware), we find the country of residence to be the strongest estimate for holding misconceptions. We also identify differences between non-Western and Western countries, demonstrating the need for region-specific research on user security knowledge, perceptions, and behavior. While we did not observe many outright misconceptions, we did identify a lack of understanding and uncertainty about several fundamental privacy and security topics.',
  'Initiating conversations with new people at work is often intimidating because of uncertainty about their interests. People worry others may reject their attempts to initiate conversation or that others may not enjoy the conversation. We introduce a new system, Nooks, built on Slack, that reduces fear of social evaluation by enabling individuals to initiate any conversation as a nook—a conversation room that identifies its topic, but not its creator. Automatically convening others interested in the nook, Nooks further reduces fears of social evaluation by guaranteeing individuals in advance that others they are about to interact with are interested in the conversation. In a multi-month deployment with participants in a summer research program, Nooks provided participants with non-threatening and inclusive interaction opportunities, and ambient awareness, leading to new interactions online and offline. Our results demonstrate how intentionally designed social spaces can reduce fears of social evaluation and catalyze new workplace connections.',
  'Herein, we present two studies on how students’ Psychological State of Decision difficulty (PSD) relates to two aspects of learning, i.e., guessing behavior and learning achievement. To measure PSD, we extracted geometric features from trajectories of drag-and-drop touch interactions collected while students aged 7–10 played a math game on a tablet device. In the first study, we explored whether eight geometric features extracted from 97,303 trial trajectories could be grouped to understand students’ PSD. In the second study, we examined whether the two aspects of learning could be predicted using the data collected from 187 students with geometric features indicating their PSD. This work provides empirical evidence that geometric features can be grouped into two types of PSD in the context of learning, including conflict and uncertainty. Moreover, our results demonstrate that data on students’ PSD collected from drag-and-drop trajectories can be used to predict learning.',
  'Artificial intelligence (AI) in healthcare has the potential to improve patient outcomes, but clinician acceptance remains a critical barrier. We developed a novel decision support interface that provides interpretable treatment recommendations for sepsis, a life-threatening condition in which decisional uncertainty is common, treatment practices vary widely, and poor outcomes can occur even with optimal decisions. This system formed the basis of a mixed-methods study in which 24 intensive care clinicians made AI-assisted decisions on real patient cases. We found that explanations generally increased confidence in the AI, but concordance with specific recommendations varied beyond the binary acceptance or rejection described in prior work. Although clinicians sometimes ignored or trusted the AI, they also often prioritized aspects of the recommendations to follow, reject, or delay in a process we term “negotiation.” These results reveal novel barriers to adoption of treatment-focused AI tools and suggest ways to better support differing clinician perspectives.',
  'This paper presents a Shape-Adaptive Ternary-Gaussian model for describing endpoint uncertainty when pointing at moving targets of arbitrary shapes. The basic idea of the model is to combine the uncertainty related to the target shape with the uncertainty caused by the target motion. First, we proposed a model to predict endpoint distribution on static targets based on a Dual-Space Decomposition (DUDE) algorithm. Then, we linearly combined a 2D Ternary-Gaussian model with the newly proposed DUDE-based model to make the 2D Ternary-Gaussian model adaptable to moving targets with random shapes. To verify the performance of our model, we compared it with the original 2D Ternary-Gaussian model and a recent proposed Inscribed Circle model in predicting endpoint distribution. The results show that the proposed model outperformed the two baseline models while maintaining good robustness across different shapes and moving speeds.',
  'We propose a new approach to uncertainty communication: we keep the uncertainty representation fixed, but adjust the distribution displayed to compensate for biases in people’s subjective probability in decision-making. To do so, we adopt a linear-in-probit model of subjective probability and derive two corrections to a Normal distribution based on the model’s intercept and slope: one correcting all right-tailed probabilities, and the other preserving the mode and one focal probability. We then conduct two experiments on U.S. demographically-representative samples. We show participants hypothetical U.S. Senate election forecasts as text or a histogram and elicit their subjective probabilities using a betting task. The first experiment estimates the linear-in-probit intercepts and slopes, and confirms the biases in participants’ subjective probabilities. The second, preregistered follow-up shows participants the bias-corrected forecast distributions. We find the corrections substantially improve participants’ decision quality by reducing the integrated absolute error of their subjective probabilities compared to the true probabilities. These corrections can be generalized to any univariate probability or confidence distribution, giving them broad applicability. Our preprint, code, data, and preregistration are available at https://doi.org/10.17605/osf.io/kcwxm',
  'Automated recruitment tools are proliferating. While having the promise of improving efficiency, various risks, including bias, challenges the potential of these tools. An in-depth understanding of the perceived risk factors and needs from the perspective of both recruiters and job seekers is needed. We address this through an interview study in the high-tech industry to compare and contrast the concerns of these two roles. We found that the importance of clarifying position requirements and assessing candidates as “whole individuals” are commonly discussed by both recruiters and job seekers. In contrast, while recruiters tended to be more aware of cognitive bias and desired more tool support during interviews, job seekers voiced more desire towards a healthy candidate-company relationship. Additionally, both roles considered the uncertainty of the current technology capability and reduced human contact as concerns for using automated tools. Based on these results, we provided design implications for automated recruitment tools and related decision-support technologies.'
]

    # Word2Vec 모델 생성
    model_Word2Vec = calculate_Word2Vec(input_data2)

    model_Doc2Vec = calculate_Doc2Vec(input_data3)
    
    # t-SNE 시각화 실행

    # tSNE_visualize(model_Word2Vec)
    tSNE_visualize_doc2vec(model_Doc2Vec)
    tSNE_visualize_doc2vec_DBSCAN(model_Doc2Vec)

    # PaCMAP 시각화 실행

    # PaCMAP_visualize(model_Word2Vec)
    # PaCMAP_visualize_doc2Vec(model_Doc2Vec)

    # print(json.dumps("hi"))


if __name__ == "__main__":
    main()