[
    {
        "title": "Text Readability in Head-Worn Displays: Color and Style Optimization in Video versus Optical See-Through Devices",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Saverio Debernardis",
            "Michele Fiorentino",
            "Michele Gattullo",
            "Giuseppe Monno",
            "Antonio Emmanuele Uva"
        ],
        "DOI": "10.1109/TVCG.2013.86",
        "citation": 50,
        "abstract": "Efficient text visualization in head-worn augmented reality (AR) displays is critical because it is sensitive to display technology, text style and color, ambient illumination and so on. The main problem for the developer is to know the optimal text style for the specific display and for applications where color coding must be strictly followed because it is regulated by laws or internal practices. In this work, we experimented the effects on readability of two head-worn devices (optical and video see-through), two backgrounds (light and dark), five colors (white, black, red, green, and blue), and two text styles (plain text and billboarded text). Font type and size were kept constant. We measured the performance of 15 subjects by collecting about 5,000 measurements using a specific test application and followed by qualitative interviews. Readability turned out to be quicker on the optical see-through device. For the video see-through device, background affects readability only in case of text without billboard. Finally, our tests suggest that a good combination for indoor augmented reality applications, regardless of device and background, could be white text and blue billboard, while a mandatory color should be displayed as billboard with a white text message."
    },
    {
        "title": "Optimal Local Searching for Fast and Robust Textureless 3D Object Tracking in Highly Cluttered Backgrounds",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Byung-Kuk Seo",
            "Hanhoon Park",
            "Jong-Il Park",
            "Stefan Hinterstoisser",
            "Slobodan Ilic"
        ],
        "DOI": "10.1109/TVCG.2013.94",
        "citation": 32,
        "abstract": "Edge-based tracking is a fast and plausible approach for textureless 3D object tracking, but its robustness is still very challenging in highly cluttered backgrounds due to numerous local minima. To overcome this problem, we propose a novel method for fast and robust textureless 3D object tracking in highly cluttered backgrounds. The proposed method is based on optimal local searching of 3D-2D correspondences between a known 3D object model and 2D scene edges in an image with heavy background clutter. In our searching scheme, searching regions are partitioned into three levels (interior, contour, and exterior) with respect to the previous object region, and confident searching directions are determined by evaluating candidates of correspondences on their region levels; thus, the correspondences are searched among likely candidates in only the confident directions instead of searching through all candidates. To ensure the confident searching direction, we also adopt the region appearance, which is efficiently modeled on a newly defined local space (called a searching bundle). Experimental results and performance evaluations demonstrate that our method fully supports fast and robust textureless 3D object tracking even in highly cluttered backgrounds."
    },
    {
        "title": "Multiphase Flow of Immiscible Fluids on Unstructured Moving Meshes",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Marek Krzysztof Misztal",
            "Kenny Erleben",
            "Adam Bargteil",
            "Jens Fursund",
            "Brian Bunch Christensen",
            "Jakob Andreas BÃ¦rentzen",
            "Robert Bridson"
        ],
        "DOI": "10.1109/TVCG.2013.97",
        "citation": 29,
        "abstract": "In this paper, we present a method for animating multiphase flow of immiscible fluids using unstructured moving meshes. Our underlying discretization is an unstructured tetrahedral mesh, the deformable simplicial complex (DSC), that moves with the flow in a Lagrangian manner. Mesh optimization operations improve element quality and avoid element inversion. In the context of multiphase flow, we guarantee that every element is occupied by a single fluid and, consequently, the interface between fluids is represented by a set of faces in the simplicial complex. This approach ensures that the underlying discretization matches the physics and avoids the additional book-keeping required in grid-based methods where multiple fluids may occupy the same cell. Our Lagrangian approach naturally leads us to adopt a finite element approach to simulation, in contrast to the finite volume approaches adopted by a majority of fluid simulation techniques that use tetrahedral meshes. We characterize fluid simulation as an optimization problem allowing for full coupling of the pressure and velocity fields and the incorporation of a second-order surface energy. We introduce a preconditioner based on the diagonal Schur complement and solve our optimization on the GPU. We provide the results of parameter studies as well as a performance analysis of our method, together with suggestions for performance optimization."
    },
    {
        "title": "Summarization-Based Image Resizing by Intelligent Object Carving",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Weiming Dong",
            "Ning Zhou",
            "Tong-Yee Lee",
            "Fuzhang Wu",
            "Yan Kong",
            "Xiaopeng Zhang"
        ],
        "DOI": "10.1109/TVCG.2013.103",
        "citation": 16,
        "abstract": "Image resizing can be more effectively achieved with a better understanding of image semantics. In this paper, similar patterns that exist in many real-world images. are analyzed. By interactively detecting similar objects in an image, the image content can be summarized rather than simply distorted or cropped. This method enables the manipulation of image pixels or patches as well as semantic objects in the scene during image resizing process. Given the special nature of similar objects in a general image, the integration of a novel object carving operator with the multi-operator framework is proposed for summarizing similar objects. The object removal sequence in the summarization strategy directly affects resizing quality. The method by which to evaluate the visual importance of the object as well as to optimally select the candidates for object carving is demonstrated. To achieve practical resizing applications for general images, a template matching-based method is developed. This method can detect similar objects even when they are of various colors, transformed in terms of perspective, or partially occluded. To validate the proposed method, comparisons with state-of-the-art resizing techniques and a user study were conducted. Convincing visual results are shown to demonstrate the effectiveness of the proposed method."
    },
    {
        "title": "GPU-Based Volume Visualization from High-Order Finite Element Fields",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Blake Nelson",
            "Robert M. Kirby",
            "Robert Haimes"
        ],
        "DOI": "10.1109/TVCG.2013.96",
        "citation": 13,
        "abstract": "This paper describes a new volume rendering system for spectral/hp finite-element methods that has as its goal to be both accurate and interactive. Even though high-order finite element methods are commonly used by scientists and engineers, there are few visualization methods designed to display this data directly. Consequently, visualizations of high-order data are generally created by first sampling the high-order field onto a regular grid and then generating the visualization via traditional methods based on linear interpolation. This approach, however, introduces error into the visualization pipeline and requires the user to balance image quality, interactivity, and resource consumption. We first show that evaluation of the volume rendering integral, when applied to the composition of piecewise-smooth transfer functions with the high-order scalar field, typically exhibits second-order convergence for a wide range of high-order quadrature schemes, and has worst case first-order convergence. This result provides bounds on the ability to achieve high-order convergence to the volume rendering integral. We then develop an algorithm for optimized evaluation of the volume rendering integral, based on the categorization of each ray according to the local behavior of the field and transfer function. We demonstrate the effectiveness of our system by running performance benchmarks on several high-order fluid-flow simulations."
    },
    {
        "title": "Grouper: A Compact, Streamable Triangle Mesh Data Structure",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Mark Luffel",
            "Topraj Gurung",
            "Peter Lindstrom",
            "Jarek Rossignac"
        ],
        "DOI": "10.1109/TVCG.2013.81",
        "citation": 12,
        "abstract": "We present Grouper: an all-in-one compact file format, random-access data structure, and streamable representation for large triangle meshes. Similarly to the recently published SQuad representation, Grouper represents the geometry and connectivity of a mesh by grouping vertices and triangles into fixed-size records, most of which store two adjacent triangles and a shared vertex. Unlike SQuad, however, Grouper interleaves geometry with connectivity and uses a new connectivity representation to ensure that vertices and triangles can be stored in a coherent order that enables memory-efficient sequential stream processing. We present a linear-time construction algorithm that allows streaming out Grouper meshes using a small memory footprint while preserving the initial ordering of vertices. As a part of this construction, we show how the problem of assigning vertices and triangles to groups reduces to a well-known NP-hard optimization problem, and present a simple yet effective heuristic solution that performs well in practice. Our array-based Grouper representation also doubles as a triangle mesh data structure that allows direct access to vertices and triangles. Storing only about two integer references per triangleÃ¢i.e., less than the three vertex references stored with each triangle in a conventional indexed mesh format-Grouper answers both incidence and adjacency queries in amortized constant time. Our compact representation enables data-parallel processing on multicore computers, instant partitioning and fast transmission for distributed processing, as well as efficient out-of-core access. We demonstrate the versatility and performance benefits of Grouper using a suite of example meshes and processing kernels."
    },
    {
        "title": "Verifying Volume Rendering Using Discretization Error Analysis",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Tiago Etiene",
            "Daniel JÃ¶nsson",
            "Timo Ropinski",
            "Carlos Scheidegger",
            "JoÃ£o L.D. Comba",
            "Luis Gustavo Nonato",
            "Robert M. Kirby",
            "Anders Ynnerman",
            "ClÃ¡udio T. Silva"
        ],
        "DOI": "10.1109/TVCG.2013.90",
        "citation": 11,
        "abstract": "We propose an approach for verification of volume rendering correctness based on an analysis of the volume rendering integral, the basis of most DVR algorithms. With respect to the most common discretization of this continuous model (Riemann summation), we make assumptions about the impact of parameter changes on the rendered results and derive convergence curves describing the expected behavior. Specifically, we progressively refine the number of samples along the ray, the grid size, and the pixel size, and evaluate how the errors observed during refinement compare against the expected approximation errors. We derive the theoretical foundations of our verification approach, explain how to realize it in practice, and discuss its limitations. We also report the errors identified by our approach when applied to two publicly available volume rendering packages."
    },
    {
        "title": "Drawing Area-Proportional Euler Diagrams Representing Up To Three Sets",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Peter Rodgers",
            "Gem Stapleton",
            "Jean Flower",
            "John Howse"
        ],
        "DOI": "10.1109/TVCG.2013.104",
        "citation": 10,
        "abstract": "Area-proportional Euler diagrams representing three sets are commonly used to visualize the results of medical experiments, business data, and information from other applications where statistical results are best shown using interlinking curves. Currently, there is no tool that will reliably visualize exact area-proportional diagrams for up to three sets. Limited success, in terms of diagram accuracy, has been achieved for a small number of cases, such as Venn-2 and Venn-3 where all intersections between the sets must be represented. Euler diagrams do not have to include all intersections and so permit the visualization of cases where some intersections have a zero value. This paper describes a general, implemented, method for visualizing all 40 Euler-3 diagrams in an area-proportional manner. We provide techniques for generating the curves with circles and convex polygons, analyze the drawability of data with these shapes, and give a mechanism for deciding whether such data can be drawn with circles. For the cases where non-convex curves are necessary, our method draws an appropriate diagram using non-convex polygons. Thus, we are now always able to automatically visualize data for up to three sets."
    },
    {
        "title": "A Deformation Framework for Focus+Context Flow Visualization",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Jun Tao",
            "Chaoli Wang",
            "Ching-Kuang Shene",
            "Seung Hyun Kim"
        ],
        "DOI": "10.1109/TVCG.2013.100",
        "citation": 8,
        "abstract": "Striking a careful balance among coverage, occlusion, and complexity is a resounding theme in the visual understanding of large and complex three-dimensional flow fields. In this paper, we present a novel deformation framework for focus+context streamline visualization that reduces occlusion and clutter around the focal regions while compacting the context region in a full view. Unlike existing techniques that vary streamline densities, we advocate a different approach that manipulates streamline positions. This is achieved by partitioning the flow field's volume space into blocks and deforming the blocks to guide streamline repositioning. We formulate block expansion and block smoothing into energy terms and solve for a deformed grid that minimizes the objective function under the volume boundary and edge flipping constraints. Leveraging a GPU linear system solver, we demonstrate interactive focus+context visualization with 3D flow field data of various characteristics. Compared to the fisheye focus+context technique, our method can magnify multiple streamlines of focus in different regions simultaneously while minimizing the distortion through optimized deformation. Both automatic and manual feature specifications are provided for flexible focus selection and effective visualization."
    },
    {
        "title": "Mass-Conserving Eulerian Liquid Simulation",
        "conferenceTitle": "IEEE Transactions on Visualization and Computer Graphics",
        "date": "Jan. 2014",
        "authors": [
            "Nuttapong Chentanez",
            "Matthias MÃ¼ller"
        ],
        "DOI": "10.1109/TVCG.2013.19",
        "citation": 8,
        "abstract": "We present a GPU friendly, Eulerian, free surface fluid simulation method that conserves mass locally and globally without the use of Lagrangian components. Local mass conservation prevents small-scale details of the free surface from disappearing, a problem that plagues many previous approaches, while global mass conservation ensures that the total volume of the liquid does not decrease over time. Our method handles moving solid boundaries as well as cells that are partially filled with solids. Due to its stability, it allows the use of large time steps that makes it suitable for both offline and real-time applications. We achieve this by using density-based surface tracking with a novel, unconditionally stable, conservative advection scheme. We also propose mass conserving methods to sharpen the interface and to reveal subgrid features of the liquid. While our approach conserves mass, volume loss is still possible but only temporarily. With constant mass, local volume loss causes a local increase of the density used for surface tracking which we detect and correct over time. We show the effectiveness of the proposed methods in several practical examples all running either at interactive rates or in real time."
    }
]