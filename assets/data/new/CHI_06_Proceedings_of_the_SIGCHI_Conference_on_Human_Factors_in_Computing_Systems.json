[
    {
        "title": "Faster document navigation with space-filling thumbnails",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation",
        "data": "April 2006",
        "authors": [
            "Andy Cockburn",
            "Carl Gutwin",
            "Jason Alexander"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124774",
        "citation": "66",
        "abstract": "Scrolling is the standard way to navigate through many types of digital documents. However, moving more than a few pages can be slow because all scrolling techniques constrain visual search to only a small document region. To improve document navigation, we developed Space-Filling Thumbnails (SFT), an overview display that eliminates most scrolling. SFT provides two views: a standard page view for reading, and a thumbnail view that shows all pages. We tested SFT in three experiments that involved finding pages in documents. The first study (n=13) compared seven current scrolling techniques, and showed that SFT is significantly faster than the other methods. The second and third studies (n=32 and n=14) were detailed comparisons of SFT with thumbnail-enhanced scrollbars (TES), which performed well in the first experiment. SFT was faster than TES across all document types and lengths, particularly when tasks involved revisitation. In addition, SFT was strongly preferred by participants."
    },
    {
        "title": "An evaluation of pan & zoom and rubber sheet navigation with and without an overview",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation",
        "data": "April 2006",
        "authors": [
            "Dmitry Nekrasovski",
            "Adam Bodnar",
            "Joanna McGrenere",
            "François Guimbretière",
            "Tamara Munzner"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124775",
        "citation": "47",
        "abstract": "We present a study that evaluates conventional Pan and Zoom Navigation and Rubber Sheet Navigation, a rectilinear Focus+Context technique. Each of the two navigation techniques was evaluated both with and without an overview. All interfaces guaranteed that regions of interest would remain visible, at least as a compressed landmark, independent of navigation actions. Interfaces implementing these techniques were used by 40 subjects to perform a task that involved navigating a large hierarchical tree dataset and making topological comparisons between nodes in the tree. Our results show that Pan and Zoom Navigation was significantly faster and required less mental effort than Rubber Sheet Navigation, independent of the presence or absence of an overview. Also, overviews did not appear to improve performance, but were still perceived as beneficial by users. We discuss the implications of our task and guaranteed visibility on the results and the limitations of our study, and we propose preliminary design guidelines and recommendations for future work."
    },
    {
        "title": "OrthoZoom scroller: 1D multi-scale navigation",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Navigation",
        "data": "April 2006",
        "authors": [
            "Caroline Appert",
            "Jean-Daniel Fekete"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124776",
        "citation": "62",
        "abstract": "This article introduces the OrthoZoom Scroller, a novel interaction technique that improves target acquisition in very large one-dimensional spaces. The OrthoZoom Scroller requires only a mouse to perform panning and zooming in a 1D space. Panning is performed along the slider dimension while zooming is performed along the orthogonal one. We present a controlled experiment showing that the OrthoZoom Scroller is about twice as fast as Speed Dependant Automatic Zooming to perform pointing tasks whose index of difficulty is in the 10-30 bits range. We also present an application to browse large textual documents with the OrthoZoom Scroller that uses semantic zooming and snapping on the structure."
    },
    {
        "title": "Time based patterns in mobile-internet surfing",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile surfing and effects of wearables",
        "data": "April 2006",
        "authors": [
            "Martin Halvey",
            "Mark T. Keane",
            "Barry Smyth"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124778",
        "citation": "38",
        "abstract": "In this paper we investigate environmental factors that can result in users having different preferences and behaviors at different times of the day. An analysis is carried out of a large sample of user data for Wireless Application Protocol (WAP) browsing to determine whether user surfing patterns vary depending on time. We examine traffic on an hourly and daily basis, and show that accesses to particular categories of pages vary relative to time. We also build Markov models, which are temporal; to predict user navigation, and illustrate those predictive models are more accurate and beneficial to mobile Internet users than traditional methods. This analysis provides insight into improving the effectiveness and efficiency of navigation prediction."
    },
    {
        "title": "Minimap: a web page visualization method for mobile phones",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile surfing and effects of wearables",
        "data": "April 2006",
        "authors": [
            "Virpi Roto",
            "Andrei Popescu",
            "Antti Koivisto",
            "Elina Vartiainen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124779",
        "citation": "75",
        "abstract": "The Web has become available even on mobile phones, but the current methods to view large pages on small screens have not been highly usable. Current mobile phone browsers reformat Web pages to a single column that fits the screen width. Because not all content is comprehensible in this format, browsers provide a second mode for viewing pages in the same layout as on a PC. We have developed a modeless Web page visualization method called Minimap that shows pages in a modified Original layout. We conducted a long-term usability study with 20 participants to compare the state-of-the-art mobile phone browser with this new method. 18 participants preferred the new method, and it also scored better in more detailed usability ratings."
    },
    {
        "title": "An examination of the effects of a wearable display on informal face-to-face communication",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Mobile surfing and effects of wearables",
        "data": "April 2006",
        "authors": [
            "Gerard McAtamney",
            "Caroline Parker"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124780",
        "citation": "40",
        "abstract": "Wearable computers have the potential to support our memory, facilitate our creativity, our communication and augment our physical senses [15] but, like email and cell-phones, they also have the potential to interrupt, displace or downgrade our social interactions. This paper presents the results of a simple laboratory-based study which examines the impact of a xybernaut head-mounted Shimadzu display on conversation between two people. We hypothesized that the wearable, by reducing eye-contact and attention in the wearer would have a detrimental effect. Pairs of friends discussed pre-defined topics under three conditions, no wearable, wearable present but inactive, wearable present and active. Likert scale statements were used to record the wearer's level of attention, concentration, listening, eye contact, naturalness and relaxation, and the impact of the wearable. The presence of the wearable without an active display did not have an effect on the conversation. The quality of the interaction was however impaired in the active wearable condition and eye-contact was effected. This effect may be the result of the nature of the information type, the interface used, the characteristics of its presentation or the novelty of the display to the user. Additional research to identify design implications is discussed."
    },
    {
        "title": "Peekaboom: a game for locating objects in images",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2006",
        "authors": [
            "Luis von Ahn",
            "Ruoran Liu",
            "Manuel Blum"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124782",
        "citation": "315",
        "abstract": "We introduce Peekaboom, an entertaining web-based game that can help computers locate objects in images. People play the game because of its entertainment value, and as a side effect of them playing, we collect valuable image metadata, such as which pixels belong to which object in the image. The collected data could be applied towards constructing more accurate computer vision algorithms, which require massive amounts of training and testing data not currently available. Peekaboom has been played by thousands of people, some of whom have spent over 12 hours a day playing, and thus far has generated millions of data points. In addition to its purely utilitarian aspect, Peekaboom is an example of a new, emerging class of games, which not only bring people together for leisure purposes, but also exist to improve artificial intelligence. Such games appeal to a general audience, while providing answers to problems that computers cannot yet solve."
    },
    {
        "title": "Representation of interwoven surfaces in 2 1/2 D drawing",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2006",
        "authors": [
            "Keith Wiley",
            "Lance R. Williams"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124783",
        "citation": "9",
        "abstract": "The state-of-the-art in computer drawing programs is based on a number of concepts that are over two decades old. One such concept is the use of layers for ordering the surfaces in a drawing from top to bottom. Unfortunately, the use of layers unnecessarily imposes a partial ordering on the depths of the surfaces and prevents the user from creating a large class of potential drawings, e.g., of Celtic knots and interwoven surfaces. In this paper we describe a novel approach which only requires local depth ordering of segments of the boundaries of surfaces in a drawing rather than a global depth relation between entire surfaces. Our program provides an intuitive user interface which allows a novice to create complex drawings of interwoven surfaces that would be difficult and time-consuming to create with standard drawing programs."
    },
    {
        "title": "Verbosity: a game for collecting common-sense facts",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2006",
        "authors": [
            "Luis von Ahn",
            "Mihir Kedia",
            "Manuel Blum"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124784",
        "citation": "172",
        "abstract": "We address the problem of collecting a database of \"\"common-sense facts\"\" using a computer game. Informally, a common-sense fact is a true statement about the world that is known to most humans: \"\"milk is white,\"\" \"\"touching hot metal hurts,\"\" etc. Several efforts have been devoted to collecting common-sense knowledge for the purpose of making computer programs more intelligent. Such efforts, however, have not succeeded in amassing enough data because the manual process of entering these facts is tedious. We therefore introduce Verbosity, a novel interactive system in the form of an enjoyable game. People play Verbosity because it is fun, and as a side effect of them playing, we collect accurate common-sense knowledge. Verbosity is an example of a game that not only brings people together for leisure, but also collects useful data for computer science."
    },
    {
        "title": "Improving accessibility of the web with a computer game",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games",
        "data": "April 2006",
        "authors": [
            "Luis von Ahn",
            "Shiry Ginosar",
            "Mihir Kedia",
            "Ruoran Liu",
            "Manuel Blum"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124785",
        "citation": "110",
        "abstract": "Images on the Web present a major accessibility issue for the visually impaired, mainly because the majority of them do not have proper captions. This paper addresses the problem of attaching proper explanatory text descriptions to arbitrary images on the Web. To this end, we introduce Phetch, an enjoyable computer game that collects explanatory descriptions of images. People play the game because it is fun, and as a side effect of game play we collect valuable information. Given any image from the World Wide Web, Phetch can output a correct annotation for it. The collected data can be applied towards significantly improving Web accessibility. In addition to improving accessibility, Phetch is an example of a new class of games that provide entertainment in exchange for human processing power. In essence, we solve a typical computer vision problem with HCI tools alone."
    },
    {
        "title": "Evaluating interfaces for privacy policy rule authoring",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy 1",
        "data": "April 2006",
        "authors": [
            "Clare-Marie Karat",
            "John Karat",
            "Carolyn Brodie",
            "Jinjuan Feng"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124787",
        "citation": "48",
        "abstract": "Privacy policy rules are often written in organizations by a team of people in different roles. Currently, people in these roles have no technological tools to guide the creation of clear and implementable high-quality privacy policy rules. High-quality privacy rules can be the basis for verifiable automated privacy access decisions. An empirical study was conducted with 36 users who were novices in privacy policy authoring to evaluate the quality of rules created and user satisfaction with two experimental privacy authoring tools and a control condition. Results show that users presented with scenarios were able to author significantly higher quality rules using either the natural language with a privacy rule guide tool or a structured list tool as compared to an unguided natural language control condition. The significant differences in quality were found in both user self-ratings of rule quality and objective quality scores. Users ranked the two experimental tools significantly higher than the control condition. Implications of the research and future research directions are discussed."
    },
    {
        "title": "Putting people in their place: an anonymous and privacy-sensitive approach to collecting sensed data in location-based applications",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy 1",
        "data": "April 2006",
        "authors": [
            "Karen P. Tang",
            "Pedram Keyani",
            "James Fogarty",
            "Jason I. Hong"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124788",
        "citation": "62",
        "abstract": "The emergence of location-based computing promises new and compelling applications, but raises very real privacy risks. Existing approaches to privacy generally treat people as the entity of interest, often using a fidelity tradeoff to manage the costs and benefits of revealing a person's location. However, these approaches cannot be applied in some applications, as a reduction in precision can render location information useless. This is true of a category of applications that use location data collected from multiple people to infer such information as whether there is a traffic jam on a bridge, whether there are seats available in a nearby coffee shop, when the next bus will arrive, or if a particular conference room is currently empty. We present hitchhiking, a new approach that treats locations as the primary entity of interest. Hitchhiking removes the fidelity tradeoff by preserving the anonymity of reports without reducing the precision of location disclosures. We can therefore support the full functionality of an interesting class of location-based applications without introducing the privacy concerns that would otherwise arise."
    },
    {
        "title": "Advancing ambiguity",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy 1",
        "data": "April 2006",
        "authors": [
            "Kirsten Boehner",
            "Jeffrey T. Hancock"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124789",
        "citation": "32",
        "abstract": "Ambiguity is an important concept for HCI because of its pervasiveness in everyday life, yet its emergent nature challenges the role of design. We examine these difficulties with regards to Aoki and Woodruff's [1] proposal to use ambiguity as a resource for designing space for stories in personal communication systems. We challenge certain assumptions about ambiguity and propose a set of design and evaluation guidelines that flow from this re-conceptualization of ambiguity and design."
    },
    {
        "title": "Girls, technology and privacy: \"is my mother listening?\"",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy 1",
        "data": "April 2006",
        "authors": [
            "Wendy March",
            "Constance Fleuriot"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124790",
        "citation": "21",
        "abstract": "This paper describes a study undertaken to explore the ways in which older teenage girls use technology to construct and maintain a sense of private space while living at home with parents. The study used blogging as an experimental and integral part of the research, in order to facilitate ongoing communication between researcher and participant."
    },
    {
        "title": "Dogear: Social bookmarking in the enterprise",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 1",
        "data": "April 2006",
        "authors": [
            "David R. Millen",
            "Jonathan Feinberg",
            "Bernard Kerr"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124792",
        "citation": "203",
        "abstract": "We describe a social bookmarking service de-signed for a large enterprise. We discuss design principles addressing online identity, privacy, information discovery (including search and pivot browsing), and service extensi-bility based on a web-friendly architectural style. In addi-tion we describe the key design features of our implementa-tion. We provide the results of an eight week field trial of this enterprise social bookmarking service, including a de-scription of user activities, based on log file analysis. We share the results of a user survey focused on the benefits of the service. The feedback from the user trial, comprising survey results, log file analysis and informal communica-tions, is quite positive and suggests several promising en-hancements to the service. Finally, we discuss potential extension and integration of social bookmarking services with other corporate collaborative applications."
    },
    {
        "title": "Increasing user decision accuracy using suggestions",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 1",
        "data": "April 2006",
        "authors": [
            "Pearl Pu",
            "Paolo Viappiani",
            "Boi Faltings"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124793",
        "citation": "21",
        "abstract": "The internet presents people with an increasingly bewildering variety of choices. Online consumers have to rely on computerized search tools to find the most preferred option in a reasonable amount of time. Recommender systems address this problem by searching for options based on a model of the user's preferences. We consider example critiquing as a methodology for mixed-initiative recommender systems. In this technique, users volunteer their preferences as critiques on examples. It is thus important to stimulate their preference expression by selecting the proper examples, called suggestions. We describe the look-ahead principle for suggestions and describe several suggestion strategies based on it. We compare them in simulations and, for the first time, report a set of user studies which prove their effectiveness in increasing users' decision accuracy by up to 75%."
    },
    {
        "title": "Co-authoring with structured annotations",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 1",
        "data": "April 2006",
        "authors": [
            "Qixing Zheng",
            "Kellogg Booth",
            "Joanna McGrenere"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124794",
        "citation": "16",
        "abstract": "Most co-authoring tools support basic annotations, such as edits and comments that are anchored at specific locations in the document. However, they do not support meta-commentary about a document (such as an author's summary of modifications) which gets separated from the document, often in the body of email messages. This causes unnecessary overhead in the write-review-edit workflow inherent in co-authoring. We present document-embedded structured annotations called \"bundles\" that incorporate the meta-commentary into a unified annotation model that meets a set of annotation requirements we identified through a small field investigation. A usability study with 20 subjects evaluated the annotation reviewing stage of co-authoring and showed that annotation bundles in our high-fidelity prototype reduced reviewing time and increased accuracy, compared to a system that only supports edits and comments."
    },
    {
        "title": "\"LINC-ing\" the family: the participatory design of an inkable family calendar",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Participatory design",
        "data": "April 2006",
        "authors": [
            "Carman Neustaedter",
            "A. J. Bernheim Brush"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124796",
        "citation": "70",
        "abstract": "Families must continually organize, plan, and stay aware of the activities of their households in order to coordinate everyday life. Despite having organization schemes, many people still feel overwhelmed when it comes to family coordination. To help overcome this, we present our research efforts on LINC: an inkable family calendar designed for the kitchen. LINC was developed using a participatory design process involving interviews, paper prototyping, and a formative evaluation. Our work outlines key implications for digital family calendars and family coordination systems in general. We found that coordination is not typically done through the family calendar; rather, the family calendar is a tool that provides family members with an awareness of activities and changes that in turn enables coordination. Thus, digital family calendars should provide tools that enable families to use their own coordination routines which leverage the social affordances prominent in existing paper calendars."
    },
    {
        "title": "Participatory design with proxies: developing a desktop-PDA system to support people with aphasia",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Participatory design",
        "data": "April 2006",
        "authors": [
            "Jordan L. Boyd-Graber",
            "Sonya S. Nikolova",
            "Karyn A. Moffatt",
            "Kenrick C. Kin",
            "Joshua Y. Lee",
            "Lester W. Mackey",
            "Marilyn M. Tremaine",
            "Maria M. Klawe"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124797",
        "citation": "71",
        "abstract": "In this paper, we describe the design and preliminary evaluation of a hybrid desktop-handheld system developed to support individuals with aphasia, a disorder which impairs the ability to speak, read, write, or understand language. The system allows its users to develop speech communication through images and sound on a desktop computer and download this speech to a mobile device that can then support communication outside the home. Using a desktop computer for input addresses some of this population's difficulties interacting with handheld devices, while the mobile device addresses stigma and portability issues. A modified participatory design approach was used in which proxies, that is, speech-language pathologists who work with aphasic individuals, assumed the role normally filled by users. This was done because of the difficulties in communicating with the target population and the high variability in aphasic disorders. In addition, the paper presents a case study of the proxy-use participatory design process that illustrates how different interview techniques resulted in different user feedback."
    },
    {
        "title": "Participatory design in emergency medical service: designing for future practice",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Participatory design",
        "data": "April 2006",
        "authors": [
            "Margit Kristensen",
            "Morten Kyng",
            "Leysia Palen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124798",
        "citation": "66",
        "abstract": "We describe our research-its approach, results and products-on Danish emergency medical service (EMS) field or \"pre-hospital\" work in minor and major incidents. We discuss how commitments to participatory design and attention to the qualitative differences between minor and major incidents address challenges identified by disaster sociolo-gists when designing for major incidents. Through qualitative research and participatory design, we have examined the features of EMS work and technology use in different emergency situations from the perspective of multiple actors. We conceptualize victims in incidents-and particularly in major incidents, where on-site medical as-sessments is highly incomplete-as boundary objects over which the complex and imperfect work of coordination is done. As an outcome of our participatory design approach, we describe a set of designs in support of future EMS work."
    },
    {
        "title": "A role for haptics in mobile interaction: initial design using a handheld tactile display prototype",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction techniques: haptic and gestural",
        "data": "April 2006",
        "authors": [
            "Joseph Luk",
            "Jerome Pasquero",
            "Shannon Little",
            "Karon MacLean",
            "Vincent Levesque",
            "Vincent Hayward"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124800",
        "citation": "151",
        "abstract": "Mobile interaction can potentially be enhanced with well-designed haptic control and display. However, advances have been limited by a vicious cycle whereby inadequate haptic technology obstructs inception of vitalizing applications. We present the first stages of a systematic design effort to break that cycle, beginning with specific usage scenarios and a new handheld display platform based on lateral skin stretch. Results of a perceptual device characterization inform mappings between device capabilities and specific roles in mobile interaction, and the next step of hardware re-engineering."
    },
    {
        "title": "The springboard: multiple modes in one spring-loaded control",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction techniques: haptic and gestural",
        "data": "April 2006",
        "authors": [
            "Ken Hinckley",
            "Francois Guimbretiere",
            "Patrick Baudisch",
            "Raman Sarin",
            "Maneesh Agrawala",
            "Ed Cutrell"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124801",
        "citation": "37",
        "abstract": "Modes allow a few inputs to invoke many operations, yet if a user misclassifies or forgets the state of a system, modes can result in errors. Spring-loaded modes (quasimodes) maintain a mode while the user holds a control such as a button or key. The Springboard is an interaction technique for tablet computers that extends quasimodes to encompass multiple tool modes in a single spring-loaded control. The Springboard allows the user to continue holding down a nonpreferred-hand command button after selecting a tool from a menu as a way to repeatedly apply the same tool. We find the Springboard improves performance for both a local marking menu and for a non-local marking menu (\"lagoon\") at the lower left corner of the screen. Despite the round-trip costs incurred to move the pen to a tool lagoon, a keystroke-level analysis of the true cost of each technique reveals the local marking menu is not significantly faster."
    },
    {
        "title": "The GlobeFish and the GlobeMouse: two new six degree of freedom input devices for graphics applications",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction techniques: haptic and gestural",
        "data": "April 2006",
        "authors": [
            "Bernd Froehlich",
            "Jan Hochstrate",
            "Verena Skuk",
            "Anke Huckauf"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124802",
        "citation": "54",
        "abstract": "We introduce two new six degree of freedom desktop input devices based on the key concept of combining forceless isotonic rotational input with force-requiring elastic translational input. The GlobeFish consists of a custom three degrees of freedom trackball which is elastically connected to a frame. The trackball is accessible from the top and bottom and can be moved slightly in all spatial directions by using force. The GlobeMouse device works in a similar way. Here the trackball is placed on top of a movable base, which requires to change the grip on the device to switch between rotating the trackball and moving the base.Our devices are manipulated with the fingertips allowing precise interaction with virtual objects. The elastic translation allows uniform input for all three axes and the isotonic trackball provides a natural mapping for rotations. Our user study revealed that the new devices perform significantly better in a docking task in comparison to the SpaceMouse, an integrated six degrees of freedom controller. Subjective data confirmed these results."
    },
    {
        "title": "Making action visible in time-critical work",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activity: design implications",
        "data": "April 2006",
        "authors": [
            "Jonas Landgren"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124804",
        "citation": "44",
        "abstract": "This paper presents descriptive accounts from an ethnographic study of time-critical work in the domain of emergency response and the operative work of fire crews. The verbal communication as part of such work creates difficulties in providing accountability of the fire crew's actions. The concept of work rhythms and temporal structures is used as an analytical framework. Design implications are presented suggesting that verbal communication should be made persistent, visible and accessible in order to support accountability. These design implications are discussed in relation to the fire crew's work practice."
    },
    {
        "title": "Support for activity-based computing in a personal computing operating system",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activity: design implications",
        "data": "April 2006",
        "authors": [
            "Jakob Bardram",
            "Jonathan Bunde-Pedersen",
            "Mads Soegaard"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124805",
        "citation": "65",
        "abstract": "Research has shown that computers are notoriously bad at supporting the management of parallel activities and interruptions, and that mobility increases the severity of these problems. This paper presents activity-based computing (ABC) which supplements the prevalent data- and application-oriented computing paradigm with technologies for handling multiple, parallel and mobile work activities. We present the design and implementation of ABC support embedded in the Windows XP operating system. This includes replacing the Windows Taskbar with an Activity Bar, support for handling Windows applications, a zoomable user interface, and support for moving activities across different computers. We report an evaluation of this Windows XP ABC system which is based on a multi-method approach, where perceived ease-of-use and usefulness was evaluated together with rich interview material. This evaluation showed that users found the ABC XP extension easy to use and likely to be useful in their own work."
    },
    {
        "title": "Share and share alike: exploring the user interface affordances of file sharing",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Activity: design implications",
        "data": "April 2006",
        "authors": [
            "Stephen Voida",
            "W. Keith Edwards",
            "Mark W. Newman",
            "Rebecca E. Grinter",
            "Nicolas Ducheneaut"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124806",
        "citation": "60",
        "abstract": "With the rapid growth of personal computer networks and the Internet, sharing files has become a central activity in computer use. The ways in which users control the what, how, and with whom of sharing are dictated by the tools they use for sharing; there are a wide range of sharing practices, and hence a wide range of tools to support these practices. In practice, users' requirements for certain sharing features may dictate their choice of tool, even though the other affordances available through that tool may not be an ideal match to the desired manner of sharing.In this paper, we explore users' current practices in file sharing and examine the tools used to share files. Based on our findings, we unpack the features and affordances of these tools into a set of dimensions along which sharing tools can be characterized. Then, we present the set of user interface features we have prototyped in an interface called a sharing palette, which provides a platform for exploration and experimentation with new modalities of sharing. We briefly present the tool as a whole and then focus on the individual features of the sharing palette that support reported styles of sharing."
    },
    {
        "title": "Tinkering and gender in end-user programmers' debugging",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: End user programming",
        "data": "April 2006",
        "authors": [
            "Laura Beckwith",
            "Cory Kissinger",
            "Margaret Burnett",
            "Susan Wiedenbeck",
            "Joseph Lawrance",
            "Alan Blackwell",
            "Curtis Cook"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124808",
        "citation": "123",
        "abstract": "Earlier research on gender effects with software features intended to help problem-solvers in end-user debugging environments has shown that females are less likely to use unfamiliar software features. This poses a serious problem because these features may be key to helping them with debugging problems. Contrasting this with research documenting males' inclination for tinkering in unfamiliar environments, the question arises as to whether encouraging tinkering with new features would help females overcome the factors, such as low self-efficacy, that led to the earlier results. In this paper, we present an experiment with males and females in an end-user debugging setting, and investigate how tinkering behavior impacts several measures of their debugging success. Our results show that the factors of tinkering, reflection, and self-efficacy, can combine in multiple ways to impact debugging effectiveness differently for males than for females."
    },
    {
        "title": "An evaluation of using programming by demonstration and guided walkthrough techniques for authoring and utilizing documentation",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: End user programming",
        "data": "April 2006",
        "authors": [
            "Madhu Prabaker",
            "Lawrence Bergman",
            "Vittorio Castelli"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124809",
        "citation": "13",
        "abstract": "Much existing documentation is informal and serves to communicate \"how-to\" knowledge among restricted working groups. Using current practices, such documentation is both difficult to maintain and difficult to use properly.In this paper, we propose a documentation system, called DocWizards, that uses programming by demonstration to support low-cost authoring and guided walkthrough techniques to improve document usability.We report a comparative study between the use of DocWizards and traditional techniques for authoring and following documentation. The study participants showed significant gains in efficiency and reduction in error rates when using DocWizards. In addition, they expressed a clear preference for using the DocWizards tool, both for authoring and for following documentation."
    },
    {
        "title": "Providing support for adaptive scripting in an on-line collaborative learning environment",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: End user programming",
        "data": "April 2006",
        "authors": [
            "Gahgene Gweon",
            "Carolyn Rose",
            "Regan Carey",
            "Zachary Zaiss"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124810",
        "citation": "39",
        "abstract": "This paper describes results from a series of experimental studies to explore issues related to structuring productive group dynamics for collaborative learning using an adaptive support mechanism. The first study provides evidence in favor of the feasibility of the endeavor by demonstrating with a tightly controlled study that even without adaptive support, problem solving in pairs is significantly more effective for learning than problem solving alone. The results from a second study offer guidelines for strategic matching of students with learning partners. Furthermore, the results reveal specific areas for needed support. Based on the results from the second study, we present the design of an adaptive support mechanism, which we evaluate in a third study. The results from the third study provide evidence that certain aspects of our design for adaptive support in the form of strategic prompts are effective for manipulating student behavior in productive ways and for supporting learning. These results also motivate specific modifications to the original design."
    },
    {
        "title": "Fast, flexible filtering with phlat",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Personal information management",
        "data": "April 2006",
        "authors": [
            "Edward Cutrell",
            "Daniel Robbins",
            "Susan Dumais",
            "Raman Sarin"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124812",
        "citation": "114",
        "abstract": "Systems for fast search of personal information are rapidly becoming ubiquitous. Such systems promise to dramatically improve personal information management, yet most are modeled on Web search in which users know very little about the content that they are searching. We describe the design and deployment of a system called Phlat that optimizes search for personal information with an intuitive interface that merges search and browsing through a variety of associative and contextual cues. In addition, Phlat supports a unified tagging (labeling) scheme for organizing personal content across storage systems (files, email, etc.). The system has been deployed to hundreds of employees within our organization. We report on both quantitative and qualitative aspects of system use. Phlat is available as a free download at http://research.microsoft.com/adapt/phlat."
    },
    {
        "title": "The project fragmentation problem in personal information management",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Personal information management",
        "data": "April 2006",
        "authors": [
            "Ofer Bergman",
            "Ruth Beyth-Marom",
            "Rafi Nachmias"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124813",
        "citation": "64",
        "abstract": "The project fragmentation problem in personal information management occurs when someone who is working on a single project stores and retrieves information items relating to that project from separate format-related collections (documents, emails and favorite Web sites). This study was aimed to test empirically users' working habits in order to shed light on the project fragmentation problem. Twenty personal computer users participated in the study. Data collection tools included an interview, screen captures and a questionnaire. Results indicate that users tend to store and retrieve project-related information items based on different formats in one project folder when the interface design encourages it. However, they store and retrieve project- related information items in different folders (documents, emails and favorite Web sites) when the design encourages such fragmentation. Two types of attempts to solve the project fragmentation problem are reviewed and a new possible solution is suggested."
    },
    {
        "title": "To have and to hold: exploring the personal archive",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Personal information management",
        "data": "April 2006",
        "authors": [
            "Joseph 'Jofish' Kaye",
            "Janet Vertesi",
            "Shari Avery",
            "Allan Dafoe",
            "Shay David",
            "Lisa Onaga",
            "Ivan Rosero",
            "Trevor Pinch"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124814",
        "citation": "99",
        "abstract": "The personal archive is not only about efficient storage and retrieval of information. This paper describes a study of forty-eight academics and the techniques and tools they use to manage their digital and material archiving of papers, emails, documents, internet bookmarks, correspondence, and other artifacts. We present two sets of results: we first discuss rationales behind subjects' archiving, which go beyond information retrieval to include creating a legacy, sharing resources, confronting fears and anxieties, and identity construction. We then show how these rationales were mapped into our subjects' physical, social and electronic spaces, and discuss implications for development of digital tools that allow for personal archiving."
    },
    {
        "title": "Peripheral display of digital handwritten notes",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Personal information management",
        "data": "April 2006",
        "authors": [
            "Gary Hsieh",
            "Kenneth Wood",
            "Abigail Sellen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124815",
        "citation": "9",
        "abstract": "We present a system for the peripheral display of digital handwritten notes, motivated by the joint observation that people seldom refer back to their notes and that these notes often contain useful information. We describe the user-led design of the system, incorporating interviews, paper prototypes, and interactive prototypes. A preliminary field trial of the system indicates that users derive value from the system both for low-distraction reminding and for serendipitous idea generation. These promising initial results suggest significant scope for future work."
    },
    {
        "title": "Perspective cursor: perspective-based interaction for multi-display environments",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multidisplay environments",
        "data": "April 2006",
        "authors": [
            "Miguel A. Nacenta",
            "Samer Sallam",
            "Bernard Champoux",
            "Sriram Subramanian",
            "Carl Gutwin"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124817",
        "citation": "63",
        "abstract": "Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance."
    },
    {
        "title": "Improving selection of off-screen targets with hopping",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multidisplay environments",
        "data": "April 2006",
        "authors": [
            "Pourang Irani",
            "Carl Gutwin",
            "Xing Dong Yang"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124818",
        "citation": "39",
        "abstract": "Many systems provide the user with a limited viewport of a larger graphical workspace. In these systems, the user often needs to find and select targets that are in the workspace, but not visible in the current view. Standard methods for navigating to the off-screen targets include scrolling, panning, and zooming; however, these are laborious when users cannot see a target's direction or distance. Techniques such as halos can provide awareness of targets, but actually getting to the target is still slow with standard navigation. To improve off-screen target selection, we developed a new technique called hop, which combines halos with a teleportation mechanism that shows proxies of distant objects. Hop provides both awareness of off-screen targets and fast navigation to the target context. A study showed that users are significantly faster at selecting off-screen targets with hopping than with two-level zooming or grab-and-drag panning, and it is clear that hop will be faster than either halos or proxy-based techniques (like drag-and-pop or vacuum filtering) by themselves. Hop both improves on halo-based navigation and extends the value of proxies to small-screen environments."
    },
    {
        "title": "Effects of display position and control space orientation on user preference and performance",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Multidisplay environments",
        "data": "April 2006",
        "authors": [
            "Daniel Wigdor",
            "Chia Shen",
            "Clifton Forlines",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124819",
        "citation": "39",
        "abstract": "In many environments, it is often the case that input is made to displays that are positioned non-traditionally relative to one or more users. This typically requires users to perform interaction tasks under transformed input-display spatial mappings, and the literature is unclear as to how such transformations affect performance. We present two experiments that explore the impact of display space position and input control space orientation on user's subjective preference and objective performance in a docking task. Our results provide guidelines as to optimal display placement and control orientation in collaborative computing environments with one or more shared displays."
    },
    {
        "title": "The benefits of augmenting telephone voice menu navigation with visual browsing and search",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing voice input",
        "data": "April 2006",
        "authors": [
            "Min Yin",
            "Shumin Zhai"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124821",
        "citation": "20",
        "abstract": "Automatic interactive voice response (IVR) based telephone routing has long been recognized as a frustrating interaction experience. This paper presents a series of experiments examining the benefits of augmenting telephone voice menus with coordinated visual displays and keyword search. The first experiment qualitatively studied callers' experience of having a visual menu on a screen in synchronization with the telephone voice menu tree navigation. The second experiment quantitatively measured callers' performance in time and accuracy with and without visual display augmentation. The third experiment tested keyword search in comparison to visual browsing of telephone menu trees. Study participants uniformly and enthusiastically liked the visual augmentation of voice menus. On average with visual augmentation callers could navigate phone trees 36% faster with 75% fewer errors, and made choices ahead of the voice menu over 60% of the time. Search vs. browsing had similar navigation performance but offered different and complementary user experiences. Overall our studies conclude that telephone voice menu navigation can be significantly improved with a visual channel augmentation, resulting in both business cost reduction and user experience satisfaction."
    },
    {
        "title": "Time is of the essence: an evaluation of temporal compression algorithms",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing voice input",
        "data": "April 2006",
        "authors": [
            "Simon Tucker",
            "Steve Whittaker"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124822",
        "citation": "19",
        "abstract": "Although speech is a potentially rich information source, a major barrier to exploiting speech archives is the lack of useful tools for efficiently accessing lengthy speech recordings. This paper develops and evaluates techniques for temporal compression - reducing the time people take to listen to a recording while still extracting critical information. We first describe an exploratory study that identifies novel excision techniques that remove unimportant words or utterances from the recording. We then develop a new method for evaluating how well temporal compression supports users in forming a general understanding of a recording. Applying this method, we demonstrate that excision techniques are generally more effective than standard compression techniques that simply speed up the entire recording."
    },
    {
        "title": "Error correction of voicemail transcripts in SCANMail",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Managing voice input",
        "data": "April 2006",
        "authors": [
            "Moira Burke",
            "Brian Amento",
            "Philip Isenhour"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124823",
        "citation": "11",
        "abstract": "Despite its widespread use, voicemail presents numerous usability challenges: People must listen to messages in their entirety, they cannot search by keywords, and audio files do not naturally support visual skimming. SCANMail overcomes these flaws by automatically generating text transcripts of voicemail messages and presenting them in an email-like interface. Transcripts facilitate quick browsing and permanent archive. However, errors from the automatic speech recognition (ASR) hinder the usefulness of the transcripts. The work presented here specifically addresses these problems by evaluating user-initiated error correction of transcripts. User studies of two editor interfaces-a grammar-assisted menu and simple replacement by typing-reveal reduced audio playback times and an emphasis on editing important words with the menu, suggesting its value in mobile environments where limited input capabilities are the norm and user privacy is essential. The study also adds to the scarce body of work on ASR confidence shading, suggesting that shading may be more helpful than previously reported."
    },
    {
        "title": "symSpline: symmetric two-handed spline manipulation",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction methods",
        "data": "April 2006",
        "authors": [
            "Celine Latulipe",
            "Stephen Mann",
            "Craig S. Kaplan",
            "Charlie L. A. Clarke"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124825",
        "citation": "30",
        "abstract": "We introduce symSpline: a symmetric, dual-mouse technique for the manipulation of spline curves. In symSpline, two cursors control the positions of the ends of the tangent to an edit point. By moving the tangent with both mice, the tangent and the edit point can be translated while the curvature of the spline is adjusted simultaneously, according to the length and angle of the tangent. We compare the symSpline technique to two asymmetric dual-mouse spline manipulation techniques and to a standard single-mouse technique. In a spline matching experiment, symSpline outperformed the two asymmetric dual-mouse techniques and all three dual-mouse techniques proved to be faster than the single-mouse technique. Additionally, symSpline was the technique most preferred by test participants."
    },
    {
        "title": "Effects of feedback, mobility and index of difficulty on deictic spatial audio target acquisition in the horizontal plane",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction methods",
        "data": "April 2006",
        "authors": [
            "Georgios N. Marentakis",
            "Stephen A. Brewster"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124826",
        "citation": "32",
        "abstract": "We present the results of an empirical study investigating the effect of feedback, mobility and index of difficulty on a deictic spatial audio target acquisition task in the horizontal plane in front of a user. With audio feedback, spatial audio display elements are found to enable usable deictic interac-tion that can be described using Fitts law. Feedback does not affect perceived workload or preferred walking speed compared to interaction without feedback. Mobility is found to degrade interaction speed and accuracy by 20%. Participants were able to perform deictic spatial audio target acquisition when mobile while walking at 73% of their pre-ferred walking speed. The proposed feedback design is ex-amined in detail and the effects of variable target widths are quantified. Deictic interaction with a spatial audio display is found to be a feasible solution for future interface designs."
    },
    {
        "title": "Prototyping retractable string-based interaction techniques for dual-display mobile devices",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction methods",
        "data": "April 2006",
        "authors": [
            "Gabor Blasko",
            "Chandra Narayanaswami",
            "Steven Feiner"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124827",
        "citation": "20",
        "abstract": "Accessing information on mobile and wearable devices often requires the user's visual attention, and the precise operation of virtual or physical widgets. However, these interactions may sometimes be too time-consuming and socially inappropriate. To address this, we introduce a novel input/output device that is based on the manipulation of a retractable string in a polar coordinate frame. Depending on how the user pulls the string from its enclosure--to a particular length, at a particular angle--various system features may be directly accessed. Furthermore, we present our concept for a 1D pixel array, embedded in the string that may be used as a secondary 1D display. Since it is possible to unwind the display itself and trigger functionality with a single pull, information may be accessed and presented quickly, and perceived at a glance. We present scenarios for how the string input/output device may be used in conjunc-tion with the mobile device's primary 2D display and describe our augmented reality proof-of-concept prototype."
    },
    {
        "title": "Enhancing human-machine interactions: virtual interface alteration through wearable computers",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interaction methods",
        "data": "April 2006",
        "authors": [
            "Alexandre Plouznikoff",
            "Nicolas Plouznikoff",
            "Jean-Marc Robert",
            "Michel Desmarais"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124828",
        "citation": "9",
        "abstract": "This paper studies a novel approach advocating the virtual alteration of real-world interfaces through a form of augmented reality. Following an introduction reminding the need for easy to use and more consistent interfaces across our many day to day devices, this paper makes the case for using wearable computers to enhance the interactions between humans and conventional appliances. We present the rationale behind our research and summarize our current prototype's functionalities, architecture and implementation. Preliminary results suggest that virtually altering the interface of real world devices improves execution times for simple tasks using these devices."
    },
    {
        "title": "Evaluating a fisheye view of source code",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding programs and interfaces",
        "data": "April 2006",
        "authors": [
            "Mikkel R. Jakobsen",
            "Kasper Hornbæk"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124830",
        "citation": "21",
        "abstract": "Navigating and understanding the source code of a program are highly challenging activities. This paper introduces a fisheye view of source code to a Java programming environment. The fisheye view aims to support a programmer's navigation and understanding by displaying those parts of the source code that have the highest degree of interest given the current focus. An experiment was conducted which compared the usability of the fisheye view with a common, linear presentation of source code. Sixteen participants performed tasks significantly faster with the fisheye view, although results varied dependent on the task type. The participants generally preferred the interface with the fisheye view. We analyse participants' interaction with the fisheye view and suggest how to improve its performance. In the calculation of the degree of interest, we suggest to emphasize those parts of the source code that are semantically related to the programmer's current focus."
    },
    {
        "title": "Barista: An implementation framework for enabling new tools, interaction techniques and views in code editors",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding programs and interfaces",
        "data": "April 2006",
        "authors": [
            "Amy J. Ko",
            "Brad A. Myers"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124831",
        "citation": "56",
        "abstract": "Recent advances in programming environments have focused on improving programmer productivity by utilizing the inherent structure in computer programs. However, because these environments represent code as plain text, it is difficult and sometimes impossible to embed interactive tools, annotations, and alternative views in the code itself. Barista is an implementation framework that enables the creation of such user interfaces by simplifying the implementation of editors that represent code internally as an abstract syntax tree and maintain a corresponding, fully structured visual representation on-screen. Barista also provides designers of editors with a standard text-editing interaction technique that closely mimics that of conventional text editors, overcoming a central usability issue of previous structured code editors."
    },
    {
        "title": "Answering why and why not questions in user interfaces",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Understanding programs and interfaces",
        "data": "April 2006",
        "authors": [
            "Brad A. Myers",
            "David A. Weitzman",
            "Amy J. Ko",
            "Duen H. Chau"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124832",
        "citation": "51",
        "abstract": "Modern applications such as Microsoft Word have many automatic features and hidden dependencies that are frequently helpful but can be mysterious to both novice and expert users. The \"\"Crystal\"\" application framework provides an architecture and interaction techniques that allow programmers to create applications that let the user ask a wide variety of questions about why things did and did not happen, and how to use the related features of the application without using natural language. A user can point to an object or a blank space and get a popup list of questions about it, or the user can ask about recent actions from a temporal list. Parts of a text editor were implemented to show that these techniques are feasible, and a user test suggests that they are helpful and well-liked."
    },
    {
        "title": "\"Alone together?\": exploring the social dynamics of massively multiplayer online games",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games and performances",
        "data": "April 2006",
        "authors": [
            "Nicolas Ducheneaut",
            "Nicholas Yee",
            "Eric Nickell",
            "Robert J. Moore"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124834",
        "citation": "387",
        "abstract": "Massively Multiplayer Online Games (MMOGs) routinely attract millions of players but little empirical data is available to assess their players' social experiences. In this paper, we use longitudinal data collected directly from the game to examine play and grouping patterns in one of the largest MMOGs: World of Warcraft. Our observations show that the prevalence and extent of social activities in MMOGs might have been previously over-estimated, and that gaming communities face important challenges affecting their cohesion and eventual longevity. We discuss the implications of our findings for the design of future games and other online social spaces."
    },
    {
        "title": "Interweaving mobile games with everyday life",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games and performances",
        "data": "April 2006",
        "authors": [
            "Marek Bell",
            "Matthew Chalmers",
            "Louise Barkhuus",
            "Malcolm Hall",
            "Scott Sherwood",
            "Paul Tennent",
            "Barry Brown",
            "Duncan Rowland",
            "Steve Benford",
            "Mauricio Capra",
            "Alastair Hampshire"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124835",
        "citation": "195",
        "abstract": "We introduce a location--based game called Feeding Yoshi that provides an example of seamful design, in which key characteristics of its underlying technologies-the coverage and security characteristics of WiFi-are exposed as a core element of gameplay. Feeding Yoshi is also a long--term, wide--area game, being played over a week between three different cities during an initial user study. The study, drawing on participant diaries and interviews, supported by observation and analysis of system logs, reveals players' reactions to the game. We see the different ways in which they embedded play into the patterns of their daily lives, augmenting existing practices and creating new ones, and observe the impact of varying location on both the ease and feel of play. We identify potential design extensions to Feeding Yoshi and conclude that seamful design provides a route to creating engaging experiences that are well adapted to their underlying technologies."
    },
    {
        "title": "The Frame of the Game: Blurring the Boundary between Fiction and Reality in Mobile Experiences",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Games and performances",
        "data": "April 2006",
        "authors": [
            "Steve Benford",
            "Andy Crabtree",
            "Stuart Reeves",
            "Jennifer Sheridan",
            "Alan Dix",
            "Martin Flintham",
            "Adam Drozd"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124836",
        "citation": "138",
        "abstract": "Mobile experiences that take place in public settings such as on city streets create new opportunities for interweaving the fictional world of a performance or game with the everyday physical world. A study of a touring performance reveals how designers generated excitement and dramatic tension by implicating bystanders and encouraging the (apparent) crossing of normal boundaries of behaviour. The study also shows how designers dealt with associated risks through a process of careful orchestration. Consequently, we extend an existing framework for designing spectator interfaces with the concept of performance frames, enabling us to distinguish audience from bystanders. We conclude that using ambiguity to blur the frame can be a powerful design tactic, empowering players to willingly suspend disbelief, so long as a safety-net of orchestration ensures that they do not stray into genuine difficulty."
    },
    {
        "title": "Getting a grip on tangible interaction: a framework on physical space and social interaction",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Designing for tangible interactions",
        "data": "April 2006",
        "authors": [
            "Eva Hornecker",
            "Jacob Buur"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124838",
        "citation": "622",
        "abstract": "Our current understanding of human interaction with hybrid or augmented environments is very limited. Here we focus on 'tangible interaction', denoting systems that rely on embodied interaction, tangible manipulation, physical representation of data, and embeddedness in real space. This synthesis of prior 'tangible' definitions enables us to address a larger design space and to integrate approaches from different disciplines. We introduce a framework that focuses on the interweaving of the material/physical and the social, contributes to understanding the (social) user experience of tangible interaction, and provides concepts and perspectives for considering the social aspects of tangible interaction. This understanding lays the ground for evolving knowledge on collaboration-sensitive tangible interaction design. Lastly, we analyze three case studies, using the framework, thereby illustrating the concepts and demonstrating their utility as analytical tools."
    },
    {
        "title": "Finding design qualities in a tangible programming space",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Designing for tangible interactions",
        "data": "April 2006",
        "authors": [
            "Ylva Fernaeus",
            "Jakob Tholander"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124839",
        "citation": "96",
        "abstract": "We reflect upon the process of developing a tangible space for children's collaborative construction of screen-based systems. As in all design work, the design process involved continual refinements of initial ideas and their practical realisation. We discuss how some widely held assumptions often put forward with tangible interfaces were given up in favour of reaching overall goals of interaction. In particular our design involved a shift from a focus on persistent representation and readability of tangible code structures, to instead focus on achieving reusability of programming resources. On a general level, our results illustrate a view on tangibles as resources for action instead of only as alternative forms of data representation. Importantly, this view includes action directed towards the computer as well as off-line socially oriented action conducted with the tangible artefacts."
    },
    {
        "title": "Design requirements for technologies that encourage physical activity",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Designing for tangible interactions",
        "data": "April 2006",
        "authors": [
            "Sunny Consolvo",
            "Katherine Everitt",
            "Ian Smith",
            "James A. Landay"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124840",
        "citation": "555",
        "abstract": "Overweight and obesity are a global epidemic, with over one billion overweight adults worldwide (300+ million of whom are obese). Obesity is linked to several serious health problems and medical conditions. Medical experts agree that physical activity is critical to maintaining fitness, reducing weight, and improving health, yet many people have difficulty increasing and maintaining physical activity in everyday life. Clinical studies have shown that health benefits can occur from simply increasing the number of steps one takes each day and that social support can motivate people to stay active. In this paper, we describe Houston, a prototype mobile phone application for encouraging activity by sharing step count with friends. We also present four design requirements for technologies that encourage physical activity that we derived from a three-week long in situ pilot study that was conducted with women who wanted to increase their physical activity."
    },
    {
        "title": "An intuitive text input method for touch wheels",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Text input",
        "data": "April 2006",
        "authors": [
            "Morten Proschowsky",
            "Nette Schultz",
            "Niels Ebbe Jacobsen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124842",
        "citation": "17",
        "abstract": "In this paper we describe a new method for doing text input with touch sensitive wheels. The method is called Transparent User guided Prediction (TUP). With TUP all characters are assigned to fixed positions on the wheel. A language prediction algorithm is used to make it easy to select the most likely characters. The use of the prediction algorithm is transparent for the users, which makes the use of TUP very intuitive. A prototype of TUP is evaluated against the date stamp method for doing wheel text input. Text entry speed for TUP is about 6-7 words per minute for novice users. This is approximately 30% faster than the date stamp method."
    },
    {
        "title": "A new error metric for text entry method evaluation",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Text input",
        "data": "April 2006",
        "authors": [
            "Jun Gong",
            "Peter Tarasewich"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124843",
        "citation": "4",
        "abstract": "On devices such as mobile phones, text is often entered using keypads and predictive text entry techniques. Current metrics used for measuring text entry error rates have limitations in terms of the types of errors they account for, and cannot easily distinguish between different types of errors. This research proposes a new text entry error metric that addresses some of the outstanding issues that exist with current metrics. Specifically, the metric accounts in detail for the way the user handles corrections during text entry, moving beyond current keystroke level error measurement. The feasibility and usefulness of this new metric is shown through the analysis of an experiment that tests an alphabetically constrained keypad design that includes upper and lower case letters, numbers, and punctuation marks."
    },
    {
        "title": "Text entry using a dual joystick game controller",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Text input",
        "data": "April 2006",
        "authors": [
            "Andrew D. Wilson",
            "Maneesh Agrawala"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124844",
        "citation": "43",
        "abstract": "We present a new bimanual text entry technique designed for today's dual-joystick game controllers. The left and right joysticks are used to independently select characters from the corresponding (left/right) half of an on-screen se-lection keyboard. Our dual-stick approach is analogous to typing on a standard keyboard, where each hand (left/right) presses keys on the corresponding side of the keyboard. We conducted a user study showing that our technique supports keyboarding skills transfer and is thereby readily learnable. Our technique increases entry speed significantly compared to the status quo single stick selection keyboard technique."
    },
    {
        "title": "Trackball text entry for people with motor impairments",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Text input",
        "data": "April 2006",
        "authors": [
            "Jacob Wobbrock",
            "Brad Myers"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124845",
        "citation": "52",
        "abstract": "We present a new gestural text entry method for trackballs. The method uses the mouse cursor and relies on crossing instead of pointing. A user writes in fluid Roman-like unistrokes by \"\"pulsing\"\" the trackball in desired letter patterns. We examine this method both theoretically using the Steering Law and empirically in two studies. Our studies show that able-bodied users who were unfamiliar with trackballs could write at about 10 wpm with <4% total errors after 45 minutes. In eight sessions, a motor-impaired trackball user peaked at 7.11 wpm with 0% uncorrected errors, compared to 5.95 wpm with 0% uncorrected errors with an on-screen keyboard. Over sessions, his speeds were significantly faster with our gestural method than with an on-screen keyboard. A former 15-year veteran of on-screen keyboards, he now uses our gestural method instead."
    },
    {
        "title": "Few-key text entry revisited: mnemonic gestures on four keys",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Text input",
        "data": "April 2006",
        "authors": [
            "Jacob Wobbrock",
            "Brad Myers",
            "Brandon Rothrock"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124846",
        "citation": "22",
        "abstract": "We present a new 4-key text entry method that, unlike most few-key methods, is gestural instead of selection-based. Importantly, its gestures mimic the writing of Roman letters for high learnability. We compare this new 4-key method to predominant 3-key and 5-key methods theoretically using KSPC and empirically using a longitudinal study of 5 subjects over 10 sessions. The study includes an evaluation of the 4-key method without any on-screen visualization-an impossible condition for the selection-based methods. Our results show that the new 4-key method is quickly learned, becoming faster than the 3-key and 5-key methods after just ~10 minutes of writing, although it produces more errors. Interestingly, removing a visualization of the gestures being made causes no detriment to the 4-key method, which is an advantage for eyes-free text entry."
    },
    {
        "title": "The effect of speech recognition accuracy rates on the usefulness and usability of webcast archives",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization and search",
        "data": "April 2006",
        "authors": [
            "Cosmin Munteanu",
            "Ronald Baecker",
            "Gerald Penn",
            "Elaine Toms",
            "David James"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124848",
        "citation": "42",
        "abstract": "The widespread availability of broadband connections has led to an increase in the use of Internet broadcasting (webcasting). Most webcasts are archived and accessed numerous times retrospectively. In the absence of transcripts of what was said, users have difficulty searching and scanning for specific topics. This research investigates user needs for transcription accuracy in webcast archives, and measures how the quality of transcripts affects user performance in a question-answering task, and how quality affects overall user experience. We tested 48 subjects in a within-subjects design under 4 conditions: perfect transcripts, transcripts with 25% Word Error Rate (WER), transcripts with 45% WER, and no transcript. Our data reveals that speech recognition accuracy linearly influences both user performance and experience, shows that transcripts with 45% WER are unsatisfactory, and suggests that transcripts having a WER of 25% or less would be useful and usable in webcast archives."
    },
    {
        "title": "Visual search and reading tasks using ClearType and regular displays: two experiments",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization and search",
        "data": "April 2006",
        "authors": [
            "Andrew Dillon",
            "Lisa Kleinman",
            "Gil Ok Choi",
            "Randolph Bias"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124849",
        "citation": "13",
        "abstract": "Two experiments comparing user performance on ClearType and Regular displays are reported. In the first, 26 participants scanned a series of spreadsheets for target information. Speed of performance was significantly faster with ClearType. In the second experiment, 25 users read two articles for meaning. Reading speed was significantly faster for ClearType. In both experiments no differences in accuracy of performance or visual fatigue scores were observed. The data also reveal substantial individual differences in performance suggesting ClearType may not be universally beneficial to information workers."
    },
    {
        "title": "Using hybrid networks for the analysis of online software development communities",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization and search",
        "data": "April 2006",
        "authors": [
            "Yevgeniy \"Eugene\" Medynskiy",
            "Nicolas Ducheneaut",
            "Ayman Farahat"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124850",
        "citation": "6",
        "abstract": "Social network-based systems usually suffer from two major limitations: they tend to rely on a single data source (e.g. email traffic), and the form of network patterns is often privileged over their content. To go beyond these limitations we describe a system we developed to visualize and navigate hybrid networks constructed from multiple data sources - with a direct link between formal representations and the raw content. We illustrate the benefits of our approach by analyzing patterns of collaboration in a large Open Source project, using hybrid networks to uncover important roles that would otherwise have been missed."
    },
    {
        "title": "Visualization of large hierarchical data by circle packing",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization and search",
        "data": "April 2006",
        "authors": [
            "Weixin Wang",
            "Hui Wang",
            "Guozhong Dai",
            "Hongan Wang"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124851",
        "citation": "108",
        "abstract": "In this paper a novel approach is described for tree visualization using nested circles. The brother nodes at the same level are represented by externally tangent circles; the tree nodes at different levels are displayed by using 2D nested circles or 3D nested cylinders. A new layout algorithm for tree structure is described. It provides a good overview for large data sets. It is easy to see all the branches and leaves of the tree. The new method has been applied to the visualization of file systems."
    },
    {
        "title": "Dispelling \"design\" as the black art of CHI",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design: creative and historical perspectives",
        "data": "April 2006",
        "authors": [
            "Tracee Vetting Wolf",
            "Jennifer A. Rode",
            "Jeremy Sussman",
            "Wendy A. Kellogg"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124853",
        "citation": "109",
        "abstract": "We discuss the legacy and processes of creative design, and differentiate it from the type of user-centered design commonly found in CHI. We provide an example of this process, and discuss how design practice constitutes an essential mode of inquiry. We argue the complementary nature of creative design and user-centered design practices. Syncretic disciplines shift and drift from their original practice. A key issue is how CHI is to respond to changes in acceptable design practice. A key contribution of this work is an illustrative example showing how designers can communicate their intellectual rigor to the CHI community."
    },
    {
        "title": "Interaction in creative tasks",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design: creative and historical perspectives",
        "data": "April 2006",
        "authors": [
            "Tim Coughlan",
            "Peter Johnson"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124854",
        "citation": "23",
        "abstract": "The design of tools for creative activities affects the creative processes and output of users. In this paper we consider how an understanding of creative interaction can inform the design of support tools in a creative domain, and where creative needs cross domain boundaries. Using observations of musical composers we analyse the theoretical approaches to understanding creativity and their use to HCI. Cycles of ideation and evaluation are suggested as atomic elements of creative interactions, with the representation of ideas a central activity for individual and collaborating composers. A model of collaborative composition was developed, along with an analysis of the representational types used in the domain. This led to the design and evaluation of a prototype Sonic Sketchpad for musical idea representation."
    },
    {
        "title": "Implications for design",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Design: creative and historical perspectives",
        "data": "April 2006",
        "authors": [
            "Paul Dourish"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124855",
        "citation": "466",
        "abstract": "Although ethnography has become a common approach in HCI research and design, considerable confusion still attends both ethnographic practice and the criteria by which it should be evaluated in HCI. Often, ethnography is seen as an approach to field investigation that can generate requirements for systems development; by that token, the major evaluative criterion for an ethnographic study is the implications it can provide for design. Exploring the nature of ethnographic inquiry, this paper suggests that \"implications for design\" may not be the best metric for evaluation and may, indeed, fail to capture the value of ethnographic investigations."
    },
    {
        "title": "Mobile phones and paper documents: evaluating a new approach for capturing microfinance data in rural India",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Information handling",
        "data": "April 2006",
        "authors": [
            "Tapan S. Parikh",
            "Paul Javid",
            "Sasikumar K.",
            "Kaushik Ghosh",
            "Kentaro Toyama"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124857",
        "citation": "120",
        "abstract": "CAM is a user interface toolkit that allows a camera-equipped mobile phone to interact with paper documents. It is designed to automate inefficient, paper-intensive information processes in the developing world. In this paper we present a usability evaluation of an application built using CAM for collecting data from microfinance groups in rural India. This application serves an important and immediate need in the microfinance industry. Our quantitative results show that the user interface is efficient, accurate and can quickly be learned by rural users. The results were competitive with an equivalent PC-based UI. Qualitatively, the interface was found easy to use by almost all users. This shows that, with a properly designed user interface, mobile phones can be a preferred platform for many rural computing applications. Voice feedback and numeric data entry were particularly well-received by users. We are conducting a pilot of this application with 400 microfinance groups in India."
    },
    {
        "title": "Handling documents and discriminating objects in hybrid spaces",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Information handling",
        "data": "April 2006",
        "authors": [
            "Paul Luff",
            "Christian Heath",
            "Hideaki Kuzuoka",
            "Keiichi Yamazaki",
            "Jun Yamashita"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124858",
        "citation": "33",
        "abstract": "Recently a number of researchers have uncovered various ways in which paper documents support everyday work practice and have suggested how these may be reflected in the design of new technologies. In this paper we consider how activities on and around paper documents may be supported when participants are remote from each other. When we consider the uses of an experimental system that provides a number of resources for supporting work over documents, it becomes apparent how critical it is to support apparently simple pointing and referencing, and how complex such conduct can be. This suggests some considerations both for developers of enhanced media spaces and analysts of everyday conduct.Clarified descriptions of technology and fragments including changes to figures. Added points concerning the scope of the technology the conception of sequence and calrified the requirement regarding redundancy. Revised descriptions of fragments in an atempt to make thsee less dense Corrected several typographic errors including those mentioned by the reviewers' gesture."
    },
    {
        "title": "ButterflyNet: a mobile capture and access system for field biology research",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Information handling",
        "data": "April 2006",
        "authors": [
            "Ron Yeh",
            "Chunyuan Liao",
            "Scott Klemmer",
            "François Guimbretière",
            "Brian Lee",
            "Boyko Kakaradov",
            "Jeannie Stamberger",
            "Andreas Paepcke"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124859",
        "citation": "156",
        "abstract": "Through a study of field biology practices, we observed that biology fieldwork generates a wealth of heterogeneous information, requiring substantial labor to coordinate and distill. To manage this data, biologists leverage a diverse set of tools, organizing their effort in paper notebooks. These observations motivated ButterflyNet, a mobile capture and access system that integrates paper notes with digital photographs captured during field research. Through ButterflyNet, the activity of leafing through a notebook expands to browsing all associated digital photos. ButterflyNet also facilitates the transfer of captured content to spreadsheets, enabling biologists to share their work. A first-use study with 14 biologists found this system to offer rich data capture and transformation, in a manner felicitous with current practice."
    },
    {
        "title": "Why phishing works",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security",
        "data": "April 2006",
        "authors": [
            "Rachna Dhamija",
            "J. D. Tygar",
            "Marti Hearst"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124861",
        "citation": "753",
        "abstract": "To build systems shielding users from fraudulent (or phishing) websites, designers need to know which attack strategies work and why. This paper provides the first empirical evidence about which malicious strategies are successful at deceiving general users. We first analyzed a large set of captured phishing attacks and developed a set of hypotheses about why these strategies might work. We then assessed these hypotheses with a usability study in which 22 participants were shown 20 web sites and asked to determine which ones were fraudulent. We found that 23% of the participants did not look at browser-based cues such as the address bar, status bar and the security indicators, leading to incorrect choices 40% of the time. We also found that some visual deception attacks can fool even the most sophisticated users. These results illustrate that standard security indicators are not effective for a substantial fraction of users, and suggest that alternative approaches are needed."
    },
    {
        "title": "Secrecy, flagging, and paranoia: adoption criteria in encrypted email",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security",
        "data": "April 2006",
        "authors": [
            "Shirley Gaw",
            "Edward W. Felten",
            "Patricia Fernandez-Kelly"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124862",
        "citation": "71",
        "abstract": "We consider the social context behind users' decisions about whether and when to encrypt email, interviewing a sample of users from an organization whose mission requires secrecy. Interview participants varied in their level of technical sophistication and in their involvement with secrets. We found that users saw universal, routine use of encryption as paranoid. Encryption flagged a message not only as confidential but also as urgent, so users found the encryption of mundane messages annoying. In general, decisions about encryption were driven not just by technical issues such as usability, but also by social factors. We argue that understanding these social factors is necessary to guide the design of encryption technologies that can be more widely adopted."
    },
    {
        "title": "Do security toolbars actually prevent phishing attacks?",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Security",
        "data": "April 2006",
        "authors": [
            "Min Wu",
            "Robert C. Miller",
            "Simson L. Garfinkel"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124863",
        "citation": "351",
        "abstract": "Security toolbars in a web browser show security-related information about a website to help users detect phishing attacks. Because the toolbars are designed for humans to use, they should be evaluated for usability -- that is, whether these toolbars really prevent users from being tricked into providing personal information. We conducted two user studies of three security toolbars and other browser security indicators and found them all ineffective at preventing phishing attacks. Even though subjects were asked to pay attention to the toolbar, many failed to look at it; others disregarded or explained away the toolbars' warnings if the content of web pages looked legitimate. We found that many subjects do not understand phishing attacks or realize how sophisticated such attacks can be."
    },
    {
        "title": "UNIFORM: automatically generating consistent remote control user interfaces",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automatic generation and usability",
        "data": "April 2006",
        "authors": [
            "Jeffrey Nichols",
            "Brad A. Myers",
            "Brandon Rothrock"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124865",
        "citation": "41",
        "abstract": "A problem with many of today's appliance interfaces is that they are inconsistent. For example, the procedure for setting the time on alarm clocks and VCRs differs, even among different models made by the same manufacturer. Finding particular functions can also be a challenge, because appliances often organize their features differently. This paper presents a system, called Uniform, which approaches this problem by automatically generating remote control interfaces that take into account previous interfaces that the user has seen during the generation process. Uniform is able to automatically identify similarities between different devices and users may specify additional similarities. The similarity information allows the interface generator to use the same type of controls for similar functions, place similar functions so that they can be found with the same navigation steps, and create interfaces that have a similar visual appearance."
    },
    {
        "title": "Generating automated predictions of behavior strategically adapted to specific performance objectives",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automatic generation and usability",
        "data": "April 2006",
        "authors": [
            "Katherine Eng",
            "Richard L. Lewis",
            "Irene Tollinger",
            "Alina Chu",
            "Andrew Howes",
            "Alonso Vera"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124866",
        "citation": "17",
        "abstract": "It has been well established in Cognitive Psychology that humans are able to strategically adapt performance, even highly skilled performance, to meet explicit task goals such as being accurate (rather than fast). This paper describes a new capability for generating multiple human performance predictions from a single task specification as a function of different performance objective functions. As a demonstration of this capability, the Cognitive Constraint Modeling approach was used to develop models for several tasks across two interfaces from the aviation domain. Performance objectives are explicitly declared as part of the model, and the CORE (Constraint-based Optimal Reasoning Engine) architecture itself formally derives the detailed strategies that are maximally adapted to these objectives. The models are analyzed for emergent strategic variation, comparing those optimized for task time with those optimized for working memory load. The approach has potential application in user interface and procedure design."
    },
    {
        "title": "Automated summative usability studies: an empirical evaluation",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Automatic generation and usability",
        "data": "April 2006",
        "authors": [
            "Ryan West",
            "Katherine Lehman"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124867",
        "citation": "14",
        "abstract": "This paper evaluates a method for summative usability testing using an automated data collection system. We found automated summative testing to be a simple and effective alternative to lab-based summative testing and could be successfully conducted remotely. In our study, a web-based control window led participants through the summative study, provided tasks to perform, and asked follow up questions about the user experience. Using a within-group comparison, we found no major differences between data collected by a usability engineer and that collected through an automated testing system for performance metrics. Using a between-group comparison, we found automated summative studies could be conducted remotely with minor but acceptable differences in time on task and likelihood to give up on a task compared to lab-based testing. Task success and task satisfaction ratings were not different between remote and lab-based summative testing. Written comments provided by participants through the testing system were sufficient to identify the major usability problems that led to task failure but did not reveal as comprehensive a set of issues as did a usability engineer observing the sessions."
    },
    {
        "title": "Olfoto: designing a smell-based interaction",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Media",
        "data": "April 2006",
        "authors": [
            "Stephen Brewster",
            "David McGookin",
            "Christopher Miller"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124869",
        "citation": "88",
        "abstract": "We present a study into the use of smell for searching digi-tal photo collections. Many people now have large photo libraries on their computers and effective search tools are needed. Smell has a strong link to memory and emotion so may be a good way to cue recall when searching. Our study compared text and smell based tagging. For the first stage we generated a set of smell and tag names from user de-scriptions of photos, participants then used these to tag pho-tos, returning two weeks later to answer questions on their photos. Results showed that participants could tag effec-tively with text labels, as this is a common and familiar task. Performance with smells was lower but participants performed significantly above chance, with some partici-pants using smells well. This suggests that smell has poten-tial. Results also showed that some smells were consistently identified and useful, but some were not and highlighted issues with smell delivery devices. We also discuss some practical issues of using smell for interaction."
    },
    {
        "title": "The television will be revolutionized: effects of PVRs and filesharing on television watching",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Media",
        "data": "April 2006",
        "authors": [
            "Barry Brown",
            "Louise Barkhuus"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124870",
        "citation": "32",
        "abstract": "This paper investigates television-watching practices amongst early adopters of personal hard-disk video recorders (PVRs such as TiVotm) and Internet downloading of shows. Through in-depth interviews with early adopters, we describe how the rhythms of television watching change when decoupled from broadcast TV. For both the PVR users and downloaders TV watching has become less of a passive process, with viewers instead actively gathered shows from the schedules or online, and watching shows from their stored collection. From these results we discuss the 'video media lifecycle', and three new design concepts for supporting TV watching."
    },
    {
        "title": "Personal vs. commercial content: the similarities between consumer use of photos and music",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Media",
        "data": "April 2006",
        "authors": [
            "Frank Bentley",
            "Crysta Metcalf",
            "Gunnar Harboe"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124871",
        "citation": "72",
        "abstract": "We describe the results of two ethnographic-style studies that investigated consumer use of photos and music respectively. Although the studies were designed, executed, and analyzed separately, in our findings we discovered striking similarities between the ways in which our participants used personally captured photos and commercially purchased music. These findings have implications for the design of future systems with respect to handling and sharing content in photo or music form. We discuss making allowances for satisficing behavior, sharing media as a way to reminisce or to communicate an experience (tell a story), getting sidetracked while browsing, and similarities in organizing behaviors."
    },
    {
        "title": "TAP: touch-and-play",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Ubiquitous computing",
        "data": "April 2006",
        "authors": [
            "Duck Gun Park",
            "Jin Kyung Kim",
            "Jin Bong Sung",
            "Jung Hwan Hwang",
            "Chang Hee Hyung",
            "Sung Weon Kang"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124873",
        "citation": "35",
        "abstract": "An intuitive context aware service between two devices is possible using touch with the intrabody communication. Using this technology, users with multimedia devices may simply touch them to establish network connection, transfer data, and provide the required service; hence the name Touch-And-Play (TAP). Using TAP, users can disclose their context by touching the specific device. For instance, a user carrying a digital camera touches the TV to begin a slide show or a printer to print a photo. TAP is expected to enable the provision of intuitive, context-aware service. This paper discusses the feasibility of TAP and its application in user interface."
    },
    {
        "title": "Beyond record and play: backpacks: tangible modulators for kinetic behavior",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Ubiquitous computing",
        "data": "April 2006",
        "authors": [
            "Hayes Raffle",
            "Amanda Parkes",
            "Hiroshi Ishii",
            "Joshua Lifton"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124874",
        "citation": "10",
        "abstract": "Digital Manipulatives embed computation in familiar children's toys and provide means for children to design behavior. Some systems use \"record and play\" as a form of programming by demonstration that is intuitive and easy to learn. With others, children write symbolic programs with a GUI and download them into a toy, an approach that is conceptually extensible, but is inconsistent with the physicality of educational manipulatives. The challenge we address is to create a tangible interface that can retain the immediacy and emotional engagement of \"record and play\" and incorporate a mechanism for real time and direct modulation of behavior during program execution.We introduce the Backpacks, modular physical components that children can incorporate into robotic creations to modulate frequency, amplitude, phase and orientation of motion recordings. Using Backpacks, children can investigate basic kinematic principles that underly why their specific creations exhibit the specific behaviors they observe. We demonstrate that Backpacks make tangible some of the benefits of symbolic abstraction, and introduce sensors, feedback and behavior modulation to the record and play paradigm. Through our review of user studies with children ages 6-15, we argue that Backpacks extend the conceptual limits of record and play with an interface that is consistent with both the physicality of educational manipulatives and the local-global systems dynamics that are characteristic of complex robots."
    },
    {
        "title": "Embedded phenomena: supporting science learning with classroom-sized distributed simulations",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Ubiquitous computing",
        "data": "April 2006",
        "authors": [
            "Tom Moher"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124875",
        "citation": "47",
        "abstract": "'Embedded phenomena' is a learning technology framework in which simulated scientific phenomena are mapped onto the physical space of classrooms. Students monitor and control the local state of the simulation through distributed media positioned around the room, gathering and aggregating evidence to solve problems or answer questions related to those phenomena. Embedded phenomena are persistent, running continuously over weeks and months, creating information channels that are temporally and physically interleaved with, but asynchronous with respect to, the regular flow of instruction. In this paper, we describe the motivations for the framework, describe classroom experiences with three embedded phenomena in the domains of seismology, insect ecology, and astronomy, and situate embedded phenomena within the context of human-computer interaction research in co-located group interfaces and learning technologies."
    },
    {
        "title": "A large scale study of wireless search behavior: Google mobile search",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search and navigation: mobiles and audio",
        "data": "April 2006",
        "authors": [
            "Maryam Kamvar",
            "Shumeet Baluja"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124877",
        "citation": "212",
        "abstract": "We present a large scale study of search patterns on Google's mobile search interface. Our goal is to understand the current state of wireless search by analyzing over 1 Million hits to Google's mobile search sites. Our study also includes the examination of search queries and the general categories under which they fall. We follow users throughout multiple interactions to determine search behavior; we estimate how long they spend inputting a query, viewing the search results, and how often they click on a search result. We also compare and contrast search patterns between 12-key keypad phones (cellphones), phones with QWERTY keyboards (PDAs) and conventional computers."
    },
    {
        "title": "FaThumb: a facet-based interface for mobile search",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search and navigation: mobiles and audio",
        "data": "April 2006",
        "authors": [
            "Amy K. Karlson",
            "George G. Robertson",
            "Daniel C. Robbins",
            "Mary P. Czerwinski",
            "Greg R. Smith"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124878",
        "citation": "83",
        "abstract": "In this paper we describe a novel approach for searching large data sets from a mobile phone. Existing interfaces for mobile search require keyword text entry and are not suited for browsing. Our alternative uses a hybrid model to de-emphasize tedious keyword entry in favor of iterative data filtering. We propose navigation and selection of hierarchical metadata (facet navigation), with incremental text entry to further narrow the results. We conducted a formative evaluation to understand the relative advantages of keyword entry versus facet navigation for both browse and search tasks on the phone. We found keyword entry to be more powerful when the name of the search target is known, while facet navigation is otherwise more effective and strongly preferred."
    },
    {
        "title": "Searching in audio: the utility of transcripts, dichotic presentation, and time-compression",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Search and navigation: mobiles and audio",
        "data": "April 2006",
        "authors": [
            "Abhishek Ranjan",
            "Ravin Balakrishnan",
            "Mark Chignell"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124879",
        "citation": "9",
        "abstract": "Searching audio data can potentially be facilitated by the use of automatic speech recognition (ASR) technology to generate text transcripts which can then be easily queried. However, since current ASR technology cannot reliably generate 100% accurate transcripts, additional techniques for fluid browsing and searching of the audio itself are required. We explore the impact of transcripts of various qualities, dichotic presentation, and time-compression on an audio search task. Results show that dichotic presentation and reasonably accurate transcripts can assist in the search process, but suggest that time-compression and low accuracy transcripts should be used carefully."
    },
    {
        "title": "Responsiveness in instant messaging: predictive models supporting inter-personal communication",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using knowledge to predict and manage",
        "data": "April 2006",
        "authors": [
            "Daniel Avrahami",
            "Scott E. Hudson"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124881",
        "citation": "55",
        "abstract": "For the majority of us, inter-personal communication is an essential part of our daily lives. Instant Messaging, or IM, has been growing in popularity for personal and work-related communication. The low cost of sending a message, combined with the limited awareness provided by current IM systems result in messages often arriving at inconvenient or disruptive times. In a step towards solving this problem, we created statistical models that successfully predict responsiveness to incoming instant messages -- simply put: whether the receiver is likely to respond to a message within a certain time period. These models were constructed using a large corpus of real IM interaction collected from 16 participants, including over 90,000 messages. The models we present can predict, with accuracy as high as 90.1%, whether a message sent to begin a new session of communication would get a response within 30 seconds, 1, 2, 5, and 10 minutes. This type of prediction can be used, for example, to drive online-status indicators, or in services aimed at finding potential communicators."
    },
    {
        "title": "Leveraging characteristics of task structure to predict the cost of interruption",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using knowledge to predict and manage",
        "data": "April 2006",
        "authors": [
            "Shamsi T. Iqbal",
            "Brian P. Bailey"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124882",
        "citation": "91",
        "abstract": "A challenge in building interruption reasoning systems is to compute an accurate cost of interruption (COI). Prior work has used interface events and other cues to predict COI, but ignore characteristics related to the structure of a task. This work investigates how well characteristics of task structure can predict COI, as objectively measured by resumption lag. In an experiment, users were interrupted during task execution at various boundaries to collect a large sample of resumption lag values. Statistical methods were employed to create a parsimonious model that uses characteristics of task structure to predict COI. A subsequent experiment with different tasks showed that the model can predict COI with reasonably high accuracy. Our model can be expediently applied to many goal-directed tasks, allowing systems to make more effective decisions about when to interrupt."
    },
    {
        "title": "A goal-oriented web browser",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Using knowledge to predict and manage",
        "data": "April 2006",
        "authors": [
            "Alexander Faaborg",
            "Henry Lieberman"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124883",
        "citation": "44",
        "abstract": "Many users are familiar with the interesting but limited functionality of Data Detector interfaces like Microsoft's Smart Tags and Google's AutoLink. In this paper we significantly expand the breadth and functionality of this type of user interface through the use of large-scale knowledge bases of semantic information. The result is a Web browser that is able to generate personalized semantic hypertext, providing a goal-oriented browsing experience.We present (1) Creo, a Programming by Example system for the Web that allows users to create a general-purpose procedure with a single example, and (2) Miro, a Data Detector that matches the content of a page to high-level user goals.An evaluation with 34 subjects found that they were more efficient using our system, and that the subjects would use features like these if they were integrated into their Web browser."
    },
    {
        "title": "Understanding photowork",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collecting and editing photos",
        "data": "April 2006",
        "authors": [
            "David Kirk",
            "Abigail Sellen",
            "Carsten Rother",
            "Ken Wood"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124885",
        "citation": "216",
        "abstract": "In this paper we introduce the notion of \"photowork\" as the activities people perform with their digital photos after cap-ture but prior to end use such as sharing. Surprisingly, these processes of reviewing, downloading, organizing, editing, sorting and filing have received little attention in the litera-ture yet they form the context for a large amount of the 'search' and 'browse' activities so commonly referred to in studies of digital photo software. Through a deeper under-standing of photowork using field observation and inter-views, we seek to highlight its significance as an interaction practice. At the same time, we discover how \"search\" as it is usually defined may have much less relevance than new ways of browsing for the design of new digital photo tools, in particular, browsing in support of the photowork activi-ties we describe."
    },
    {
        "title": "Gaze-based interaction for semi-automatic photo cropping",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collecting and editing photos",
        "data": "April 2006",
        "authors": [
            "Anthony Santella",
            "Maneesh Agrawala",
            "Doug DeCarlo",
            "David Salesin",
            "Michael Cohen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124886",
        "citation": "272",
        "abstract": "We present an interactive method for cropping photographs given minimal information about important content location, provided by eye tracking. Cropping is formulated in a general optimization framework that facilitates adding new composition rules, and adapting the system to particular applications. Our system uses fixation data</ to identify important image content and compute the best crop for any given aspect ratio or size, enabling applications such as automatic snapshot recomposition, adaptive documents, and thumbnailing. We validate our approach with studies in which users compare our crops to ones produced by hand and by a completely automatic approach. Experiments show that viewers prefer our gaze-based crops to uncropped images and fully automatic crops."
    },
    {
        "title": "Tabletop sharing of digital photographs for the elderly",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Collecting and editing photos",
        "data": "April 2006",
        "authors": [
            "Trent Apted",
            "Judy Kay",
            "Aaron Quigley"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124887",
        "citation": "116",
        "abstract": "We have recently begun to see hardware support for the tabletop user interface, offering a number of new ways for humans to interact with computers. Tabletops offer great potential for face-to-face social interaction; advances in touch technology and computer graphics provide natural ways to directly manipulate virtual objects, which we can display on the tabletop surface. Such an interface has the potential to benefit a wide range of the population and it is important that we design for usability and learnability with diverse groups of people.This paper describes the design of SharePic -- a multiuser, multi-touch, gestural, collaborative digital photograph sharing application for a tabletop -- and our evaluation with both young adult and elderly user groups. We describe the guidelines we have developed for the design of tabletop interfaces for a range of adult users, including elders, and the user interface we have built based on them. Novel aspects of the interface include a design strongly influenced by the metaphor of physical photographs placed on the table with interaction techniques designed to be easy to learn and easy to remember. In our evaluation, we gave users the final task of creating a digital postcard from a collage of photographs and performed a realistic think-aloud with pairs of novice participants learning together, from a tutorial script."
    },
    {
        "title": "GUESS: a language and interface for graph exploration",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization 1",
        "data": "April 2006",
        "authors": [
            "Eytan Adar"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124889",
        "citation": "110",
        "abstract": "As graph models are applied to more widely varying fields, researchers struggle with tools for exploring and analyzing these structures. We describe GUESS, a novel system for graph exploration that combines an interpreted language with a graphical front end that allows researchers to rapidly prototype and deploy new visualizations. GUESS also contains a novel, interactive interpreter that connects the language and interface in a way that facilities exploratory visualization tasks. Our language, Gython, is a domain-specific embedded language which provides all the advantages of Python with new, graph specific operators, primitives, and shortcuts. We highlight key aspects of the system in the context of a large user survey and specific, real-world, case studies ranging from social and knowledge networks to distributed computer network analysis."
    },
    {
        "title": "The Sandbox for analysis: concepts and methods",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization 1",
        "data": "April 2006",
        "authors": [
            "William Wright",
            "David Schroh",
            "Pascale Proulx",
            "Alex Skaburskis",
            "Brian Cort"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124890",
        "citation": "133",
        "abstract": "The Sandbox is a flexible and expressive thinking environment that supports both ad-hoc and more formal analytical tasks. It is the evidence marshalling and sense-making component for the analytical software environment called nSpace. This paper presents innovative Sandbox human information interaction capabilities and the rationale underlying them including direct observations of analysis work as well as structured interviews. Key capabilities for the Sandbox include \"put-this-there\" cognition, automatic process model templates, gestures for the fluid expression of thought, assertions with evidence and scalability mechanisms to support larger analysis tasks. The Sandbox integrates advanced computational linguistic functions using a Web Services interface and protocol. An independent third party evaluation experiment with the Sandbox has been completed. The experiment showed that analyst subjects using the Sandbox did higher quality analysis in less time than with standard tools. Usability test results indicated the analysts became proficient in using the Sandbox with three hours of training."
    },
    {
        "title": "Visual exploration of multivariate graphs",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization 1",
        "data": "April 2006",
        "authors": [
            "Martin Wattenberg"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124891",
        "citation": "160",
        "abstract": "This paper introduces PivotGraph, a software tool that uses a new technique for visualizing and analyzing graph structures. The technique is designed specifically for graphs that are \"multivariate,\" i.e., where each node is associated with several attributes. Unlike visualizations which emphasize global graph topology, PivotGraph uses a simple grid-based approach to focus on the relationship between node attributes and connections. The interaction technique is derived from an analogy with methods seen in spreadsheet pivot tables and in online analytical processing (OLAP). Finally, several examples are presented in which PivotGraph was applied to real-world data sets."
    },
    {
        "title": "Keeping up appearances: understanding the dimensions of incidental information privacy",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy 2",
        "data": "April 2006",
        "authors": [
            "Kirstie Hawkey",
            "Kori M. Inkpen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124893",
        "citation": "14",
        "abstract": "We conducted a survey of 155 participants to examine privacy concerns relating to the viewing of incidental information (i.e. traces of previous activity unrelated to the task at hand) in web browsers. We have identified several dimensions of privacy for this domain. Results revealed the scope of this problem and how location and device affect web browsing activity and contribute to the types of incidental information that may be visible. We found that there are different privacy comfort levels inherent to the participant and dependent on the context of subsequent viewing of incidental information, including the sensitivity of the content, their relationship to the viewer and the level of control retained over input devices."
    },
    {
        "title": "Being watched or being special: how I learned to stop worrying and love being monitored, surveilled, and assessed",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Privacy 2",
        "data": "April 2006",
        "authors": [
            "Erica Robles",
            "Abhay Sukumaran",
            "Kathryn Rickertsen",
            "Cliff Nass"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124894",
        "citation": "10",
        "abstract": "This paper explores the relationship between display of feedback (public vs. private) and the basis for evaluation (present vs. absent) of that feedback. Using a controlled, laboratory setting, we employ a fundamentally social, interpersonal context (speed-dating). Two participants (one male and one female) receive real-time performance feedback about either only themselves (private) or about both participants (public). We measure participant perceptions of monitoring, conformity, and self-consciousness about themselves and their dating partner. We also assess perceptions of system invasiveness, system competence, and system support. Results reveal a consistent pattern of significant interaction between feedback display and basis for evaluation conditions. In each of these interactions, public feedback with an added, trivial, basis for evaluation creates significantly lower perception of monitoring, conformity, self-consciousness, and system invasiveness, than the other three conditions. Additionally there is a main effect for basis for evaluation with respect to system competence and supportiveness. In each case, the presence of a basis produces more positive assessments than its absence. The experiment shows that reactions to being monitored and evaluated do not differ strictly along the dimension of public vs. private; basis for evaluation of feedback functions as a mediator and thus co-determines participant attitudinal responses. We discuss the implications of this at several levels, and present a broader cultural explanation in terms of the theory of rationalization. We also discuss the issues around and functionality of linking laboratory settings to larger cultural contexts in this and related fields of inquiry."
    },
    {
        "title": "Effectiveness of annotating by hand for non-alphabetical languages",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Pen",
        "data": "April 2006",
        "authors": [
            "Muhd Dzulkhiflee Hamzah",
            "Shun'ichi Tano",
            "Mitsuru Iwata",
            "Tomonori Hashiyama"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124896",
        "citation": "10",
        "abstract": "Unlike documents, annotation for multimedia information needs to be input as text, not in the form of symbols such as underlines and circles. This is problematic with keyboard input for non-alphabetical languages, especially the East Asian languages such as Chinese and Japanese, because it is labor intensive and imposes a high cognitive load. This study provides a quantitative analysis of the effectiveness of making annotations by hand during a note-taking task in Japanese. Although the lessons learned from this study come from Japanese text input, they are also generally applicable to other East Asian Languages which use ideographic characters such as Chinese. In our study, we focused on both the ergonomic and cognitive aspects and found that during annotation and note-taking task input by hand is more effective than input by keyboard. Finally, we anatomized the keyboard input problem and discuss it in this paper."
    },
    {
        "title": "Speech pen: predictive handwriting based on ambient multimodal recognition",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Pen",
        "data": "April 2006",
        "authors": [
            "Kazutaka Kurihara",
            "Masataka Goto",
            "Jun Ogata",
            "Takeo Igarashi"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124897",
        "citation": "30",
        "abstract": "It is tedious to handwrite long passages of text by hand. To make this process more efficient, we propose predictive handwriting that provides input predictions when the user writes by hand. A predictive handwriting system presents possible next words as a list and allows the user to select one to skip manual writing. Since it is not clear if people are willing to use prediction, we first run a user study to compare handwriting and selecting from the list. The result shows that, in Japanese, people prefer to select, especially when the expected performance gain from using selection is large. Based on these observations, we designed a multimodal input system, called speech-pen, that assists digital writing during lectures or presentations with background speech and handwriting recognition. The system recognizes speech and handwriting in the background and provides the instructor with predictions for further writing. The speech-pen system also allows the sharing of context information for predictions among the instructor and the audience; the result of the instructor's speech recognition is sent to the audience to support their own note-taking. Our preliminary study shows the effectiveness of this system and the implications for further improvements."
    },
    {
        "title": "Hover widgets: using the tracking state to extend the capabilities of pen-operated devices",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Pen",
        "data": "April 2006",
        "authors": [
            "Tovi Grossman",
            "Ken Hinckley",
            "Patrick Baudisch",
            "Maneesh Agrawala",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124898",
        "citation": "93",
        "abstract": "We present Hover Widgets, a new technique for increasing the capabilities of pen-based interfaces. Hover Widgets are implemented by using the pen movements above the display surface, in the tracking state. Short gestures while hovering, followed by a pen down, access the Hover Widgets, which can be used to activate localized interface widgets. By using the tracking state movements, Hover Widgets create a new command layer which is clearly distinct from the input layer of a pen interface. In a formal experiment Hover Widgets were found to be faster than a more traditional command activation technique, and also reduced errors due to divided attention."
    },
    {
        "title": "Everyday practices with mobile video telephony",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Everyday use of mobiles",
        "data": "April 2006",
        "authors": [
            "Kenton O'Hara",
            "Alison Black",
            "Matthew Lipson"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124900",
        "citation": "83",
        "abstract": "The mobile phone allowed people to communicate when and where they wanted, dramatically changing how audio telephony was integrated into daily life. With video telephony services now available on everyday mobile phones, comparable arguments are being made that this will change how people relate to and use video telephony. The mobile and personal natures of mobile phones remove factors that previously hindered use of video telephony. Mobility also brings new challenges and concerns that may hinder use of video telephony in particular contexts. With this in mind, the paper revisits the notion of video telephony but within the context of mobile phones. A study is presented of people's everyday use of mobile video telephony using diary techniques and ethnographic interviews. The study uses real episodes to highlight key motivations and circumstances under which mobile video telephony was and wasn't used. Implications for adoption of design of mobile video phones are discussed."
    },
    {
        "title": "Sashay: designing for wonderment",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Everyday use of mobiles",
        "data": "April 2006",
        "authors": [
            "Eric Paulos",
            "Chris Beckmann"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124901",
        "citation": "12",
        "abstract": "No longer confined to our offices, schools, and homes, technology is expanding at an astonishing rate across our everyday public urban landscapes. From the visible (mobile phones, laptops, and blackberries) to the invisible (GPS, WiFi, GSM, and EVDO), we find the full spectrum of digital technologies transforming nearly every facet of our urban experience. Many current urban computing systems focus on improving our efficiency and productivity in the city by providing \"location services\" and/or interactive navigation and mapping tools. While agreeing with the need for such systems, we are reminded that urban life spans a much wider range of emotions and experiences. Our claim is that our successful future urban technological tools will be those that incorporate the full range of urban experiences -- from improving productivity and efficiency to promoting wonderment and daydreaming. We discuss intervention as a research strategy for understanding wonderment; demonstrate an example of such a study using a matchbook experiment to expose relationships between locations and emotions within a city; and use the results to develop Sashay -- a mobile phone application that promotes wonderment by visualizing an individual's personal patterns across the invisible, manufactured geography of mobile phone cellular towers."
    },
    {
        "title": "Urbanhermes: social signaling with electronic fashion",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Everyday use of mobiles",
        "data": "April 2006",
        "authors": [
            "Christine M. Liu",
            "Judith S. Donath"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124902",
        "citation": "23",
        "abstract": "Humans use fashion signals to indicate access to information. While fashion is typically associated with clothing, fashion also transpires within the domain of electronic media: weblogs, discussion lists, and online communities teem continuously with fresh, digestible content. A fashionable status - well-informed and well-connected - is demonstrated through a consistent, timely, and meaningful display of newly acquired information. While production constraints of material-based fashions limit the signal refresh rate, ephemeral electronic fashions can cycle as quickly as the flow of information. The challenge we present is to develop physical objects that can go beyond the limitations of their materiality, and to signal with the rapidity of electronic fashions. We introduce the design of urbanhermes as a communicative accessory that integrates the fresh, dynamic, fluid nature of electronic-based fashion signals within the tactile, face-to-face environment of a physical space. This paper presents the design discussion within the framework of fashion as a social signal."
    },
    {
        "title": "Because I carry my cell phone anyway: functional location-based reminder applications",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Everyday use of mobiles",
        "data": "April 2006",
        "authors": [
            "Pamela J. Ludford",
            "Dan Frankowski",
            "Ken Reily",
            "Kurt Wilms",
            "Loren Terveen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124903",
        "citation": "83",
        "abstract": "Although they have potential, to date location-based information systems have not radically improved the way we interact with our surroundings. To study related issues, we developed a location-based reminder system, PlaceMail, and demonstrate its utility in supporting everyday tasks through a month-long field study. We identify current tools and practices people use to manage distributed tasks and note problems with current methods, including the common \"to-do list\". Our field study shows that PlaceMail supports useful location-based reminders and functional place-based lists. The study also sheds rich and surprising light on a new issue: when and where to deliver location-based information. The traditional 'geofence' radius around a place proves insufficient. Instead, effective delivery depends on people's movement patterns through an area and the geographic layout of the space. Our results both provide a compelling demonstration of the utility of location-based information and raise significant new challenges for location-based information distribution."
    },
    {
        "title": "From awareness to connectedness: the design and deployment of presence displays",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Awareness and presence",
        "data": "April 2006",
        "authors": [
            "Anind K. Dey",
            "Ed de Guzman"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124905",
        "citation": "90",
        "abstract": "Computer displays can be helpful for making users aware of the remote presence of friends and family. In many of the research projects that have explored the use of novel displays, the real goal is to improve a user's sense of connectedness to those remote loved ones. However, very few have leveraged a user-centered design process or empirically studied the effects of using a display on users' sense of awareness and connectedness. In this paper, we present our multi-phase, user-centered design process for building displays that support awareness and connectedness: Presence Displays, which are physical, peripheral awareness displays of online presence of close friends or family. We present evidence, from a 5-week long field study, that these displays provide significantly better awareness of and connectedness to a loved one, than a traditional graphical display of online presence."
    },
    {
        "title": "Negotiating presence-in-absence: contact, content and context",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Awareness and presence",
        "data": "April 2006",
        "authors": [
            "Steve Howard",
            "Jesper Kjeldskov",
            "Mikael B. Skov",
            "Kasper Garnæs",
            "Olga Grünberger"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124906",
        "citation": "22",
        "abstract": "On the basis of a longitudinal field study of domestic communication, we report some essential constituents of the user experience of awareness of others who are distant in space or time, i.e. presence-in-absence. We discuss presence-in-absence in terms of its social (Contact) and informational (Content) facets, and the circumstances of the experience (Context). The field evaluation of a prototype, 'The Cube', designed to support presence-in-absence, threw up issues in the interrelationships between contact, content and context; issues that the designers of similar social artifacts will need to address."
    },
    {
        "title": "Using linguistic features to measure presence in computer-mediated communication",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Awareness and presence",
        "data": "April 2006",
        "authors": [
            "Adam D. I. Kramer",
            "Lui Min Oh",
            "Susan R. Fussell"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124907",
        "citation": "21",
        "abstract": "We propose a method of measuring people's sense of presence in computer-mediated communication (CMC) systems) based on linguistic features of their dialogues. We create variations in presence by asking participants to collaborate on physical tasks in four CMC conditions. We then correlate self-reported feelings of presence with the use of specific linguistic features. Regression analyses show that 30% of the variance in self-reported presence can be accounted for by a small number of task-independent linguistic features. Even better prediction can be obtained when self-reported coordination is added to the regression equation. We conclude that linguistic measures of presence have value for studies of CMC."
    },
    {
        "title": "The paradox of the assisted user: guidance can be counterproductive",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Awareness and presence",
        "data": "April 2006",
        "authors": [
            "Christof C. van Nimwegen",
            "Daniel Burgos",
            "Herre H. van Oostendorp",
            "Hermina H. J. M. Schijf"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124908",
        "citation": "16",
        "abstract": "This paper investigates the influence of interface styles on problem solving performance. It is often assumed that performance on problem solving tasks improves when users are assisted by externalizing task-related information on the interface. Although externalization requires less recall and relieves working memory, it does not instigate planning, understanding and knowledge acquisition. Without this assistance, task-information must be internalized, stored in the user's memory, leading to more planning and thinking and perhaps to better performance and knowledge. Another variable that can influence behavior is \"Need for Cognition\" (NFC), the tendency to engage in effortful cognitive tasks. We investigated the effects of interface style and cognitive style on performance using a conference planning application. Interface style influenced behavior and performance, but NFC did not. The internalization interface led to more planful behavior and smarter solutions. When planning and learning are the aim, designers should thus beware of giving a user (too) much assistance. Understanding how people react to interface information can be crucial in designing effective software, especially important in the areas of education and learning."
    },
    {
        "title": "Investigating health management practices of individuals with diabetes",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Healthcare",
        "data": "April 2006",
        "authors": [
            "Lena Mamykina",
            "Elizabeth D. Mynatt",
            "David R. Kaufman"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124910",
        "citation": "112",
        "abstract": "Chronic diseases, endemic in the rapidly aging population, are stretching the capacity of healthcare resources. Increasingly, individuals need to adopt proactive health attitudes and contribute to the management of their own health. We investigate existing diabetes self-management practices and ways in which reflection on prior actions impacts future lifestyle choices. The findings suggest that individuals generate and evaluate hypotheses regarding health implications of their actions. Thus, health-monitoring applications can assist individuals in making educated choices by facilitating discovery of correlations between their past actions and health states. Deployment of an early prototype of a health-monitoring application demonstrated the need for careful presentation techniques to promote more robust understanding and to avoid reinforcement of biases."
    },
    {
        "title": "Tensions in designing capture technologies for an evidence-based care community",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Healthcare",
        "data": "April 2006",
        "authors": [
            "Gillian R. Hayes",
            "Gregory D. Abowd"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124911",
        "citation": "37",
        "abstract": "Evidence-based care is an increasingly popular process for long term diagnosis and monitoring of education and healthcare disabilities. Because this evidence must also be collected in everyday life, it is a technique that can greatly benefit from automated capture technologies. These solutions, however, can raise significant concerns about privacy, control, and surveillance. In this paper, we present an analysis of these concerns with regard to evidence-based care. This analysis underscores the need to consider community-based risk and reward analyses in addition to the traditionally used analyses for individual users when designing socially appropriate technologies."
    },
    {
        "title": "Pride and prejudice: learning how chronically ill people think about food",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Healthcare",
        "data": "April 2006",
        "authors": [
            "Katie A. Siek",
            "Kay H. Connelly",
            "Yvonne Rogers"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124912",
        "citation": "25",
        "abstract": "In this paper, we describe a formative study to learn how one chronically ill population thinks about food, mentally organizes food, and interprets consumption-level icons. We found that many participants let their pride influence their choices, resulting in preferred interfaces that they could not accurately interpret. The results indicate that participants organized food in similar ways, had difficulty reading from their preferred consumption-level icons, and wanted to combine multiple interface designs when searching for food."
    },
    {
        "title": "Insert movie reference here: a system to bridge conversation and item-oriented web sites",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online communities",
        "data": "April 2006",
        "authors": [
            "Sara Drenner",
            "Max Harper",
            "Dan Frankowski",
            "John Riedl",
            "Loren Terveen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124914",
        "citation": "16",
        "abstract": "Item-oriented Web sites maintain repositories of information about things such as books, games, or products. Many of these Web sites offer discussion forums. However, these forums are often disconnected from the rich data available in the item repositories. We describe a system, movie linking, that bridges a movie recommendation Web site and a movie-oriented discussion forum. Through automatic detection and an interactive component, the system recognizes references to movies in the forum and adds recommendation data to the forums and conversation threads to movie pages. An eight week observational study shows that the system was able to identify movie references with precision of .93 and recall of .78. Though users reported that the feature was useful, their behavior indicates that the feature was more successful at enriching the interface than at integrating the system."
    },
    {
        "title": "Motivating participation by displaying the value of contribution",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online communities",
        "data": "April 2006",
        "authors": [
            "Al M. Rashid",
            "Kimberly Ling",
            "Regina D. Tassone",
            "Paul Resnick",
            "Robert Kraut",
            "John Riedl"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124915",
        "citation": "115",
        "abstract": "One of the important challenges faced by designers of online communities is eliciting sufficent contributions from community members. Users in online communities may have difficulty either in finding opportunities to add value, or in understanding the value of their contributions to the community. Various social science theories suggest that showing users different perspectives on the value they add to the community will lead to differing amounts of contribution. The present study investigates a design augmentation for an existing community Web site that could benefit from additional contribution. The augmented interface includes individualized opportunities for contribution and an estimate of the value of each contribution to the community. The value is computed in one of four different ways: (1) value to self; (2) value to a small group the user has affinity with; (3) value to a small group the user does not have affinity with; and (4) value to the entire user community. The study compares the effectiveness of the different notions of value to 160 community members."
    },
    {
        "title": "Talk to me: foundations for successful individual-group interactions in online communities",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online communities",
        "data": "April 2006",
        "authors": [
            "Jaime Arguello",
            "Brian S. Butler",
            "Elisabeth Joyce",
            "Robert Kraut",
            "Kimberly S. Ling",
            "Carolyn Rosé",
            "Xiaoqing Wang"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124916",
        "citation": "232",
        "abstract": "People come to online communities seeking information, encouragement, and conversation. When a community responds, participants benefit and become more committed. Yet interactions often fail. In a longitudinal sample of 6,172 messages from 8 Usenet newsgroups, 27% of posts received no response. The information context, posters' prior engagement in the community, and the content of their posts all influenced the likelihood that they received a reply, and, as a result, their willingness to continue active participation. Posters were less likely to get a reply if they were newcomers. Posting ontopic, introducing oneself via autobiographical testimonials, asking questions, using less complex language and other features of the messages, increased replies. Results suggest ways that developers might increase the ability of online communities to support successful individual-group interactions."
    },
    {
        "title": "Routine patterns of internet use & psychological well-being: coping with a residential move",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Online communities",
        "data": "April 2006",
        "authors": [
            "Irina Shklovski",
            "Robert Kraut",
            "Jonathon Cummings"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124917",
        "citation": "18",
        "abstract": "In this paper we examine how routine uses of the Internet for communication with family and friends and for entertainment may serve as indicators of overall levels of psychological well-being. Changes in psychological well-being in response to a major life event, such as a residential move, can drive changes in routine uses of the Internet, suggesting Internet-based coping strategies. Specifically, women who report high levels of depressive affect, decrease internet use for communication. Men with similar levels of depressive affect increase internet use for entertainment. We discuss implications of these findings for our understanding of the role of the Internet in everyday behavior and instances of coping with stressful situations."
    },
    {
        "title": "Visualizing email content: portraying relationships from conversational histories",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization 2",
        "data": "April 2006",
        "authors": [
            "Fernanda B. Viégas",
            "Scott Golder",
            "Judith Donath"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124919",
        "citation": "158",
        "abstract": "We present Themail, a visualization that portrays relationships using the interaction histories preserved in email archives. Using the content of exchanged messages, it shows the words that characterize one's correspondence with an individual and how they change over the period of the relationship.This paper describes the interface and content-parsing algorithms in Themail. It also presents the results from a user study where two main interaction modes with the visualization emerged: exploration of \"big picture\" trends and themes in email (haystack mode) and more detail-oriented exploration (needle mode). Finally, the paper discusses the limitations of the content parsing approach in Themail and the implications for further research on email content visualization."
    },
    {
        "title": "Clipping lists and change borders: improving multitasking efficiency with peripheral information design",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization 2",
        "data": "April 2006",
        "authors": [
            "Tara Matthews",
            "Mary Czerwinski",
            "George Robertson",
            "Desney Tan"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124920",
        "citation": "20",
        "abstract": "Information workers often have to balance many tasks and interruptions. In this work, we explore peripheral display techniques that improve multitasking efficiency by helping users maintain task flow, know when to resume tasks, and more easily reacquire tasks. Specifically, we compare two types of abstraction that provide different task information: semantic content extraction, which displays only the most relevant content in a window, and change detection, which signals when a change has occurred in a window (all de-signed as modifications to Scalable Fabric [17]). Results from our user study suggest that semantic content extraction improves multitasking performance more so than either change detection or our base case of scaling. Results also show that semantic content extraction provides significant benefits to task flow, resumption timing, and reacquisition. We discuss the implication of these findings on the design of peripheral interfaces that support multitasking."
    },
    {
        "title": "A fisheye follow-up: further reflections on focus + context",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Visualization 2",
        "data": "April 2006",
        "authors": [
            "George W. Furnas"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124921",
        "citation": "68",
        "abstract": "Information worlds continue to grow, posing daunting challenges for interfaces. This paper tries to increase our understanding of approaches to the problem, building on the Generalized Fisheye View framework. Three issues are discussed. First a number of existing techniques are unified by the commonality of what they show, certain fisheye-related subsets, with the techniques differing only in how they show those subsets. Then the elevated importance of these subsets, and their generality, is used to discuss the possibility of non-visual fisheye-views, to attack problems not so amenable to visualization. Finally, several models are given for why these subsets might be important in user interactions, with the goal of better informing design rationales."
    },
    {
        "title": "Prototyping and sampling experience to evaluate ubiquitous computing privacy in the real world",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel methods: emotions, gestures, events",
        "data": "April 2006",
        "authors": [
            "Giovanni Iachello",
            "Khai N. Truong",
            "Gregory D. Abowd",
            "Gillian R. Hayes",
            "Molly Stevens"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124923",
        "citation": "56",
        "abstract": "We developed an inquiry technique, which we called \"paratype,\" based on experience prototyping and event-contingent experience sampling, to survey people in real-life situations about ubiquitous computing (ubicomp) technology. We used this tool to probe the opinions of the conversation partners of users of the Personal Audio Loop, a memory aid that can have a strong impact on their privacy. We present the findings of this study and their implications, specifically the need to broaden public awareness of ubicomp applications and the unfitness of traditional data protection guidelines for tackling the privacy issues of many ubicomp applications. We also point out benefits and methodological issues of paratypes and discuss why they are particularly fit for studying certain classes of mobile and ubicomp applications."
    },
    {
        "title": "Design and experimental analysis of continuous location tracking techniques for Wizard of Oz testing",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel methods: emotions, gestures, events",
        "data": "April 2006",
        "authors": [
            "Yang Li",
            "Evan Welbourne",
            "James A. Landay"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124924",
        "citation": "4",
        "abstract": "Wizard of Oz (WOz) testing has shown promise as an effective way to test location-enhanced applications. However, it is challenging to conduct a location-based WOz test because of the dynamic nature of target settings in the field. In particular, continuous location tracking, a major task in such a test, requires a wizard to frequently update a user's location to simulate a location system. This imposes a heavy task load on a wizard. To ease wizards' tasks for location tracking, we designed two techniques, Directional Crossing and Steering, and conducted a field experiment to investigate the performance of the two techniques. A quantitative analysis shows that Directional Crossing and Steering significantly lowered a wizard's task load for location tracking without sacrificing accuracy."
    },
    {
        "title": "Measuring emotional valence during interactive experiences: boys at video game play",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel methods: emotions, gestures, events",
        "data": "April 2006",
        "authors": [
            "Richard L. Hazlett"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124925",
        "citation": "93",
        "abstract": "This paper describes the use of facial electromyography (EMG) as a measure of positive and negative emotional valence during interactive experience. Thirteen boys played a car racing video game on an Xbox platform while facial EMG data were collected. Through video review positive and negative events during play were identified. The zygomaticus muscle EMG, which controls smiling, was found to be significantly greater during positive events as compared to negative. The corrugator muscle EMG, which controls frowning, was found to be significantly greater during negative events. The results of this study demonstrate that positive valence can be measured during interactive experiences with physiologic measures. This study also found that the corrugator EMG can still measure negative valence during high intensity interactive play in spite of the confounding factor of mental effort. These methods appear useful for associating the player's emotion with game events, and could be applied to HCI in general."
    },
    {
        "title": "A continuous and objective evaluation of emotional experience with interactive play environments",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Novel methods: emotions, gestures, events",
        "data": "April 2006",
        "authors": [
            "Regan L. Mandryk",
            "M. Stella Atkins",
            "Kori M. Inkpen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124926",
        "citation": "171",
        "abstract": "Researchers are using emerging technologies to develop novel play environments, while established computer and console game markets continue to grow rapidly. Even so, evaluating the success of interactive play environments is still an open research challenge. Both subjective and objective techniques fall short due to limited evaluative bandwidth; there remains no corollary in play environments to task performance with productivity systems. This paper presents a method of modeling user emotional state, based on a user's physiology, for users interacting with play technologies. Modeled emotions are powerful because they capture usability and playability through metrics relevant to ludic experience; account for user emotion; are quantitative and objective; and are represented continuously over a session. Furthermore, our modeled emotions show the same trends as reported emotions for fun, boredom, and excitement; however, the modeled emotions revealed differences between three play conditions, while the differences between the subjective reports failed to reach significance."
    },
    {
        "title": "Using intelligent task routing and contribution review to help communities build artifacts of lasting value",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 2",
        "data": "April 2006",
        "authors": [
            "Dan Cosley",
            "Dan Frankowski",
            "Loren Terveen",
            "John Riedl"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124928",
        "citation": "63",
        "abstract": "Many online communities are emerging that, like Wikipedia, bring people together to build community-maintained artifacts of lasting value (CALVs). Motivating people to contribute is a key problem because the quantity and quality of contributions ultimately determine a CALV's value. We pose two related research questions: 1) How does intelligent task routing---matching people with work---affect the quantity of contributions? 2) How does reviewing contributions before accepting them affect the quality of contributions? A field experiment with 197 contributors shows that simple, intelligent task routing algorithms have large effects. We also model the effect of reviewing contributions on the value of CALVs. The model predicts, and experimental data shows, that value grows more slowly with review before acceptance. It also predicts, surprisingly, that a CALV will reach the same final value whether contributions are reviewed before or after they are made available to the community."
    },
    {
        "title": "groupTime: preference based group scheduling",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 2",
        "data": "April 2006",
        "authors": [
            "Mike Brzozowski",
            "Kendra Carattini",
            "Scott R. Klemmer",
            "Patrick Mihelich",
            "Jiang Hu",
            "Andrew Y. Ng"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124929",
        "citation": "16",
        "abstract": "As our business, academic, and personal lives continue to move at an ever-faster pace, finding times for busy people to meet has become an art. One of the most perplexing challenges facing groupware is effective asynchronous group scheduling (GS). This paper presents a lightweight interaction model for GS that can extend its reach beyond users of current group calendaring solutions. By expressing availability in terms of preferences, we create a flexible framework for GS that preserves plausible deniability while exerting social pressure to encourage honesty among users. We also propose an ontology that enables us to model user preferences with machine learning, predicting user responses to further lower cognitive load. The combination of visualization/direct manipulation with machine learning allows users to easily and efficiently optimize meeting times. We also suggest resulting design implications for this class of intelligent user interfaces."
    },
    {
        "title": "Accounting for taste: using profile similarity to improve recommender systems",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 2",
        "data": "April 2006",
        "authors": [
            "Philip Bonhard",
            "Clare Harries",
            "John McCarthy",
            "M. Angela Sasse"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124930",
        "citation": "41",
        "abstract": "Recommender systems have been developed to address the abundance of choice we face in taste domains (films, music, restaurants) when shopping or going out. However, consumers currently struggle to evaluate the appropriateness of recommendations offered. With collaborative filtering, recommendations are based on people's ratings of items. In this paper, we propose that the usefulness of recommender systems can be improved by including more information about recommenders. We conducted a laboratory online experiment with 100 participants simulating a movie recommender system to determine how familiarity of the recommender, profile similarity between decision-maker and recommender, and rating overlap with a particular recommender influence the choices of decision-makers in such a context. While familiarity in this experiment did not affect the participants' choices, profile similarity and rating overlap had a significant influence. These results help us understand the decision-making processes in an online context and form the basis for user-centered social recommender system design."
    },
    {
        "title": "Improving menu interaction: a comparison of standard, force enhanced and jumping menus",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Menus",
        "data": "April 2006",
        "authors": [
            "David Ahlstroem",
            "Rainer Alexandrowicz",
            "Martin Hitz"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124932",
        "citation": "26",
        "abstract": "In this paper we show how a model centered analysis of the usage of the mouse click interaction action in graphical user interfaces can be used to create a new menu system. The analysis identifies a possible new usage of the click action in cascading pull-down menus which can make it easier for the user during menu navigation and selection. A new menu system which is easy to implement, the \"\"Jumping Menu\"\", is introduced. The new menu system warps the screen cursor to the right into open sub-menu levels when a mouse click is detected inside a parent item. The Jumping Menu was compared with standard pull-down menus and force enhanced menus in a user experiment. The results show that the Jumping Menu and a force enhanced menu can facilitate menu interaction and that they are promising alternatives to conventional menu systems. Based on the results, a prediction model for selection times in Jumping Menus is developed."
    },
    {
        "title": "Zone and polygon menus: using relative position to increase the breadth of multi-stroke marking menus",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Menus",
        "data": "April 2006",
        "authors": [
            "Shengdong Zhao",
            "Maneesh Agrawala",
            "Ken Hinckley"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124933",
        "citation": "68",
        "abstract": "We present Zone and Polygon menus, two new variants of multi-stroke marking menus that consider both the relative position and orientation of strokes. Our menus are designed to increase menu breadth over the 8 item limit of status quo orientation-based marking menus. An experiment shows that Zone and Polygon menus can successfully increase breadth by a factor of 2 or more over orientation-based marking menus, while maintaining high selection speed and accuracy. We also discuss hybrid techniques that may further increase menu breadth and performance. Our techniques offer UI designers new options for balancing menu breadth and depth against selection speed and accuracy."
    },
    {
        "title": "Measuring the difficulty of steering through corners",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Menus",
        "data": "April 2006",
        "authors": [
            "Robert Pastel"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124934",
        "citation": "45",
        "abstract": "The steering law is intended to predict the performance of cursor manipulations in user interfaces, but the law has been verified for only a few path shapes and should be verified for more if it is to be generalized. This study extends the steering law to paths with corners. Two experiments compare the movement times of negotiating paths with corners to straight paths with the same width and movement amplitude. The experimental results show a significant effect on the movement times due to the corners, extending far into the legs of the path's corner. Modeling the results using resource theory, a cognitive theory for divided attention, suggests that steering through corners is two simultaneous tasks: steering along the legs of the corner and aiming at the corner."
    },
    {
        "title": "Face-tracking as an augmented input in video games: enhancing presence, role-playing and control",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Selecting and tracking",
        "data": "April 2006",
        "authors": [
            "Shuo Wang",
            "Xiaocao Xiong",
            "Yan Xu",
            "Chao Wang",
            "Weiwei Zhang",
            "Xiaofeng Dai",
            "Dongmei Zhang"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124936",
        "citation": "37",
        "abstract": "Motion-detection only games have inherent limitations on game experience in that the systems cannot identify the player's existence and identity. A way of improvement is by introducing information such as a player's face or head into the system. We designed and implemented two game prototypes that apply real-time face position information as intrinsic elements of gameplay to enhance game experience. The first prototype augmented a typical motion-detection-based game. Face information was designed to enhance the sense of presence and role-playing. In the second prototype, face tracking is applied as a new axis of control in a First Person Shooter (FPS) game.Although Face detection and tracking technology has started utilizing in game scenarios, there was little systematic research on how user experience is leveraged by applying face information to video games. The results of our user tests on comparing camera-based video games with and without face tracking demonstrated that using face position information can effectively enhance presence and role-playing. In addition, an intuitive control that augmented by face-tracking in the FPS game also got positive feedbacks from the test."
    },
    {
        "title": "Direct pointer: direct manipulation for large-display interaction using handheld cameras",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Selecting and tracking",
        "data": "April 2006",
        "authors": [
            "Hao Jiang",
            "Eyal Ofek",
            "Neema Moraveji",
            "Yuanchun Shi"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124937",
        "citation": "24",
        "abstract": "This paper describes the design and evaluation of a technique, Direct Pointer, that enables users to interact intuitively with large displays using cameras equipped on handheld devices, such as mobile phones and personal digital assistant (PDA). In contrast to many existing interaction methods that attempt to address the same problem, ours offers direct manipulation of the pointer position with continuous visual feedback. The primary advantage of this technique is that it only requires equipment that is readily available: an electronic display, a handheld digital camera, and a connection between the two. No special visual markers in the display content are needed, nor are fixed cameras pointing at the display. We evaluated the performance of Direct Pointer as an interaction product, showing that it performs as well as comparable techniques that require more sophisticated equipment."
    },
    {
        "title": "Interacting with communication appliances: an evaluation of two computer vision-based selection techniques",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Selecting and tracking",
        "data": "April 2006",
        "authors": [
            "Jacob Eisenstein",
            "Wendy E. Mackay"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124938",
        "citation": "6",
        "abstract": "Communication appliances, intended for home settings, require intuitive forms of interaction. Computer vision offers a potential solution, but is not yet sufficiently accurate.As interaction designers, we need to know more than the absolute accuracy of such techniques: we must also be able to compare how they will work in our design settings, especially if we allow users to collaborate in the interpretation of their actions. We conducted a 2x4 within-subjects experiment to compare two interaction techniques based on computer vision: motion sensing, with EyeToy®-like feedback, and object tracking. Both techniques were 100% accurate with 2 or 5 choices. With 21 choices, object-tracking had significantly fewer errors and took less time for an accurate selection. Participants' subjective preferences were divided equally between the two techniques. This study compares these techniques as they would be used in real-world applications, with integrated user feedback, allowing interface designers to choose the one that best suits the specific user requirements for their particular application."
    },
    {
        "title": "Attention funnel: omnidirectional 3D cursor for mobile augmented reality platforms",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Selecting and tracking",
        "data": "April 2006",
        "authors": [
            "Frank Biocca",
            "Arthur Tang",
            "Charles Owen",
            "Fan Xiao"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124939",
        "citation": "110",
        "abstract": "The attention funnel is a general purpose AR interface technique that interactively guides the attention of a user to any object, person, or place in space. The technique utilizes dynamic perceptual affordances to draw user attention \"down\" the funnel to the target location. Attention funnel can be used to cue objects completely out of sight including objects behind the user, or occluded by other objects or walls.An experiment evaluating user performance with the attention funnel and other conventional AR attention directing techniques found that the attention funnel increased the consistency of the user's search by 65%, increased search speed by 22%, and decreased mental workload by 18%. The attention funnel has potential applicability as a general 3D cursor or cue in a wide array of spatially enabled mobile and AR systems, and for applications where systems can support users in visual search, object awareness, and emergency warning in indoor and outdoor spaces."
    },
    {
        "title": "Feeling what you hear: tactile feedback for navigation of audio graphs",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disabilities",
        "data": "April 2006",
        "authors": [
            "Steven Wall",
            "Stephen Brewster"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124941",
        "citation": "79",
        "abstract": "Access to digitally stored numerical data is currently very limited for sight impaired people. Graphs and visualizations are often used to analyze relationships between numerical data, but the current methods of accessing them are highly visually mediated. Representing data using audio feedback is a common method of making data more accessible, but methods of navigating and accessing the data are often serial in nature and laborious. Tactile or haptic displays could be used to provide additional feedback to support a point-and-click type interaction for the visually impaired. A requirements capture conducted with sight impaired computer users produced a review of current accessibility technologies, and guidelines were extracted for using tactile feedback to aid navigation. The results of a qualitative evaluation with a prototype interface are also presented. Providing an absolute position input device and tactile feedback allowed the users to explore the graph using tactile and proprioceptive cues in a manner analogous to point-and-click techniques."
    },
    {
        "title": "Remote usability evaluations With disabled people",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disabilities",
        "data": "April 2006",
        "authors": [
            "Helen Petrie",
            "Fraser Hamilton",
            "Neil King",
            "Pete Pavan"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124942",
        "citation": "109",
        "abstract": "Finding participants for evaluations with specific demographics can be a problem for usability and user experience specialists. In particular, finding participants with disabilities is especially problematic, yet testing with disabled people is becoming increasingly important. Two case studies are presented that explore using asynchronous remote evaluation techniques with disabled participants. These show that while quantitative data are comparable, the amount and richness of qualitative data are not likely to be comparable. The implications for formative and summative evaluations are discussed and a set of principles for local and remote evaluations with disabled users is presented."
    },
    {
        "title": "Desperately seeking simplicity: how young adults with cognitive disabilities and their families adopt assistive technologies",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Disabilities",
        "data": "April 2006",
        "authors": [
            "Melissa Dawe"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124943",
        "citation": "160",
        "abstract": "A surprisingly high percentage of assistive technology devices (35% or more) are purchased, but not successfully adopted. Through semi-structured interviews with a dozen families, we have come to understand the role technology plays in the lives of families who have a young adult with cognitive disabilities, and how families find, acquire, and use these technologies. This study addresses gaps in existing research and informs future efforts in assistive technology design. Design implications include the importance of simplicity not only in technology function but in configuration, documentation, maintenance, and upgrade or replacement; as well as the need for designers to use methods that consider the multiple individuals and stages involved in the technology adoption process."
    },
    {
        "title": "Can a virtual cat persuade you?: the role of gender and realism in speaker persuasiveness",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Beliefs and affect",
        "data": "April 2006",
        "authors": [
            "Catherine Zanbaka",
            "Paula Goolkasian",
            "Larry Hodges"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124945",
        "citation": "79",
        "abstract": "This study examines the roles of gender and visual realism in the persuasiveness of speakers. Participants were presented with a persuasive passage delivered by a male or female person, virtual human, or virtual character. They were then assessed on attitude change and their ratings of the argument, message, and speaker. The results indicated that the virtual speakers were as effective at changing attitudes as real people. Male participants were more persuaded when the speaker was female than when the speaker was male, whereas female participants were more persuaded when the speaker was male than when the speaker was female. Cross gender interactions occurred across all conditions, suggesting that some of the gender stereotypes that occur with people may carry over to interaction with virtual characters. Ratings of the perceptions of the speaker were more favorable for virtual speakers than for human speakers. We discuss the application of these findings in the design of persuasive human computer interfaces."
    },
    {
        "title": "The sensual evaluation instrument: developing an affective evaluation tool",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Beliefs and affect",
        "data": "April 2006",
        "authors": [
            "Katherine Isbister",
            "Kristina Höök",
            "Michael Sharp",
            "Jarmo Laaksolahti"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124946",
        "citation": "110",
        "abstract": "In this paper we describe the development and initial testing of a tool for self-assessment of affect while interacting with computer systems: the Sensual Evaluation Instrument. We discuss our research approach within the context of existing affective and HCI theory, and describe stages of evolution of the tool, and initial testing of its effectiveness."
    },
    {
        "title": "Listening to your inner voices: investigating means for voice notifications",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Beliefs and affect",
        "data": "April 2006",
        "authors": [
            "Saurabh Bhatia",
            "Scott McCrickard"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124947",
        "citation": "4",
        "abstract": "Our research investigates notification qualities of different types of voices, moving toward interfaces that support optimal allocation of attention to maximize system utility. We conducted an experiment to determine the interruption, reaction, and comprehension values of three different voice categories: the user's voice, a familiar voice, and an unfamiliar voice. Initial testing showed significant and impactful results: unfamiliar voices are the least interruptive, and a user reacts most quickly to one's own voice. Motivated by these findings, we report on the development and deployment of a notification system that exploits the differences in familiarity of a voice."
    },
    {
        "title": "Adaptive language behavior in HCI: how expectations and beliefs about a system affect users' word choice",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Beliefs and affect",
        "data": "April 2006",
        "authors": [
            "Jamie Pearson",
            "Jiang Hu",
            "Holly P. Branigan",
            "Martin J. Pickering",
            "Clifford I. Nass"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124948",
        "citation": "46",
        "abstract": "People display adaptive language behaviors in face-to-face conversations, but will computer users do the same during HCI? We report an experiment (N=20) demonstrating that users' use of language (in terms of lexical choice) is influenced by their beliefs and expectations about a system: When users believe that the system is unsophisticated and restricted in capability, they adapt their language to match the system's language more than when they believe the system is relatively sophisticated and capable. Moreover, this tendency is based entirely on users' expectations about the system; it is unaffected by the actual behavior that the system exhibits. Our results demonstrate that interface design engenders particular beliefs in users about a system's capabilities, and that these beliefs can determine the extent to which users adapt to the system. We argue that such effects can be leveraged to improve the quality and effectiveness of human-computer interactions."
    },
    {
        "title": "Collaborative coupling over tabletop displays",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gestures and visualizations",
        "data": "April 2006",
        "authors": [
            "Anthony Tang",
            "Melanie Tory",
            "Barry Po",
            "Petra Neumann",
            "Sheelagh Carpendale"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124950",
        "citation": "212",
        "abstract": "Designing collaborative interfaces for tabletops remains difficult because we do not fully understand how groups coordinate their actions when working collaboratively over tables. We present two observational studies of pairs completing independent and shared tasks that investigate collaborative coupling, or the manner in which collaborators are involved and occupied with each other's work. Our results indicate that individuals frequently and fluidly engage and disengage with group activity through several distinct, recognizable states with unique characteristics. We describe these states and explore the consequences of these states for tabletop interface design."
    },
    {
        "title": "Comparing remote gesture technologies for supporting collaborative physical tasks",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gestures and visualizations",
        "data": "April 2006",
        "authors": [
            "David Kirk",
            "Danae Stanton Fraser"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124951",
        "citation": "104",
        "abstract": "The design of remote gesturing technologies is an area of growing interest. Current technologies have taken differing approaches to the representation of remote gesture. It is not clear which approach has the most benefit to task performance. This study therefore compared performance in a collaborative physical (assembly) task using remote gesture systems constructed with combinations of three different gesture formats (unmediated hands only, hands and sketch and digital sketch only) and two different gesture output locations (direct projection into a worker's task space or on an external monitor). Results indicated that gesturing with an unmediated representation of the hands leads to faster performance with no loss of accuracy. Comparison of gesture output locations did not find a significant difference between projecting gestures and presenting them on external monitors. These results are discussed in relation to theories of conversational grounding and the design of technologies from a 'mixed ecologies' perspective."
    },
    {
        "title": "Cooperative gestures: multi-user gestural interactions for co-located groupware",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Gestures and visualizations",
        "data": "April 2006",
        "authors": [
            "Meredith Ringel Morris",
            "Anqi Huang",
            "Andreas Paepcke",
            "Terry Winograd"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124952",
        "citation": "196",
        "abstract": "Multi-user, touch-sensing input devices create opportunities for the use of cooperative gestures -- multi-user gestural interactions for single display groupware. Cooperative gestures are interactions where the system interprets the gestures of more than one user as contributing to a single, combined command. Cooperative gestures can be used to enhance users' sense of teamwork, increase awareness of important system events, facilitate reachability and access control on large, shared displays, or add a unique touch to an entertainment-oriented activity. This paper discusses motivating scenarios for the use of cooperative gesturing and describes some initial experiences with CollabDraw, a system for collaborative art and photo manipulation. We identify design issues relevant to cooperative gesturing interfaces, and present a preliminary design framework. We conclude by identifying directions for future research on cooperative gesturing interaction techniques."
    },
    {
        "title": "Collective creation and sense-making of mobile media",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 3",
        "data": "April 2006",
        "authors": [
            "Antti Salovaara",
            "Giulio Jacucci",
            "Antti Oulasvirta",
            "Timo Saari",
            "Pekka Kanerva",
            "Esko Kurvinen",
            "Sauli Tiitta"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124954",
        "citation": "43",
        "abstract": "Traditionally, mobile media sharing and messaging has been studied from the perspective of an individual author making media available to other users. With the aim of supporting spectator groups at large-scale events, we developed a messaging application for camera phones with the idea of collectively created albums called Media Stories. The field trial at a rally competition pointed out the collective and participative practices involved in the creation and sense-making of media, challenging the view of individual authorship. Members contributed actively to producing chains of messages in Media Stories, with more than half of the members as authors on average in each story. Observations indicate the centrality of collocated viewing and creation in the use of media. Design implications include providing a \"\"common space\"\" and possibilities of creating collective objects, adding features that enrich collocated collective use, and supporting the active construction of awareness and social presence through the created media."
    },
    {
        "title": "Watching the cars go round and round: designing for active spectating",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 3",
        "data": "April 2006",
        "authors": [
            "Mattias Esbjörnsson",
            "Barry Brown",
            "Oskar Juhlin",
            "Daniel Normark",
            "Mattias Östergren",
            "Eric Laurier"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124955",
        "citation": "28",
        "abstract": "Spectating at sport events is a common and popular leisure activity worldwide. Recently spectating has also become a topic of interest to CHI, particularly the design of technology for both performers and audiences. In this paper we describe an in-depth study of spectating, drawn from fieldwork of outdoor car rallies in the UK and Sweden. We describe three findings with relevance to design: the viewing paradox of spectating, active spectating and the role of sociability. We describe the MySplitTime prototype which address these issues while retaining the active sociable nature of the spectating experience."
    },
    {
        "title": "Ethnography in the kindergarten: examining children's play experiences",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 3",
        "data": "April 2006",
        "authors": [
            "Peta Wyeth"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124956",
        "citation": "21",
        "abstract": "This paper describes an ethnographic study completed within a kindergarten environment with the view of gaining insights into the development of new technology for young children. Ethnography within HCI has primarily focused on studies of work practices. This project explored the effectiveness of ethnography in supporting the design of playful technology for a constantly changing, creative, and (sometimes) messy environment. The study was effective in drawing out patterns in observations and as such provides useful suggestions for the development of technology for kindergarten settings."
    },
    {
        "title": "Robot-human interaction with an anthropomorphic percussionist",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Social computing 3",
        "data": "April 2006",
        "authors": [
            "Gil Weinberg",
            "Scott Driscoll"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124957",
        "citation": "35",
        "abstract": "The paper presents our approach for human-machine interaction with an anthropomorphic mechanical percussionist that can listen to live players, analyze perceptual musical aspects in real-time, and use the product of this analysis to play along in a collaborative manner. Our robot, named Haile, is designed to combine the benefits of computational power, perceptual modeling, and algorithmic music with the richness, visual interactivity, and expression of acoustic playing. We believe that when interacting with live players, Haile can facilitate a musical experience that is not possible by any other means, inspiring users to collaborate with it in novel and expressive manners. Haile can, therefore, serve a test-bed for novel forms of musical human-machine interaction, bringing perceptual aspects of computer music into the physical world both visually and acoustically."
    },
    {
        "title": "Breaking the fidelity barrier: an examination of our current characterization of prototypes and an example of a mixed-fidelity success",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability methods",
        "data": "April 2006",
        "authors": [
            "Michael McCurdy",
            "Christopher Connors",
            "Guy Pyrzak",
            "Bob Kanefsky",
            "Alonso Vera"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124959",
        "citation": "99",
        "abstract": "This paper presents a summary of the space of commonly-used HCI prototyping methods (low-fidelity to high-fidelity) and asserts that with a better understanding of this space, HCI practitioners will be better equipped to direct scarce prototyping resources toward an effort likely to yield specific results. It presents a set of five dimensions along which prototypes can be planned and characterized. The paper then describes an analysis of this space performed by members of the NASA Ames Human-Computer Interaction Group when considering prototyping approaches for a new set of tools for Mars mission planning and scheduling tools. A description is presented of a prototype that demonstrates design solutions that would have been particularly difficult to test given conventional low- or mid- fidelity prototyping methods. The prototype created was \"mixed-fidelity,\" that is, high-fidelity on some dimensions and low-fidelity on others. The prototype is compared to a preexisting tool being redesigned and to a tool that has been developed using the prototype. Experimental data are presented that show the prototype to be a good predictor of eventual user performance with the final application. Given the relative cost of developing prototypes, it is critical to better characterize the space of fidelity in order to more precisely allocate design and development resources."
    },
    {
        "title": "Getting the right design and the design right",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability methods",
        "data": "April 2006",
        "authors": [
            "Maryam Tohidi",
            "William Buxton",
            "Ronald Baecker",
            "Abigail Sellen"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124960",
        "citation": "132",
        "abstract": "We present a study comparing usability testing of a single interface versus three functionally equivalent but stylistically distinct designs. We found that when presented with a single design, users give significantly higher ratings and were more reluctant to criticize than when presented with the same design in a group of three. Our results imply that by presenting users with alternative design solutions, subjective ratings are less prone to inflation and give rise to more and stronger criticisms when appropriate. Contrary to our expectations, our results also suggest that usability testing by itself, even when multiple designs are presented, is not an effective vehicle for soliciting constructive suggestions about how to improve the design from end users. It is a means to identify problems, not provide solutions."
    },
    {
        "title": "The validity of the stimulated retrospective think-aloud method as measured by eye tracking",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Usability methods",
        "data": "April 2006",
        "authors": [
            "Zhiwei Guan",
            "Shirley Lee",
            "Elisabeth Cuddihy",
            "Judith Ramey"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124961",
        "citation": "103",
        "abstract": "Retrospective Think aloud (RTA) is a usability method that collects the verbalization of a user's performance after the performance is over. There has been little work done to investigate the validity and reliability of RTA. This paper reports on an experiment investigating these issues with a form of the method called stimulated RTA. By comparing subjects' verbalizations with their eye movements, we support the validity and reliability of stimulated RTA: the method provides a valid account of what people attended to in completing tasks, it has a low risk of introducing fabrications, and its validity isn't affected by task complexity. More detailed analysis of RTA shows that it also provides additional information about user's inferences and strategies in completing tasks. The findings of this study provide valuable support for usability practitioners to use RTA and to trust the users' performance information collected by this method in a usability study."
    },
    {
        "title": "Precise selection techniques for multi-touch screens",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with large surfaces",
        "data": "April 2006",
        "authors": [
            "Hrvoje Benko",
            "Andrew D. Wilson",
            "Patrick Baudisch"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124963",
        "citation": "274",
        "abstract": "The size of human fingers and the lack of sensing precision can make precise touch screen interactions difficult. We present a set of five techniques, called Dual Finger Selections, which leverage the recent development of multi-touch sensitive displays to help users select very small targets. These techniques facilitate pixel-accurate targeting by adjusting the control-display ratio with a secondary finger while the primary finger controls the movement of the cursor. We also contribute a \"clicking\" technique, called SimPress, which reduces motion errors during clicking and allows us to simulate a hover state on devices unable to sense proximity. We implemented our techniques on a multi-touch tabletop prototype that offers computer vision-based tracking. In our formal user study, we tested the performance of our three most promising techniques (Stretch, X-Menu, and Slider) against our baseline (Offset), on four target sizes and three input noise levels. All three chosen techniques outperformed the control technique in terms of error rate reduction and were preferred by our participants, with Stretch being the overall performance and preference winner."
    },
    {
        "title": "TeamTag: exploring centralized versus replicated controls for co-located tabletop groupware",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with large surfaces",
        "data": "April 2006",
        "authors": [
            "Meredith Ringel Morris",
            "Andreas Paepcke",
            "Terry Winograd",
            "Jeannie Stamberger"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124964",
        "citation": "53",
        "abstract": "We explore how the placement of control widgets (such as menus) affects collaboration and usability for co-located tabletop groupware applications. We evaluated two design alternatives: a centralized set of controls shared by all users, and separate per-user controls replicated around the borders of the shared tabletop. We conducted this evaluation in the context of TeamTag, a system for collective annotation of digital photos. Our comparison of the two design alternatives found that users preferred replicated over shared controls. We discuss the cause of this preference, and also present data on the impact of these interface design variants on collaboration, as well as the role that orientation, co-touching, and the use of different regions of the table played in shaping users' behavior and preferences."
    },
    {
        "title": "Keepin' it real: pushing the desktop metaphor with physics, piles and the pen",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Interacting with large surfaces",
        "data": "April 2006",
        "authors": [
            "Anand Agarawala",
            "Ravin Balakrishnan"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124965",
        "citation": "170",
        "abstract": "We explore making virtual desktops behave in a more physically realistic manner by adding physics simulation and using piling instead of filing as the fundamental organizational structure. Objects can be casually dragged and tossed around, influenced by physical characteristics such as friction and mass, much like we would manipulate lightweight objects in the real world. We present a prototype, called BumpTop, that coherently integrates a variety of interaction and visualization techniques optimized for pen input we have developed to support this new style of desktop organization."
    },
    {
        "title": "Synchronous broadcast messaging: the use of ICT",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Computer-mediated communication",
        "data": "April 2006",
        "authors": [
            "Justin D. Weisz",
            "Thomas Erickson",
            "Wendy A. Kellogg"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124967",
        "citation": "17",
        "abstract": "IBM Community Tools (ICT) is a synchronous broadcast messaging system in use by a very large, globally distributed organization. ICT is interesting for a number of reasons, including its scale of use (thousands of users per day), its usage model of employing large scale broadcast to strangers to initiate small group interactions, and the fact that it is a synchronous system used across multiple time zones. In this paper we characterize the use of ICT in its context, examine the activities for which it is used, the motivations of its users, and the values they derive from it. We also explore problems with the system, and look at the social and technical ways in which users deal with them."
    },
    {
        "title": "The impact of delayed visual feedback on collaborative performance",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Computer-mediated communication",
        "data": "April 2006",
        "authors": [
            "Darren Gergle",
            "Robert E. Kraut",
            "Susan R. Fussell"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124968",
        "citation": "27",
        "abstract": "When pairs work together on a physical task, seeing a common workspace benefits their performance and transforms their use of language. Previous results have demonstrated that visual information helps collaborative pairs to understand the current state of their task, ground their conversations, and communicate efficiently. However, collaborative technologies often impinge on the visual information needed to support successful collaboration. One example of this is the introduction of delayed visual feedback in a collaborative environment. We present results from two studies that detail the form of the function that describes the relationship between visual delay and collaborative task performance. The first study precisely demonstrates how a range of visual delays differentially impact performance and the collaborative strategies employed. The second study describes how parameters of the task, such as the dynamics of the visual environment, reduce the amount of delay that can be tolerated."
    },
    {
        "title": "Collocation blindness in partially distributed groups: is there a downside to being collocated?",
        "conferenceTitle": "CHI '06: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "Session": "SESSION: Computer-mediated communication",
        "data": "April 2006",
        "authors": [
            "Nathan Bos",
            "Judith Olson",
            "Ning Nan",
            "N Sadat Shami",
            "Susannah Hoch",
            "Erik Johnston"
        ],
        "DOI": "https://doi.org/10.1145/1124772.1124969",
        "citation": "23",
        "abstract": "Under what circumstances might a group member be better off as a long-distance participant rather than collocated? We ran a set of experiments to study how partially-distributed groups collaborate when skill sets are unequally distributed. Partially distributed groups are those where some collaborators work together in the same space (collocated) and some work remotely using computer-mediated communications. Previous experiments had shown that these groups tend to form semi-autonomous 'in-groups'. In this set of experiments the configuration was changed so that some player skills were located only in the collocated space, and some were located only remotely, creating local surplus of some skills and local scarcity of others in the collocated room. Players whose skills were locally in surplus performed significantly worse. They experienced 'collocation blindness' and failed to pay enough attention to collaborators outside of the room. In contrast, the remote players whose skills were scarce inside the collocated room did particularly well because they charged a high price for their skills."
    }
]